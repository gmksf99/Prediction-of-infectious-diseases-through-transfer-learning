{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras import Input, Model, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_step(data, ts, lag, duration):\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    \n",
    "    for i in range(len(data)-ts-(lag-1)-(duration-1)):\n",
    "        dataX.append(data[i:i+ts])\n",
    "        dataY.append(data[i+ts+lag-1:i+ts+lag-1+duration])\n",
    "        \n",
    "    dataX = np.array(dataX)\n",
    "    dataY = np.array(dataY)  \n",
    "\n",
    "    return dataX, dataY\n",
    "\n",
    "def normalization(data_train, data_val, data_test):\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(data_train)\n",
    "    \n",
    "    n_data_train = scaler.transform(data_train)\n",
    "    n_data_val = scaler.transform(data_val)\n",
    "    n_data_test = scaler.transform(data_test)\n",
    "    \n",
    "    return n_data_train, n_data_val, n_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv'\n",
    "\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>...</th>\n",
       "      <th>3/1/21</th>\n",
       "      <th>3/2/21</th>\n",
       "      <th>3/3/21</th>\n",
       "      <th>3/4/21</th>\n",
       "      <th>3/5/21</th>\n",
       "      <th>3/6/21</th>\n",
       "      <th>3/7/21</th>\n",
       "      <th>3/8/21</th>\n",
       "      <th>3/9/21</th>\n",
       "      <th>3/10/21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>33.939110</td>\n",
       "      <td>67.709953</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>55733</td>\n",
       "      <td>55759</td>\n",
       "      <td>55770</td>\n",
       "      <td>55775</td>\n",
       "      <td>55827</td>\n",
       "      <td>55840</td>\n",
       "      <td>55847</td>\n",
       "      <td>55876</td>\n",
       "      <td>55876</td>\n",
       "      <td>55894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Albania</td>\n",
       "      <td>41.153300</td>\n",
       "      <td>20.168300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>107931</td>\n",
       "      <td>108823</td>\n",
       "      <td>109674</td>\n",
       "      <td>110521</td>\n",
       "      <td>111301</td>\n",
       "      <td>112078</td>\n",
       "      <td>112897</td>\n",
       "      <td>113580</td>\n",
       "      <td>114209</td>\n",
       "      <td>114840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Algeria</td>\n",
       "      <td>28.033900</td>\n",
       "      <td>1.659600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>113255</td>\n",
       "      <td>113430</td>\n",
       "      <td>113593</td>\n",
       "      <td>113761</td>\n",
       "      <td>113948</td>\n",
       "      <td>114104</td>\n",
       "      <td>114234</td>\n",
       "      <td>114382</td>\n",
       "      <td>114543</td>\n",
       "      <td>114681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Andorra</td>\n",
       "      <td>42.506300</td>\n",
       "      <td>1.521800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10889</td>\n",
       "      <td>10908</td>\n",
       "      <td>10948</td>\n",
       "      <td>10976</td>\n",
       "      <td>10998</td>\n",
       "      <td>11019</td>\n",
       "      <td>11042</td>\n",
       "      <td>11069</td>\n",
       "      <td>11089</td>\n",
       "      <td>11130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Angola</td>\n",
       "      <td>-11.202700</td>\n",
       "      <td>17.873900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20854</td>\n",
       "      <td>20882</td>\n",
       "      <td>20923</td>\n",
       "      <td>20981</td>\n",
       "      <td>21026</td>\n",
       "      <td>21055</td>\n",
       "      <td>21086</td>\n",
       "      <td>21108</td>\n",
       "      <td>21114</td>\n",
       "      <td>21161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Vietnam</td>\n",
       "      <td>14.058324</td>\n",
       "      <td>108.277199</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2448</td>\n",
       "      <td>2475</td>\n",
       "      <td>2482</td>\n",
       "      <td>2488</td>\n",
       "      <td>2494</td>\n",
       "      <td>2501</td>\n",
       "      <td>2512</td>\n",
       "      <td>2524</td>\n",
       "      <td>2526</td>\n",
       "      <td>2529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>West Bank and Gaza</td>\n",
       "      <td>31.952200</td>\n",
       "      <td>35.233200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>185336</td>\n",
       "      <td>187309</td>\n",
       "      <td>189326</td>\n",
       "      <td>191203</td>\n",
       "      <td>193029</td>\n",
       "      <td>194548</td>\n",
       "      <td>196812</td>\n",
       "      <td>198554</td>\n",
       "      <td>200382</td>\n",
       "      <td>202378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yemen</td>\n",
       "      <td>15.552727</td>\n",
       "      <td>48.516388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2310</td>\n",
       "      <td>2342</td>\n",
       "      <td>2363</td>\n",
       "      <td>2375</td>\n",
       "      <td>2411</td>\n",
       "      <td>2444</td>\n",
       "      <td>2473</td>\n",
       "      <td>2545</td>\n",
       "      <td>2586</td>\n",
       "      <td>2627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zambia</td>\n",
       "      <td>-13.133897</td>\n",
       "      <td>27.849332</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>79002</td>\n",
       "      <td>79557</td>\n",
       "      <td>80090</td>\n",
       "      <td>80687</td>\n",
       "      <td>81341</td>\n",
       "      <td>82011</td>\n",
       "      <td>82421</td>\n",
       "      <td>82655</td>\n",
       "      <td>82897</td>\n",
       "      <td>83333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zimbabwe</td>\n",
       "      <td>-19.015438</td>\n",
       "      <td>29.154857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36115</td>\n",
       "      <td>36148</td>\n",
       "      <td>36179</td>\n",
       "      <td>36223</td>\n",
       "      <td>36248</td>\n",
       "      <td>36260</td>\n",
       "      <td>36271</td>\n",
       "      <td>36289</td>\n",
       "      <td>36321</td>\n",
       "      <td>36341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>274 rows × 418 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Province/State      Country/Region        Lat        Long  1/22/20  \\\n",
       "0              NaN         Afghanistan  33.939110   67.709953        0   \n",
       "1              NaN             Albania  41.153300   20.168300        0   \n",
       "2              NaN             Algeria  28.033900    1.659600        0   \n",
       "3              NaN             Andorra  42.506300    1.521800        0   \n",
       "4              NaN              Angola -11.202700   17.873900        0   \n",
       "..             ...                 ...        ...         ...      ...   \n",
       "269            NaN             Vietnam  14.058324  108.277199        0   \n",
       "270            NaN  West Bank and Gaza  31.952200   35.233200        0   \n",
       "271            NaN               Yemen  15.552727   48.516388        0   \n",
       "272            NaN              Zambia -13.133897   27.849332        0   \n",
       "273            NaN            Zimbabwe -19.015438   29.154857        0   \n",
       "\n",
       "     1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  ...  3/1/21  3/2/21  3/3/21  \\\n",
       "0          0        0        0        0        0  ...   55733   55759   55770   \n",
       "1          0        0        0        0        0  ...  107931  108823  109674   \n",
       "2          0        0        0        0        0  ...  113255  113430  113593   \n",
       "3          0        0        0        0        0  ...   10889   10908   10948   \n",
       "4          0        0        0        0        0  ...   20854   20882   20923   \n",
       "..       ...      ...      ...      ...      ...  ...     ...     ...     ...   \n",
       "269        2        2        2        2        2  ...    2448    2475    2482   \n",
       "270        0        0        0        0        0  ...  185336  187309  189326   \n",
       "271        0        0        0        0        0  ...    2310    2342    2363   \n",
       "272        0        0        0        0        0  ...   79002   79557   80090   \n",
       "273        0        0        0        0        0  ...   36115   36148   36179   \n",
       "\n",
       "     3/4/21  3/5/21  3/6/21  3/7/21  3/8/21  3/9/21  3/10/21  \n",
       "0     55775   55827   55840   55847   55876   55876    55894  \n",
       "1    110521  111301  112078  112897  113580  114209   114840  \n",
       "2    113761  113948  114104  114234  114382  114543   114681  \n",
       "3     10976   10998   11019   11042   11069   11089    11130  \n",
       "4     20981   21026   21055   21086   21108   21114    21161  \n",
       "..      ...     ...     ...     ...     ...     ...      ...  \n",
       "269    2488    2494    2501    2512    2524    2526     2529  \n",
       "270  191203  193029  194548  196812  198554  200382   202378  \n",
       "271    2375    2411    2444    2473    2545    2586     2627  \n",
       "272   80687   81341   82011   82421   82655   82897    83333  \n",
       "273   36223   36248   36260   36271   36289   36321    36341  \n",
       "\n",
       "[274 rows x 418 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/pandas/core/frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# 한국의 누적 확진자수를 일일 신규 확진자수로 변경\n",
    "\n",
    "df = df[df['Country/Region'] == 'Korea, South']\n",
    "df.drop(['Province/State', 'Country/Region', 'Lat', 'Long'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1/22/20</th>\n",
       "      <th>1/23/20</th>\n",
       "      <th>1/24/20</th>\n",
       "      <th>1/25/20</th>\n",
       "      <th>1/26/20</th>\n",
       "      <th>1/27/20</th>\n",
       "      <th>1/28/20</th>\n",
       "      <th>1/29/20</th>\n",
       "      <th>1/30/20</th>\n",
       "      <th>1/31/20</th>\n",
       "      <th>...</th>\n",
       "      <th>3/1/21</th>\n",
       "      <th>3/2/21</th>\n",
       "      <th>3/3/21</th>\n",
       "      <th>3/4/21</th>\n",
       "      <th>3/5/21</th>\n",
       "      <th>3/6/21</th>\n",
       "      <th>3/7/21</th>\n",
       "      <th>3/8/21</th>\n",
       "      <th>3/9/21</th>\n",
       "      <th>3/10/21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>90372</td>\n",
       "      <td>90816</td>\n",
       "      <td>91240</td>\n",
       "      <td>91638</td>\n",
       "      <td>92055</td>\n",
       "      <td>92471</td>\n",
       "      <td>92817</td>\n",
       "      <td>93263</td>\n",
       "      <td>93733</td>\n",
       "      <td>94198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 414 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1/22/20  1/23/20  1/24/20  1/25/20  1/26/20  1/27/20  1/28/20  1/29/20  \\\n",
       "158        1        1        2        2        3        4        4        4   \n",
       "\n",
       "     1/30/20  1/31/20  ...  3/1/21  3/2/21  3/3/21  3/4/21  3/5/21  3/6/21  \\\n",
       "158        4       11  ...   90372   90816   91240   91638   92055   92471   \n",
       "\n",
       "     3/7/21  3/8/21  3/9/21  3/10/21  \n",
       "158   92817   93263   93733    94198  \n",
       "\n",
       "[1 rows x 414 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.T\n",
    "df.columns = ['Confirmed']\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "data = []\n",
    "for index, value in enumerate(df['Confirmed']):\n",
    "    if index == 0:\n",
    "        data.append(value)\n",
    "    else:\n",
    "        data.append(value - df['Confirmed'].iloc[index-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 73,\n",
       " 100,\n",
       " 229,\n",
       " 169,\n",
       " 231,\n",
       " 144,\n",
       " 284,\n",
       " 505,\n",
       " 571,\n",
       " 813,\n",
       " 586,\n",
       " 599,\n",
       " 851,\n",
       " 435,\n",
       " 467,\n",
       " 505,\n",
       " 448,\n",
       " 273,\n",
       " 164,\n",
       " 35,\n",
       " 242,\n",
       " 114,\n",
       " 110,\n",
       " 107,\n",
       " 76,\n",
       " 74,\n",
       " 84,\n",
       " 93,\n",
       " 152,\n",
       " 87,\n",
       " 147,\n",
       " 162,\n",
       " 0,\n",
       " 76,\n",
       " 100,\n",
       " 104,\n",
       " 91,\n",
       " 146,\n",
       " 105,\n",
       " 78,\n",
       " 125,\n",
       " 101,\n",
       " 89,\n",
       " 86,\n",
       " 94,\n",
       " 81,\n",
       " 47,\n",
       " 47,\n",
       " 53,\n",
       " 39,\n",
       " 27,\n",
       " 30,\n",
       " 32,\n",
       " 25,\n",
       " 27,\n",
       " 27,\n",
       " 22,\n",
       " 22,\n",
       " 18,\n",
       " 8,\n",
       " 13,\n",
       " 9,\n",
       " 11,\n",
       " 14,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 14,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 13,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 12,\n",
       " 18,\n",
       " 34,\n",
       " 35,\n",
       " 27,\n",
       " 26,\n",
       " 29,\n",
       " 27,\n",
       " 19,\n",
       " 13,\n",
       " 15,\n",
       " 13,\n",
       " 32,\n",
       " 12,\n",
       " 20,\n",
       " 23,\n",
       " 25,\n",
       " 16,\n",
       " 19,\n",
       " 40,\n",
       " 79,\n",
       " 58,\n",
       " 39,\n",
       " 27,\n",
       " 35,\n",
       " 38,\n",
       " 49,\n",
       " 39,\n",
       " 39,\n",
       " 51,\n",
       " 57,\n",
       " 38,\n",
       " 38,\n",
       " 50,\n",
       " 45,\n",
       " 56,\n",
       " 48,\n",
       " 34,\n",
       " 36,\n",
       " 34,\n",
       " 43,\n",
       " 59,\n",
       " 49,\n",
       " 67,\n",
       " 48,\n",
       " 17,\n",
       " 46,\n",
       " 51,\n",
       " 28,\n",
       " 39,\n",
       " 51,\n",
       " 62,\n",
       " 42,\n",
       " 43,\n",
       " 50,\n",
       " 54,\n",
       " 63,\n",
       " 63,\n",
       " 61,\n",
       " 46,\n",
       " 44,\n",
       " 63,\n",
       " 49,\n",
       " 45,\n",
       " 35,\n",
       " 44,\n",
       " 62,\n",
       " 33,\n",
       " 39,\n",
       " 61,\n",
       " 60,\n",
       " 39,\n",
       " 34,\n",
       " 26,\n",
       " 45,\n",
       " 63,\n",
       " 59,\n",
       " 41,\n",
       " 113,\n",
       " 58,\n",
       " 25,\n",
       " 28,\n",
       " 48,\n",
       " 18,\n",
       " 36,\n",
       " 31,\n",
       " 30,\n",
       " 23,\n",
       " 34,\n",
       " 33,\n",
       " 43,\n",
       " 20,\n",
       " 43,\n",
       " 36,\n",
       " 28,\n",
       " 34,\n",
       " 54,\n",
       " 56,\n",
       " 103,\n",
       " 166,\n",
       " 279,\n",
       " 197,\n",
       " 246,\n",
       " 297,\n",
       " 288,\n",
       " 324,\n",
       " 332,\n",
       " 397,\n",
       " 266,\n",
       " 280,\n",
       " 320,\n",
       " 441,\n",
       " 371,\n",
       " 323,\n",
       " 299,\n",
       " 248,\n",
       " 235,\n",
       " 267,\n",
       " 195,\n",
       " 198,\n",
       " 168,\n",
       " 167,\n",
       " 119,\n",
       " 136,\n",
       " 156,\n",
       " 155,\n",
       " 176,\n",
       " 136,\n",
       " 121,\n",
       " 109,\n",
       " 106,\n",
       " 113,\n",
       " 153,\n",
       " 126,\n",
       " 110,\n",
       " 82,\n",
       " 70,\n",
       " 61,\n",
       " 110,\n",
       " 125,\n",
       " 114,\n",
       " 61,\n",
       " 95,\n",
       " 50,\n",
       " 38,\n",
       " 113,\n",
       " 77,\n",
       " 63,\n",
       " 75,\n",
       " 64,\n",
       " 73,\n",
       " 75,\n",
       " 114,\n",
       " 69,\n",
       " 54,\n",
       " 72,\n",
       " 58,\n",
       " 97,\n",
       " 102,\n",
       " 84,\n",
       " 99,\n",
       " 47,\n",
       " 73,\n",
       " 91,\n",
       " 76,\n",
       " 58,\n",
       " 91,\n",
       " 119,\n",
       " 155,\n",
       " 77,\n",
       " 61,\n",
       " 119,\n",
       " 88,\n",
       " 103,\n",
       " 125,\n",
       " 114,\n",
       " 126,\n",
       " 124,\n",
       " 97,\n",
       " 75,\n",
       " 118,\n",
       " 125,\n",
       " 145,\n",
       " 89,\n",
       " 143,\n",
       " 126,\n",
       " 100,\n",
       " 146,\n",
       " 143,\n",
       " 191,\n",
       " 205,\n",
       " 208,\n",
       " 223,\n",
       " 229,\n",
       " 313,\n",
       " 343,\n",
       " 363,\n",
       " 386,\n",
       " 330,\n",
       " 271,\n",
       " 349,\n",
       " 382,\n",
       " 583,\n",
       " 569,\n",
       " 488,\n",
       " 449,\n",
       " 377,\n",
       " 451,\n",
       " 511,\n",
       " 540,\n",
       " 629,\n",
       " 583,\n",
       " 631,\n",
       " 615,\n",
       " 594,\n",
       " 677,\n",
       " 666,\n",
       " 688,\n",
       " 950,\n",
       " 1030,\n",
       " 718,\n",
       " 880,\n",
       " 1078,\n",
       " 1011,\n",
       " 1062,\n",
       " 1055,\n",
       " 1095,\n",
       " 926,\n",
       " 869,\n",
       " 1090,\n",
       " 983,\n",
       " 1237,\n",
       " 1132,\n",
       " 970,\n",
       " 808,\n",
       " 1045,\n",
       " 1048,\n",
       " 967,\n",
       " 1029,\n",
       " 824,\n",
       " 651,\n",
       " 1020,\n",
       " 715,\n",
       " 839,\n",
       " 868,\n",
       " 672,\n",
       " 641,\n",
       " 665,\n",
       " 450,\n",
       " 537,\n",
       " 561,\n",
       " 516,\n",
       " 513,\n",
       " 579,\n",
       " 520,\n",
       " 389,\n",
       " 386,\n",
       " 403,\n",
       " 400,\n",
       " 344,\n",
       " 430,\n",
       " 392,\n",
       " 437,\n",
       " 354,\n",
       " 554,\n",
       " 497,\n",
       " 469,\n",
       " 455,\n",
       " 355,\n",
       " 303,\n",
       " 336,\n",
       " 467,\n",
       " 451,\n",
       " 369,\n",
       " 393,\n",
       " 372,\n",
       " 289,\n",
       " 302,\n",
       " 443,\n",
       " 504,\n",
       " 403,\n",
       " 362,\n",
       " 326,\n",
       " 344,\n",
       " 456,\n",
       " 621,\n",
       " 621,\n",
       " 561,\n",
       " 446,\n",
       " 418,\n",
       " 332,\n",
       " 357,\n",
       " 439,\n",
       " 396,\n",
       " 406,\n",
       " 399,\n",
       " 355,\n",
       " 355,\n",
       " 341,\n",
       " 444,\n",
       " 424,\n",
       " 398,\n",
       " 417,\n",
       " 416,\n",
       " 346,\n",
       " 446,\n",
       " 470,\n",
       " 465]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_list = []\n",
    "for ts in range(3, 11, 1):\n",
    "    data_X, data_Y = time_step(data , ts, 1, 1)\n",
    "    \n",
    "    NUM_VAL = int(data_X.shape[0] * 0.8)\n",
    "    test_Y =data_Y[NUM_VAL:]\n",
    "    \n",
    "    std_list.append(test_Y.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 246 samples, validate on 82 samples\n",
      "Epoch 1/10000\n",
      "246/246 [==============================] - 85s 347ms/step - loss: 26733.6981 - val_loss: 163665.3893\n",
      "Epoch 2/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26700.9988 - val_loss: 163508.9535\n",
      "Epoch 3/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26646.1622 - val_loss: 163230.1480\n",
      "Epoch 4/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26548.5590 - val_loss: 162724.0250\n",
      "Epoch 5/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26378.9221 - val_loss: 161838.1940\n",
      "Epoch 6/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26096.2152 - val_loss: 160318.3155\n",
      "Epoch 7/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 25637.7499 - val_loss: 157990.5706\n",
      "Epoch 8/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 24993.8085 - val_loss: 154776.5458\n",
      "Epoch 9/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 24136.4043 - val_loss: 150493.5923\n",
      "Epoch 10/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 23044.0744 - val_loss: 144993.5304\n",
      "Epoch 11/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 21730.0118 - val_loss: 138317.7364\n",
      "Epoch 12/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 20255.2299 - val_loss: 130677.8171\n",
      "Epoch 13/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 18713.5504 - val_loss: 122415.5265\n",
      "Epoch 14/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 17212.9110 - val_loss: 113962.8583\n",
      "Epoch 15/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 15850.0039 - val_loss: 105747.5057\n",
      "Epoch 16/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 14685.5337 - val_loss: 98093.7894\n",
      "Epoch 17/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 13734.9546 - val_loss: 91215.1014\n",
      "Epoch 18/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 12985.9112 - val_loss: 85221.2824\n",
      "Epoch 19/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 12402.9568 - val_loss: 80089.3863\n",
      "Epoch 20/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11943.2478 - val_loss: 75723.0579\n",
      "Epoch 21/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11568.7567 - val_loss: 71996.3226\n",
      "Epoch 22/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11250.4181 - val_loss: 68782.8586\n",
      "Epoch 23/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10968.0742 - val_loss: 65970.7901\n",
      "Epoch 24/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10708.5088 - val_loss: 63468.5095\n",
      "Epoch 25/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10464.3414 - val_loss: 61198.2228\n",
      "Epoch 26/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10230.0753 - val_loss: 59111.3464\n",
      "Epoch 27/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10002.4356 - val_loss: 57165.1887\n",
      "Epoch 28/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9779.5622 - val_loss: 55326.8520\n",
      "Epoch 29/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9560.1565 - val_loss: 53574.1923\n",
      "Epoch 30/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9343.3157 - val_loss: 51889.8084\n",
      "Epoch 31/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9128.5553 - val_loss: 50260.3297\n",
      "Epoch 32/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8915.5420 - val_loss: 48675.2090\n",
      "Epoch 33/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8704.0968 - val_loss: 47127.0431\n",
      "Epoch 34/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8494.1273 - val_loss: 45610.1934\n",
      "Epoch 35/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8285.6056 - val_loss: 44121.0052\n",
      "Epoch 36/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8078.5361 - val_loss: 42656.8430\n",
      "Epoch 37/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7873.0574 - val_loss: 41215.1148\n",
      "Epoch 38/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7669.2454 - val_loss: 39795.6813\n",
      "Epoch 39/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7467.2489 - val_loss: 38397.8328\n",
      "Epoch 40/10000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 7267.3040 - val_loss: 37020.8599\n",
      "Epoch 41/10000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 7069.6075 - val_loss: 35665.5250\n",
      "Epoch 42/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6875.8042 - val_loss: 34329.0223\n",
      "Epoch 43/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6685.4322 - val_loss: 33018.0613\n",
      "Epoch 44/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6498.2776 - val_loss: 31734.2331\n",
      "Epoch 45/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6314.7335 - val_loss: 30477.5536\n",
      "Epoch 46/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6135.1760 - val_loss: 29249.0294\n",
      "Epoch 47/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5959.8249 - val_loss: 28050.8546\n",
      "Epoch 48/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5788.8639 - val_loss: 26884.4280\n",
      "Epoch 49/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5622.6358 - val_loss: 25749.8166\n",
      "Epoch 50/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5461.4235 - val_loss: 24649.0536\n",
      "Epoch 51/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5305.5198 - val_loss: 23582.8644\n",
      "Epoch 52/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5155.2733 - val_loss: 22552.3124\n",
      "Epoch 53/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5010.9511 - val_loss: 21557.9703\n",
      "Epoch 54/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4872.8162 - val_loss: 20601.1560\n",
      "Epoch 55/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4741.0732 - val_loss: 19682.8443\n",
      "Epoch 56/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4615.8879 - val_loss: 18803.8733\n",
      "Epoch 57/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4497.4280 - val_loss: 17964.6129\n",
      "Epoch 58/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4385.7970 - val_loss: 17165.4133\n",
      "Epoch 59/10000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 4282.3298 - val_loss: 16403.0066\n",
      "Epoch 60/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4187.0327 - val_loss: 15682.1899\n",
      "Epoch 61/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4099.3171 - val_loss: 15004.8332\n",
      "Epoch 62/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4018.2129 - val_loss: 14371.2234\n",
      "Epoch 63/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3943.4694 - val_loss: 13779.1098\n",
      "Epoch 64/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3874.9463 - val_loss: 13226.3463\n",
      "Epoch 65/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3812.4037 - val_loss: 12711.0053\n",
      "Epoch 66/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3756.0146 - val_loss: 12231.2176\n",
      "Epoch 67/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3705.0788 - val_loss: 11787.4081\n",
      "Epoch 68/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3659.0167 - val_loss: 11378.3099\n",
      "Epoch 69/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3617.4455 - val_loss: 11001.3712\n",
      "Epoch 70/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3580.0972 - val_loss: 10653.5949\n",
      "Epoch 71/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3546.7441 - val_loss: 10333.1530\n",
      "Epoch 72/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3517.1904 - val_loss: 10038.0658\n",
      "Epoch 73/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3490.9377 - val_loss: 9767.4225\n",
      "Epoch 74/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 1ms/step - loss: 3467.5986 - val_loss: 9519.5627\n",
      "Epoch 75/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3446.9031 - val_loss: 9292.5655\n",
      "Epoch 76/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3428.5672 - val_loss: 9084.8042\n",
      "Epoch 77/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3412.3346 - val_loss: 8894.8684\n",
      "Epoch 78/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3397.9661 - val_loss: 8721.4415\n",
      "Epoch 79/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3385.2424 - val_loss: 8563.0913\n",
      "Epoch 80/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3373.9750 - val_loss: 8418.3977\n",
      "Epoch 81/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3363.9811 - val_loss: 8286.4971\n",
      "Epoch 82/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3355.0993 - val_loss: 8166.1736\n",
      "Epoch 83/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3347.1829 - val_loss: 8056.4862\n",
      "Epoch 84/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3340.1162 - val_loss: 7956.1801\n",
      "Epoch 85/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3333.7558 - val_loss: 7864.8834\n",
      "Epoch 86/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3328.0142 - val_loss: 7781.6978\n",
      "Epoch 87/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3322.8032 - val_loss: 7705.8100\n",
      "Epoch 88/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3318.0453 - val_loss: 7636.6577\n",
      "Epoch 89/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3313.6726 - val_loss: 7573.6852\n",
      "Epoch 90/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3309.6277 - val_loss: 7516.2469\n",
      "Epoch 91/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3305.8606 - val_loss: 7463.9658\n",
      "Epoch 92/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3302.3255 - val_loss: 7416.0886\n",
      "Epoch 93/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3298.9826 - val_loss: 7372.5162\n",
      "Epoch 94/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3295.8048 - val_loss: 7332.7372\n",
      "Epoch 95/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3292.7671 - val_loss: 7296.4495\n",
      "Epoch 96/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3289.8483 - val_loss: 7263.3388\n",
      "Epoch 97/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3287.0354 - val_loss: 7233.1648\n",
      "Epoch 98/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3284.3099 - val_loss: 7205.4945\n",
      "Epoch 99/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3281.6594 - val_loss: 7179.9723\n",
      "Epoch 100/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3279.0707 - val_loss: 7156.5869\n",
      "Epoch 101/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3276.5309 - val_loss: 7134.8679\n",
      "Epoch 102/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3274.4945 - val_loss: 7117.4532\n",
      "Epoch 103/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3271.8660 - val_loss: 7093.9407\n",
      "Epoch 104/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3269.0338 - val_loss: 7077.6081\n",
      "Epoch 105/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3266.6184 - val_loss: 7062.4254\n",
      "Epoch 106/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3264.2269 - val_loss: 7048.0286\n",
      "Epoch 107/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3261.8598 - val_loss: 7034.3501\n",
      "Epoch 108/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3259.4867 - val_loss: 7021.6933\n",
      "Epoch 109/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3257.1302 - val_loss: 7009.9489\n",
      "Epoch 110/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3254.7916 - val_loss: 6998.9902\n",
      "Epoch 111/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3252.4672 - val_loss: 6988.7687\n",
      "Epoch 112/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3250.1648 - val_loss: 6979.1215\n",
      "Epoch 113/10000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 3247.8528 - val_loss: 6969.8822\n",
      "Epoch 114/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3245.5641 - val_loss: 6961.1609\n",
      "Epoch 115/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3243.2854 - val_loss: 6952.8716\n",
      "Epoch 116/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3241.0272 - val_loss: 6945.0304\n",
      "Epoch 117/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3238.7693 - val_loss: 6937.4209\n",
      "Epoch 118/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3236.5400 - val_loss: 6930.1522\n",
      "Epoch 119/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3234.3057 - val_loss: 6922.9275\n",
      "Epoch 120/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3232.0839 - val_loss: 6916.0183\n",
      "Epoch 121/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3229.8673 - val_loss: 6909.2311\n",
      "Epoch 122/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3227.6708 - val_loss: 6902.6468\n",
      "Epoch 123/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3225.4656 - val_loss: 6896.3532\n",
      "Epoch 124/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3223.2718 - val_loss: 6890.3259\n",
      "Epoch 125/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3221.0942 - val_loss: 6884.5133\n",
      "Epoch 126/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3218.9009 - val_loss: 6878.8853\n",
      "Epoch 127/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3216.7314 - val_loss: 6873.4036\n",
      "Epoch 128/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3214.5679 - val_loss: 6867.7732\n",
      "Epoch 129/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3212.4069 - val_loss: 6862.1788\n",
      "Epoch 130/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3210.2522 - val_loss: 6856.6885\n",
      "Epoch 131/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3208.1056 - val_loss: 6851.3496\n",
      "Epoch 132/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3205.9654 - val_loss: 6846.1884\n",
      "Epoch 133/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3203.8171 - val_loss: 6841.1166\n",
      "Epoch 134/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3201.6943 - val_loss: 6836.0007\n",
      "Epoch 135/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3199.5678 - val_loss: 6831.1984\n",
      "Epoch 136/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3197.4394 - val_loss: 6826.5932\n",
      "Epoch 137/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3195.3414 - val_loss: 6821.8515\n",
      "Epoch 138/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3193.2421 - val_loss: 6817.0895\n",
      "Epoch 139/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3191.1687 - val_loss: 6812.5088\n",
      "Epoch 140/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3189.0639 - val_loss: 6808.1735\n",
      "Epoch 141/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3186.9780 - val_loss: 6803.6313\n",
      "Epoch 142/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3184.9015 - val_loss: 6798.9231\n",
      "Epoch 143/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3182.8453 - val_loss: 6794.2233\n",
      "Epoch 144/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3180.7879 - val_loss: 6789.6798\n",
      "Epoch 145/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3178.7382 - val_loss: 6785.3441\n",
      "Epoch 146/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3176.6986 - val_loss: 6781.0246\n",
      "Epoch 147/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3174.6687 - val_loss: 6776.5740\n",
      "Epoch 148/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3172.6417 - val_loss: 6772.2493\n",
      "Epoch 149/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3170.6053 - val_loss: 6767.8640\n",
      "Epoch 150/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3168.6232 - val_loss: 6763.2235\n",
      "Epoch 151/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3166.6220 - val_loss: 6758.8993\n",
      "Epoch 152/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3164.6101 - val_loss: 6754.7856\n",
      "Epoch 153/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3162.6114 - val_loss: 6750.4090\n",
      "Epoch 154/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3160.6556 - val_loss: 6745.8384\n",
      "Epoch 155/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3158.6604 - val_loss: 6741.6579\n",
      "Epoch 156/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3156.7122 - val_loss: 6737.4654\n",
      "Epoch 157/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3154.7304 - val_loss: 6733.4691\n",
      "Epoch 158/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3152.7977 - val_loss: 6729.2103\n",
      "Epoch 159/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3150.8322 - val_loss: 6725.0852\n",
      "Epoch 160/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3148.8931 - val_loss: 6720.7118\n",
      "Epoch 161/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3146.9805 - val_loss: 6716.4822\n",
      "Epoch 162/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3145.0391 - val_loss: 6712.5436\n",
      "Epoch 163/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3143.1181 - val_loss: 6708.5029\n",
      "Epoch 164/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3141.2046 - val_loss: 6704.4235\n",
      "Epoch 165/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3139.3002 - val_loss: 6700.3788\n",
      "Epoch 166/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3137.4019 - val_loss: 6696.3333\n",
      "Epoch 167/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3135.5134 - val_loss: 6692.2192\n",
      "Epoch 168/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3133.6253 - val_loss: 6688.2766\n",
      "Epoch 169/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3131.7507 - val_loss: 6684.2807\n",
      "Epoch 170/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3129.9040 - val_loss: 6680.3939\n",
      "Epoch 171/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3128.0168 - val_loss: 6676.7417\n",
      "Epoch 172/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3126.1483 - val_loss: 6672.8040\n",
      "Epoch 173/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3124.2814 - val_loss: 6668.8432\n",
      "Epoch 174/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3123.7132 - val_loss: 6717.7159\n",
      "Epoch 175/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3121.7752 - val_loss: 6683.3051\n",
      "Epoch 176/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3119.4157 - val_loss: 6669.2161\n",
      "Epoch 177/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3117.4192 - val_loss: 6661.0032\n",
      "Epoch 178/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3115.5287 - val_loss: 6655.0565\n",
      "Epoch 179/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3113.6309 - val_loss: 6650.4117\n",
      "Epoch 180/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3111.7797 - val_loss: 6645.9173\n",
      "Epoch 181/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3109.9470 - val_loss: 6641.5165\n",
      "Epoch 182/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3108.1250 - val_loss: 6637.3565\n",
      "Epoch 183/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3106.3480 - val_loss: 6633.3992\n",
      "Epoch 184/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3104.5399 - val_loss: 6629.9022\n",
      "Epoch 185/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3102.7507 - val_loss: 6626.3650\n",
      "Epoch 186/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3100.9729 - val_loss: 6622.8546\n",
      "Epoch 187/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3099.2052 - val_loss: 6619.3273\n",
      "Epoch 188/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3097.4432 - val_loss: 6615.9056\n",
      "Epoch 189/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3095.6872 - val_loss: 6612.5752\n",
      "Epoch 190/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3093.9421 - val_loss: 6609.2076\n",
      "Epoch 191/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3092.2101 - val_loss: 6605.9614\n",
      "Epoch 192/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3090.4642 - val_loss: 6602.9044\n",
      "Epoch 193/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3088.7368 - val_loss: 6599.6704\n",
      "Epoch 194/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3087.0180 - val_loss: 6596.3379\n",
      "Epoch 195/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3085.3054 - val_loss: 6593.0145\n",
      "Epoch 196/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3083.5982 - val_loss: 6589.7892\n",
      "Epoch 197/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3081.9031 - val_loss: 6586.4290\n",
      "Epoch 198/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3080.2177 - val_loss: 6583.1539\n",
      "Epoch 199/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3078.5304 - val_loss: 6580.1050\n",
      "Epoch 200/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3076.8534 - val_loss: 6577.0257\n",
      "Epoch 201/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3075.1485 - val_loss: 6573.8321\n",
      "Epoch 202/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3073.5168 - val_loss: 6570.2338\n",
      "Epoch 203/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3071.8584 - val_loss: 6567.0971\n",
      "Epoch 204/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3070.1714 - val_loss: 6564.0628\n",
      "Epoch 205/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3068.5639 - val_loss: 6560.5651\n",
      "Epoch 206/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3066.9240 - val_loss: 6557.5903\n",
      "Epoch 207/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3065.2628 - val_loss: 6554.5970\n",
      "Epoch 208/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3063.6710 - val_loss: 6551.2239\n",
      "Epoch 209/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3062.0183 - val_loss: 6548.2209\n",
      "Epoch 210/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3060.4397 - val_loss: 6545.0218\n",
      "Epoch 211/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3058.8015 - val_loss: 6542.0191\n",
      "Epoch 212/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3057.2422 - val_loss: 6538.7891\n",
      "Epoch 213/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3055.6503 - val_loss: 6536.1254\n",
      "Epoch 214/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3054.0342 - val_loss: 6533.5406\n",
      "Epoch 215/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3052.4895 - val_loss: 6530.4710\n",
      "Epoch 216/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3050.8840 - val_loss: 6527.8202\n",
      "Epoch 217/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3049.3526 - val_loss: 6524.7775\n",
      "Epoch 218/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3047.7634 - val_loss: 6522.0944\n",
      "Epoch 219/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3046.2443 - val_loss: 6519.1412\n",
      "Epoch 220/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3044.6661 - val_loss: 6516.6358\n",
      "Epoch 221/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3043.1606 - val_loss: 6513.7336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3041.5984 - val_loss: 6511.2737\n",
      "Epoch 223/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3040.0686 - val_loss: 6508.2803\n",
      "Epoch 224/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3038.5879 - val_loss: 6505.3996\n",
      "Epoch 225/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3037.0376 - val_loss: 6503.0953\n",
      "Epoch 226/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3035.5704 - val_loss: 6500.5360\n",
      "Epoch 227/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3034.0391 - val_loss: 6498.5010\n",
      "Epoch 228/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3032.5782 - val_loss: 6496.0724\n",
      "Epoch 229/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3031.0659 - val_loss: 6494.7635\n",
      "Epoch 230/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3029.5833 - val_loss: 6492.0164\n",
      "Epoch 231/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3028.1517 - val_loss: 6488.9848\n",
      "Epoch 232/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3026.6460 - val_loss: 6486.9434\n",
      "Epoch 233/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3025.1832 - val_loss: 6484.3863\n",
      "Epoch 234/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3023.7705 - val_loss: 6482.6279\n",
      "Epoch 235/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3022.2876 - val_loss: 6480.3804\n",
      "Epoch 236/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3020.8862 - val_loss: 6477.7831\n",
      "Epoch 237/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3019.4193 - val_loss: 6475.8104\n",
      "Epoch 238/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3017.9887 - val_loss: 6473.3739\n",
      "Epoch 239/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3016.6250 - val_loss: 6471.7442\n",
      "Epoch 240/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3015.1669 - val_loss: 6470.1465\n",
      "Epoch 241/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3013.7549 - val_loss: 6467.8382\n",
      "Epoch 242/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3012.3506 - val_loss: 6465.3013\n",
      "Epoch 243/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3011.0137 - val_loss: 6462.7310\n",
      "Epoch 244/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3009.5785 - val_loss: 6461.3283\n",
      "Epoch 245/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3008.1897 - val_loss: 6459.2428\n",
      "Epoch 246/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3006.8141 - val_loss: 6457.5938\n",
      "Epoch 247/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3005.4633 - val_loss: 6454.8402\n",
      "Epoch 248/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3004.1008 - val_loss: 6452.8278\n",
      "Epoch 249/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3002.7308 - val_loss: 6450.8472\n",
      "Epoch 250/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3001.3957 - val_loss: 6448.6318\n",
      "Epoch 251/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3000.0582 - val_loss: 6447.5815\n",
      "Epoch 252/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2998.7034 - val_loss: 6445.2313\n",
      "Epoch 253/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2997.3801 - val_loss: 6442.8254\n",
      "Epoch 254/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2996.0376 - val_loss: 6441.8851\n",
      "Epoch 255/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2994.6695 - val_loss: 6439.7435\n",
      "Epoch 256/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2995.1686 - val_loss: 6509.8049\n",
      "Epoch 257/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2993.5451 - val_loss: 6460.3265\n",
      "Epoch 258/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2991.4892 - val_loss: 6445.7394\n",
      "Epoch 259/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2989.9594 - val_loss: 6440.0810\n",
      "Epoch 260/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2988.5483 - val_loss: 6436.0060\n",
      "Epoch 261/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2987.1656 - val_loss: 6433.6044\n",
      "Epoch 262/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2985.8471 - val_loss: 6432.1317\n",
      "Epoch 263/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2984.5169 - val_loss: 6429.7127\n",
      "Epoch 264/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2983.2336 - val_loss: 6427.5994\n",
      "Epoch 265/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2981.9281 - val_loss: 6426.0676\n",
      "Epoch 266/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2980.6717 - val_loss: 6425.1512\n",
      "Epoch 267/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2979.3884 - val_loss: 6423.1858\n",
      "Epoch 268/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2978.1495 - val_loss: 6421.4255\n",
      "Epoch 269/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2976.8833 - val_loss: 6421.0970\n",
      "Epoch 270/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2975.6647 - val_loss: 6418.9386\n",
      "Epoch 271/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2974.4114 - val_loss: 6417.7081\n",
      "Epoch 272/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2973.2046 - val_loss: 6416.1897\n",
      "Epoch 273/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2971.9709 - val_loss: 6415.9784\n",
      "Epoch 274/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2970.7831 - val_loss: 6413.8385\n",
      "Epoch 275/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2969.5596 - val_loss: 6412.6844\n",
      "Epoch 276/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2968.3820 - val_loss: 6412.1600\n",
      "Epoch 277/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2967.1779 - val_loss: 6410.4511\n",
      "Epoch 278/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2966.0137 - val_loss: 6408.8793\n",
      "Epoch 279/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2964.8223 - val_loss: 6408.7821\n",
      "Epoch 280/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2963.6756 - val_loss: 6406.7515\n",
      "Epoch 281/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2962.4944 - val_loss: 6405.7898\n",
      "Epoch 282/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2961.5665 - val_loss: 6404.3940\n",
      "Epoch 283/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2960.2282 - val_loss: 6406.7801\n",
      "Epoch 284/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2959.0886 - val_loss: 6405.1702\n",
      "Epoch 285/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2957.9597 - val_loss: 6404.0135\n",
      "Epoch 286/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2956.8350 - val_loss: 6401.1888\n",
      "Epoch 287/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2955.7118 - val_loss: 6399.1283\n",
      "Epoch 288/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2954.5986 - val_loss: 6398.3860\n",
      "Epoch 289/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2953.4930 - val_loss: 6396.6402\n",
      "Epoch 290/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2952.3896 - val_loss: 6395.0630\n",
      "Epoch 291/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2951.2942 - val_loss: 6393.6487\n",
      "Epoch 292/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2950.2072 - val_loss: 6393.4590\n",
      "Epoch 293/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2949.3381 - val_loss: 6391.5713\n",
      "Epoch 294/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2948.0033 - val_loss: 6394.8154\n",
      "Epoch 295/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2946.9849 - val_loss: 6394.0957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2945.9306 - val_loss: 6392.8804\n",
      "Epoch 297/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2944.8172 - val_loss: 6391.6801\n",
      "Epoch 298/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2943.8312 - val_loss: 6389.4511\n",
      "Epoch 299/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2942.7777 - val_loss: 6389.8986\n",
      "Epoch 300/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2941.6842 - val_loss: 6388.2479\n",
      "Epoch 301/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2940.7153 - val_loss: 6385.7381\n",
      "Epoch 302/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2939.6783 - val_loss: 6386.6178\n",
      "Epoch 303/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2938.6067 - val_loss: 6385.2826\n",
      "Epoch 304/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2937.6550 - val_loss: 6382.9726\n",
      "Epoch 305/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2936.5792 - val_loss: 6384.0859\n",
      "Epoch 306/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2935.8736 - val_loss: 6381.4886\n",
      "Epoch 307/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2934.6938 - val_loss: 6384.0989\n",
      "Epoch 308/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2933.6764 - val_loss: 6383.6485\n",
      "Epoch 309/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2932.6833 - val_loss: 6381.7280\n",
      "Epoch 310/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2931.6916 - val_loss: 6379.3722\n",
      "Epoch 311/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2930.7034 - val_loss: 6377.2188\n",
      "Epoch 312/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2930.0106 - val_loss: 6375.6027\n",
      "Epoch 313/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2928.8346 - val_loss: 6377.1986\n",
      "Epoch 314/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2927.8665 - val_loss: 6376.3866\n",
      "Epoch 315/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2926.9113 - val_loss: 6374.5067\n",
      "Epoch 316/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2926.2495 - val_loss: 6371.3020\n",
      "Epoch 317/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2925.0890 - val_loss: 6372.6463\n",
      "Epoch 318/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2924.0856 - val_loss: 6368.8809\n",
      "Epoch 319/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2923.0586 - val_loss: 6369.0946\n",
      "Epoch 320/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2922.4309 - val_loss: 6367.7517\n",
      "Epoch 321/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2921.3680 - val_loss: 6394.4393\n",
      "Epoch 322/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2920.6588 - val_loss: 6385.5024\n",
      "Epoch 323/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2920.0492 - val_loss: 6377.2127\n",
      "Epoch 324/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2918.8170 - val_loss: 6375.1091\n",
      "Epoch 325/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2917.9392 - val_loss: 6372.3240\n",
      "Epoch 326/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2917.4249 - val_loss: 6370.0312\n",
      "Epoch 327/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2916.1869 - val_loss: 6371.0492\n",
      "Epoch 328/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2915.6769 - val_loss: 6368.1215\n",
      "Epoch 329/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2914.8166 - val_loss: 6366.9495\n",
      "Epoch 330/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2913.6755 - val_loss: 6367.9456\n",
      "Epoch 331/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2913.1804 - val_loss: 6365.0606\n",
      "Epoch 332/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.3757 - val_loss: 6364.6631\n",
      "Epoch 333/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2911.2147 - val_loss: 6366.2121\n",
      "Epoch 334/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2910.7396 - val_loss: 6362.5341\n",
      "Epoch 335/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.5705 - val_loss: 6363.9806\n",
      "Epoch 336/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.1659 - val_loss: 6361.1959\n",
      "Epoch 337/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2908.3815 - val_loss: 6361.4961\n",
      "Epoch 338/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2907.2039 - val_loss: 6363.6750\n",
      "Epoch 339/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2906.8107 - val_loss: 6360.8250\n",
      "Epoch 340/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2906.0638 - val_loss: 6360.5428\n",
      "Epoch 341/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2904.9820 - val_loss: 6364.7166\n",
      "Epoch 342/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2904.1047 - val_loss: 6362.8879\n",
      "Epoch 343/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.7884 - val_loss: 6359.1309\n",
      "Epoch 344/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.0706 - val_loss: 6358.4273\n",
      "Epoch 345/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.9403 - val_loss: 6361.7755\n",
      "Epoch 346/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.5466 - val_loss: 6359.6688\n",
      "Epoch 347/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.1490 - val_loss: 6362.5376\n",
      "Epoch 348/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.0878 - val_loss: 6352.2515\n",
      "Epoch 349/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2899.0892 - val_loss: 6353.8907\n",
      "Epoch 350/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2898.3879 - val_loss: 6355.8903\n",
      "Epoch 351/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2897.3601 - val_loss: 6387.0475\n",
      "Epoch 352/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2897.4821 - val_loss: 6372.3672\n",
      "Epoch 353/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.9755 - val_loss: 6368.9659\n",
      "Epoch 354/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2896.0050 - val_loss: 6360.9385\n",
      "Epoch 355/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.3761 - val_loss: 6358.8940\n",
      "Epoch 356/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.1272 - val_loss: 6362.9413\n",
      "Epoch 357/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2893.9688 - val_loss: 6359.9785\n",
      "Epoch 358/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2892.4993 - val_loss: 6362.7257\n",
      "Epoch 359/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2892.6367 - val_loss: 6356.6847\n",
      "Epoch 360/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2892.0475 - val_loss: 6355.5144\n",
      "Epoch 361/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.8911 - val_loss: 6359.4540\n",
      "Epoch 362/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.6460 - val_loss: 6358.3331\n",
      "Epoch 363/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2889.3389 - val_loss: 6361.5857\n",
      "Epoch 364/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2889.4566 - val_loss: 6355.1531\n",
      "Epoch 365/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2888.7718 - val_loss: 6355.5891\n",
      "Epoch 366/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.4033 - val_loss: 6360.3397\n",
      "Epoch 367/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.6036 - val_loss: 6354.2467\n",
      "Epoch 368/10000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.9327 - val_loss: 6355.1291\n",
      "Train on 245 samples, validate on 82 samples\n",
      "Epoch 1/10000\n",
      "245/245 [==============================] - 85s 348ms/step - loss: 26808.0644 - val_loss: 163446.2992\n",
      "Epoch 2/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 26770.8946 - val_loss: 163249.7663\n",
      "Epoch 3/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 26701.3464 - val_loss: 162861.9827\n",
      "Epoch 4/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 26572.2727 - val_loss: 162101.7139\n",
      "Epoch 5/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 26331.1897 - val_loss: 160787.1702\n",
      "Epoch 6/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 25950.3957 - val_loss: 158742.5853\n",
      "Epoch 7/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 25372.6133 - val_loss: 155668.4739\n",
      "Epoch 8/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 24536.7372 - val_loss: 151218.3358\n",
      "Epoch 9/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 23401.9660 - val_loss: 145243.7444\n",
      "Epoch 10/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 21979.4032 - val_loss: 137768.5853\n",
      "Epoch 11/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 20331.3531 - val_loss: 129000.1730\n",
      "Epoch 12/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 18566.8223 - val_loss: 119356.0228\n",
      "Epoch 13/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 16823.6957 - val_loss: 109396.3336\n",
      "Epoch 14/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 15232.4057 - val_loss: 99698.3502\n",
      "Epoch 15/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 13880.3755 - val_loss: 90729.9769\n",
      "Epoch 16/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 12797.8037 - val_loss: 82796.8558\n",
      "Epoch 17/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 11966.4636 - val_loss: 76028.7536\n",
      "Epoch 18/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 11337.4314 - val_loss: 70372.6423\n",
      "Epoch 19/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 10853.0581 - val_loss: 65678.1629\n",
      "Epoch 20/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 10464.4594 - val_loss: 61760.1967\n",
      "Epoch 21/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 10136.6190 - val_loss: 58443.5149\n",
      "Epoch 22/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 9846.3807 - val_loss: 55584.6733\n",
      "Epoch 23/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 9579.6907 - val_loss: 53068.7831\n",
      "Epoch 24/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 9328.9988 - val_loss: 50805.4665\n",
      "Epoch 25/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 9089.6142 - val_loss: 48736.2374\n",
      "Epoch 26/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 8858.5442 - val_loss: 46816.0277\n",
      "Epoch 27/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 8634.0432 - val_loss: 45013.6831\n",
      "Epoch 28/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 8414.9839 - val_loss: 43306.1695\n",
      "Epoch 29/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 8200.7590 - val_loss: 41675.1191\n",
      "Epoch 30/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7991.1170 - val_loss: 40107.9508\n",
      "Epoch 31/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7785.8499 - val_loss: 38595.7634\n",
      "Epoch 32/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7584.8896 - val_loss: 37133.1611\n",
      "Epoch 33/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7388.2086 - val_loss: 35715.6643\n",
      "Epoch 34/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7195.9105 - val_loss: 34340.1971\n",
      "Epoch 35/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7008.0891 - val_loss: 33004.7367\n",
      "Epoch 36/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6824.9104 - val_loss: 31707.4753\n",
      "Epoch 37/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6646.5239 - val_loss: 30448.9063\n",
      "Epoch 38/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6473.0940 - val_loss: 29228.7559\n",
      "Epoch 39/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6304.8195 - val_loss: 28047.2072\n",
      "Epoch 40/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6141.9145 - val_loss: 26903.7364\n",
      "Epoch 41/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5984.5466 - val_loss: 25799.1226\n",
      "Epoch 42/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5832.9154 - val_loss: 24733.4758\n",
      "Epoch 43/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5687.2078 - val_loss: 23707.0855\n",
      "Epoch 44/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5547.5884 - val_loss: 22719.7992\n",
      "Epoch 45/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5414.2207 - val_loss: 21771.9868\n",
      "Epoch 46/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5287.2181 - val_loss: 20864.1171\n",
      "Epoch 47/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5166.6443 - val_loss: 19996.9074\n",
      "Epoch 48/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5052.5808 - val_loss: 19170.2045\n",
      "Epoch 49/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4945.0562 - val_loss: 18383.7688\n",
      "Epoch 50/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4844.1948 - val_loss: 17636.5606\n",
      "Epoch 51/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4750.5642 - val_loss: 16928.2474\n",
      "Epoch 52/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4663.3451 - val_loss: 16260.8713\n",
      "Epoch 53/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4582.3242 - val_loss: 15632.8154\n",
      "Epoch 54/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4507.3630 - val_loss: 15042.7416\n",
      "Epoch 55/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4438.2339 - val_loss: 14489.6731\n",
      "Epoch 56/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4374.6970 - val_loss: 13972.0665\n",
      "Epoch 57/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4316.4972 - val_loss: 13488.7277\n",
      "Epoch 58/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4263.3495 - val_loss: 13038.1523\n",
      "Epoch 59/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4215.3064 - val_loss: 12618.3716\n",
      "Epoch 60/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4171.6667 - val_loss: 12229.6709\n",
      "Epoch 61/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4132.0255 - val_loss: 11870.0163\n",
      "Epoch 62/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4096.0932 - val_loss: 11537.2261\n",
      "Epoch 63/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4063.5638 - val_loss: 11229.6662\n",
      "Epoch 64/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4034.1269 - val_loss: 10945.8671\n",
      "Epoch 65/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4007.4855 - val_loss: 10684.0158\n",
      "Epoch 66/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3983.3533 - val_loss: 10442.7285\n",
      "Epoch 67/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3961.4714 - val_loss: 10220.3823\n",
      "Epoch 68/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3941.5822 - val_loss: 10015.8881\n",
      "Epoch 69/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3923.4569 - val_loss: 9827.8329\n",
      "Epoch 70/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3906.8821 - val_loss: 9655.0931\n",
      "Epoch 71/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3891.6648 - val_loss: 9496.2682\n",
      "Epoch 72/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3877.6304 - val_loss: 9350.3188\n",
      "Epoch 73/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3864.6217 - val_loss: 9216.2840\n",
      "Epoch 74/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 1ms/step - loss: 3852.5021 - val_loss: 9093.1219\n",
      "Epoch 75/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3841.1557 - val_loss: 8979.7485\n",
      "Epoch 76/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3830.4992 - val_loss: 8875.2210\n",
      "Epoch 77/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3820.4141 - val_loss: 8779.2684\n",
      "Epoch 78/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3810.8088 - val_loss: 8690.8060\n",
      "Epoch 79/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3801.5969 - val_loss: 8609.7193\n",
      "Epoch 80/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3792.7355 - val_loss: 8535.0889\n",
      "Epoch 81/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3784.1676 - val_loss: 8466.4954\n",
      "Epoch 82/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3775.8250 - val_loss: 8403.7759\n",
      "Epoch 83/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3767.6835 - val_loss: 8345.8228\n",
      "Epoch 84/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3759.7049 - val_loss: 8292.0941\n",
      "Epoch 85/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3751.8615 - val_loss: 8242.1305\n",
      "Epoch 86/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3744.1253 - val_loss: 8195.7846\n",
      "Epoch 87/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3736.4839 - val_loss: 8152.7038\n",
      "Epoch 88/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3728.9246 - val_loss: 8112.3417\n",
      "Epoch 89/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3721.4360 - val_loss: 8074.5178\n",
      "Epoch 90/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3714.0037 - val_loss: 8038.6861\n",
      "Epoch 91/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3706.6055 - val_loss: 8005.1678\n",
      "Epoch 92/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3699.2462 - val_loss: 7973.4017\n",
      "Epoch 93/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3691.9175 - val_loss: 7943.5144\n",
      "Epoch 94/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3684.6289 - val_loss: 7915.2971\n",
      "Epoch 95/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3677.3760 - val_loss: 7888.6009\n",
      "Epoch 96/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3670.1590 - val_loss: 7862.9800\n",
      "Epoch 97/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3662.9635 - val_loss: 7838.5879\n",
      "Epoch 98/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3655.7837 - val_loss: 7815.2665\n",
      "Epoch 99/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3648.6308 - val_loss: 7792.6921\n",
      "Epoch 100/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3641.4972 - val_loss: 7770.7824\n",
      "Epoch 101/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3634.3763 - val_loss: 7749.8211\n",
      "Epoch 102/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3627.2708 - val_loss: 7729.4777\n",
      "Epoch 103/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3620.1760 - val_loss: 7709.9426\n",
      "Epoch 104/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3613.0928 - val_loss: 7691.2555\n",
      "Epoch 105/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3606.0327 - val_loss: 7672.8664\n",
      "Epoch 106/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3598.9889 - val_loss: 7654.7639\n",
      "Epoch 107/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3591.9581 - val_loss: 7636.9877\n",
      "Epoch 108/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3584.9395 - val_loss: 7619.5348\n",
      "Epoch 109/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3577.9339 - val_loss: 7602.4999\n",
      "Epoch 110/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3570.9424 - val_loss: 7585.7719\n",
      "Epoch 111/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3563.9633 - val_loss: 7569.4277\n",
      "Epoch 112/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3556.9980 - val_loss: 7553.4638\n",
      "Epoch 113/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3550.0470 - val_loss: 7537.6955\n",
      "Epoch 114/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3543.1102 - val_loss: 7522.0791\n",
      "Epoch 115/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3536.1901 - val_loss: 7506.5942\n",
      "Epoch 116/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3529.2839 - val_loss: 7491.3964\n",
      "Epoch 117/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3522.3951 - val_loss: 7476.3237\n",
      "Epoch 118/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3515.5239 - val_loss: 7461.4207\n",
      "Epoch 119/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3508.6688 - val_loss: 7446.5396\n",
      "Epoch 120/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3501.8286 - val_loss: 7431.8329\n",
      "Epoch 121/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3495.0061 - val_loss: 7417.2254\n",
      "Epoch 122/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3488.2013 - val_loss: 7402.7899\n",
      "Epoch 123/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3481.4139 - val_loss: 7388.4219\n",
      "Epoch 124/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3474.6426 - val_loss: 7374.1507\n",
      "Epoch 125/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3467.8834 - val_loss: 7360.0567\n",
      "Epoch 126/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3461.1327 - val_loss: 7346.2134\n",
      "Epoch 127/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3454.3990 - val_loss: 7332.3631\n",
      "Epoch 128/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3447.6778 - val_loss: 7318.5579\n",
      "Epoch 129/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3440.9738 - val_loss: 7304.7994\n",
      "Epoch 130/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3434.2872 - val_loss: 7291.2268\n",
      "Epoch 131/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3427.6178 - val_loss: 7277.9348\n",
      "Epoch 132/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3420.9696 - val_loss: 7264.7143\n",
      "Epoch 133/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3414.3374 - val_loss: 7251.6146\n",
      "Epoch 134/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3407.7234 - val_loss: 7238.6776\n",
      "Epoch 135/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3401.1295 - val_loss: 7225.7661\n",
      "Epoch 136/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3394.5534 - val_loss: 7212.9286\n",
      "Epoch 137/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3387.9937 - val_loss: 7200.1843\n",
      "Epoch 138/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3381.4510 - val_loss: 7187.5633\n",
      "Epoch 139/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3374.9300 - val_loss: 7174.9198\n",
      "Epoch 140/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3368.4243 - val_loss: 7162.4573\n",
      "Epoch 141/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3361.9428 - val_loss: 7149.9251\n",
      "Epoch 142/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3355.4768 - val_loss: 7137.5948\n",
      "Epoch 143/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3349.0292 - val_loss: 7125.3475\n",
      "Epoch 144/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3342.6011 - val_loss: 7113.1272\n",
      "Epoch 145/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3336.1962 - val_loss: 7100.8763\n",
      "Epoch 146/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3329.8084 - val_loss: 7088.7681\n",
      "Epoch 147/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3323.4423 - val_loss: 7076.7644\n",
      "Epoch 148/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3317.0899 - val_loss: 7065.0214\n",
      "Epoch 149/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3310.7640 - val_loss: 7053.2307\n",
      "Epoch 150/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3304.4592 - val_loss: 7041.5354\n",
      "Epoch 151/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3298.1735 - val_loss: 7030.0079\n",
      "Epoch 152/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3291.9130 - val_loss: 7018.4656\n",
      "Epoch 153/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3285.6683 - val_loss: 7007.1279\n",
      "Epoch 154/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3279.4535 - val_loss: 6995.6974\n",
      "Epoch 155/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3273.2556 - val_loss: 6984.5217\n",
      "Epoch 156/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3267.0829 - val_loss: 6973.3880\n",
      "Epoch 157/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3260.9321 - val_loss: 6962.4204\n",
      "Epoch 158/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3254.8059 - val_loss: 6951.4988\n",
      "Epoch 159/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3248.6978 - val_loss: 6940.8075\n",
      "Epoch 160/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3242.6180 - val_loss: 6930.1239\n",
      "Epoch 161/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3236.5586 - val_loss: 6919.5898\n",
      "Epoch 162/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3230.5272 - val_loss: 6909.1132\n",
      "Epoch 163/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3224.5244 - val_loss: 6898.5816\n",
      "Epoch 164/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3218.5429 - val_loss: 6888.1964\n",
      "Epoch 165/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3212.5894 - val_loss: 6877.8796\n",
      "Epoch 166/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3206.6568 - val_loss: 6867.7845\n",
      "Epoch 167/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3200.7521 - val_loss: 6857.7570\n",
      "Epoch 168/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3194.8740 - val_loss: 6847.8035\n",
      "Epoch 169/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3189.0267 - val_loss: 6837.8466\n",
      "Epoch 170/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3183.2031 - val_loss: 6828.0449\n",
      "Epoch 171/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3177.4088 - val_loss: 6818.3537\n",
      "Epoch 172/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3171.6394 - val_loss: 6808.8463\n",
      "Epoch 173/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3165.9000 - val_loss: 6799.4014\n",
      "Epoch 174/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3160.1850 - val_loss: 6790.1438\n",
      "Epoch 175/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3154.5057 - val_loss: 6780.8277\n",
      "Epoch 176/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3148.8528 - val_loss: 6771.6862\n",
      "Epoch 177/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3143.2323 - val_loss: 6762.5902\n",
      "Epoch 178/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3137.6424 - val_loss: 6753.5630\n",
      "Epoch 179/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3132.0821 - val_loss: 6744.6682\n",
      "Epoch 180/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3126.5548 - val_loss: 6735.8750\n",
      "Epoch 181/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3121.0560 - val_loss: 6727.2873\n",
      "Epoch 182/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3115.5911 - val_loss: 6718.7329\n",
      "Epoch 183/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3110.1593 - val_loss: 6710.2686\n",
      "Epoch 184/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3104.7589 - val_loss: 6701.9739\n",
      "Epoch 185/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3099.3929 - val_loss: 6693.7660\n",
      "Epoch 186/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3094.0604 - val_loss: 6685.6432\n",
      "Epoch 187/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3088.7608 - val_loss: 6677.6887\n",
      "Epoch 188/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3083.4957 - val_loss: 6669.8309\n",
      "Epoch 189/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3078.2633 - val_loss: 6662.1224\n",
      "Epoch 190/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3073.0678 - val_loss: 6654.4689\n",
      "Epoch 191/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3067.9081 - val_loss: 6646.9244\n",
      "Epoch 192/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3062.7819 - val_loss: 6639.5455\n",
      "Epoch 193/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3057.6945 - val_loss: 6632.1787\n",
      "Epoch 194/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3052.6399 - val_loss: 6625.0216\n",
      "Epoch 195/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3047.6281 - val_loss: 6617.8065\n",
      "Epoch 196/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3042.6499 - val_loss: 6610.7706\n",
      "Epoch 197/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3037.7128 - val_loss: 6603.8108\n",
      "Epoch 198/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3032.8115 - val_loss: 6596.9864\n",
      "Epoch 199/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3027.9534 - val_loss: 6590.1435\n",
      "Epoch 200/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3023.1339 - val_loss: 6583.4173\n",
      "Epoch 201/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3018.3035 - val_loss: 6578.8158\n",
      "Epoch 202/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3013.4280 - val_loss: 6572.8563\n",
      "Epoch 203/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3008.5876 - val_loss: 6566.6134\n",
      "Epoch 204/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3003.7890 - val_loss: 6560.3802\n",
      "Epoch 205/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2999.0339 - val_loss: 6554.1855\n",
      "Epoch 206/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2994.3188 - val_loss: 6548.1874\n",
      "Epoch 207/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2989.6465 - val_loss: 6542.2941\n",
      "Epoch 208/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2984.9920 - val_loss: 6538.6577\n",
      "Epoch 209/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2980.2596 - val_loss: 6533.3672\n",
      "Epoch 210/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2975.5671 - val_loss: 6527.6544\n",
      "Epoch 211/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2970.9200 - val_loss: 6521.9545\n",
      "Epoch 212/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2966.3167 - val_loss: 6516.3912\n",
      "Epoch 213/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2961.7598 - val_loss: 6510.8867\n",
      "Epoch 214/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2957.2465 - val_loss: 6505.6264\n",
      "Epoch 215/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2952.7767 - val_loss: 6500.5285\n",
      "Epoch 216/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2948.3541 - val_loss: 6495.5658\n",
      "Epoch 217/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2943.9677 - val_loss: 6490.8190\n",
      "Epoch 218/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2939.6314 - val_loss: 6485.9998\n",
      "Epoch 219/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2935.3347 - val_loss: 6481.4424\n",
      "Epoch 220/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2931.0797 - val_loss: 6476.8138\n",
      "Epoch 221/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2926.8726 - val_loss: 6472.2336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2922.7121 - val_loss: 6467.8239\n",
      "Epoch 223/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2918.5969 - val_loss: 6463.5420\n",
      "Epoch 224/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2914.5318 - val_loss: 6459.2808\n",
      "Epoch 225/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2910.5116 - val_loss: 6455.2334\n",
      "Epoch 226/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2906.5312 - val_loss: 6451.5239\n",
      "Epoch 227/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2902.5915 - val_loss: 6447.6962\n",
      "Epoch 228/10000\n",
      "245/245 [==============================] - 0s 2ms/step - loss: 2898.6988 - val_loss: 6444.0144\n",
      "Epoch 229/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2894.7972 - val_loss: 6442.7255\n",
      "Epoch 230/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2890.8401 - val_loss: 6439.6221\n",
      "Epoch 231/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2886.9401 - val_loss: 6435.8921\n",
      "Epoch 232/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2883.0910 - val_loss: 6432.4342\n",
      "Epoch 233/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2879.2934 - val_loss: 6429.1507\n",
      "Epoch 234/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2875.5471 - val_loss: 6426.0344\n",
      "Epoch 235/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2871.8481 - val_loss: 6423.1111\n",
      "Epoch 236/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2868.1968 - val_loss: 6420.2398\n",
      "Epoch 237/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2864.6011 - val_loss: 6417.3583\n",
      "Epoch 238/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2861.0536 - val_loss: 6414.6578\n",
      "Epoch 239/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2857.5557 - val_loss: 6411.9500\n",
      "Epoch 240/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2854.1112 - val_loss: 6409.4914\n",
      "Epoch 241/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2850.7165 - val_loss: 6407.1380\n",
      "Epoch 242/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2847.3691 - val_loss: 6404.8728\n",
      "Epoch 243/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2844.0752 - val_loss: 6402.6537\n",
      "Epoch 244/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2840.8287 - val_loss: 6400.5677\n",
      "Epoch 245/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2837.6328 - val_loss: 6398.4135\n",
      "Epoch 246/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2834.4775 - val_loss: 6398.8696\n",
      "Epoch 247/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2831.2332 - val_loss: 6397.3419\n",
      "Epoch 248/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2828.0483 - val_loss: 6395.3776\n",
      "Epoch 249/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2824.9169 - val_loss: 6393.5229\n",
      "Epoch 250/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2821.8379 - val_loss: 6391.9062\n",
      "Epoch 251/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2818.8180 - val_loss: 6390.4782\n",
      "Epoch 252/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2815.8439 - val_loss: 6389.3902\n",
      "Epoch 253/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2812.9170 - val_loss: 6388.1254\n",
      "Epoch 254/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2810.0398 - val_loss: 6386.8205\n",
      "Epoch 255/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2807.2177 - val_loss: 6385.7530\n",
      "Epoch 256/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2804.4312 - val_loss: 6384.6963\n",
      "Epoch 257/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2801.6918 - val_loss: 6383.4421\n",
      "Epoch 258/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2799.0008 - val_loss: 6382.3378\n",
      "Epoch 259/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2796.3575 - val_loss: 6376.5717\n",
      "Epoch 260/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2793.9124 - val_loss: 6374.9510\n",
      "Epoch 261/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2791.5104 - val_loss: 6374.1604\n",
      "Epoch 262/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2789.1597 - val_loss: 6373.6647\n",
      "Epoch 263/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2786.8216 - val_loss: 6376.0218\n",
      "Epoch 264/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2784.4113 - val_loss: 6375.5440\n",
      "Epoch 265/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2782.1301 - val_loss: 6370.6281\n",
      "Epoch 266/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2779.9655 - val_loss: 6369.6001\n",
      "Epoch 267/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2777.8436 - val_loss: 6369.7434\n",
      "Epoch 268/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2775.7597 - val_loss: 6369.6122\n",
      "Epoch 269/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2773.7239 - val_loss: 6369.2471\n",
      "Epoch 270/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2771.7327 - val_loss: 6369.0345\n",
      "Epoch 271/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2769.7974 - val_loss: 6371.5828\n",
      "Epoch 272/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2767.7434 - val_loss: 6371.4878\n",
      "Epoch 273/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2765.7438 - val_loss: 6371.0770\n",
      "Epoch 274/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2763.8032 - val_loss: 6370.9222\n",
      "Epoch 275/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2761.9082 - val_loss: 6370.7094\n",
      "Epoch 276/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2760.0546 - val_loss: 6370.4901\n",
      "Epoch 277/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2758.2469 - val_loss: 6370.2659\n",
      "Epoch 278/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2756.4964 - val_loss: 6370.1084\n",
      "Epoch 279/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2754.7720 - val_loss: 6370.5361\n",
      "Epoch 280/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2753.0838 - val_loss: 6370.7146\n",
      "Epoch 281/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2751.4421 - val_loss: 6370.8021\n",
      "Epoch 282/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2749.8318 - val_loss: 6370.9947\n",
      "Epoch 283/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2748.2648 - val_loss: 6371.0067\n",
      "Epoch 284/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2746.7323 - val_loss: 6371.1318\n",
      "Epoch 285/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2745.2287 - val_loss: 6371.1298\n",
      "Epoch 286/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2743.7686 - val_loss: 6371.2572\n",
      "Epoch 287/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2742.3421 - val_loss: 6371.3391\n",
      "Epoch 288/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2740.9374 - val_loss: 6367.3268\n",
      "Epoch 289/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2739.6870 - val_loss: 6367.2095\n",
      "Epoch 290/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2738.4714 - val_loss: 6367.6199\n",
      "Epoch 291/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2737.2684 - val_loss: 6367.8664\n",
      "Epoch 292/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2736.1016 - val_loss: 6367.9511\n",
      "Epoch 293/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2734.9634 - val_loss: 6368.2932\n",
      "Epoch 294/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2733.8624 - val_loss: 6368.2223\n",
      "Epoch 295/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2732.7769 - val_loss: 6368.7612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2731.7268 - val_loss: 6368.9228\n",
      "Epoch 297/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2730.6945 - val_loss: 6369.2204\n",
      "Epoch 298/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2729.6956 - val_loss: 6369.2855\n",
      "Epoch 299/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2728.7128 - val_loss: 6369.5610\n",
      "Epoch 300/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2727.7541 - val_loss: 6369.5210\n",
      "Epoch 301/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2726.8189 - val_loss: 6369.7890\n",
      "Epoch 302/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2725.9100 - val_loss: 6370.0337\n",
      "Epoch 303/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2725.0199 - val_loss: 6370.3298\n",
      "Epoch 304/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2724.1543 - val_loss: 6370.2808\n",
      "Epoch 305/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2723.3049 - val_loss: 6370.3891\n",
      "Epoch 306/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2722.4861 - val_loss: 6370.1571\n",
      "Epoch 307/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2721.6697 - val_loss: 6370.2571\n",
      "Epoch 308/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2720.8870 - val_loss: 6370.0398\n",
      "Epoch 309/10000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2720.1148 - val_loss: 6370.1322\n",
      "Train on 244 samples, validate on 82 samples\n",
      "Epoch 1/10000\n",
      "244/244 [==============================] - 86s 352ms/step - loss: 26933.4744 - val_loss: 163545.0157\n",
      "Epoch 2/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26898.1228 - val_loss: 163353.5722\n",
      "Epoch 3/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26839.7415 - val_loss: 163053.2869\n",
      "Epoch 4/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26746.4268 - val_loss: 162574.4624\n",
      "Epoch 5/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26593.5904 - val_loss: 161796.5038\n",
      "Epoch 6/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26346.9477 - val_loss: 160522.4544\n",
      "Epoch 7/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 25975.3631 - val_loss: 158595.4497\n",
      "Epoch 8/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 25448.1886 - val_loss: 155877.1345\n",
      "Epoch 9/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 24737.0951 - val_loss: 152214.5650\n",
      "Epoch 10/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 23825.3491 - val_loss: 147524.0124\n",
      "Epoch 11/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 22716.7272 - val_loss: 141805.6284\n",
      "Epoch 12/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 21440.0114 - val_loss: 135146.1716\n",
      "Epoch 13/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 20037.5076 - val_loss: 127638.6333\n",
      "Epoch 14/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 18566.5370 - val_loss: 119541.1544\n",
      "Epoch 15/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 17114.5583 - val_loss: 111226.7740\n",
      "Epoch 16/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 15758.0120 - val_loss: 103032.9383\n",
      "Epoch 17/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 14552.8235 - val_loss: 95254.7767\n",
      "Epoch 18/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13528.5469 - val_loss: 88108.6232\n",
      "Epoch 19/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12688.3800 - val_loss: 81716.9200\n",
      "Epoch 20/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12015.3258 - val_loss: 76114.1921\n",
      "Epoch 21/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11481.2050 - val_loss: 71267.5696\n",
      "Epoch 22/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11055.0016 - val_loss: 67102.3095\n",
      "Epoch 23/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10708.4715 - val_loss: 63524.6206\n",
      "Epoch 24/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 10418.7286 - val_loss: 60438.1537\n",
      "Epoch 25/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10168.6467 - val_loss: 57753.8466\n",
      "Epoch 26/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9946.0843 - val_loss: 55394.5064\n",
      "Epoch 27/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9742.7517 - val_loss: 53295.8955\n",
      "Epoch 28/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9553.1090 - val_loss: 51405.9712\n",
      "Epoch 29/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9373.5028 - val_loss: 49683.2814\n",
      "Epoch 30/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9201.5323 - val_loss: 48095.2290\n",
      "Epoch 31/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9035.6124 - val_loss: 46616.3160\n",
      "Epoch 32/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8874.6895 - val_loss: 45226.7072\n",
      "Epoch 33/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8718.0536 - val_loss: 43910.9235\n",
      "Epoch 34/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8562.8901 - val_loss: 42673.4165\n",
      "Epoch 35/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8400.3583 - val_loss: 41436.4735\n",
      "Epoch 36/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8237.8273 - val_loss: 40245.1472\n",
      "Epoch 37/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8075.2951 - val_loss: 39076.0031\n",
      "Epoch 38/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7913.5397 - val_loss: 37925.6323\n",
      "Epoch 39/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7753.4332 - val_loss: 36792.9224\n",
      "Epoch 40/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7595.5931 - val_loss: 35677.8956\n",
      "Epoch 41/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7440.4799 - val_loss: 34581.1502\n",
      "Epoch 42/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7288.4602 - val_loss: 33503.5752\n",
      "Epoch 43/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7139.8417 - val_loss: 32446.2210\n",
      "Epoch 44/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6994.8896 - val_loss: 31410.2040\n",
      "Epoch 45/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6853.8381 - val_loss: 30396.6498\n",
      "Epoch 46/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6716.8957 - val_loss: 29406.6138\n",
      "Epoch 47/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6584.2489 - val_loss: 28441.1642\n",
      "Epoch 48/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6456.0639 - val_loss: 27501.2515\n",
      "Epoch 49/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6332.4841 - val_loss: 26587.7505\n",
      "Epoch 50/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6213.6305 - val_loss: 25701.4532\n",
      "Epoch 51/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6099.6024 - val_loss: 24843.0527\n",
      "Epoch 52/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5990.4754 - val_loss: 24013.1580\n",
      "Epoch 53/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5886.2982 - val_loss: 23212.3597\n",
      "Epoch 54/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5787.0978 - val_loss: 22440.9066\n",
      "Epoch 55/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5692.8741 - val_loss: 21699.0384\n",
      "Epoch 56/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5603.5974 - val_loss: 20986.9060\n",
      "Epoch 57/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5519.2180 - val_loss: 20304.5093\n",
      "Epoch 58/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5439.6589 - val_loss: 19651.7462\n",
      "Epoch 59/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5364.8173 - val_loss: 19028.4452\n",
      "Epoch 60/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 5294.5714 - val_loss: 18434.3017\n",
      "Epoch 61/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5229.0024 - val_loss: 17868.2192\n",
      "Epoch 62/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5167.9227 - val_loss: 17330.7258\n",
      "Epoch 63/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5110.9020 - val_loss: 16821.9335\n",
      "Epoch 64/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 5057.7278 - val_loss: 16341.3001\n",
      "Epoch 65/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5008.1689 - val_loss: 15886.5584\n",
      "Epoch 66/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4962.0644 - val_loss: 15457.0912\n",
      "Epoch 67/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4919.1726 - val_loss: 15052.0244\n",
      "Epoch 68/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4879.4649 - val_loss: 14703.8953\n",
      "Epoch 69/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 4841.5021 - val_loss: 14318.7563\n",
      "Epoch 70/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4806.1338 - val_loss: 13966.1231\n",
      "Epoch 71/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4773.4014 - val_loss: 13637.2028\n",
      "Epoch 72/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4742.9619 - val_loss: 13333.5922\n",
      "Epoch 73/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4714.6411 - val_loss: 13053.5315\n",
      "Epoch 74/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4688.5127 - val_loss: 12778.2152\n",
      "Epoch 75/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4663.8139 - val_loss: 12540.3862\n",
      "Epoch 76/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4640.7584 - val_loss: 12306.1597\n",
      "Epoch 77/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4619.0974 - val_loss: 12086.6845\n",
      "Epoch 78/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4598.6111 - val_loss: 11878.3145\n",
      "Epoch 79/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4579.0824 - val_loss: 11697.3982\n",
      "Epoch 80/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4560.8148 - val_loss: 11521.5538\n",
      "Epoch 81/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4543.3586 - val_loss: 11354.1517\n",
      "Epoch 82/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4526.5722 - val_loss: 11195.3055\n",
      "Epoch 83/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4510.3193 - val_loss: 11055.4576\n",
      "Epoch 84/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4495.0831 - val_loss: 10918.4711\n",
      "Epoch 85/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4480.1262 - val_loss: 10787.6611\n",
      "Epoch 86/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4465.6046 - val_loss: 10667.1730\n",
      "Epoch 87/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4451.4962 - val_loss: 10555.8578\n",
      "Epoch 88/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4437.7477 - val_loss: 10452.4937\n",
      "Epoch 89/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 4424.2661 - val_loss: 10362.1279\n",
      "Epoch 90/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4411.2548 - val_loss: 10266.7658\n",
      "Epoch 91/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4398.3385 - val_loss: 10173.1134\n",
      "Epoch 92/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4385.5755 - val_loss: 10092.2894\n",
      "Epoch 93/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4373.0133 - val_loss: 10017.1022\n",
      "Epoch 94/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4360.4770 - val_loss: 9952.1301\n",
      "Epoch 95/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4348.4464 - val_loss: 9880.3952\n",
      "Epoch 96/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4336.3140 - val_loss: 9808.7304\n",
      "Epoch 97/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4324.2521 - val_loss: 9747.6131\n",
      "Epoch 98/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4312.2805 - val_loss: 9690.5652\n",
      "Epoch 99/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4300.3934 - val_loss: 9636.6820\n",
      "Epoch 100/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4288.4798 - val_loss: 9586.3778\n",
      "Epoch 101/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4276.9427 - val_loss: 9533.6368\n",
      "Epoch 102/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4265.2535 - val_loss: 9484.2231\n",
      "Epoch 103/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4253.6354 - val_loss: 9433.6619\n",
      "Epoch 104/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4242.0247 - val_loss: 9391.2057\n",
      "Epoch 105/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4230.4736 - val_loss: 9350.7545\n",
      "Epoch 106/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4218.8808 - val_loss: 9312.3647\n",
      "Epoch 107/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4207.6061 - val_loss: 9270.5700\n",
      "Epoch 108/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4196.1912 - val_loss: 9227.1477\n",
      "Epoch 109/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4184.7660 - val_loss: 9191.3208\n",
      "Epoch 110/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4173.3834 - val_loss: 9157.2545\n",
      "Epoch 111/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4162.0644 - val_loss: 9120.1332\n",
      "Epoch 112/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4150.6334 - val_loss: 9093.8917\n",
      "Epoch 113/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4139.5528 - val_loss: 9054.5804\n",
      "Epoch 114/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4128.2702 - val_loss: 9022.1028\n",
      "Epoch 115/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4117.0341 - val_loss: 8987.6725\n",
      "Epoch 116/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4105.7998 - val_loss: 8959.4569\n",
      "Epoch 117/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4094.4650 - val_loss: 8936.5856\n",
      "Epoch 118/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4083.5578 - val_loss: 8900.4399\n",
      "Epoch 119/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4072.3879 - val_loss: 8871.0785\n",
      "Epoch 120/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4061.2656 - val_loss: 8839.8766\n",
      "Epoch 121/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4050.1381 - val_loss: 8814.5279\n",
      "Epoch 122/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4039.0412 - val_loss: 8789.8057\n",
      "Epoch 123/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 4027.9664 - val_loss: 8765.7205\n",
      "Epoch 124/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 4017.0439 - val_loss: 8737.3076\n",
      "Epoch 125/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 4006.0370 - val_loss: 8706.9116\n",
      "Epoch 126/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3995.0075 - val_loss: 8682.7703\n",
      "Epoch 127/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3983.8780 - val_loss: 8663.6891\n",
      "Epoch 128/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3973.1892 - val_loss: 8631.9637\n",
      "Epoch 129/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3962.2226 - val_loss: 8606.7060\n",
      "Epoch 130/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3951.2990 - val_loss: 8579.7448\n",
      "Epoch 131/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3940.3745 - val_loss: 8558.1681\n",
      "Epoch 132/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3929.3976 - val_loss: 8541.1154\n",
      "Epoch 133/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3918.7605 - val_loss: 8511.2415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3907.9016 - val_loss: 8487.5606\n",
      "Epoch 135/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3897.0642 - val_loss: 8465.5946\n",
      "Epoch 136/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3886.1361 - val_loss: 8445.1996\n",
      "Epoch 137/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3875.6061 - val_loss: 8420.0077\n",
      "Epoch 138/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3864.8403 - val_loss: 8396.7442\n",
      "Epoch 139/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3854.0986 - val_loss: 8372.0068\n",
      "Epoch 140/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3843.3556 - val_loss: 8352.5320\n",
      "Epoch 141/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3832.6406 - val_loss: 8337.2731\n",
      "Epoch 142/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3822.1133 - val_loss: 8312.6610\n",
      "Epoch 143/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3811.4693 - val_loss: 8286.9580\n",
      "Epoch 144/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3800.6561 - val_loss: 8271.0943\n",
      "Epoch 145/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3790.3396 - val_loss: 8246.5348\n",
      "Epoch 146/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3779.7416 - val_loss: 8224.3384\n",
      "Epoch 147/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3769.1685 - val_loss: 8201.2381\n",
      "Epoch 148/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3758.4910 - val_loss: 8186.9443\n",
      "Epoch 149/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3748.2321 - val_loss: 8163.6073\n",
      "Epoch 150/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3737.7268 - val_loss: 8142.3694\n",
      "Epoch 151/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3727.2311 - val_loss: 8123.1271\n",
      "Epoch 152/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3716.7340 - val_loss: 8108.7387\n",
      "Epoch 153/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3706.5036 - val_loss: 8085.3716\n",
      "Epoch 154/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3696.1030 - val_loss: 8061.7437\n",
      "Epoch 155/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3685.5841 - val_loss: 8047.6662\n",
      "Epoch 156/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3675.5064 - val_loss: 8024.8139\n",
      "Epoch 157/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3665.1638 - val_loss: 8004.5135\n",
      "Epoch 158/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3654.9669 - val_loss: 7994.1071\n",
      "Epoch 159/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3645.2206 - val_loss: 7964.3699\n",
      "Epoch 160/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3634.9070 - val_loss: 7944.1011\n",
      "Epoch 161/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3625.1808 - val_loss: 7917.7552\n",
      "Epoch 162/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3615.1880 - val_loss: 7900.4657\n",
      "Epoch 163/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3605.2820 - val_loss: 7880.0292\n",
      "Epoch 164/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3595.5743 - val_loss: 7853.1364\n",
      "Epoch 165/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3585.7559 - val_loss: 7836.2279\n",
      "Epoch 166/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3575.9534 - val_loss: 7816.5944\n",
      "Epoch 167/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3566.1892 - val_loss: 7794.7487\n",
      "Epoch 168/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3556.6792 - val_loss: 7767.3267\n",
      "Epoch 169/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3546.9332 - val_loss: 7751.0738\n",
      "Epoch 170/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3537.2702 - val_loss: 7732.3959\n",
      "Epoch 171/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3527.6478 - val_loss: 7711.7043\n",
      "Epoch 172/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3518.2712 - val_loss: 7685.4078\n",
      "Epoch 173/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3508.6603 - val_loss: 7670.7053\n",
      "Epoch 174/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3499.1475 - val_loss: 7653.1932\n",
      "Epoch 175/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3489.6790 - val_loss: 7633.6553\n",
      "Epoch 176/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3480.2476 - val_loss: 7613.3384\n",
      "Epoch 177/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3471.1404 - val_loss: 7587.3075\n",
      "Epoch 178/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3461.6300 - val_loss: 7574.7228\n",
      "Epoch 179/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3452.3210 - val_loss: 7559.0523\n",
      "Epoch 180/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3443.0585 - val_loss: 7541.1413\n",
      "Epoch 181/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3433.8354 - val_loss: 7522.2817\n",
      "Epoch 182/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3424.8957 - val_loss: 7497.0376\n",
      "Epoch 183/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3415.6222 - val_loss: 7485.3458\n",
      "Epoch 184/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3406.5101 - val_loss: 7486.8293\n",
      "Epoch 185/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3397.5704 - val_loss: 7464.2222\n",
      "Epoch 186/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 3388.5640 - val_loss: 7443.3267\n",
      "Epoch 187/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3379.5959 - val_loss: 7424.3869\n",
      "Epoch 188/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3370.8353 - val_loss: 7397.7621\n",
      "Epoch 189/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3361.8857 - val_loss: 7388.1000\n",
      "Epoch 190/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3353.0584 - val_loss: 7375.7576\n",
      "Epoch 191/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3344.2883 - val_loss: 7360.8947\n",
      "Epoch 192/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3335.5703 - val_loss: 7361.5434\n",
      "Epoch 193/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3327.0119 - val_loss: 7339.3182\n",
      "Epoch 194/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3318.3828 - val_loss: 7319.4961\n",
      "Epoch 195/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3309.7983 - val_loss: 7302.1083\n",
      "Epoch 196/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3301.2674 - val_loss: 7285.9438\n",
      "Epoch 197/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3292.7904 - val_loss: 7270.3105\n",
      "Epoch 198/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3284.3881 - val_loss: 7271.7030\n",
      "Epoch 199/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3276.3108 - val_loss: 7241.0479\n",
      "Epoch 200/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3267.8458 - val_loss: 7230.6375\n",
      "Epoch 201/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3260.6656 - val_loss: 7248.1647\n",
      "Epoch 202/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3252.0265 - val_loss: 7194.8874\n",
      "Epoch 203/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3243.2425 - val_loss: 7192.8092\n",
      "Epoch 204/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3235.1183 - val_loss: 7178.5119\n",
      "Epoch 205/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3227.0403 - val_loss: 7175.1470\n",
      "Epoch 206/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3219.1700 - val_loss: 7149.4854\n",
      "Epoch 207/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3211.0933 - val_loss: 7129.7119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3203.1690 - val_loss: 7134.4879\n",
      "Epoch 209/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3195.5123 - val_loss: 7124.3228\n",
      "Epoch 210/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3187.7131 - val_loss: 7101.3580\n",
      "Epoch 211/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3179.9136 - val_loss: 7096.4405\n",
      "Epoch 212/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3172.3573 - val_loss: 7094.4140\n",
      "Epoch 213/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3164.9072 - val_loss: 7070.7043\n",
      "Epoch 214/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3157.3109 - val_loss: 7063.9536\n",
      "Epoch 215/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3149.9154 - val_loss: 7044.8122\n",
      "Epoch 216/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3142.4368 - val_loss: 7047.5660\n",
      "Epoch 217/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3135.2907 - val_loss: 7036.2078\n",
      "Epoch 218/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3128.0379 - val_loss: 7015.4840\n",
      "Epoch 219/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3120.7393 - val_loss: 7002.1500\n",
      "Epoch 220/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3113.7475 - val_loss: 7013.1424\n",
      "Epoch 221/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3106.7089 - val_loss: 6990.8619\n",
      "Epoch 222/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3099.7019 - val_loss: 6987.3775\n",
      "Epoch 223/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3092.7215 - val_loss: 6985.8706\n",
      "Epoch 224/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3086.0549 - val_loss: 6962.7992\n",
      "Epoch 225/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3079.1386 - val_loss: 6948.5555\n",
      "Epoch 226/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3072.4540 - val_loss: 6942.2576\n",
      "Epoch 227/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3065.7790 - val_loss: 6945.3029\n",
      "Epoch 228/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3059.2593 - val_loss: 6938.0874\n",
      "Epoch 229/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3052.6808 - val_loss: 6918.0229\n",
      "Epoch 230/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3046.2558 - val_loss: 6921.5212\n",
      "Epoch 231/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3039.8865 - val_loss: 6909.2696\n",
      "Epoch 232/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3033.4694 - val_loss: 6894.0093\n",
      "Epoch 233/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3027.4121 - val_loss: 6905.0084\n",
      "Epoch 234/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3021.1263 - val_loss: 6885.0613\n",
      "Epoch 235/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3015.0157 - val_loss: 6893.6609\n",
      "Epoch 236/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3009.0393 - val_loss: 6873.2243\n",
      "Epoch 237/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3003.0822 - val_loss: 6865.7863\n",
      "Epoch 238/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2996.9936 - val_loss: 6875.8820\n",
      "Epoch 239/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2991.3466 - val_loss: 6853.5438\n",
      "Epoch 240/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 2985.3841 - val_loss: 6847.0460\n",
      "Epoch 241/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2979.7649 - val_loss: 6851.5147\n",
      "Epoch 242/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2974.1441 - val_loss: 6845.7079\n",
      "Epoch 243/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2968.4835 - val_loss: 6848.2768\n",
      "Epoch 244/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2963.2089 - val_loss: 6827.0439\n",
      "Epoch 245/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2957.6407 - val_loss: 6826.1538\n",
      "Epoch 246/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2952.1790 - val_loss: 6829.1142\n",
      "Epoch 247/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2946.9969 - val_loss: 6812.6776\n",
      "Epoch 248/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2941.7739 - val_loss: 6809.1407\n",
      "Epoch 249/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2936.5105 - val_loss: 6819.1221\n",
      "Epoch 250/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2931.4088 - val_loss: 6800.8770\n",
      "Epoch 251/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2926.4740 - val_loss: 6812.7502\n",
      "Epoch 252/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2921.4072 - val_loss: 6799.1136\n",
      "Epoch 253/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2916.3661 - val_loss: 6801.9697\n",
      "Epoch 254/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2911.7873 - val_loss: 6794.4928\n",
      "Epoch 255/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2906.6615 - val_loss: 6806.1002\n",
      "Epoch 256/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2902.3158 - val_loss: 6784.2594\n",
      "Epoch 257/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2897.4175 - val_loss: 6786.7394\n",
      "Epoch 258/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2892.8394 - val_loss: 6792.8339\n",
      "Epoch 259/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2888.3062 - val_loss: 6790.1869\n",
      "Epoch 260/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2883.7837 - val_loss: 6794.3943\n",
      "Epoch 261/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2879.4243 - val_loss: 6786.1919\n",
      "Epoch 262/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2874.9058 - val_loss: 6805.3558\n",
      "Epoch 263/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2870.9865 - val_loss: 6786.0062\n",
      "Epoch 264/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2866.4766 - val_loss: 6777.2321\n",
      "Epoch 265/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2862.3513 - val_loss: 6801.9778\n",
      "Epoch 266/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2858.1563 - val_loss: 6785.3635\n",
      "Epoch 267/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2854.1791 - val_loss: 6806.5789\n",
      "Epoch 268/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2849.9207 - val_loss: 6820.1442\n",
      "Epoch 269/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2846.4245 - val_loss: 6799.4663\n",
      "Epoch 270/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2842.2018 - val_loss: 6793.9696\n",
      "Epoch 271/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2838.3405 - val_loss: 6809.5976\n",
      "Epoch 272/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2834.5716 - val_loss: 6829.2792\n",
      "Epoch 273/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2831.2031 - val_loss: 6820.8748\n",
      "Epoch 274/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2827.6839 - val_loss: 6799.6073\n",
      "Epoch 275/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2824.4436 - val_loss: 6823.7796\n",
      "Epoch 276/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2821.0836 - val_loss: 6825.6586\n",
      "Epoch 277/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2817.9107 - val_loss: 6805.3031\n",
      "Epoch 278/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2814.7486 - val_loss: 6815.4280\n",
      "Epoch 279/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2811.6925 - val_loss: 6801.8815\n",
      "Epoch 280/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2808.7895 - val_loss: 6811.5775\n",
      "Epoch 281/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2805.8056 - val_loss: 6806.8903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2802.7607 - val_loss: 6802.9668\n",
      "Epoch 283/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2800.2704 - val_loss: 6803.4343\n",
      "Epoch 284/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2797.1185 - val_loss: 6812.5262\n",
      "Train on 244 samples, validate on 81 samples\n",
      "Epoch 1/10000\n",
      "244/244 [==============================] - 87s 356ms/step - loss: 26966.2522 - val_loss: 165691.9133\n",
      "Epoch 2/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26956.1585 - val_loss: 165642.6436\n",
      "Epoch 3/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26942.1937 - val_loss: 165569.1638\n",
      "Epoch 4/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26918.6537 - val_loss: 165435.4559\n",
      "Epoch 5/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26878.6487 - val_loss: 165213.3343\n",
      "Epoch 6/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26814.5063 - val_loss: 164854.0505\n",
      "Epoch 7/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26713.9557 - val_loss: 164280.7344\n",
      "Epoch 8/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26555.9232 - val_loss: 163386.7294\n",
      "Epoch 9/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26319.0193 - val_loss: 162057.0312\n",
      "Epoch 10/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 25972.7427 - val_loss: 160133.5643\n",
      "Epoch 11/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 25488.0728 - val_loss: 157462.4099\n",
      "Epoch 12/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 24833.1249 - val_loss: 153879.8578\n",
      "Epoch 13/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 23987.3272 - val_loss: 149261.5809\n",
      "Epoch 14/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 22938.4793 - val_loss: 143559.8746\n",
      "Epoch 15/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 21704.7849 - val_loss: 136829.8505\n",
      "Epoch 16/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 20323.5495 - val_loss: 129208.8737\n",
      "Epoch 17/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 18852.9878 - val_loss: 120930.5631\n",
      "Epoch 18/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 17364.5186 - val_loss: 112292.6454\n",
      "Epoch 19/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 15931.5415 - val_loss: 103615.1161\n",
      "Epoch 20/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 14616.5459 - val_loss: 95205.2526\n",
      "Epoch 21/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13464.3252 - val_loss: 87335.1658\n",
      "Epoch 22/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12497.9173 - val_loss: 80205.8721\n",
      "Epoch 23/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11716.6593 - val_loss: 73917.2408\n",
      "Epoch 24/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11100.7220 - val_loss: 68480.7846\n",
      "Epoch 25/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10620.7955 - val_loss: 63843.9012\n",
      "Epoch 26/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10245.7744 - val_loss: 59915.0915\n",
      "Epoch 27/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 9947.6767 - val_loss: 56586.9790\n",
      "Epoch 28/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9703.9307 - val_loss: 53751.4167\n",
      "Epoch 29/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9497.0983 - val_loss: 51307.2546\n",
      "Epoch 30/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9315.7348 - val_loss: 49188.7787\n",
      "Epoch 31/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9152.9723 - val_loss: 47334.6882\n",
      "Epoch 32/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9003.3805 - val_loss: 45691.8602\n",
      "Epoch 33/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8863.4525 - val_loss: 44217.0928\n",
      "Epoch 34/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8730.8366 - val_loss: 42877.0345\n",
      "Epoch 35/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8604.3180 - val_loss: 41644.5216\n",
      "Epoch 36/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8482.8619 - val_loss: 40501.2384\n",
      "Epoch 37/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8365.5103 - val_loss: 39431.4907\n",
      "Epoch 38/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8251.8276 - val_loss: 38422.6792\n",
      "Epoch 39/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8141.4618 - val_loss: 37465.5517\n",
      "Epoch 40/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8034.0963 - val_loss: 36552.7713\n",
      "Epoch 41/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7929.4943 - val_loss: 35678.5346\n",
      "Epoch 42/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7827.5078 - val_loss: 34837.9323\n",
      "Epoch 43/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7728.0528 - val_loss: 34027.1410\n",
      "Epoch 44/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7631.0104 - val_loss: 33243.4380\n",
      "Epoch 45/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7536.2873 - val_loss: 32484.5423\n",
      "Epoch 46/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7443.7914 - val_loss: 31748.6051\n",
      "Epoch 47/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7353.5114 - val_loss: 31033.8210\n",
      "Epoch 48/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7265.3817 - val_loss: 30339.1987\n",
      "Epoch 49/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7179.3600 - val_loss: 29663.4895\n",
      "Epoch 50/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7095.4319 - val_loss: 29005.5316\n",
      "Epoch 51/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7013.5673 - val_loss: 28364.7920\n",
      "Epoch 52/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6933.7182 - val_loss: 27740.8769\n",
      "Epoch 53/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6855.8580 - val_loss: 27133.3783\n",
      "Epoch 54/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6779.9601 - val_loss: 26541.8009\n",
      "Epoch 55/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6706.0104 - val_loss: 25965.5203\n",
      "Epoch 56/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6633.9865 - val_loss: 25404.2001\n",
      "Epoch 57/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6563.8650 - val_loss: 24857.6618\n",
      "Epoch 58/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6495.6210 - val_loss: 24325.5848\n",
      "Epoch 59/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6429.2365 - val_loss: 23807.7417\n",
      "Epoch 60/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6364.6838 - val_loss: 23303.9095\n",
      "Epoch 61/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6301.9400 - val_loss: 22813.7621\n",
      "Epoch 62/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6240.9886 - val_loss: 22336.9327\n",
      "Epoch 63/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6181.8035 - val_loss: 21873.2378\n",
      "Epoch 64/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6124.3531 - val_loss: 21422.5702\n",
      "Epoch 65/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 6068.6125 - val_loss: 20984.8385\n",
      "Epoch 66/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6014.5512 - val_loss: 20559.7772\n",
      "Epoch 67/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5962.1420 - val_loss: 20147.1484\n",
      "Epoch 68/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5911.3562 - val_loss: 19746.5780\n",
      "Epoch 69/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5862.1571 - val_loss: 19357.9455\n",
      "Epoch 70/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5814.5129 - val_loss: 18981.0964\n",
      "Epoch 71/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 5768.3882 - val_loss: 18615.7959\n",
      "Epoch 72/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5723.7478 - val_loss: 18261.7080\n",
      "Epoch 73/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5680.5537 - val_loss: 17918.7214\n",
      "Epoch 74/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5638.8337 - val_loss: 17586.2907\n",
      "Epoch 75/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5598.6804 - val_loss: 17264.2255\n",
      "Epoch 76/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5560.0562 - val_loss: 16952.6099\n",
      "Epoch 77/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5522.8522 - val_loss: 16651.5988\n",
      "Epoch 78/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5487.1191 - val_loss: 16360.7067\n",
      "Epoch 79/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5452.8535 - val_loss: 16080.0764\n",
      "Epoch 80/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5419.9194 - val_loss: 15810.0313\n",
      "Epoch 81/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5388.0619 - val_loss: 15550.7909\n",
      "Epoch 82/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 5357.1966 - val_loss: 15301.7200\n",
      "Epoch 83/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5327.2879 - val_loss: 15062.0108\n",
      "Epoch 84/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5298.3058 - val_loss: 14831.2359\n",
      "Epoch 85/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5270.1941 - val_loss: 14608.9542\n",
      "Epoch 86/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5242.9170 - val_loss: 14394.6675\n",
      "Epoch 87/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5216.4413 - val_loss: 14188.1713\n",
      "Epoch 88/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5190.7152 - val_loss: 13989.0507\n",
      "Epoch 89/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5165.7088 - val_loss: 13797.2362\n",
      "Epoch 90/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5141.3715 - val_loss: 13612.2913\n",
      "Epoch 91/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5117.6709 - val_loss: 13433.9786\n",
      "Epoch 92/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5094.5689 - val_loss: 13262.1015\n",
      "Epoch 93/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5072.0244 - val_loss: 13096.5013\n",
      "Epoch 94/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5050.0060 - val_loss: 12936.6517\n",
      "Epoch 95/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5028.4838 - val_loss: 12782.5251\n",
      "Epoch 96/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5007.4186 - val_loss: 12633.9779\n",
      "Epoch 97/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4986.7921 - val_loss: 12490.6291\n",
      "Epoch 98/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4966.5796 - val_loss: 12352.2321\n",
      "Epoch 99/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4946.7877 - val_loss: 12218.5676\n",
      "Epoch 100/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4927.3688 - val_loss: 12089.6221\n",
      "Epoch 101/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4908.3028 - val_loss: 11965.1805\n",
      "Epoch 102/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4889.5651 - val_loss: 11845.0638\n",
      "Epoch 103/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4871.1132 - val_loss: 11728.8322\n",
      "Epoch 104/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4852.9051 - val_loss: 11616.7584\n",
      "Epoch 105/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4834.9485 - val_loss: 11508.6250\n",
      "Epoch 106/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4817.2611 - val_loss: 11403.9415\n",
      "Epoch 107/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4799.8071 - val_loss: 11302.8207\n",
      "Epoch 108/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4782.5733 - val_loss: 11205.0421\n",
      "Epoch 109/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4765.5403 - val_loss: 11110.6037\n",
      "Epoch 110/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4748.6847 - val_loss: 11019.4072\n",
      "Epoch 111/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4731.9998 - val_loss: 10931.1513\n",
      "Epoch 112/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4715.4680 - val_loss: 10845.7983\n",
      "Epoch 113/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4699.0841 - val_loss: 10762.7590\n",
      "Epoch 114/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4682.7959 - val_loss: 10682.5232\n",
      "Epoch 115/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4666.6303 - val_loss: 10604.9170\n",
      "Epoch 116/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4650.5810 - val_loss: 10529.7361\n",
      "Epoch 117/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4634.6398 - val_loss: 10456.7695\n",
      "Epoch 118/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4618.8004 - val_loss: 10385.9460\n",
      "Epoch 119/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4603.0565 - val_loss: 10317.2617\n",
      "Epoch 120/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4587.4012 - val_loss: 10250.5228\n",
      "Epoch 121/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4571.8312 - val_loss: 10185.5734\n",
      "Epoch 122/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4556.3390 - val_loss: 10122.4681\n",
      "Epoch 123/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4540.9230 - val_loss: 10061.0603\n",
      "Epoch 124/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4525.5776 - val_loss: 10001.2400\n",
      "Epoch 125/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4510.2972 - val_loss: 9942.9551\n",
      "Epoch 126/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4495.0800 - val_loss: 9886.1170\n",
      "Epoch 127/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4479.9213 - val_loss: 9830.6987\n",
      "Epoch 128/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4464.8188 - val_loss: 9776.6844\n",
      "Epoch 129/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4449.7705 - val_loss: 9724.0078\n",
      "Epoch 130/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4434.7742 - val_loss: 9672.5839\n",
      "Epoch 131/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4423.0289 - val_loss: 9839.5275\n",
      "Epoch 132/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4408.9928 - val_loss: 9696.2168\n",
      "Epoch 133/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4392.8312 - val_loss: 9597.0104\n",
      "Epoch 134/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4377.4744 - val_loss: 9519.7738\n",
      "Epoch 135/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4362.3854 - val_loss: 9455.4075\n",
      "Epoch 136/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4347.4382 - val_loss: 9399.0285\n",
      "Epoch 137/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4332.5848 - val_loss: 9347.9082\n",
      "Epoch 138/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4317.8010 - val_loss: 9300.3833\n",
      "Epoch 139/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4303.0740 - val_loss: 9255.3920\n",
      "Epoch 140/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4288.3966 - val_loss: 9212.3047\n",
      "Epoch 141/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4273.7641 - val_loss: 9170.6985\n",
      "Epoch 142/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4259.1712 - val_loss: 9130.2868\n",
      "Epoch 143/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4244.6157 - val_loss: 9090.8592\n",
      "Epoch 144/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4230.0963 - val_loss: 9052.3184\n",
      "Epoch 145/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4215.6102 - val_loss: 9014.5634\n",
      "Epoch 146/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4201.1570 - val_loss: 8977.5759\n",
      "Epoch 147/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4186.7360 - val_loss: 8941.3008\n",
      "Epoch 148/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4172.3467 - val_loss: 8905.6625\n",
      "Epoch 149/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4157.9882 - val_loss: 8870.6523\n",
      "Epoch 150/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4143.6594 - val_loss: 8836.2501\n",
      "Epoch 151/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4129.3622 - val_loss: 8802.4113\n",
      "Epoch 152/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4115.0959 - val_loss: 8769.1602\n",
      "Epoch 153/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4100.8486 - val_loss: 8736.4582\n",
      "Epoch 154/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4086.6307 - val_loss: 8704.3191\n",
      "Epoch 155/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4072.4432 - val_loss: 8672.7206\n",
      "Epoch 156/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 4058.2840 - val_loss: 8641.5560\n",
      "Epoch 157/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4044.1543 - val_loss: 8610.9000\n",
      "Epoch 158/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4030.0533 - val_loss: 8580.7601\n",
      "Epoch 159/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4015.9845 - val_loss: 8551.0617\n",
      "Epoch 160/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4001.9394 - val_loss: 8521.9656\n",
      "Epoch 161/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3987.9270 - val_loss: 8493.2357\n",
      "Epoch 162/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3973.9449 - val_loss: 8464.9903\n",
      "Epoch 163/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3959.9981 - val_loss: 8436.9775\n",
      "Epoch 164/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3946.0711 - val_loss: 8409.4649\n",
      "Epoch 165/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3932.1761 - val_loss: 8382.4288\n",
      "Epoch 166/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3918.3135 - val_loss: 8355.7618\n",
      "Epoch 167/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3904.4839 - val_loss: 8329.4645\n",
      "Epoch 168/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3890.6899 - val_loss: 8303.5421\n",
      "Epoch 169/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3876.9296 - val_loss: 8277.9796\n",
      "Epoch 170/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3863.2005 - val_loss: 8252.6726\n",
      "Epoch 171/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3849.5039 - val_loss: 8227.5719\n",
      "Epoch 172/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3835.8384 - val_loss: 8202.8687\n",
      "Epoch 173/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3822.2067 - val_loss: 8178.5984\n",
      "Epoch 174/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3808.6128 - val_loss: 8154.7655\n",
      "Epoch 175/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3795.0593 - val_loss: 8131.1076\n",
      "Epoch 176/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3781.5326 - val_loss: 8107.8613\n",
      "Epoch 177/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3768.0441 - val_loss: 8084.9152\n",
      "Epoch 178/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3754.5946 - val_loss: 8062.2583\n",
      "Epoch 179/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3741.1857 - val_loss: 8039.8820\n",
      "Epoch 180/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3727.8176 - val_loss: 8017.8237\n",
      "Epoch 181/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3714.4918 - val_loss: 7996.0327\n",
      "Epoch 182/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3701.2083 - val_loss: 7974.5219\n",
      "Epoch 183/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3687.9691 - val_loss: 7953.2809\n",
      "Epoch 184/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3674.7748 - val_loss: 7932.4730\n",
      "Epoch 185/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3661.5991 - val_loss: 7910.4725\n",
      "Epoch 186/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3648.4081 - val_loss: 7892.5511\n",
      "Epoch 187/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3635.3428 - val_loss: 7874.7073\n",
      "Epoch 188/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3622.3907 - val_loss: 7855.7597\n",
      "Epoch 189/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3609.4284 - val_loss: 7837.1705\n",
      "Epoch 190/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3596.5697 - val_loss: 7818.0383\n",
      "Epoch 191/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3583.7128 - val_loss: 7799.5922\n",
      "Epoch 192/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3570.9526 - val_loss: 7780.8145\n",
      "Epoch 193/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3558.2070 - val_loss: 7763.2639\n",
      "Epoch 194/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3545.5885 - val_loss: 7744.0839\n",
      "Epoch 195/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3532.9452 - val_loss: 7725.9358\n",
      "Epoch 196/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3520.3750 - val_loss: 7708.7613\n",
      "Epoch 197/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3507.8849 - val_loss: 7691.3138\n",
      "Epoch 198/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3495.4627 - val_loss: 7674.9953\n",
      "Epoch 199/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3483.1093 - val_loss: 7657.2631\n",
      "Epoch 200/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3470.7852 - val_loss: 7641.3609\n",
      "Epoch 201/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3458.5829 - val_loss: 7623.8092\n",
      "Epoch 202/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3446.3788 - val_loss: 7607.1533\n",
      "Epoch 203/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3434.2658 - val_loss: 7592.1892\n",
      "Epoch 204/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3422.2477 - val_loss: 7575.6012\n",
      "Epoch 205/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3410.2429 - val_loss: 7559.9156\n",
      "Epoch 206/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3398.3570 - val_loss: 7546.7048\n",
      "Epoch 207/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3386.5696 - val_loss: 7530.1136\n",
      "Epoch 208/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3374.7895 - val_loss: 7514.8784\n",
      "Epoch 209/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3363.0723 - val_loss: 7500.6809\n",
      "Epoch 210/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3351.5156 - val_loss: 7488.4851\n",
      "Epoch 211/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3340.0118 - val_loss: 7473.2056\n",
      "Epoch 212/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3328.5401 - val_loss: 7459.2961\n",
      "Epoch 213/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3317.1833 - val_loss: 7447.2664\n",
      "Epoch 214/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3305.9234 - val_loss: 7433.6503\n",
      "Epoch 215/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3294.7275 - val_loss: 7421.7770\n",
      "Epoch 216/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3283.6581 - val_loss: 7408.4424\n",
      "Epoch 217/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3272.6274 - val_loss: 7397.0535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3261.7502 - val_loss: 7384.1601\n",
      "Epoch 219/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3250.8970 - val_loss: 7373.3428\n",
      "Epoch 220/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3240.2146 - val_loss: 7360.8672\n",
      "Epoch 221/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3229.5488 - val_loss: 7350.5572\n",
      "Epoch 222/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3219.0599 - val_loss: 7338.7165\n",
      "Epoch 223/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3208.5976 - val_loss: 7329.0464\n",
      "Epoch 224/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3198.3023 - val_loss: 7317.8339\n",
      "Epoch 225/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3188.0582 - val_loss: 7308.6534\n",
      "Epoch 226/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3177.9478 - val_loss: 7299.2483\n",
      "Epoch 227/10000\n",
      "244/244 [==============================] - 0s 2ms/step - loss: 3167.8212 - val_loss: 7291.3833\n",
      "Epoch 228/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3157.7700 - val_loss: 7281.6332\n",
      "Epoch 229/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3147.8961 - val_loss: 7274.3161\n",
      "Epoch 230/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3138.0820 - val_loss: 7264.0494\n",
      "Epoch 231/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3128.3579 - val_loss: 7256.2316\n",
      "Epoch 232/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3118.7651 - val_loss: 7247.1127\n",
      "Epoch 233/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3109.3219 - val_loss: 7240.9756\n",
      "Epoch 234/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3099.9677 - val_loss: 7231.5826\n",
      "Epoch 235/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3090.7139 - val_loss: 7225.0235\n",
      "Epoch 236/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3081.5751 - val_loss: 7218.2976\n",
      "Epoch 237/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3072.6104 - val_loss: 7209.7306\n",
      "Epoch 238/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3063.7200 - val_loss: 7204.2327\n",
      "Epoch 239/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3054.9522 - val_loss: 7198.3018\n",
      "Epoch 240/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3046.3307 - val_loss: 7190.6258\n",
      "Epoch 241/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3037.8537 - val_loss: 7186.5085\n",
      "Epoch 242/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3029.4515 - val_loss: 7181.0702\n",
      "Epoch 243/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3021.0450 - val_loss: 7180.4398\n",
      "Epoch 244/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3012.5625 - val_loss: 7174.9231\n",
      "Epoch 245/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3004.2777 - val_loss: 7172.1952\n",
      "Epoch 246/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2996.0098 - val_loss: 7165.8608\n",
      "Epoch 247/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2988.0146 - val_loss: 7163.1262\n",
      "Epoch 248/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2980.0065 - val_loss: 7158.4144\n",
      "Epoch 249/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2972.1784 - val_loss: 7152.4748\n",
      "Epoch 250/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2964.5655 - val_loss: 7150.6891\n",
      "Epoch 251/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2956.9558 - val_loss: 7146.6659\n",
      "Epoch 252/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2949.5530 - val_loss: 7142.9312\n",
      "Epoch 253/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2942.2784 - val_loss: 7138.0345\n",
      "Epoch 254/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2935.2032 - val_loss: 7137.5868\n",
      "Epoch 255/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2928.1462 - val_loss: 7134.7216\n",
      "Epoch 256/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2921.2743 - val_loss: 7131.9089\n",
      "Epoch 257/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2914.5328 - val_loss: 7129.4772\n",
      "Epoch 258/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2907.9241 - val_loss: 7127.3748\n",
      "Epoch 259/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2901.4484 - val_loss: 7125.2613\n",
      "Epoch 260/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2895.1045 - val_loss: 7125.6766\n",
      "Epoch 261/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2888.7320 - val_loss: 7123.5772\n",
      "Epoch 262/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2882.6084 - val_loss: 7125.4042\n",
      "Epoch 263/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2876.4669 - val_loss: 7124.1815\n",
      "Epoch 264/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2870.5217 - val_loss: 7123.0346\n",
      "Epoch 265/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2864.7041 - val_loss: 7123.1958\n",
      "Epoch 266/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2859.0230 - val_loss: 7121.5000\n",
      "Epoch 267/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2853.4586 - val_loss: 7120.4786\n",
      "Epoch 268/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2848.0212 - val_loss: 7120.0020\n",
      "Epoch 269/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2842.7014 - val_loss: 7119.9100\n",
      "Epoch 270/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2837.4987 - val_loss: 7120.1863\n",
      "Epoch 271/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2832.4230 - val_loss: 7121.2618\n",
      "Epoch 272/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2827.4914 - val_loss: 7120.2306\n",
      "Epoch 273/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2822.6627 - val_loss: 7120.2273\n",
      "Epoch 274/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2817.9498 - val_loss: 7120.9788\n",
      "Epoch 275/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2813.3687 - val_loss: 7122.8281\n",
      "Epoch 276/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2808.8987 - val_loss: 7122.5477\n",
      "Epoch 277/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2804.5262 - val_loss: 7123.0888\n",
      "Epoch 278/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2800.2975 - val_loss: 7124.8300\n",
      "Epoch 279/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2796.1728 - val_loss: 7124.9737\n",
      "Epoch 280/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2792.1411 - val_loss: 7126.9694\n",
      "Epoch 281/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2788.2620 - val_loss: 7122.9224\n",
      "Epoch 282/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2784.6075 - val_loss: 7122.7148\n",
      "Epoch 283/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2781.0988 - val_loss: 7124.6567\n",
      "Epoch 284/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2777.6572 - val_loss: 7124.8670\n",
      "Epoch 285/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2774.3577 - val_loss: 7127.2561\n",
      "Epoch 286/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2771.1125 - val_loss: 7127.6827\n",
      "Epoch 287/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2768.0111 - val_loss: 7130.0486\n",
      "Epoch 288/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2764.9612 - val_loss: 7131.7006\n",
      "Epoch 289/10000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2762.0351 - val_loss: 7131.9042\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/10000\n",
      "243/243 [==============================] - 87s 357ms/step - loss: 27057.8714 - val_loss: 165522.3764\n",
      "Epoch 2/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 27003.1358 - val_loss: 165241.9846\n",
      "Epoch 3/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26911.9775 - val_loss: 164743.4319\n",
      "Epoch 4/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26752.9061 - val_loss: 163845.5127\n",
      "Epoch 5/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26484.1625 - val_loss: 162320.8078\n",
      "Epoch 6/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26056.6215 - val_loss: 159935.2914\n",
      "Epoch 7/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 25427.1969 - val_loss: 156449.4960\n",
      "Epoch 8/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 24554.3757 - val_loss: 151636.4625\n",
      "Epoch 9/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 23427.3044 - val_loss: 145445.1307\n",
      "Epoch 10/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 22061.4058 - val_loss: 137896.0400\n",
      "Epoch 11/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 20502.1930 - val_loss: 129098.1135\n",
      "Epoch 12/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 18814.0564 - val_loss: 119303.5309\n",
      "Epoch 13/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 17102.5216 - val_loss: 109014.7116\n",
      "Epoch 14/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 15486.5885 - val_loss: 98788.0928\n",
      "Epoch 15/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 14062.5739 - val_loss: 89137.1249\n",
      "Epoch 16/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12884.6335 - val_loss: 80442.4249\n",
      "Epoch 17/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11959.9848 - val_loss: 72906.1812\n",
      "Epoch 18/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11259.2800 - val_loss: 66560.3685\n",
      "Epoch 19/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10734.9790 - val_loss: 61313.2962\n",
      "Epoch 20/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10337.9644 - val_loss: 57008.0284\n",
      "Epoch 21/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10027.3133 - val_loss: 53468.6531\n",
      "Epoch 22/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9772.8964 - val_loss: 50530.9895\n",
      "Epoch 23/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9549.9308 - val_loss: 48046.1521\n",
      "Epoch 24/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9344.5359 - val_loss: 45901.0429\n",
      "Epoch 25/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9149.7998 - val_loss: 44003.0121\n",
      "Epoch 26/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8963.2086 - val_loss: 42288.8361\n",
      "Epoch 27/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8783.7193 - val_loss: 40712.4519\n",
      "Epoch 28/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8611.0246 - val_loss: 39248.5427\n",
      "Epoch 29/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8444.3029 - val_loss: 37874.5818\n",
      "Epoch 30/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8283.1024 - val_loss: 36574.5667\n",
      "Epoch 31/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 8127.0512 - val_loss: 35341.7006\n",
      "Epoch 32/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7976.4171 - val_loss: 34159.6165\n",
      "Epoch 33/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7829.1778 - val_loss: 33055.2234\n",
      "Epoch 34/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7685.4028 - val_loss: 31943.2531\n",
      "Epoch 35/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7541.4187 - val_loss: 30878.4582\n",
      "Epoch 36/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7400.2893 - val_loss: 29872.8690\n",
      "Epoch 37/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7263.5119 - val_loss: 28819.9543\n",
      "Epoch 38/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7127.7938 - val_loss: 27813.2157\n",
      "Epoch 39/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6996.5423 - val_loss: 26866.0056\n",
      "Epoch 40/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6868.6762 - val_loss: 25920.4166\n",
      "Epoch 41/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 6751.1349 - val_loss: 25486.7868\n",
      "Epoch 42/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 6639.5218 - val_loss: 24316.2466\n",
      "Epoch 43/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6524.5125 - val_loss: 23690.1649\n",
      "Epoch 44/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6413.4851 - val_loss: 22599.9555\n",
      "Epoch 45/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6299.7954 - val_loss: 21610.1447\n",
      "Epoch 46/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6192.9991 - val_loss: 20805.2234\n",
      "Epoch 47/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6092.7822 - val_loss: 20031.4314\n",
      "Epoch 48/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5998.7339 - val_loss: 19392.4798\n",
      "Epoch 49/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5910.7971 - val_loss: 18707.3661\n",
      "Epoch 50/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5826.1677 - val_loss: 18104.1722\n",
      "Epoch 51/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5745.7395 - val_loss: 17486.4223\n",
      "Epoch 52/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5669.5984 - val_loss: 16992.5735\n",
      "Epoch 53/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5597.0462 - val_loss: 16447.9010\n",
      "Epoch 54/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5527.8137 - val_loss: 15975.0382\n",
      "Epoch 55/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5461.5156 - val_loss: 15517.0016\n",
      "Epoch 56/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5397.9135 - val_loss: 15119.9979\n",
      "Epoch 57/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5337.1726 - val_loss: 14647.7198\n",
      "Epoch 58/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5277.6648 - val_loss: 14324.1912\n",
      "Epoch 59/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5220.5521 - val_loss: 13930.0483\n",
      "Epoch 60/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5164.9743 - val_loss: 13622.6913\n",
      "Epoch 61/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5111.4601 - val_loss: 13298.4490\n",
      "Epoch 62/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5058.7172 - val_loss: 13015.7198\n",
      "Epoch 63/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5007.7134 - val_loss: 12736.7076\n",
      "Epoch 64/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4958.1344 - val_loss: 12468.0219\n",
      "Epoch 65/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4909.0465 - val_loss: 12237.2589\n",
      "Epoch 66/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4860.9246 - val_loss: 12046.3404\n",
      "Epoch 67/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4813.6914 - val_loss: 11802.9859\n",
      "Epoch 68/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4766.6118 - val_loss: 11619.6423\n",
      "Epoch 69/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4720.8274 - val_loss: 11397.6564\n",
      "Epoch 70/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4676.2559 - val_loss: 11256.1547\n",
      "Epoch 71/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 4631.9084 - val_loss: 11063.6658\n",
      "Epoch 72/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4588.5202 - val_loss: 10890.8662\n",
      "Epoch 73/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4545.4613 - val_loss: 10754.7800\n",
      "Epoch 74/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4503.0274 - val_loss: 10633.3033\n",
      "Epoch 75/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 1ms/step - loss: 4461.1349 - val_loss: 10479.8279\n",
      "Epoch 76/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4419.6748 - val_loss: 10346.4795\n",
      "Epoch 77/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4378.7076 - val_loss: 10295.9352\n",
      "Epoch 78/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4337.6828 - val_loss: 10146.9585\n",
      "Epoch 79/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4297.6579 - val_loss: 10010.6497\n",
      "Epoch 80/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4258.0215 - val_loss: 9908.7542\n",
      "Epoch 81/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4218.8593 - val_loss: 9812.1151\n",
      "Epoch 82/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4180.2826 - val_loss: 9741.0951\n",
      "Epoch 83/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4141.9867 - val_loss: 9634.0085\n",
      "Epoch 84/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4104.0874 - val_loss: 9553.9374\n",
      "Epoch 85/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4066.6463 - val_loss: 9459.8349\n",
      "Epoch 86/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4029.6601 - val_loss: 9389.4241\n",
      "Epoch 87/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3993.1079 - val_loss: 9303.5991\n",
      "Epoch 88/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3957.0424 - val_loss: 9239.2195\n",
      "Epoch 89/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3921.2634 - val_loss: 9143.3353\n",
      "Epoch 90/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3886.1952 - val_loss: 9075.5696\n",
      "Epoch 91/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3851.4921 - val_loss: 9008.8517\n",
      "Epoch 92/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3817.2379 - val_loss: 8942.5279\n",
      "Epoch 93/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3783.4437 - val_loss: 8877.2645\n",
      "Epoch 94/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3750.1130 - val_loss: 8813.5821\n",
      "Epoch 95/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3717.2512 - val_loss: 8753.3700\n",
      "Epoch 96/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3684.9047 - val_loss: 8702.9904\n",
      "Epoch 97/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3653.0302 - val_loss: 8652.4915\n",
      "Epoch 98/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3621.8571 - val_loss: 8621.9901\n",
      "Epoch 99/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3591.3380 - val_loss: 8573.4421\n",
      "Epoch 100/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3561.0800 - val_loss: 8512.0826\n",
      "Epoch 101/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3531.7423 - val_loss: 8493.4665\n",
      "Epoch 102/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3502.7403 - val_loss: 8425.6965\n",
      "Epoch 103/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3474.4130 - val_loss: 8407.7390\n",
      "Epoch 104/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3446.6732 - val_loss: 8339.3106\n",
      "Epoch 105/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3419.5663 - val_loss: 8324.3413\n",
      "Epoch 106/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3392.9254 - val_loss: 8258.1642\n",
      "Epoch 107/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3367.2451 - val_loss: 8244.8817\n",
      "Epoch 108/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3341.8241 - val_loss: 8226.0209\n",
      "Epoch 109/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3317.3560 - val_loss: 8148.1915\n",
      "Epoch 110/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3293.3505 - val_loss: 8139.3204\n",
      "Epoch 111/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3269.9453 - val_loss: 8123.1194\n",
      "Epoch 112/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3247.2785 - val_loss: 8046.3156\n",
      "Epoch 113/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3225.4059 - val_loss: 8040.0121\n",
      "Epoch 114/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3204.0139 - val_loss: 8024.4077\n",
      "Epoch 115/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3183.2812 - val_loss: 8002.9017\n",
      "Epoch 116/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3163.2218 - val_loss: 7979.8679\n",
      "Epoch 117/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3143.8122 - val_loss: 7898.1604\n",
      "Epoch 118/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3125.2020 - val_loss: 7897.4065\n",
      "Epoch 119/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3107.1432 - val_loss: 7883.6467\n",
      "Epoch 120/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3089.7039 - val_loss: 7863.5088\n",
      "Epoch 121/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3073.1672 - val_loss: 7872.5608\n",
      "Epoch 122/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3056.9039 - val_loss: 7835.0062\n",
      "Epoch 123/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3041.3797 - val_loss: 7807.1711\n",
      "Epoch 124/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3026.4885 - val_loss: 7784.5149\n",
      "Epoch 125/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3012.2109 - val_loss: 7763.0269\n",
      "Epoch 126/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2998.8468 - val_loss: 7771.6240\n",
      "Epoch 127/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2985.6208 - val_loss: 7734.2952\n",
      "Epoch 128/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2973.0693 - val_loss: 7707.3911\n",
      "Epoch 129/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2961.3814 - val_loss: 7714.8951\n",
      "Epoch 130/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2949.8555 - val_loss: 7677.5646\n",
      "Epoch 131/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2938.9095 - val_loss: 7651.2738\n",
      "Epoch 132/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2928.8660 - val_loss: 7658.5146\n",
      "Epoch 133/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2918.7799 - val_loss: 7622.3844\n",
      "Epoch 134/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2909.6274 - val_loss: 7625.7798\n",
      "Epoch 135/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2900.5242 - val_loss: 7592.3081\n",
      "Epoch 136/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2892.2511 - val_loss: 7596.4881\n",
      "Epoch 137/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2884.1238 - val_loss: 7578.6088\n",
      "Epoch 138/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2876.8895 - val_loss: 7584.1343\n",
      "Epoch 139/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2869.4745 - val_loss: 7542.7224\n",
      "Epoch 140/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2863.1547 - val_loss: 7570.3062\n",
      "Epoch 141/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2856.4572 - val_loss: 7521.8013\n",
      "Epoch 142/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2850.8086 - val_loss: 7548.3338\n",
      "Epoch 143/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2844.7984 - val_loss: 7499.2805\n",
      "Epoch 144/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2839.8615 - val_loss: 7526.4572\n",
      "Epoch 145/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2834.3693 - val_loss: 7477.5165\n",
      "Epoch 146/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2830.1603 - val_loss: 7504.8476\n",
      "Epoch 147/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2825.5131 - val_loss: 7510.9019\n",
      "Epoch 148/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2821.1719 - val_loss: 7450.3738\n",
      "Epoch 149/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 1ms/step - loss: 2817.4482 - val_loss: 7479.0146\n",
      "Epoch 150/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2813.2268 - val_loss: 7429.0030\n",
      "Epoch 151/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2810.2971 - val_loss: 7457.4211\n",
      "Epoch 152/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2806.8404 - val_loss: 7462.0752\n",
      "Epoch 153/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2803.2561 - val_loss: 7402.8983\n",
      "Epoch 154/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2800.8585 - val_loss: 7431.7829\n",
      "Epoch 155/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2797.9484 - val_loss: 7436.2223\n",
      "Epoch 156/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2795.2046 - val_loss: 7435.2541\n",
      "Epoch 157/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2792.4901 - val_loss: 7371.6945\n",
      "Epoch 158/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2790.4554 - val_loss: 7402.0660\n",
      "Epoch 159/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2788.1128 - val_loss: 7407.0588\n",
      "Epoch 160/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2785.6561 - val_loss: 7379.0840\n",
      "Epoch 161/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2783.8191 - val_loss: 7372.1036\n",
      "Epoch 162/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2781.9608 - val_loss: 7366.5798\n",
      "Epoch 163/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2780.1022 - val_loss: 7374.5093\n",
      "Epoch 164/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2778.2702 - val_loss: 7374.3839\n",
      "Epoch 165/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2776.1680 - val_loss: 7310.3794\n",
      "Epoch 166/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2775.0519 - val_loss: 7341.7051\n",
      "Epoch 167/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2773.4140 - val_loss: 7344.6861\n",
      "Epoch 168/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2771.8491 - val_loss: 7341.9674\n",
      "Epoch 169/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2770.3450 - val_loss: 7340.0364\n",
      "Epoch 170/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2768.7822 - val_loss: 7315.1132\n",
      "Epoch 171/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2767.2614 - val_loss: 7282.3063\n",
      "Epoch 172/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2766.3037 - val_loss: 7305.5681\n",
      "Epoch 173/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2764.9676 - val_loss: 7306.5147\n",
      "Epoch 174/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2763.6768 - val_loss: 7303.6246\n",
      "Epoch 175/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2762.4210 - val_loss: 7301.7952\n",
      "Epoch 176/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2761.2002 - val_loss: 7300.0820\n",
      "Epoch 177/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2759.6697 - val_loss: 7231.6594\n",
      "Epoch 178/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2758.9917 - val_loss: 7265.2314\n",
      "Epoch 179/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2757.8234 - val_loss: 7267.5919\n",
      "Epoch 180/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2756.6939 - val_loss: 7264.3173\n",
      "Epoch 181/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2755.5867 - val_loss: 7261.9709\n",
      "Epoch 182/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2754.5017 - val_loss: 7260.0746\n",
      "Epoch 183/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2753.4353 - val_loss: 7258.2043\n",
      "Epoch 184/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2752.3083 - val_loss: 7230.3466\n",
      "Epoch 185/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2751.3141 - val_loss: 7220.7406\n",
      "Epoch 186/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2750.3853 - val_loss: 7229.0589\n",
      "Epoch 187/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2749.1654 - val_loss: 7202.5595\n",
      "Epoch 188/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2748.4332 - val_loss: 7216.4271\n",
      "Epoch 189/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2747.4393 - val_loss: 7216.6613\n",
      "Epoch 190/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2746.4617 - val_loss: 7214.4037\n",
      "Epoch 191/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2745.4962 - val_loss: 7212.6517\n",
      "Epoch 192/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2744.4503 - val_loss: 7184.2800\n",
      "Epoch 193/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2743.6217 - val_loss: 7194.9636\n",
      "Epoch 194/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2742.6485 - val_loss: 7173.3531\n",
      "Epoch 195/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2741.7715 - val_loss: 7180.7514\n",
      "Epoch 196/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2740.8480 - val_loss: 7179.7568\n",
      "Epoch 197/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2739.7153 - val_loss: 7152.0313\n",
      "Epoch 198/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2739.0741 - val_loss: 7166.9923\n",
      "Epoch 199/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2738.1645 - val_loss: 7167.5077\n",
      "Epoch 200/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2737.2673 - val_loss: 7165.6263\n",
      "Epoch 201/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2736.3008 - val_loss: 7136.4528\n",
      "Epoch 202/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2735.5208 - val_loss: 7148.0883\n",
      "Epoch 203/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2734.6045 - val_loss: 7126.1682\n",
      "Epoch 204/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2733.7883 - val_loss: 7134.3066\n",
      "Epoch 205/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2732.9213 - val_loss: 7133.5013\n",
      "Epoch 206/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2732.0600 - val_loss: 7131.4252\n",
      "Epoch 207/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2731.2054 - val_loss: 7129.6375\n",
      "Epoch 208/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2730.1227 - val_loss: 7102.2085\n",
      "Epoch 209/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2729.5600 - val_loss: 7118.2333\n",
      "Epoch 210/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2728.6266 - val_loss: 7090.7917\n",
      "Epoch 211/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2727.9006 - val_loss: 7102.8461\n",
      "Epoch 212/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2727.0172 - val_loss: 7081.0135\n",
      "Epoch 213/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2726.2596 - val_loss: 7089.6609\n",
      "Epoch 214/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2725.4352 - val_loss: 7089.2391\n",
      "Epoch 215/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2724.6169 - val_loss: 7087.6106\n",
      "Epoch 216/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2723.8047 - val_loss: 7086.2294\n",
      "Epoch 217/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2722.9972 - val_loss: 7085.0292\n",
      "Epoch 218/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2722.1033 - val_loss: 7055.2878\n",
      "Epoch 219/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2721.4218 - val_loss: 7068.2188\n",
      "Epoch 220/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2720.5633 - val_loss: 7046.1975\n",
      "Epoch 221/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2719.8546 - val_loss: 7055.1994\n",
      "Epoch 222/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2718.8402 - val_loss: 7029.8071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2718.3312 - val_loss: 7045.2985\n",
      "Epoch 224/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2717.5449 - val_loss: 7046.1318\n",
      "Epoch 225/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2716.7683 - val_loss: 7044.7749\n",
      "Epoch 226/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2715.9971 - val_loss: 7043.9486\n",
      "Epoch 227/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2715.1542 - val_loss: 7014.1723\n",
      "Epoch 228/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2714.4953 - val_loss: 7027.9530\n",
      "Epoch 229/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2713.6776 - val_loss: 7005.9253\n",
      "Epoch 230/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2713.0002 - val_loss: 7015.6204\n",
      "Epoch 231/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2712.2474 - val_loss: 7015.2664\n",
      "Epoch 232/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2711.4995 - val_loss: 7014.0466\n",
      "Epoch 233/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2710.7563 - val_loss: 7013.2316\n",
      "Epoch 234/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2709.8101 - val_loss: 6986.4684\n",
      "Epoch 235/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2709.3301 - val_loss: 7003.7911\n",
      "Epoch 236/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2708.5379 - val_loss: 6975.3466\n",
      "Epoch 237/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2707.8895 - val_loss: 6989.3840\n",
      "Epoch 238/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2707.1198 - val_loss: 6967.4109\n",
      "Epoch 239/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2706.4607 - val_loss: 6977.9034\n",
      "Epoch 240/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2705.7406 - val_loss: 6977.9379\n",
      "Epoch 241/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2705.0244 - val_loss: 6977.2487\n",
      "Epoch 242/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2704.3125 - val_loss: 6976.9243\n",
      "Epoch 243/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2703.4397 - val_loss: 6942.0985\n",
      "Epoch 244/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2702.7397 - val_loss: 6955.4051\n",
      "Epoch 245/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2701.8484 - val_loss: 6933.0083\n",
      "Epoch 246/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2701.1225 - val_loss: 6942.5928\n",
      "Epoch 247/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2700.3051 - val_loss: 6941.9092\n",
      "Epoch 248/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2699.4867 - val_loss: 6940.5482\n",
      "Epoch 249/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2698.4622 - val_loss: 6913.9568\n",
      "Epoch 250/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2697.8924 - val_loss: 6931.6824\n",
      "Epoch 251/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2697.0409 - val_loss: 6902.9007\n",
      "Epoch 252/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2696.3132 - val_loss: 6917.5269\n",
      "Epoch 253/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2695.4900 - val_loss: 6895.5498\n",
      "Epoch 254/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2694.7401 - val_loss: 6906.5039\n",
      "Epoch 255/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2693.9433 - val_loss: 6906.9794\n",
      "Epoch 256/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2693.5268 - val_loss: 6924.3876\n",
      "Epoch 257/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2692.6743 - val_loss: 6880.0497\n",
      "Epoch 258/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2692.3972 - val_loss: 6911.7089\n",
      "Epoch 259/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2691.5395 - val_loss: 6875.5322\n",
      "Epoch 260/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2691.2576 - val_loss: 6902.8813\n",
      "Epoch 261/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2690.2930 - val_loss: 6880.7616\n",
      "Epoch 262/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2690.1743 - val_loss: 6910.8560\n",
      "Epoch 263/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2689.3684 - val_loss: 6862.9436\n",
      "Epoch 264/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2689.1198 - val_loss: 6898.5364\n",
      "Epoch 265/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2688.3440 - val_loss: 6872.8228\n",
      "Epoch 266/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2687.8569 - val_loss: 6871.1772\n",
      "Epoch 267/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2687.2308 - val_loss: 6866.8796\n",
      "Epoch 268/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2686.5742 - val_loss: 6837.3460\n",
      "Epoch 269/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2686.5716 - val_loss: 6899.2309\n",
      "Epoch 270/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2685.6952 - val_loss: 6838.2295\n",
      "Epoch 271/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2685.3017 - val_loss: 6873.7353\n",
      "Epoch 272/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2684.4150 - val_loss: 6825.2179\n",
      "Epoch 273/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2684.0462 - val_loss: 6856.2231\n",
      "Epoch 274/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2683.1136 - val_loss: 6818.3696\n",
      "Epoch 275/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2682.7291 - val_loss: 6846.3238\n",
      "Epoch 276/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2681.6407 - val_loss: 6804.3323\n",
      "Epoch 277/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2681.9088 - val_loss: 6866.1926\n",
      "Epoch 278/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2680.5878 - val_loss: 6795.7240\n",
      "Epoch 279/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2680.3075 - val_loss: 6840.0303\n",
      "Epoch 280/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2679.4486 - val_loss: 6790.4137\n",
      "Epoch 281/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2678.8601 - val_loss: 6832.0513\n",
      "Epoch 282/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2678.3416 - val_loss: 6802.8944\n",
      "Epoch 283/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2677.3781 - val_loss: 6777.6939\n",
      "Epoch 284/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2677.3234 - val_loss: 6844.5952\n",
      "Epoch 285/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2676.3790 - val_loss: 6752.6878\n",
      "Epoch 286/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2675.9809 - val_loss: 6832.0614\n",
      "Epoch 287/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2675.5248 - val_loss: 6770.2708\n",
      "Epoch 288/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2674.8553 - val_loss: 6802.3846\n",
      "Epoch 289/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2674.1724 - val_loss: 6801.2289\n",
      "Epoch 290/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2674.0417 - val_loss: 6815.9254\n",
      "Epoch 291/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2673.2951 - val_loss: 6755.5198\n",
      "Epoch 292/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2673.0770 - val_loss: 6796.6661\n",
      "Epoch 293/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2672.1874 - val_loss: 6749.3233\n",
      "Epoch 294/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2672.6818 - val_loss: 6808.7471\n",
      "Epoch 295/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2671.5236 - val_loss: 6764.9653\n",
      "Epoch 296/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2671.2636 - val_loss: 6789.3725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2670.6864 - val_loss: 6757.1134\n",
      "Epoch 298/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2670.4770 - val_loss: 6786.8342\n",
      "Epoch 299/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2669.9123 - val_loss: 6733.7634\n",
      "Epoch 300/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2669.5012 - val_loss: 6770.9418\n",
      "Epoch 301/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2668.9022 - val_loss: 6743.8756\n",
      "Epoch 302/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2669.1072 - val_loss: 6809.6622\n",
      "Epoch 303/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2668.3378 - val_loss: 6703.1296\n",
      "Epoch 304/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2668.0318 - val_loss: 6776.5789\n",
      "Epoch 305/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2667.1176 - val_loss: 6716.1207\n",
      "Epoch 306/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2667.6401 - val_loss: 6799.1287\n",
      "Epoch 307/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2666.9146 - val_loss: 6738.3659\n",
      "Epoch 308/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2665.9419 - val_loss: 6737.0468\n",
      "Epoch 309/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2665.7948 - val_loss: 6747.3922\n",
      "Epoch 310/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2665.1541 - val_loss: 6735.1200\n",
      "Epoch 311/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2664.9564 - val_loss: 6743.3524\n",
      "Epoch 312/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2664.4593 - val_loss: 6716.7128\n",
      "Epoch 313/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2664.5745 - val_loss: 6767.9878\n",
      "Epoch 314/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2664.0261 - val_loss: 6698.5214\n",
      "Epoch 315/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2663.4963 - val_loss: 6736.7680\n",
      "Epoch 316/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2662.9184 - val_loss: 6709.0995\n",
      "Epoch 317/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2662.7415 - val_loss: 6734.8457\n",
      "Epoch 318/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2662.1429 - val_loss: 6706.3385\n",
      "Epoch 319/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2661.8771 - val_loss: 6744.9402\n",
      "Epoch 320/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2661.6945 - val_loss: 6659.9321\n",
      "Epoch 321/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2661.3983 - val_loss: 6733.8210\n",
      "Epoch 322/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2660.5695 - val_loss: 6719.4688\n",
      "Epoch 323/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2660.5066 - val_loss: 6665.1357\n",
      "Epoch 324/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2660.0544 - val_loss: 6705.9000\n",
      "Epoch 325/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2659.6886 - val_loss: 6728.8836\n",
      "Epoch 326/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2659.3930 - val_loss: 6642.5483\n",
      "Epoch 327/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2659.5820 - val_loss: 6743.2595\n",
      "Epoch 328/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2658.7639 - val_loss: 6659.6386\n",
      "Epoch 329/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2658.4569 - val_loss: 6720.9114\n",
      "Epoch 330/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2657.8565 - val_loss: 6651.3655\n",
      "Epoch 331/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2657.7497 - val_loss: 6693.1211\n",
      "Epoch 332/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2657.0020 - val_loss: 6672.5053\n",
      "Epoch 333/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2656.8599 - val_loss: 6707.2187\n",
      "Epoch 334/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2656.6209 - val_loss: 6642.2788\n",
      "Epoch 335/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2656.3746 - val_loss: 6705.7423\n",
      "Epoch 336/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2655.5621 - val_loss: 6635.2241\n",
      "Epoch 337/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2656.1568 - val_loss: 6703.4672\n",
      "Epoch 338/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2655.0834 - val_loss: 6633.8233\n",
      "Epoch 339/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2655.0711 - val_loss: 6673.7613\n",
      "Epoch 340/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2654.2140 - val_loss: 6673.0280\n",
      "Epoch 341/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2654.2595 - val_loss: 6645.7660\n",
      "Epoch 342/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2653.6939 - val_loss: 6670.5388\n",
      "Epoch 343/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2653.5602 - val_loss: 6666.7335\n",
      "Epoch 344/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2652.9584 - val_loss: 6615.3227\n",
      "Epoch 345/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2653.1538 - val_loss: 6681.4110\n",
      "Epoch 346/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2652.3296 - val_loss: 6642.0192\n",
      "Epoch 347/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2652.1660 - val_loss: 6628.3809\n",
      "Epoch 348/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2651.7932 - val_loss: 6653.8635\n",
      "Epoch 349/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2651.6351 - val_loss: 6650.1756\n",
      "Epoch 350/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2650.9173 - val_loss: 6631.5446\n",
      "Epoch 351/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2651.1446 - val_loss: 6621.1403\n",
      "Epoch 352/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2650.3896 - val_loss: 6640.4174\n",
      "Epoch 353/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2650.3919 - val_loss: 6646.5663\n",
      "Epoch 354/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2649.8476 - val_loss: 6588.7384\n",
      "Epoch 355/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2649.8627 - val_loss: 6635.2089\n",
      "Epoch 356/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2649.1841 - val_loss: 6633.0687\n",
      "Epoch 357/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2649.0655 - val_loss: 6606.3058\n",
      "Epoch 358/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2648.6638 - val_loss: 6608.3398\n",
      "Epoch 359/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2648.5446 - val_loss: 6648.7102\n",
      "Epoch 360/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2647.9398 - val_loss: 6553.7388\n",
      "Epoch 361/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2648.6245 - val_loss: 6663.5773\n",
      "Epoch 362/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2647.5716 - val_loss: 6574.6129\n",
      "Epoch 363/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2647.4641 - val_loss: 6616.6475\n",
      "Epoch 364/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2646.6313 - val_loss: 6586.0640\n",
      "Epoch 365/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2646.8566 - val_loss: 6615.2249\n",
      "Epoch 366/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2646.0865 - val_loss: 6587.1434\n",
      "Epoch 367/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2646.1076 - val_loss: 6628.1500\n",
      "Epoch 368/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2645.7628 - val_loss: 6539.4587\n",
      "Epoch 369/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2645.8009 - val_loss: 6619.4391\n",
      "Epoch 370/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2644.8612 - val_loss: 6601.5833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 371/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2645.0284 - val_loss: 6548.5749\n",
      "Epoch 372/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2644.5029 - val_loss: 6591.1180\n",
      "Epoch 373/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2644.3880 - val_loss: 6614.9355\n",
      "Epoch 374/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2643.9631 - val_loss: 6525.2479\n",
      "Epoch 375/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2644.4313 - val_loss: 6633.8595\n",
      "Epoch 376/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2643.5165 - val_loss: 6517.6634\n",
      "Epoch 377/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2643.5479 - val_loss: 6600.2649\n",
      "Epoch 378/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2642.6745 - val_loss: 6553.2560\n",
      "Epoch 379/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2642.8473 - val_loss: 6582.4885\n",
      "Epoch 380/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2642.1095 - val_loss: 6560.6046\n",
      "Epoch 381/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2642.1343 - val_loss: 6598.8220\n",
      "Epoch 382/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2641.8037 - val_loss: 6504.6847\n",
      "Epoch 383/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2641.8879 - val_loss: 6588.5952\n",
      "Epoch 384/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2640.8382 - val_loss: 6549.8393\n",
      "Epoch 385/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2641.1776 - val_loss: 6536.0825\n",
      "Epoch 386/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2640.5367 - val_loss: 6562.2949\n",
      "Epoch 387/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2640.5224 - val_loss: 6586.8178\n",
      "Epoch 388/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2640.1497 - val_loss: 6491.8989\n",
      "Epoch 389/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2640.3082 - val_loss: 6576.9278\n",
      "Epoch 390/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2639.3096 - val_loss: 6537.8177\n",
      "Epoch 391/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2639.4701 - val_loss: 6557.6632\n",
      "Epoch 392/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2639.1049 - val_loss: 6526.5985\n",
      "Epoch 393/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2638.9286 - val_loss: 6558.2082\n",
      "Epoch 394/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2638.5300 - val_loss: 6499.8627\n",
      "Epoch 395/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2638.9843 - val_loss: 6593.4308\n",
      "Epoch 396/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2638.3780 - val_loss: 6480.5368\n",
      "Epoch 397/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2638.1366 - val_loss: 6562.3403\n",
      "Epoch 398/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2637.4646 - val_loss: 6493.8610\n",
      "Epoch 399/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2637.7871 - val_loss: 6566.3824\n",
      "Epoch 400/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2637.1314 - val_loss: 6490.6154\n",
      "Epoch 401/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2636.9989 - val_loss: 6534.4662\n",
      "Epoch 402/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2636.3210 - val_loss: 6503.1575\n",
      "Epoch 403/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2636.4739 - val_loss: 6533.3776\n",
      "Epoch 404/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2635.8258 - val_loss: 6505.8014\n",
      "Epoch 405/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2635.8862 - val_loss: 6547.7708\n",
      "Epoch 406/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2635.6183 - val_loss: 6459.0249\n",
      "Epoch 407/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2635.6643 - val_loss: 6540.9358\n",
      "Epoch 408/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2634.7366 - val_loss: 6468.2509\n",
      "Epoch 409/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2635.6367 - val_loss: 6559.8462\n",
      "Epoch 410/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2634.9634 - val_loss: 6473.2455\n",
      "Epoch 411/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2634.1223 - val_loss: 6492.1757\n",
      "Epoch 412/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2634.2632 - val_loss: 6551.9555\n",
      "Epoch 413/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2634.3422 - val_loss: 6464.9062\n",
      "Epoch 414/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2633.6164 - val_loss: 6488.0951\n",
      "Epoch 415/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2633.5023 - val_loss: 6529.5969\n",
      "Epoch 416/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2633.3991 - val_loss: 6439.7183\n",
      "Epoch 417/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2633.4123 - val_loss: 6541.2079\n",
      "Epoch 418/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2633.0512 - val_loss: 6454.6186\n",
      "Epoch 419/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2633.0899 - val_loss: 6508.4098\n",
      "Epoch 420/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2632.3676 - val_loss: 6450.1711\n",
      "Epoch 421/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2632.7054 - val_loss: 6512.9326\n",
      "Epoch 422/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2632.1400 - val_loss: 6467.2581\n",
      "Epoch 423/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2631.9604 - val_loss: 6524.1345\n",
      "Epoch 424/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2632.3020 - val_loss: 6471.1435\n",
      "Epoch 425/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2631.4867 - val_loss: 6495.5525\n",
      "Epoch 426/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2631.2117 - val_loss: 6445.9753\n",
      "Epoch 427/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2631.3091 - val_loss: 6514.8343\n",
      "Epoch 428/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2631.0498 - val_loss: 6415.3865\n",
      "Epoch 429/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2631.5436 - val_loss: 6546.6934\n",
      "Epoch 430/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2631.1850 - val_loss: 6422.9467\n",
      "Epoch 431/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2630.4387 - val_loss: 6509.6809\n",
      "Epoch 432/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2630.3631 - val_loss: 6455.5164\n",
      "Epoch 433/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2629.7170 - val_loss: 6450.9852\n",
      "Epoch 434/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2630.1283 - val_loss: 6504.0647\n",
      "Epoch 435/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2630.0261 - val_loss: 6432.9431\n",
      "Epoch 436/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2628.9919 - val_loss: 6469.4161\n",
      "Epoch 437/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2629.0931 - val_loss: 6442.0014\n",
      "Epoch 438/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2629.3764 - val_loss: 6520.1620\n",
      "Epoch 439/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2629.8830 - val_loss: 6453.3227\n",
      "Epoch 440/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2628.7548 - val_loss: 6426.5598\n",
      "Epoch 441/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2629.1950 - val_loss: 6520.2348\n",
      "Epoch 442/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2628.8900 - val_loss: 6404.9877\n",
      "Epoch 443/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2628.4228 - val_loss: 6490.5347\n",
      "Epoch 444/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2628.1640 - val_loss: 6416.9413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2627.9005 - val_loss: 6506.6122\n",
      "Epoch 446/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2628.1463 - val_loss: 6396.4756\n",
      "Epoch 447/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2627.0575 - val_loss: 6471.7822\n",
      "Epoch 448/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2627.0564 - val_loss: 6383.7279\n",
      "Epoch 449/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2628.5766 - val_loss: 6535.3076\n",
      "Epoch 450/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2627.8644 - val_loss: 6393.6892\n",
      "Epoch 451/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2626.2280 - val_loss: 6468.3504\n",
      "Epoch 452/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2626.6018 - val_loss: 6402.9441\n",
      "Epoch 453/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2627.1375 - val_loss: 6540.2094\n",
      "Epoch 454/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2627.7023 - val_loss: 6374.2711\n",
      "Epoch 455/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2625.7269 - val_loss: 6397.9467\n",
      "Epoch 456/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2626.9038 - val_loss: 6529.3114\n",
      "Epoch 457/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2626.7721 - val_loss: 6381.8701\n",
      "Epoch 458/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2625.0661 - val_loss: 6422.9332\n",
      "Epoch 459/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2625.2502 - val_loss: 6431.5368\n",
      "Epoch 460/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2624.9630 - val_loss: 6465.8872\n",
      "Epoch 461/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2625.5580 - val_loss: 6396.6577\n",
      "Epoch 462/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2624.7752 - val_loss: 6455.7282\n",
      "Epoch 463/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2625.0588 - val_loss: 6428.6230\n",
      "Epoch 464/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2624.6940 - val_loss: 6386.2560\n",
      "Epoch 465/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2624.6549 - val_loss: 6414.5148\n",
      "Epoch 466/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2625.3537 - val_loss: 6478.3811\n",
      "Epoch 467/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2624.5163 - val_loss: 6364.8763\n",
      "Epoch 468/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2624.2626 - val_loss: 6496.2942\n",
      "Epoch 469/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2624.7415 - val_loss: 6370.6482\n",
      "Epoch 470/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2623.4021 - val_loss: 6396.9346\n",
      "Epoch 471/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2623.7410 - val_loss: 6475.1634\n",
      "Epoch 472/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2624.2732 - val_loss: 6403.1783\n",
      "Epoch 473/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2623.1979 - val_loss: 6377.2474\n",
      "Epoch 474/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2623.6619 - val_loss: 6473.3002\n",
      "Epoch 475/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2623.3465 - val_loss: 6380.8261\n",
      "Epoch 476/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2622.1080 - val_loss: 6401.6037\n",
      "Epoch 477/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2622.3727 - val_loss: 6387.9764\n",
      "Epoch 478/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2622.3323 - val_loss: 6441.0063\n",
      "Epoch 479/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2622.8605 - val_loss: 6392.3764\n",
      "Epoch 480/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2622.1172 - val_loss: 6388.0970\n",
      "Epoch 481/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2622.0639 - val_loss: 6423.1145\n",
      "Epoch 482/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2621.7441 - val_loss: 6383.7890\n",
      "Epoch 483/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2621.3843 - val_loss: 6388.3094\n",
      "Epoch 484/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2621.5317 - val_loss: 6412.2429\n",
      "Epoch 485/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2621.6339 - val_loss: 6421.2594\n",
      "Epoch 486/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2621.8128 - val_loss: 6383.8909\n",
      "Epoch 487/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2621.1177 - val_loss: 6411.6199\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/10000\n",
      "243/243 [==============================] - 87s 360ms/step - loss: 27063.0662 - val_loss: 179205.6783\n",
      "Epoch 2/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 27026.8111 - val_loss: 179008.1844\n",
      "Epoch 3/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26973.3496 - val_loss: 178672.8515\n",
      "Epoch 4/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26878.1151 - val_loss: 178027.0195\n",
      "Epoch 5/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26728.0298 - val_loss: 177063.4451\n",
      "Epoch 6/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26504.7993 - val_loss: 175622.3388\n",
      "Epoch 7/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26169.4046 - val_loss: 173440.7665\n",
      "Epoch 8/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 25673.6277 - val_loss: 170241.9319\n",
      "Epoch 9/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 24967.9216 - val_loss: 165743.3377\n",
      "Epoch 10/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 24009.9364 - val_loss: 159650.3585\n",
      "Epoch 11/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 22753.9847 - val_loss: 151611.6963\n",
      "Epoch 12/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 21185.4309 - val_loss: 141568.0152\n",
      "Epoch 13/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 19364.7000 - val_loss: 129817.7314\n",
      "Epoch 14/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 17417.2988 - val_loss: 116956.1028\n",
      "Epoch 15/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 15501.0777 - val_loss: 103819.1692\n",
      "Epoch 16/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 13783.2053 - val_loss: 91281.9317\n",
      "Epoch 17/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12374.9823 - val_loss: 80056.1322\n",
      "Epoch 18/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11314.2991 - val_loss: 70605.1839\n",
      "Epoch 19/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10566.8125 - val_loss: 63022.4513\n",
      "Epoch 20/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10056.9466 - val_loss: 57119.6367\n",
      "Epoch 21/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9706.7807 - val_loss: 52605.7365\n",
      "Epoch 22/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9455.2917 - val_loss: 49150.2546\n",
      "Epoch 23/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9261.0505 - val_loss: 46462.8836\n",
      "Epoch 24/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9096.4210 - val_loss: 44314.7588\n",
      "Epoch 25/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8937.1637 - val_loss: 42554.2859\n",
      "Epoch 26/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8784.0166 - val_loss: 40981.7334\n",
      "Epoch 27/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8637.9367 - val_loss: 39553.2980\n",
      "Epoch 28/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8495.8671 - val_loss: 38202.1349\n",
      "Epoch 29/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8356.0766 - val_loss: 36994.3348\n",
      "Epoch 30/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8221.0942 - val_loss: 35820.1245\n",
      "Epoch 31/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8089.4523 - val_loss: 34709.0942\n",
      "Epoch 32/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7961.2092 - val_loss: 33658.0731\n",
      "Epoch 33/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7836.7198 - val_loss: 32628.4945\n",
      "Epoch 34/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7715.3096 - val_loss: 31675.3322\n",
      "Epoch 35/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7597.5931 - val_loss: 30733.2442\n",
      "Epoch 36/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7482.6011 - val_loss: 29830.9103\n",
      "Epoch 37/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7370.7520 - val_loss: 28999.4025\n",
      "Epoch 38/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7261.9819 - val_loss: 28154.4035\n",
      "Epoch 39/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7155.3049 - val_loss: 27378.7577\n",
      "Epoch 40/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7052.0285 - val_loss: 26588.4371\n",
      "Epoch 41/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6950.5835 - val_loss: 25829.5753\n",
      "Epoch 42/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6851.5936 - val_loss: 25102.1522\n",
      "Epoch 43/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6754.9750 - val_loss: 24438.9458\n",
      "Epoch 44/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6661.0151 - val_loss: 23756.0583\n",
      "Epoch 45/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6568.8372 - val_loss: 23099.3244\n",
      "Epoch 46/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6478.7972 - val_loss: 22469.5157\n",
      "Epoch 47/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6390.8589 - val_loss: 21863.1486\n",
      "Epoch 48/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6304.9549 - val_loss: 21280.4174\n",
      "Epoch 49/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6221.0091 - val_loss: 20720.0436\n",
      "Epoch 50/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6138.9560 - val_loss: 20180.9352\n",
      "Epoch 51/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6058.6007 - val_loss: 19696.6837\n",
      "Epoch 52/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5980.4733 - val_loss: 19186.3870\n",
      "Epoch 53/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5903.6727 - val_loss: 18697.5258\n",
      "Epoch 54/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5828.5227 - val_loss: 18231.5193\n",
      "Epoch 55/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5754.9894 - val_loss: 17785.8992\n",
      "Epoch 56/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5683.0087 - val_loss: 17358.7999\n",
      "Epoch 57/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5612.5172 - val_loss: 16949.6160\n",
      "Epoch 58/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5543.4608 - val_loss: 16557.3802\n",
      "Epoch 59/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5475.7972 - val_loss: 16177.3800\n",
      "Epoch 60/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5409.5578 - val_loss: 15815.0695\n",
      "Epoch 61/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5344.6244 - val_loss: 15469.8970\n",
      "Epoch 62/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5282.9587 - val_loss: 15336.7103\n",
      "Epoch 63/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5216.5413 - val_loss: 14875.0072\n",
      "Epoch 64/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5151.3540 - val_loss: 14499.2721\n",
      "Epoch 65/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5088.6869 - val_loss: 14172.4013\n",
      "Epoch 66/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5027.6736 - val_loss: 13873.9958\n",
      "Epoch 67/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4967.9987 - val_loss: 13595.8156\n",
      "Epoch 68/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4909.7480 - val_loss: 13364.9165\n",
      "Epoch 69/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4852.6968 - val_loss: 13116.7343\n",
      "Epoch 70/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 4796.6727 - val_loss: 12896.1548\n",
      "Epoch 71/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4741.5495 - val_loss: 12663.7890\n",
      "Epoch 72/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4687.3999 - val_loss: 12460.0175\n",
      "Epoch 73/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4634.0851 - val_loss: 12247.3089\n",
      "Epoch 74/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4581.7583 - val_loss: 12060.8686\n",
      "Epoch 75/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4530.2432 - val_loss: 11880.3296\n",
      "Epoch 76/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 4481.1235 - val_loss: 11758.8414\n",
      "Epoch 77/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4464.3307 - val_loss: 12936.4056\n",
      "Epoch 78/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4422.1101 - val_loss: 11623.3874\n",
      "Epoch 79/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 4351.8324 - val_loss: 11151.5782\n",
      "Epoch 80/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 4296.0093 - val_loss: 10907.4371\n",
      "Epoch 81/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 4243.9739 - val_loss: 10735.8606\n",
      "Epoch 82/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4194.1972 - val_loss: 10575.2988\n",
      "Epoch 83/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4146.1768 - val_loss: 10422.2015\n",
      "Epoch 84/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4099.6333 - val_loss: 10311.0921\n",
      "Epoch 85/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4054.6564 - val_loss: 10227.9279\n",
      "Epoch 86/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4012.9362 - val_loss: 10187.4765\n",
      "Epoch 87/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3970.7382 - val_loss: 10064.3234\n",
      "Epoch 88/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3931.1932 - val_loss: 10065.3940\n",
      "Epoch 89/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3891.4814 - val_loss: 9868.3004\n",
      "Epoch 90/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3851.8370 - val_loss: 9809.7747\n",
      "Epoch 91/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3813.8892 - val_loss: 9686.8070\n",
      "Epoch 92/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3777.6109 - val_loss: 9661.2120\n",
      "Epoch 93/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3740.7513 - val_loss: 9531.2046\n",
      "Epoch 94/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3706.2327 - val_loss: 9545.4995\n",
      "Epoch 95/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3670.0233 - val_loss: 9435.4248\n",
      "Epoch 96/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3634.9955 - val_loss: 9366.5374\n",
      "Epoch 97/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3601.0839 - val_loss: 9316.8292\n",
      "Epoch 98/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3567.7691 - val_loss: 9256.5621\n",
      "Epoch 99/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3535.6668 - val_loss: 9227.2627\n",
      "Epoch 100/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3504.4187 - val_loss: 9193.4657\n",
      "Epoch 101/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3473.2204 - val_loss: 9075.8068\n",
      "Epoch 102/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3443.8246 - val_loss: 9072.0300\n",
      "Epoch 103/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3415.3383 - val_loss: 9079.1937\n",
      "Epoch 104/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3387.6544 - val_loss: 8971.2748\n",
      "Epoch 105/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 1ms/step - loss: 3361.3174 - val_loss: 8998.6112\n",
      "Epoch 106/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3335.1782 - val_loss: 8899.0866\n",
      "Epoch 107/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3311.1794 - val_loss: 8968.8219\n",
      "Epoch 108/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3286.4435 - val_loss: 8815.9964\n",
      "Epoch 109/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3265.0420 - val_loss: 8879.8041\n",
      "Epoch 110/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3242.2858 - val_loss: 8842.2836\n",
      "Epoch 111/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3221.2037 - val_loss: 8755.5636\n",
      "Epoch 112/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3202.3935 - val_loss: 8788.8066\n",
      "Epoch 113/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3182.8057 - val_loss: 8761.5494\n",
      "Epoch 114/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3164.5310 - val_loss: 8735.0011\n",
      "Epoch 115/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3147.6756 - val_loss: 8739.4233\n",
      "Epoch 116/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3130.6307 - val_loss: 8644.5382\n",
      "Epoch 117/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3115.8876 - val_loss: 8692.2052\n",
      "Epoch 118/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3100.7301 - val_loss: 8656.7298\n",
      "Epoch 119/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3086.8295 - val_loss: 8619.5465\n",
      "Epoch 120/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3074.1448 - val_loss: 8656.5322\n",
      "Epoch 121/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3061.3314 - val_loss: 8576.3874\n",
      "Epoch 122/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 3049.9689 - val_loss: 8610.1531\n",
      "Epoch 123/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3038.2626 - val_loss: 8594.7560\n",
      "Epoch 124/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3027.5170 - val_loss: 8570.7529\n",
      "Epoch 125/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3017.3853 - val_loss: 8537.0211\n",
      "Epoch 126/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3008.0222 - val_loss: 8499.8014\n",
      "Epoch 127/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2999.6236 - val_loss: 8518.3353\n",
      "Epoch 128/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2991.1282 - val_loss: 8490.0590\n",
      "Epoch 129/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2983.2124 - val_loss: 8483.5551\n",
      "Epoch 130/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2975.8944 - val_loss: 8470.5861\n",
      "Epoch 131/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2968.6619 - val_loss: 8480.7152\n",
      "Epoch 132/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2961.3131 - val_loss: 8427.8659\n",
      "Epoch 133/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2954.9479 - val_loss: 8456.5533\n",
      "Epoch 134/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2948.0380 - val_loss: 8428.3464\n",
      "Epoch 135/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2942.0989 - val_loss: 8435.7773\n",
      "Epoch 136/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2936.3034 - val_loss: 8428.4953\n",
      "Epoch 137/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2930.5095 - val_loss: 8436.5665\n",
      "Epoch 138/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2925.0797 - val_loss: 8396.4063\n",
      "Epoch 139/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2919.7503 - val_loss: 8409.2572\n",
      "Epoch 140/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2914.7450 - val_loss: 8402.9991\n",
      "Epoch 141/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2909.5785 - val_loss: 8373.8058\n",
      "Epoch 142/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2905.1496 - val_loss: 8378.4744\n",
      "Epoch 143/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2900.2879 - val_loss: 8352.1588\n",
      "Epoch 144/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2896.2814 - val_loss: 8390.7994\n",
      "Epoch 145/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2891.4112 - val_loss: 8350.8147\n",
      "Epoch 146/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2887.7466 - val_loss: 8396.6970\n",
      "Epoch 147/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2883.1094 - val_loss: 8345.3162\n",
      "Epoch 148/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2879.2345 - val_loss: 8344.2102\n",
      "Epoch 149/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2875.5713 - val_loss: 8381.5985\n",
      "Epoch 150/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2871.1610 - val_loss: 8316.2816\n",
      "Epoch 151/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2868.0282 - val_loss: 8366.8731\n",
      "Epoch 152/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2863.6836 - val_loss: 8312.0405\n",
      "Epoch 153/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2860.4972 - val_loss: 8341.9878\n",
      "Epoch 154/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2856.5313 - val_loss: 8334.7410\n",
      "Epoch 155/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2852.9952 - val_loss: 8309.4745\n",
      "Epoch 156/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2849.5594 - val_loss: 8318.8731\n",
      "Epoch 157/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2846.0240 - val_loss: 8304.6200\n",
      "Epoch 158/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2842.4697 - val_loss: 8292.8170\n",
      "Epoch 159/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2839.3672 - val_loss: 8325.6133\n",
      "Epoch 160/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2835.4278 - val_loss: 8271.1585\n",
      "Epoch 161/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2832.5995 - val_loss: 8297.7547\n",
      "Epoch 162/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2829.0226 - val_loss: 8317.8680\n",
      "Epoch 163/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2826.5584 - val_loss: 8386.7016\n",
      "Epoch 164/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2821.2421 - val_loss: 8297.8848\n",
      "Epoch 165/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2817.8961 - val_loss: 8282.4214\n",
      "Epoch 166/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2814.3717 - val_loss: 8289.4453\n",
      "Epoch 167/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2810.8536 - val_loss: 8266.4417\n",
      "Epoch 168/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2807.3544 - val_loss: 8254.2803\n",
      "Epoch 169/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2803.8516 - val_loss: 8276.0568\n",
      "Epoch 170/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2800.8737 - val_loss: 8254.5675\n",
      "Epoch 171/10000\n",
      "243/243 [==============================] - 0s 2ms/step - loss: 2797.6831 - val_loss: 8234.7412\n",
      "Epoch 172/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2794.4982 - val_loss: 8208.4530\n",
      "Epoch 173/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2791.6365 - val_loss: 8242.5156\n",
      "Epoch 174/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2788.4182 - val_loss: 8230.5045\n",
      "Epoch 175/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2785.4711 - val_loss: 8267.3743\n",
      "Epoch 176/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2782.3650 - val_loss: 8222.6836\n",
      "Epoch 177/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2779.3039 - val_loss: 8205.8040\n",
      "Epoch 178/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2776.2412 - val_loss: 8197.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2773.1765 - val_loss: 8189.1407\n",
      "Epoch 180/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2770.1215 - val_loss: 8180.9663\n",
      "Epoch 181/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2767.1192 - val_loss: 8186.0484\n",
      "Epoch 182/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2764.2499 - val_loss: 8221.3133\n",
      "Epoch 183/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2761.1959 - val_loss: 8178.7935\n",
      "Epoch 184/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2758.1982 - val_loss: 8163.7490\n",
      "Epoch 185/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2755.1929 - val_loss: 8155.8580\n",
      "Epoch 186/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2752.2712 - val_loss: 8161.1285\n",
      "Epoch 187/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2749.2668 - val_loss: 8147.4017\n",
      "Epoch 188/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2746.3405 - val_loss: 8174.1395\n",
      "Epoch 189/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2743.3128 - val_loss: 8141.3988\n",
      "Epoch 190/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2740.4758 - val_loss: 8188.6087\n",
      "Epoch 191/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2737.5497 - val_loss: 8142.0674\n",
      "Epoch 192/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2734.5759 - val_loss: 8125.6992\n",
      "Epoch 193/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2731.6622 - val_loss: 8130.4146\n",
      "Epoch 194/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2728.7276 - val_loss: 8115.5406\n",
      "Epoch 195/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2725.7666 - val_loss: 8106.1461\n",
      "Epoch 196/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2722.8404 - val_loss: 8111.8974\n",
      "Epoch 197/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2719.9441 - val_loss: 8098.3885\n",
      "Epoch 198/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2717.1829 - val_loss: 8135.3147\n",
      "Epoch 199/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2714.2161 - val_loss: 8097.1218\n",
      "Epoch 200/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2711.3788 - val_loss: 8097.2607\n",
      "Epoch 201/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2708.4499 - val_loss: 8082.2985\n",
      "Epoch 202/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2705.5378 - val_loss: 8073.0646\n",
      "Epoch 203/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2702.7157 - val_loss: 8079.5934\n",
      "Epoch 204/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2699.8122 - val_loss: 8064.7892\n",
      "Epoch 205/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2696.8036 - val_loss: 8107.6434\n",
      "Epoch 206/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2694.3274 - val_loss: 8074.5803\n",
      "Epoch 207/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2691.4224 - val_loss: 8051.2929\n",
      "Epoch 208/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2688.5423 - val_loss: 8055.0350\n",
      "Epoch 209/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2685.7315 - val_loss: 8038.4016\n",
      "Epoch 210/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2682.8363 - val_loss: 8028.1512\n",
      "Epoch 211/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2679.9682 - val_loss: 8033.9418\n",
      "Epoch 212/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2676.9911 - val_loss: 8008.0589\n",
      "Epoch 213/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2674.2791 - val_loss: 8004.7984\n",
      "Epoch 214/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2671.4209 - val_loss: 8012.9812\n",
      "Epoch 215/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2668.5894 - val_loss: 7998.0321\n",
      "Epoch 216/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2665.7450 - val_loss: 8051.3354\n",
      "Epoch 217/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2663.0132 - val_loss: 8012.8789\n",
      "Epoch 218/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2659.9452 - val_loss: 7978.6902\n",
      "Epoch 219/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2657.2138 - val_loss: 7975.3467\n",
      "Epoch 220/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2654.3984 - val_loss: 7983.3607\n",
      "Epoch 221/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2651.4983 - val_loss: 7967.2718\n",
      "Epoch 222/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2648.5647 - val_loss: 7973.0266\n",
      "Epoch 223/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2645.7341 - val_loss: 7957.4383\n",
      "Epoch 224/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2642.7817 - val_loss: 7949.4776\n",
      "Epoch 225/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2639.7342 - val_loss: 7947.9302\n",
      "Epoch 226/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2636.9814 - val_loss: 8003.2932\n",
      "Epoch 227/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2634.3644 - val_loss: 7951.4240\n",
      "Epoch 228/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2631.3694 - val_loss: 7955.5853\n",
      "Epoch 229/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2628.4439 - val_loss: 7939.5204\n",
      "Epoch 230/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2625.4693 - val_loss: 7947.2302\n",
      "Epoch 231/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2622.5946 - val_loss: 7932.5812\n",
      "Epoch 232/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2619.5594 - val_loss: 7909.7601\n",
      "Epoch 233/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2617.1117 - val_loss: 7920.6285\n",
      "Epoch 234/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2614.5892 - val_loss: 7923.0035\n",
      "Epoch 235/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2611.9936 - val_loss: 7920.5465\n",
      "Epoch 236/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2609.5628 - val_loss: 7947.3181\n",
      "Epoch 237/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2607.1068 - val_loss: 7922.6815\n",
      "Epoch 238/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2604.5778 - val_loss: 7920.3657\n",
      "Epoch 239/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2602.0322 - val_loss: 7921.1111\n",
      "Epoch 240/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2599.2672 - val_loss: 7934.1630\n",
      "Epoch 241/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2597.1743 - val_loss: 7927.3106\n",
      "Epoch 242/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2594.5938 - val_loss: 7937.1161\n",
      "Epoch 243/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2592.2090 - val_loss: 7907.2705\n",
      "Epoch 244/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2589.5401 - val_loss: 7920.0074\n",
      "Epoch 245/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2586.9871 - val_loss: 7969.7903\n",
      "Epoch 246/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2584.8342 - val_loss: 7913.5550\n",
      "Epoch 247/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2581.9551 - val_loss: 7929.7272\n",
      "Epoch 248/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2579.6830 - val_loss: 7933.6806\n",
      "Epoch 249/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2577.3040 - val_loss: 7926.5743\n",
      "Epoch 250/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2574.6870 - val_loss: 7959.7932\n",
      "Epoch 251/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2572.3036 - val_loss: 7952.2961\n",
      "Epoch 252/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2569.9647 - val_loss: 7927.3517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 253/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2567.2760 - val_loss: 7939.0893\n",
      "Epoch 254/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2564.8203 - val_loss: 7954.7387\n",
      "Epoch 255/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2562.2779 - val_loss: 7947.6464\n",
      "Epoch 256/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2560.0217 - val_loss: 7959.7233\n",
      "Epoch 257/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2557.5497 - val_loss: 7954.3590\n",
      "Epoch 258/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2555.1701 - val_loss: 7947.4800\n",
      "Epoch 259/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2552.5950 - val_loss: 7952.0872\n",
      "Epoch 260/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2549.9595 - val_loss: 8003.9167\n",
      "Epoch 261/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2547.9916 - val_loss: 7943.4408\n",
      "Epoch 262/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2544.9871 - val_loss: 7970.0040\n",
      "Epoch 263/10000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2542.9201 - val_loss: 7962.4102\n",
      "Train on 242 samples, validate on 81 samples\n",
      "Epoch 1/10000\n",
      "242/242 [==============================] - 90s 371ms/step - loss: 27202.0921 - val_loss: 179357.7174\n",
      "Epoch 2/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 27159.1727 - val_loss: 179100.8463\n",
      "Epoch 3/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 27108.8339 - val_loss: 178813.0089\n",
      "Epoch 4/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 27034.0424 - val_loss: 178323.4869\n",
      "Epoch 5/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 26922.2341 - val_loss: 177599.3962\n",
      "Epoch 6/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 26755.9062 - val_loss: 176471.4878\n",
      "Epoch 7/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 26489.1958 - val_loss: 174621.3439\n",
      "Epoch 8/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 26059.8470 - val_loss: 171703.0176\n",
      "Epoch 9/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 25412.7866 - val_loss: 167403.8060\n",
      "Epoch 10/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 24497.1631 - val_loss: 161403.5944\n",
      "Epoch 11/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 23274.1223 - val_loss: 153426.8565\n",
      "Epoch 12/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 21729.2671 - val_loss: 143319.4006\n",
      "Epoch 13/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 19892.7453 - val_loss: 131226.3943\n",
      "Epoch 14/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 17878.1504 - val_loss: 117758.8912\n",
      "Epoch 15/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 15859.3591 - val_loss: 103776.3300\n",
      "Epoch 16/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 14006.1911 - val_loss: 90077.2134\n",
      "Epoch 17/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12457.1145 - val_loss: 77703.8004\n",
      "Epoch 18/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11297.7332 - val_loss: 67399.0740\n",
      "Epoch 19/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10507.5698 - val_loss: 59374.7907\n",
      "Epoch 20/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9997.4963 - val_loss: 53411.4129\n",
      "Epoch 21/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9666.9777 - val_loss: 49088.3433\n",
      "Epoch 22/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9436.5181 - val_loss: 45970.0053\n",
      "Epoch 23/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9253.2215 - val_loss: 43633.3517\n",
      "Epoch 24/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9097.4806 - val_loss: 42168.9321\n",
      "Epoch 25/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8954.4410 - val_loss: 40486.0419\n",
      "Epoch 26/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8801.8711 - val_loss: 39064.9073\n",
      "Epoch 27/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8653.3586 - val_loss: 37831.9205\n",
      "Epoch 28/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8508.0383 - val_loss: 36678.6080\n",
      "Epoch 29/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8365.4100 - val_loss: 35672.8907\n",
      "Epoch 30/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8224.8402 - val_loss: 34634.0001\n",
      "Epoch 31/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8085.3754 - val_loss: 33689.1518\n",
      "Epoch 32/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7948.4091 - val_loss: 32725.4397\n",
      "Epoch 33/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7812.0092 - val_loss: 31850.2515\n",
      "Epoch 34/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7678.5603 - val_loss: 30957.4012\n",
      "Epoch 35/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7546.3744 - val_loss: 30128.8654\n",
      "Epoch 36/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7416.1097 - val_loss: 29272.5459\n",
      "Epoch 37/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7287.0730 - val_loss: 28449.1866\n",
      "Epoch 38/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7160.0703 - val_loss: 27638.5845\n",
      "Epoch 39/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 7034.2182 - val_loss: 26853.0668\n",
      "Epoch 40/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6910.4016 - val_loss: 26134.6045\n",
      "Epoch 41/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 6788.5418 - val_loss: 25349.0642\n",
      "Epoch 42/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6667.9550 - val_loss: 24629.3135\n",
      "Epoch 43/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6549.5352 - val_loss: 23977.3042\n",
      "Epoch 44/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6433.4571 - val_loss: 23255.5632\n",
      "Epoch 45/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6318.5494 - val_loss: 22599.2890\n",
      "Epoch 46/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6206.0840 - val_loss: 21930.9398\n",
      "Epoch 47/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6095.5541 - val_loss: 21370.0922\n",
      "Epoch 48/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5987.6442 - val_loss: 20737.7344\n",
      "Epoch 49/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5881.2979 - val_loss: 20167.9467\n",
      "Epoch 50/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5777.4934 - val_loss: 19584.3123\n",
      "Epoch 51/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5675.6435 - val_loss: 19062.2831\n",
      "Epoch 52/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5576.7361 - val_loss: 18521.9080\n",
      "Epoch 53/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5479.9935 - val_loss: 18006.4604\n",
      "Epoch 54/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5386.0434 - val_loss: 17594.8136\n",
      "Epoch 55/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 5294.4502 - val_loss: 17110.3442\n",
      "Epoch 56/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5204.7826 - val_loss: 16651.8036\n",
      "Epoch 57/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5117.8868 - val_loss: 16252.6468\n",
      "Epoch 58/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5033.1776 - val_loss: 15835.1854\n",
      "Epoch 59/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4950.9081 - val_loss: 15471.9822\n",
      "Epoch 60/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4871.1156 - val_loss: 15090.8026\n",
      "Epoch 61/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4793.3562 - val_loss: 14731.9005\n",
      "Epoch 62/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4718.1242 - val_loss: 14424.8194\n",
      "Epoch 63/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4645.2312 - val_loss: 14095.4815\n",
      "Epoch 64/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4574.6730 - val_loss: 13822.7250\n",
      "Epoch 65/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4506.4529 - val_loss: 13549.7098\n",
      "Epoch 66/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4440.3351 - val_loss: 13257.0941\n",
      "Epoch 67/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4382.3796 - val_loss: 13259.0694\n",
      "Epoch 68/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4317.6261 - val_loss: 12858.1325\n",
      "Epoch 69/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4254.8503 - val_loss: 12539.9594\n",
      "Epoch 70/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4196.3336 - val_loss: 12341.4352\n",
      "Epoch 71/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4139.8980 - val_loss: 12093.3291\n",
      "Epoch 72/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4085.9173 - val_loss: 11899.2864\n",
      "Epoch 73/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4034.0965 - val_loss: 11691.5554\n",
      "Epoch 74/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3984.2074 - val_loss: 11502.6392\n",
      "Epoch 75/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3937.0607 - val_loss: 11386.2310\n",
      "Epoch 76/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3891.1889 - val_loss: 11204.4477\n",
      "Epoch 77/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3847.5250 - val_loss: 11064.0435\n",
      "Epoch 78/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3805.4928 - val_loss: 10905.6221\n",
      "Epoch 79/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3765.9100 - val_loss: 10815.8730\n",
      "Epoch 80/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3727.4585 - val_loss: 10665.0249\n",
      "Epoch 81/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3690.9324 - val_loss: 10555.1559\n",
      "Epoch 82/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3656.2539 - val_loss: 10455.2352\n",
      "Epoch 83/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3622.9139 - val_loss: 10352.3142\n",
      "Epoch 84/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3591.2049 - val_loss: 10258.7303\n",
      "Epoch 85/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3561.1492 - val_loss: 10164.8292\n",
      "Epoch 86/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3532.1977 - val_loss: 10076.7319\n",
      "Epoch 87/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3505.1541 - val_loss: 9997.7626\n",
      "Epoch 88/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3479.1858 - val_loss: 9944.2549\n",
      "Epoch 89/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3454.1744 - val_loss: 9838.9833\n",
      "Epoch 90/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3431.0719 - val_loss: 9796.1790\n",
      "Epoch 91/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3408.6169 - val_loss: 9723.6243\n",
      "Epoch 92/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3387.6298 - val_loss: 9680.6915\n",
      "Epoch 93/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3367.3318 - val_loss: 9613.4957\n",
      "Epoch 94/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3348.3936 - val_loss: 9549.2569\n",
      "Epoch 95/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3330.5208 - val_loss: 9515.1038\n",
      "Epoch 96/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3313.4112 - val_loss: 9476.5251\n",
      "Epoch 97/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3296.9200 - val_loss: 9417.0844\n",
      "Epoch 98/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3281.4956 - val_loss: 9387.4507\n",
      "Epoch 99/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3266.3723 - val_loss: 9336.7642\n",
      "Epoch 100/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3252.3712 - val_loss: 9321.1730\n",
      "Epoch 101/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3238.4422 - val_loss: 9297.8189\n",
      "Epoch 102/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3225.1600 - val_loss: 9270.2665\n",
      "Epoch 103/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3212.7956 - val_loss: 9261.6570\n",
      "Epoch 104/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3200.6212 - val_loss: 9223.0862\n",
      "Epoch 105/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3189.0772 - val_loss: 9188.8835\n",
      "Epoch 106/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3178.0827 - val_loss: 9158.9563\n",
      "Epoch 107/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3167.5898 - val_loss: 9131.3964\n",
      "Epoch 108/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3157.5683 - val_loss: 9107.4663\n",
      "Epoch 109/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3148.0388 - val_loss: 9094.6751\n",
      "Epoch 110/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3139.0833 - val_loss: 9088.8630\n",
      "Epoch 111/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3130.1130 - val_loss: 9033.1772\n",
      "Epoch 112/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3122.1875 - val_loss: 9037.7600\n",
      "Epoch 113/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3113.6003 - val_loss: 9022.3354\n",
      "Epoch 114/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3105.5330 - val_loss: 8992.8642\n",
      "Epoch 115/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3098.1102 - val_loss: 8988.0575\n",
      "Epoch 116/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3090.4149 - val_loss: 8958.6341\n",
      "Epoch 117/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3083.2274 - val_loss: 8944.7115\n",
      "Epoch 118/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3076.0454 - val_loss: 8918.7697\n",
      "Epoch 119/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3069.4941 - val_loss: 8916.7476\n",
      "Epoch 120/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3062.5822 - val_loss: 8888.3104\n",
      "Epoch 121/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3056.4156 - val_loss: 8893.9493\n",
      "Epoch 122/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3050.5028 - val_loss: 8881.2777\n",
      "Epoch 123/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3044.5088 - val_loss: 8866.0099\n",
      "Epoch 124/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3038.4360 - val_loss: 8831.4721\n",
      "Epoch 125/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3033.6527 - val_loss: 8851.1686\n",
      "Epoch 126/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3027.4896 - val_loss: 8836.2819\n",
      "Epoch 127/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3022.1014 - val_loss: 8831.6222\n",
      "Epoch 128/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3016.4756 - val_loss: 8813.3557\n",
      "Epoch 129/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3011.4410 - val_loss: 8819.4045\n",
      "Epoch 130/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3005.8073 - val_loss: 8797.7750\n",
      "Epoch 131/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 3000.8601 - val_loss: 8781.5524\n",
      "Epoch 132/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2995.8250 - val_loss: 8774.3575\n",
      "Epoch 133/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2991.3930 - val_loss: 8776.0081\n",
      "Epoch 134/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2986.6137 - val_loss: 8761.6045\n",
      "Epoch 135/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2982.1458 - val_loss: 8709.5483\n",
      "Epoch 136/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2978.7875 - val_loss: 8717.6339\n",
      "Epoch 137/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2974.5522 - val_loss: 8697.6919\n",
      "Epoch 138/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2971.2593 - val_loss: 8711.0606\n",
      "Epoch 139/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2967.1243 - val_loss: 8684.9291\n",
      "Epoch 140/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2963.3984 - val_loss: 8665.3082\n",
      "Epoch 141/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2960.0958 - val_loss: 8671.2717\n",
      "Epoch 142/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2956.4039 - val_loss: 8670.2139\n",
      "Epoch 143/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2952.5048 - val_loss: 8639.3811\n",
      "Epoch 144/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2949.5885 - val_loss: 8637.6319\n",
      "Epoch 145/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2946.1025 - val_loss: 8613.5684\n",
      "Epoch 146/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2942.9753 - val_loss: 8605.0632\n",
      "Epoch 147/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2940.1520 - val_loss: 8607.4189\n",
      "Epoch 148/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2936.9878 - val_loss: 8605.4063\n",
      "Epoch 149/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2933.8314 - val_loss: 8600.1470\n",
      "Epoch 150/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2930.3831 - val_loss: 8573.2130\n",
      "Epoch 151/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2927.4533 - val_loss: 8558.5267\n",
      "Epoch 152/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2924.7855 - val_loss: 8564.9184\n",
      "Epoch 153/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2921.7291 - val_loss: 8564.9540\n",
      "Epoch 154/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2918.2912 - val_loss: 8539.7384\n",
      "Epoch 155/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2915.8618 - val_loss: 8551.2934\n",
      "Epoch 156/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2912.4655 - val_loss: 8526.0914\n",
      "Epoch 157/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2909.8393 - val_loss: 8526.5321\n",
      "Epoch 158/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2906.8580 - val_loss: 8524.0237\n",
      "Epoch 159/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2903.8904 - val_loss: 8519.0111\n",
      "Epoch 160/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2900.5748 - val_loss: 8492.4340\n",
      "Epoch 161/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2898.0703 - val_loss: 8494.9403\n",
      "Epoch 162/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2894.8220 - val_loss: 8476.9561\n",
      "Epoch 163/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2892.2225 - val_loss: 8480.1486\n",
      "Epoch 164/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2889.2659 - val_loss: 8479.8612\n",
      "Epoch 165/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2886.1809 - val_loss: 8476.0761\n",
      "Epoch 166/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2883.1527 - val_loss: 8462.4451\n",
      "Epoch 167/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2880.2762 - val_loss: 8449.3179\n",
      "Epoch 168/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2877.5356 - val_loss: 8437.3732\n",
      "Epoch 169/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2874.8795 - val_loss: 8429.1988\n",
      "Epoch 170/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2872.2011 - val_loss: 8423.2045\n",
      "Epoch 171/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2869.1033 - val_loss: 8397.4512\n",
      "Epoch 172/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2866.7778 - val_loss: 8401.6216\n",
      "Epoch 173/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2864.0253 - val_loss: 8401.0471\n",
      "Epoch 174/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2861.2557 - val_loss: 8397.9363\n",
      "Epoch 175/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2858.4698 - val_loss: 8394.5001\n",
      "Epoch 176/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2855.6925 - val_loss: 8391.3558\n",
      "Epoch 177/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2853.0185 - val_loss: 8396.6483\n",
      "Epoch 178/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2850.1249 - val_loss: 8387.5609\n",
      "Epoch 179/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2847.3629 - val_loss: 8381.0063\n",
      "Epoch 180/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2844.6011 - val_loss: 8376.2393\n",
      "Epoch 181/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2841.8387 - val_loss: 8372.6951\n",
      "Epoch 182/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2839.0642 - val_loss: 8369.7275\n",
      "Epoch 183/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2836.2904 - val_loss: 8366.3110\n",
      "Epoch 184/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2833.5149 - val_loss: 8362.2593\n",
      "Epoch 185/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2830.7636 - val_loss: 8358.6476\n",
      "Epoch 186/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2828.0039 - val_loss: 8354.6774\n",
      "Epoch 187/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2825.2523 - val_loss: 8351.7545\n",
      "Epoch 188/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2822.4609 - val_loss: 8349.6050\n",
      "Epoch 189/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2819.8233 - val_loss: 8357.5852\n",
      "Epoch 190/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2816.6848 - val_loss: 8342.5376\n",
      "Epoch 191/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2814.2886 - val_loss: 8351.6303\n",
      "Epoch 192/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2811.3689 - val_loss: 8355.7615\n",
      "Epoch 193/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2807.9033 - val_loss: 8328.2624\n",
      "Epoch 194/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2805.8630 - val_loss: 8335.5992\n",
      "Epoch 195/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2803.2190 - val_loss: 8338.2086\n",
      "Epoch 196/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2800.5612 - val_loss: 8337.2780\n",
      "Epoch 197/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2797.4812 - val_loss: 8306.9203\n",
      "Epoch 198/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2795.4903 - val_loss: 8321.4748\n",
      "Epoch 199/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2792.7494 - val_loss: 8328.6899\n",
      "Epoch 200/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2789.5908 - val_loss: 8310.0135\n",
      "Epoch 201/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2787.4686 - val_loss: 8319.7059\n",
      "Epoch 202/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2784.7121 - val_loss: 8325.5089\n",
      "Epoch 203/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2781.4390 - val_loss: 8296.7875\n",
      "Epoch 204/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2779.5320 - val_loss: 8310.5571\n",
      "Epoch 205/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2776.9516 - val_loss: 8326.7421\n",
      "Epoch 206/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2774.1021 - val_loss: 8324.5389\n",
      "Epoch 207/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2771.3108 - val_loss: 8314.6077\n",
      "Epoch 208/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2768.9916 - val_loss: 8312.8057\n",
      "Epoch 209/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2766.7032 - val_loss: 8322.2240\n",
      "Epoch 210/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2763.5077 - val_loss: 8285.1373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2761.9515 - val_loss: 8305.5277\n",
      "Epoch 212/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2759.2761 - val_loss: 8305.6896\n",
      "Epoch 213/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2756.9700 - val_loss: 8315.9286\n",
      "Epoch 214/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2753.9349 - val_loss: 8289.9592\n",
      "Epoch 215/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2752.2526 - val_loss: 8308.8913\n",
      "Epoch 216/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2749.7500 - val_loss: 8301.7633\n",
      "Epoch 217/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2747.3612 - val_loss: 8286.3595\n",
      "Epoch 218/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2745.6149 - val_loss: 8286.1727\n",
      "Epoch 219/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2743.6611 - val_loss: 8296.5403\n",
      "Epoch 220/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2740.8752 - val_loss: 8268.5753\n",
      "Epoch 221/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2739.6809 - val_loss: 8294.6213\n",
      "Epoch 222/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2737.2011 - val_loss: 8286.1277\n",
      "Epoch 223/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2735.3146 - val_loss: 8291.4804\n",
      "Epoch 224/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2732.8446 - val_loss: 8272.5934\n",
      "Epoch 225/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2731.1315 - val_loss: 8273.5082\n",
      "Epoch 226/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2729.2146 - val_loss: 8285.3784\n",
      "Epoch 227/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2726.4564 - val_loss: 8260.1629\n",
      "Epoch 228/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2725.1071 - val_loss: 8279.8972\n",
      "Epoch 229/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2722.7463 - val_loss: 8279.5407\n",
      "Epoch 230/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2720.8355 - val_loss: 8292.6651\n",
      "Epoch 231/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2718.2781 - val_loss: 8278.1900\n",
      "Epoch 232/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2716.5043 - val_loss: 8283.7104\n",
      "Epoch 233/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2714.5601 - val_loss: 8299.9891\n",
      "Epoch 234/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2711.6968 - val_loss: 8275.7200\n",
      "Epoch 235/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2710.4715 - val_loss: 8297.8913\n",
      "Epoch 236/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2707.8280 - val_loss: 8288.3028\n",
      "Epoch 237/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2706.3157 - val_loss: 8305.7664\n",
      "Epoch 238/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2703.7983 - val_loss: 8302.7884\n",
      "Epoch 239/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2702.1828 - val_loss: 8314.4167\n",
      "Epoch 240/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2699.5825 - val_loss: 8299.8971\n",
      "Epoch 241/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2698.1411 - val_loss: 8316.3103\n",
      "Epoch 242/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2696.0520 - val_loss: 8323.9635\n",
      "Epoch 243/10000\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 2693.5700 - val_loss: 8307.3000\n",
      "Epoch 244/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2692.1486 - val_loss: 8321.4088\n",
      "Epoch 245/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2689.7124 - val_loss: 8303.8035\n",
      "Epoch 246/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2688.3051 - val_loss: 8316.8297\n",
      "Epoch 247/10000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2685.8367 - val_loss: 8300.3040\n",
      "Train on 241 samples, validate on 81 samples\n",
      "Epoch 1/10000\n",
      "241/241 [==============================] - 88s 365ms/step - loss: 27295.8912 - val_loss: 179303.0502\n",
      "Epoch 2/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 27254.4911 - val_loss: 179027.2580\n",
      "Epoch 3/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 27172.2005 - val_loss: 178449.2536\n",
      "Epoch 4/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 27020.9327 - val_loss: 177427.6868\n",
      "Epoch 5/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 26786.3280 - val_loss: 175900.2832\n",
      "Epoch 6/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 26442.2817 - val_loss: 173672.2586\n",
      "Epoch 7/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 25951.2497 - val_loss: 170510.7031\n",
      "Epoch 8/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 25268.6380 - val_loss: 166076.2932\n",
      "Epoch 9/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 24354.6650 - val_loss: 160171.6367\n",
      "Epoch 10/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 23189.9586 - val_loss: 152655.2327\n",
      "Epoch 11/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 21791.3067 - val_loss: 143618.0876\n",
      "Epoch 12/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 20210.4830 - val_loss: 133262.0838\n",
      "Epoch 13/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 18523.3790 - val_loss: 121927.2387\n",
      "Epoch 14/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 16831.3234 - val_loss: 110161.6421\n",
      "Epoch 15/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 15248.9525 - val_loss: 98604.9982\n",
      "Epoch 16/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 13872.3201 - val_loss: 87857.9237\n",
      "Epoch 17/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 12756.4043 - val_loss: 78371.4987\n",
      "Epoch 18/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 11907.6610 - val_loss: 70380.4626\n",
      "Epoch 19/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 11292.9136 - val_loss: 63901.4632\n",
      "Epoch 20/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 10858.7262 - val_loss: 58788.5853\n",
      "Epoch 21/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 10550.4536 - val_loss: 54812.4320\n",
      "Epoch 22/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 10323.6629 - val_loss: 51727.5716\n",
      "Epoch 23/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 10147.1192 - val_loss: 49314.7843\n",
      "Epoch 24/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 10000.8258 - val_loss: 47395.5142\n",
      "Epoch 25/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 9872.4125 - val_loss: 45820.2155\n",
      "Epoch 26/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 9754.0731 - val_loss: 44494.6657\n",
      "Epoch 27/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 9641.6353 - val_loss: 43356.4673\n",
      "Epoch 28/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 9533.7923 - val_loss: 42351.5158\n",
      "Epoch 29/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 9429.5659 - val_loss: 41479.8648\n",
      "Epoch 30/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 9325.8966 - val_loss: 40673.9133\n",
      "Epoch 31/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 9220.9899 - val_loss: 39918.8980\n",
      "Epoch 32/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 9116.5604 - val_loss: 39197.9312\n",
      "Epoch 33/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 9013.8340 - val_loss: 38586.3508\n",
      "Epoch 34/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 8909.4033 - val_loss: 37875.2157\n",
      "Epoch 35/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 8804.3902 - val_loss: 37186.7687\n",
      "Epoch 36/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 8699.9789 - val_loss: 36539.2299\n",
      "Epoch 37/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/241 [==============================] - 0s 1ms/step - loss: 8596.2229 - val_loss: 35890.5269\n",
      "Epoch 38/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 8492.6774 - val_loss: 35268.7142\n",
      "Epoch 39/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 8389.4892 - val_loss: 34664.7325\n",
      "Epoch 40/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 8286.7148 - val_loss: 34072.8610\n",
      "Epoch 41/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 8184.1748 - val_loss: 33487.6314\n",
      "Epoch 42/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 8081.8443 - val_loss: 32902.7418\n",
      "Epoch 43/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7979.5874 - val_loss: 32336.4508\n",
      "Epoch 44/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7877.8560 - val_loss: 31744.6407\n",
      "Epoch 45/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7775.9756 - val_loss: 31208.1105\n",
      "Epoch 46/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7674.8641 - val_loss: 30609.4119\n",
      "Epoch 47/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7573.3747 - val_loss: 30093.0499\n",
      "Epoch 48/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7473.2482 - val_loss: 29510.0859\n",
      "Epoch 49/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7372.6956 - val_loss: 29000.2815\n",
      "Epoch 50/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7273.3147 - val_loss: 28429.5156\n",
      "Epoch 51/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7173.7943 - val_loss: 27937.6666\n",
      "Epoch 52/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 7075.3113 - val_loss: 27377.9876\n",
      "Epoch 53/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6977.1178 - val_loss: 26905.2046\n",
      "Epoch 54/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6879.5419 - val_loss: 26403.2594\n",
      "Epoch 55/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6782.7556 - val_loss: 25906.7834\n",
      "Epoch 56/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6686.6674 - val_loss: 25437.4008\n",
      "Epoch 57/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6591.8881 - val_loss: 24901.5109\n",
      "Epoch 58/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6497.1351 - val_loss: 24472.3435\n",
      "Epoch 59/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6403.6244 - val_loss: 24028.5673\n",
      "Epoch 60/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6311.3054 - val_loss: 23510.3089\n",
      "Epoch 61/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6219.8107 - val_loss: 23155.8181\n",
      "Epoch 62/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6129.9642 - val_loss: 22648.4756\n",
      "Epoch 63/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 6040.0806 - val_loss: 22236.8699\n",
      "Epoch 64/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5952.1180 - val_loss: 21833.4813\n",
      "Epoch 65/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5865.4050 - val_loss: 21434.7743\n",
      "Epoch 66/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5780.0152 - val_loss: 21041.6073\n",
      "Epoch 67/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5696.0091 - val_loss: 20655.3821\n",
      "Epoch 68/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5613.5292 - val_loss: 20210.7501\n",
      "Epoch 69/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5532.1941 - val_loss: 19852.5398\n",
      "Epoch 70/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5451.9202 - val_loss: 19501.5267\n",
      "Epoch 71/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5372.9137 - val_loss: 19611.2110\n",
      "Epoch 72/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5296.2252 - val_loss: 18921.3423\n",
      "Epoch 73/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5210.0912 - val_loss: 18401.4691\n",
      "Epoch 74/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 5129.2913 - val_loss: 17971.2451\n",
      "Epoch 75/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 5055.7148 - val_loss: 17752.5553\n",
      "Epoch 76/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4983.0709 - val_loss: 17429.4223\n",
      "Epoch 77/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4913.9549 - val_loss: 17220.5295\n",
      "Epoch 78/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4847.2610 - val_loss: 16809.3101\n",
      "Epoch 79/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4779.9013 - val_loss: 16593.4929\n",
      "Epoch 80/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 4714.3266 - val_loss: 16149.7761\n",
      "Epoch 81/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4653.7028 - val_loss: 15969.7656\n",
      "Epoch 82/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4592.5957 - val_loss: 15785.5441\n",
      "Epoch 83/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4532.7914 - val_loss: 15476.5302\n",
      "Epoch 84/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4477.0111 - val_loss: 15321.0906\n",
      "Epoch 85/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4420.8524 - val_loss: 14943.9962\n",
      "Epoch 86/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4368.8128 - val_loss: 14784.8625\n",
      "Epoch 87/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4316.9611 - val_loss: 14624.8928\n",
      "Epoch 88/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4266.8675 - val_loss: 14474.2876\n",
      "Epoch 89/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4219.9754 - val_loss: 14136.4405\n",
      "Epoch 90/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4173.7739 - val_loss: 14016.3741\n",
      "Epoch 91/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4128.1610 - val_loss: 13686.4877\n",
      "Epoch 92/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4087.9498 - val_loss: 13563.4849\n",
      "Epoch 93/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4047.3038 - val_loss: 13439.3863\n",
      "Epoch 94/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 4008.3760 - val_loss: 13344.7606\n",
      "Epoch 95/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3969.5927 - val_loss: 13030.8781\n",
      "Epoch 96/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3935.6144 - val_loss: 12925.6505\n",
      "Epoch 97/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3901.9549 - val_loss: 12862.1083\n",
      "Epoch 98/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3867.1036 - val_loss: 12668.2785\n",
      "Epoch 99/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3837.2049 - val_loss: 12607.1793\n",
      "Epoch 100/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3805.6360 - val_loss: 12351.7149\n",
      "Epoch 101/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3779.5327 - val_loss: 12315.4534\n",
      "Epoch 102/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3751.1685 - val_loss: 12268.2152\n",
      "Epoch 103/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3724.3706 - val_loss: 12006.3491\n",
      "Epoch 104/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3701.3057 - val_loss: 11984.3473\n",
      "Epoch 105/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3676.5149 - val_loss: 11953.1965\n",
      "Epoch 106/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3652.9766 - val_loss: 11712.9234\n",
      "Epoch 107/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3633.6024 - val_loss: 11725.4938\n",
      "Epoch 108/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3612.0849 - val_loss: 11720.5997\n",
      "Epoch 109/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3591.5894 - val_loss: 11483.9212\n",
      "Epoch 110/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3574.9403 - val_loss: 11497.5649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3556.1536 - val_loss: 11495.8548\n",
      "Epoch 112/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3538.3126 - val_loss: 11291.2214\n",
      "Epoch 113/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3523.9211 - val_loss: 11283.4036\n",
      "Epoch 114/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3507.6393 - val_loss: 11291.3925\n",
      "Epoch 115/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3492.0277 - val_loss: 11104.5516\n",
      "Epoch 116/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3479.6541 - val_loss: 11128.4193\n",
      "Epoch 117/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3464.4745 - val_loss: 11069.8733\n",
      "Epoch 118/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3451.2797 - val_loss: 10990.6975\n",
      "Epoch 119/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3439.2381 - val_loss: 10934.6027\n",
      "Epoch 120/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3427.8625 - val_loss: 10883.2760\n",
      "Epoch 121/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3416.9909 - val_loss: 10834.5204\n",
      "Epoch 122/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3406.8039 - val_loss: 10809.9607\n",
      "Epoch 123/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3396.7680 - val_loss: 10759.2908\n",
      "Epoch 124/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3387.2012 - val_loss: 10712.4290\n",
      "Epoch 125/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3378.3166 - val_loss: 10691.4080\n",
      "Epoch 126/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3369.3756 - val_loss: 10645.1518\n",
      "Epoch 127/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3361.1710 - val_loss: 10624.4139\n",
      "Epoch 128/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3352.8855 - val_loss: 10579.7264\n",
      "Epoch 129/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3345.2933 - val_loss: 10561.0858\n",
      "Epoch 130/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3337.5416 - val_loss: 10522.0696\n",
      "Epoch 131/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3330.2563 - val_loss: 10508.7412\n",
      "Epoch 132/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3322.9820 - val_loss: 10492.0748\n",
      "Epoch 133/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3315.7609 - val_loss: 10452.0961\n",
      "Epoch 134/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3309.0370 - val_loss: 10438.9311\n",
      "Epoch 135/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3302.3399 - val_loss: 10414.9260\n",
      "Epoch 136/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3295.9711 - val_loss: 10398.5661\n",
      "Epoch 137/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3289.1582 - val_loss: 10326.4518\n",
      "Epoch 138/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3283.6160 - val_loss: 10335.7646\n",
      "Epoch 139/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3277.5722 - val_loss: 10326.9272\n",
      "Epoch 140/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3271.4597 - val_loss: 10294.6753\n",
      "Epoch 141/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3265.9406 - val_loss: 10297.9252\n",
      "Epoch 142/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3260.2061 - val_loss: 10285.0150\n",
      "Epoch 143/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3254.4036 - val_loss: 10251.4103\n",
      "Epoch 144/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3249.1318 - val_loss: 10255.1380\n",
      "Epoch 145/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3243.4285 - val_loss: 10217.4596\n",
      "Epoch 146/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3238.6881 - val_loss: 10218.3574\n",
      "Epoch 147/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3233.6539 - val_loss: 10205.4801\n",
      "Epoch 148/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3228.6883 - val_loss: 10184.2998\n",
      "Epoch 149/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3223.9963 - val_loss: 10173.5032\n",
      "Epoch 150/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3219.2361 - val_loss: 10163.1959\n",
      "Epoch 151/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3214.5156 - val_loss: 10144.4919\n",
      "Epoch 152/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3210.0037 - val_loss: 10134.6970\n",
      "Epoch 153/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3205.6224 - val_loss: 10130.1123\n",
      "Epoch 154/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3201.0737 - val_loss: 10115.5953\n",
      "Epoch 155/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3196.5534 - val_loss: 10096.3314\n",
      "Epoch 156/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3192.1763 - val_loss: 10088.6087\n",
      "Epoch 157/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3187.8713 - val_loss: 10090.5115\n",
      "Epoch 158/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3183.4840 - val_loss: 10087.8862\n",
      "Epoch 159/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3178.8717 - val_loss: 10052.6758\n",
      "Epoch 160/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3174.8392 - val_loss: 10057.5624\n",
      "Epoch 161/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3170.5958 - val_loss: 10044.6597\n",
      "Epoch 162/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3166.6879 - val_loss: 10020.9401\n",
      "Epoch 163/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3162.9553 - val_loss: 10011.7774\n",
      "Epoch 164/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3159.0644 - val_loss: 9992.6659\n",
      "Epoch 165/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3155.3552 - val_loss: 9986.0423\n",
      "Epoch 166/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3151.5534 - val_loss: 9977.8597\n",
      "Epoch 167/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3147.6742 - val_loss: 9958.5814\n",
      "Epoch 168/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3143.9887 - val_loss: 9952.3241\n",
      "Epoch 169/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3140.2259 - val_loss: 9944.6975\n",
      "Epoch 170/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3136.3655 - val_loss: 9925.8516\n",
      "Epoch 171/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3132.7136 - val_loss: 9920.3036\n",
      "Epoch 172/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3128.9963 - val_loss: 9912.9286\n",
      "Epoch 173/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3125.1151 - val_loss: 9886.6592\n",
      "Epoch 174/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3121.4897 - val_loss: 9873.7212\n",
      "Epoch 175/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3118.6043 - val_loss: 9934.2712\n",
      "Epoch 176/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 3114.1920 - val_loss: 9887.6541\n",
      "Epoch 177/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3110.6385 - val_loss: 9869.9823\n",
      "Epoch 178/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3107.1673 - val_loss: 9847.7889\n",
      "Epoch 179/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3103.8970 - val_loss: 9839.9378\n",
      "Epoch 180/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3100.5734 - val_loss: 9830.4694\n",
      "Epoch 181/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3097.2607 - val_loss: 9820.3324\n",
      "Epoch 182/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3093.9557 - val_loss: 9810.0000\n",
      "Epoch 183/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3091.3126 - val_loss: 9851.9724\n",
      "Epoch 184/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3087.0471 - val_loss: 9775.9815\n",
      "Epoch 185/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3084.1224 - val_loss: 9772.1243\n",
      "Epoch 186/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3081.5799 - val_loss: 9830.6831\n",
      "Epoch 187/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3077.1503 - val_loss: 9729.3997\n",
      "Epoch 188/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3075.7300 - val_loss: 9781.0182\n",
      "Epoch 189/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3071.2525 - val_loss: 9765.8650\n",
      "Epoch 190/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3068.0189 - val_loss: 9750.6706\n",
      "Epoch 191/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3065.6188 - val_loss: 9800.5365\n",
      "Epoch 192/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3061.5387 - val_loss: 9746.0140\n",
      "Epoch 193/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3058.4733 - val_loss: 9732.2998\n",
      "Epoch 194/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3055.9781 - val_loss: 9785.4899\n",
      "Epoch 195/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3051.7753 - val_loss: 9705.5233\n",
      "Epoch 196/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3048.8579 - val_loss: 9700.5679\n",
      "Epoch 197/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3046.3883 - val_loss: 9749.5091\n",
      "Epoch 198/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3042.4625 - val_loss: 9701.5808\n",
      "Epoch 199/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3039.3701 - val_loss: 9690.9675\n",
      "Epoch 200/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3037.0232 - val_loss: 9745.2190\n",
      "Epoch 201/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3033.0769 - val_loss: 9691.4196\n",
      "Epoch 202/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3029.9691 - val_loss: 9677.7844\n",
      "Epoch 203/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3027.6744 - val_loss: 9730.9836\n",
      "Epoch 204/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3023.6766 - val_loss: 9676.7776\n",
      "Epoch 205/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3020.5878 - val_loss: 9662.9129\n",
      "Epoch 206/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3018.3804 - val_loss: 9716.5684\n",
      "Epoch 207/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3014.2703 - val_loss: 9662.3452\n",
      "Epoch 208/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3012.0577 - val_loss: 9711.3952\n",
      "Epoch 209/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3008.1385 - val_loss: 9655.8799\n",
      "Epoch 210/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3005.8452 - val_loss: 9704.8476\n",
      "Epoch 211/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 3002.0949 - val_loss: 9653.9813\n",
      "Epoch 212/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2998.9800 - val_loss: 9638.0499\n",
      "Epoch 213/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2996.7295 - val_loss: 9691.4279\n",
      "Epoch 214/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2992.7162 - val_loss: 9636.5834\n",
      "Epoch 215/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2990.4925 - val_loss: 9684.4828\n",
      "Epoch 216/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2986.5914 - val_loss: 9621.3224\n",
      "Epoch 217/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2984.5885 - val_loss: 9664.0366\n",
      "Epoch 218/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2980.9186 - val_loss: 9601.3391\n",
      "Epoch 219/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2978.9746 - val_loss: 9647.9510\n",
      "Epoch 220/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2975.3084 - val_loss: 9585.4951\n",
      "Epoch 221/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2973.4399 - val_loss: 9630.1495\n",
      "Epoch 222/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 2969.7237 - val_loss: 9569.1831\n",
      "Epoch 223/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2967.9042 - val_loss: 9617.1866\n",
      "Epoch 224/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2964.1476 - val_loss: 9555.2421\n",
      "Epoch 225/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2962.4533 - val_loss: 9600.5393\n",
      "Epoch 226/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2958.6029 - val_loss: 9539.4128\n",
      "Epoch 227/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2957.0287 - val_loss: 9585.4219\n",
      "Epoch 228/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2953.0769 - val_loss: 9524.5463\n",
      "Epoch 229/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2951.6467 - val_loss: 9570.6812\n",
      "Epoch 230/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2947.8766 - val_loss: 9535.1802\n",
      "Epoch 231/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2945.8516 - val_loss: 9573.7581\n",
      "Epoch 232/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2942.3475 - val_loss: 9460.7717\n",
      "Epoch 233/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2941.4036 - val_loss: 9519.1266\n",
      "Epoch 234/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2938.1555 - val_loss: 9557.4591\n",
      "Epoch 235/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2934.2281 - val_loss: 9487.2684\n",
      "Epoch 236/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2932.8590 - val_loss: 9530.3820\n",
      "Epoch 237/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 2928.7605 - val_loss: 9467.8806\n",
      "Epoch 238/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2927.6586 - val_loss: 9514.1974\n",
      "Epoch 239/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2924.4537 - val_loss: 9544.3744\n",
      "Epoch 240/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2922.3299 - val_loss: 9501.4158\n",
      "Epoch 241/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2918.9507 - val_loss: 9458.9516\n",
      "Epoch 242/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2917.4402 - val_loss: 9500.7649\n",
      "Epoch 243/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2914.3310 - val_loss: 9527.4323\n",
      "Epoch 244/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2910.4269 - val_loss: 9452.6147\n",
      "Epoch 245/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2909.2367 - val_loss: 9493.0591\n",
      "Epoch 246/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2905.3924 - val_loss: 9454.9839\n",
      "Epoch 247/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2903.7886 - val_loss: 9491.5409\n",
      "Epoch 248/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2900.2099 - val_loss: 9429.5862\n",
      "Epoch 249/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2899.2438 - val_loss: 9511.4770\n",
      "Epoch 250/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2895.2047 - val_loss: 9437.4990\n",
      "Epoch 251/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2894.1220 - val_loss: 9498.0404\n",
      "Epoch 252/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2890.0371 - val_loss: 9416.4675\n",
      "Epoch 253/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2888.9343 - val_loss: 9453.0370\n",
      "Epoch 254/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2885.9547 - val_loss: 9477.3363\n",
      "Epoch 255/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2884.4110 - val_loss: 9463.4859\n",
      "Epoch 256/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2880.6746 - val_loss: 9402.1746\n",
      "Epoch 257/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2879.6057 - val_loss: 9434.7112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 258/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2876.7195 - val_loss: 9455.9332\n",
      "Epoch 259/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2873.7693 - val_loss: 9467.9785\n",
      "Epoch 260/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2870.4381 - val_loss: 9367.2347\n",
      "Epoch 261/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2869.9665 - val_loss: 9406.0271\n",
      "Epoch 262/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2867.1145 - val_loss: 9431.2557\n",
      "Epoch 263/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2864.1897 - val_loss: 9444.6466\n",
      "Epoch 264/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2861.1972 - val_loss: 9399.0072\n",
      "Epoch 265/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2860.1787 - val_loss: 9462.4410\n",
      "Epoch 266/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2855.8605 - val_loss: 9368.3282\n",
      "Epoch 267/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2855.0176 - val_loss: 9399.5150\n",
      "Epoch 268/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2852.6982 - val_loss: 9448.1709\n",
      "Epoch 269/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2848.3120 - val_loss: 9305.1515\n",
      "Epoch 270/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2849.2980 - val_loss: 9394.8476\n",
      "Epoch 271/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2845.7690 - val_loss: 9409.2730\n",
      "Epoch 272/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2843.4335 - val_loss: 9442.6667\n",
      "Epoch 273/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2839.3036 - val_loss: 9340.9621\n",
      "Epoch 274/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2839.2805 - val_loss: 9413.5589\n",
      "Epoch 275/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2836.3537 - val_loss: 9445.6481\n",
      "Epoch 276/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2832.5053 - val_loss: 9328.2536\n",
      "Epoch 277/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2832.6073 - val_loss: 9427.1337\n",
      "Epoch 278/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 2829.0553 - val_loss: 9422.7394\n",
      "Epoch 279/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2825.2786 - val_loss: 9273.4614\n",
      "Epoch 280/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 2826.0073 - val_loss: 9351.0709\n",
      "Epoch 281/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 2822.7790 - val_loss: 9357.7666\n",
      "Epoch 282/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2821.1576 - val_loss: 9434.7813\n",
      "Epoch 283/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2816.7328 - val_loss: 9334.6398\n",
      "Epoch 284/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2816.2151 - val_loss: 9383.0019\n",
      "Epoch 285/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2813.3105 - val_loss: 9401.1850\n",
      "Epoch 286/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2810.1320 - val_loss: 9322.7375\n",
      "Epoch 287/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2809.5796 - val_loss: 9373.1941\n",
      "Epoch 288/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2806.0053 - val_loss: 9332.0048\n",
      "Epoch 289/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2805.4895 - val_loss: 9374.0490\n",
      "Epoch 290/10000\n",
      "241/241 [==============================] - 0s 2ms/step - loss: 2802.3963 - val_loss: 9359.2712\n",
      "Epoch 291/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2799.4377 - val_loss: 9295.6075\n",
      "Epoch 292/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2799.0156 - val_loss: 9352.0292\n",
      "Epoch 293/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2796.4855 - val_loss: 9382.1411\n",
      "Epoch 294/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2792.5824 - val_loss: 9285.3638\n",
      "Epoch 295/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2792.9102 - val_loss: 9377.0274\n",
      "Epoch 296/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2788.3968 - val_loss: 9286.5033\n",
      "Epoch 297/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2788.3378 - val_loss: 9338.5538\n",
      "Epoch 298/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2785.8280 - val_loss: 9367.4878\n",
      "Epoch 299/10000\n",
      "241/241 [==============================] - 0s 1ms/step - loss: 2782.8062 - val_loss: 9341.8553\n"
     ]
    }
   ],
   "source": [
    "# Sub model 1 - DNN\n",
    "\n",
    "rmse = []\n",
    "r2 = []\n",
    "\n",
    "for ts in range(3, 11, 1): \n",
    "    \n",
    "#     train_X, train_Y = time_step(df_train, ts, 1, 1)\n",
    "#     val_X, val_Y = time_step(df_val, ts, 1, 1)\n",
    "#     test_X, test_Y = time_step(df_test, ts, 1, 1)\n",
    "\n",
    "#     train_X, val_X, test_X = normalization(train_X, val_X, test_X)\n",
    "    \n",
    "    \n",
    "    # time step & lag\n",
    "    data_X, data_Y = time_step(data , ts, 1, 1)\n",
    "    \n",
    "    # 데이터 분할\n",
    "    NUM_TRAIN = int(data_X.shape[0] * 0.6)\n",
    "    NUM_VAL = int(data_X.shape[0] * 0.8)\n",
    "\n",
    "    train_X = data_X[:NUM_TRAIN]\n",
    "    train_Y = data_Y[:NUM_TRAIN]\n",
    "\n",
    "    val_X = data_X[NUM_TRAIN:NUM_VAL]\n",
    "    val_Y = data_Y[NUM_TRAIN:NUM_VAL]\n",
    "\n",
    "    test_X = data_X[NUM_VAL:]\n",
    "    test_Y =data_Y[NUM_VAL:]\n",
    "\n",
    "    train_X, val_X, test_X = normalization(train_X, val_X, test_X)\n",
    "    \n",
    "    # 함수형 API\n",
    "    input_tensor = Input(shape=(train_X.shape[1],))\n",
    "    x = layers.Dense(32, activation='relu')(input_tensor)\n",
    "    x = layers.Dense(16, activation='relu')(x)\n",
    "    x = layers.Dense(8, activation='relu')(x)\n",
    "    output_tensor = layers.Dense(1)(x)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    mc = ModelCheckpoint('./model/DNN/model_{}.h5'.format(ts), monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    model.fit(train_X, train_Y,\n",
    "              batch_size=8,\n",
    "              epochs=10000,\n",
    "              validation_data=(val_X, val_Y),\n",
    "              callbacks=[early_stopping, mc],\n",
    "              shuffle=False,\n",
    "              verbose=1)\n",
    "    \n",
    "    best_model = load_model('./model/DNN/model_{}.h5'.format(ts))\n",
    "    \n",
    "    y_pred = best_model.predict(test_X)\n",
    "    y_pred = y_pred.reshape(-1).astype('float32')\n",
    "    y_real = test_Y.reshape(-1).astype('float32')\n",
    "    \n",
    "    raw= {'Observed': list(y_real), 'Predicted': list(y_pred)}\n",
    "    rr = pd.DataFrame(raw)\n",
    "#     rr.to_csv(\"./Submodel/DNN/time_step/timse_step{}.csv\".format(ts))\n",
    "    reg = sm.OLS.from_formula(\"Observed ~ Predicted\",rr).fit()\n",
    "\n",
    "    try:\n",
    "        RMSE = round(math.sqrt(mean_squared_error(y_real, y_pred)), 3)\n",
    "        R2 = round(reg.rsquared, 3)   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    rmse.append(RMSE)\n",
    "    r2.append(R2)\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.plot(test_Y, label='Observed')\n",
    "#     plt.plot(y_predict, label='Predicted')\n",
    "#     plt.legend()\n",
    "#     plt.savefig('fig_{}.png'.format(ts), dpi=300)\n",
    " \n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101.764, 105.861, 106.129, 111.844, 115.267, 131.033, 133.629, 138.19]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.84, 0.832, 0.831, 0.817, 0.813, 0.79, 0.819, 0.825]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.41, 0.427, 0.428, 0.451, 0.465, 0.538, 0.549, 0.568]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = list(np.array(rmse) / np.array(std_list))\n",
    "\n",
    "rmse_std = []\n",
    "for i in tmp:\n",
    "    rmse_std.append(round(i, 3))\n",
    "rmse_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 246 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/compu/anaconda3/envs/dream/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "246/246 [==============================] - 3s 14ms/step - loss: 26735.1548 - val_loss: 163705.3637\n",
      "Epoch 2/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 26726.3433 - val_loss: 163671.7723\n",
      "Epoch 3/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 26711.5878 - val_loss: 163604.6814\n",
      "Epoch 4/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 26673.6362 - val_loss: 163330.6990\n",
      "Epoch 5/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 26429.8139 - val_loss: 160093.9665\n",
      "Epoch 6/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 24553.5013 - val_loss: 145375.4450\n",
      "Epoch 7/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 19809.1060 - val_loss: 111698.3536\n",
      "Epoch 8/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 14631.7260 - val_loss: 82676.5057\n",
      "Epoch 9/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 12979.5712 - val_loss: 73352.5623\n",
      "Epoch 10/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 12090.0231 - val_loss: 67565.6501\n",
      "Epoch 11/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 11425.8615 - val_loss: 62087.6022\n",
      "Epoch 12/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 10852.8360 - val_loss: 57225.5718\n",
      "Epoch 13/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 10340.8834 - val_loss: 52696.4577\n",
      "Epoch 14/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 9865.3929 - val_loss: 48640.8047\n",
      "Epoch 15/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 9378.1354 - val_loss: 44730.6911\n",
      "Epoch 16/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 8951.6947 - val_loss: 40938.6036\n",
      "Epoch 17/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 8571.7902 - val_loss: 37572.8175\n",
      "Epoch 18/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 8223.4771 - val_loss: 34606.4487\n",
      "Epoch 19/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 7906.6435 - val_loss: 31942.7948\n",
      "Epoch 20/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 7612.2148 - val_loss: 29619.4800\n",
      "Epoch 21/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 7320.0202 - val_loss: 27328.9328\n",
      "Epoch 22/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 7042.0831 - val_loss: 25186.0428\n",
      "Epoch 23/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 6834.8096 - val_loss: 23274.7883\n",
      "Epoch 24/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 6657.2486 - val_loss: 21785.5456\n",
      "Epoch 25/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 6494.0162 - val_loss: 20540.6002\n",
      "Epoch 26/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 6356.0712 - val_loss: 19387.5572\n",
      "Epoch 27/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 6240.0881 - val_loss: 18409.8404\n",
      "Epoch 28/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 6140.7077 - val_loss: 17594.4874\n",
      "Epoch 29/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 6057.2432 - val_loss: 16908.2314\n",
      "Epoch 30/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5987.0769 - val_loss: 16342.1088\n",
      "Epoch 31/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5926.4203 - val_loss: 15859.4170\n",
      "Epoch 32/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5873.8218 - val_loss: 15442.6505\n",
      "Epoch 33/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5827.6290 - val_loss: 15099.4160\n",
      "Epoch 34/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5786.8160 - val_loss: 14807.6043\n",
      "Epoch 35/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5748.6635 - val_loss: 14570.3635\n",
      "Epoch 36/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5711.9196 - val_loss: 14376.0804\n",
      "Epoch 37/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5673.7290 - val_loss: 14191.8291\n",
      "Epoch 38/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5642.0034 - val_loss: 14025.3631\n",
      "Epoch 39/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5621.1752 - val_loss: 13881.6567\n",
      "Epoch 40/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5602.5912 - val_loss: 13786.4936\n",
      "Epoch 41/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5585.2288 - val_loss: 13688.2160\n",
      "Epoch 42/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5566.9647 - val_loss: 13597.0432\n",
      "Epoch 43/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5544.9946 - val_loss: 13501.2838\n",
      "Epoch 44/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5520.6249 - val_loss: 13417.8795\n",
      "Epoch 45/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5500.2849 - val_loss: 13314.4718\n",
      "Epoch 46/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5484.8073 - val_loss: 13218.3223\n",
      "Epoch 47/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5472.0309 - val_loss: 13171.8605\n",
      "Epoch 48/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 2ms/step - loss: 5465.3885 - val_loss: 13112.4546\n",
      "Epoch 49/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5459.6815 - val_loss: 13088.1679\n",
      "Epoch 50/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5452.9093 - val_loss: 13085.6584\n",
      "Epoch 51/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5446.7450 - val_loss: 13063.4875\n",
      "Epoch 52/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5440.1191 - val_loss: 13053.3841\n",
      "Epoch 53/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5432.5697 - val_loss: 13042.5473\n",
      "Epoch 54/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5425.0784 - val_loss: 13009.0825\n",
      "Epoch 55/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5414.8323 - val_loss: 12978.3683\n",
      "Epoch 56/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5406.5933 - val_loss: 12933.9128\n",
      "Epoch 57/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5398.3795 - val_loss: 12907.9621\n",
      "Epoch 58/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5392.5827 - val_loss: 12850.7837\n",
      "Epoch 59/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5386.9951 - val_loss: 12825.5760\n",
      "Epoch 60/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5382.3823 - val_loss: 12796.1035\n",
      "Epoch 61/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5380.2752 - val_loss: 12767.6748\n",
      "Epoch 62/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5377.7188 - val_loss: 12758.7766\n",
      "Epoch 63/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5374.8761 - val_loss: 12760.9205\n",
      "Epoch 64/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5372.9194 - val_loss: 12737.6302\n",
      "Epoch 65/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5369.7272 - val_loss: 12756.0553\n",
      "Epoch 66/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5366.9637 - val_loss: 12744.2556\n",
      "Epoch 67/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5364.4429 - val_loss: 12726.8821\n",
      "Epoch 68/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5361.8741 - val_loss: 12736.1456\n",
      "Epoch 69/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5360.2539 - val_loss: 12703.7104\n",
      "Epoch 70/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5357.7123 - val_loss: 12710.7857\n",
      "Epoch 71/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5354.0029 - val_loss: 12738.4752\n",
      "Epoch 72/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5352.2664 - val_loss: 12707.6369\n",
      "Epoch 73/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5349.7582 - val_loss: 12710.8526\n",
      "Epoch 74/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5345.0872 - val_loss: 12750.8545\n",
      "Epoch 75/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5344.8736 - val_loss: 12686.5734\n",
      "Epoch 76/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5342.0453 - val_loss: 12703.6110\n",
      "Epoch 77/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5338.9830 - val_loss: 12715.0393\n",
      "Epoch 78/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5337.1371 - val_loss: 12697.7107\n",
      "Epoch 79/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5333.8680 - val_loss: 12715.7959\n",
      "Epoch 80/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5331.0610 - val_loss: 12705.3223\n",
      "Epoch 81/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5329.4368 - val_loss: 12694.2408\n",
      "Epoch 82/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5326.7144 - val_loss: 12702.3942\n",
      "Epoch 83/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5323.8877 - val_loss: 12708.1411\n",
      "Epoch 84/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5321.7455 - val_loss: 12703.9660\n",
      "Epoch 85/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5319.4386 - val_loss: 12706.1117\n",
      "Epoch 86/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5314.7714 - val_loss: 12749.6470\n",
      "Epoch 87/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5314.6543 - val_loss: 12690.8994\n",
      "Epoch 88/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5312.9117 - val_loss: 12687.1398\n",
      "Epoch 89/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5310.3171 - val_loss: 12695.9724\n",
      "Epoch 90/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5306.2055 - val_loss: 12732.9981\n",
      "Epoch 91/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5304.7416 - val_loss: 12683.4053\n",
      "Epoch 92/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5300.8531 - val_loss: 12700.4360\n",
      "Epoch 93/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5297.7306 - val_loss: 12681.6393\n",
      "Epoch 94/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5294.3054 - val_loss: 12675.6361\n",
      "Epoch 95/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5291.7317 - val_loss: 12658.0178\n",
      "Epoch 96/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5288.2957 - val_loss: 12675.8467\n",
      "Epoch 97/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5287.6914 - val_loss: 12634.8564\n",
      "Epoch 98/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5285.1069 - val_loss: 12632.6404\n",
      "Epoch 99/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5284.0283 - val_loss: 12644.6891\n",
      "Epoch 100/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5281.5529 - val_loss: 12634.7726\n",
      "Epoch 101/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5280.7561 - val_loss: 12624.0110\n",
      "Epoch 102/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5278.4380 - val_loss: 12640.0990\n",
      "Epoch 103/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5277.2161 - val_loss: 12615.3864\n",
      "Epoch 104/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5274.6641 - val_loss: 12630.4777\n",
      "Epoch 105/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5272.7847 - val_loss: 12621.2204\n",
      "Epoch 106/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5271.4160 - val_loss: 12593.8232\n",
      "Epoch 107/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5265.5667 - val_loss: 12625.6552\n",
      "Epoch 108/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5261.9677 - val_loss: 12568.8672\n",
      "Epoch 109/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5256.1937 - val_loss: 12580.7630\n",
      "Epoch 110/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5253.7247 - val_loss: 12550.7332\n",
      "Epoch 111/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5249.9451 - val_loss: 12549.1503\n",
      "Epoch 112/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5249.1836 - val_loss: 12512.3501\n",
      "Epoch 113/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5247.5835 - val_loss: 12523.5246\n",
      "Epoch 114/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5245.8898 - val_loss: 12516.3487\n",
      "Epoch 115/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5244.5103 - val_loss: 12527.1079\n",
      "Epoch 116/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5243.5298 - val_loss: 12503.9075\n",
      "Epoch 117/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5240.4044 - val_loss: 12555.9133\n",
      "Epoch 118/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5241.7239 - val_loss: 12485.3726\n",
      "Epoch 119/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5237.9316 - val_loss: 12553.1645\n",
      "Epoch 120/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5238.3352 - val_loss: 12492.7881\n",
      "Epoch 121/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5235.4362 - val_loss: 12539.5410\n",
      "Epoch 122/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 2ms/step - loss: 5235.1346 - val_loss: 12510.3308\n",
      "Epoch 123/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5233.3505 - val_loss: 12517.6462\n",
      "Epoch 124/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5230.8842 - val_loss: 12539.8465\n",
      "Epoch 125/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5231.4560 - val_loss: 12493.0500\n",
      "Epoch 126/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5228.2289 - val_loss: 12535.4860\n",
      "Epoch 127/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5228.2903 - val_loss: 12492.7013\n",
      "Epoch 128/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5225.5776 - val_loss: 12523.2424\n",
      "Epoch 129/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5225.3080 - val_loss: 12497.1569\n",
      "Epoch 130/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5223.2543 - val_loss: 12510.9310\n",
      "Epoch 131/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5221.0046 - val_loss: 12520.3319\n",
      "Epoch 132/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5221.6175 - val_loss: 12472.3862\n",
      "Epoch 133/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5218.2023 - val_loss: 12523.1336\n",
      "Epoch 134/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5218.9857 - val_loss: 12466.4010\n",
      "Epoch 135/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5216.1827 - val_loss: 12502.8650\n",
      "Epoch 136/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5215.5182 - val_loss: 12487.8728\n",
      "Epoch 137/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5213.8392 - val_loss: 12488.1509\n",
      "Epoch 138/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5212.1899 - val_loss: 12494.5994\n",
      "Epoch 139/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5210.7076 - val_loss: 12486.6451\n",
      "Epoch 140/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5210.6424 - val_loss: 12458.2136\n",
      "Epoch 141/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5207.6683 - val_loss: 12509.4649\n",
      "Epoch 142/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5208.3119 - val_loss: 12444.1240\n",
      "Epoch 143/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5204.4261 - val_loss: 12520.3635\n",
      "Epoch 144/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5204.8739 - val_loss: 12448.9976\n",
      "Epoch 145/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5201.9098 - val_loss: 12490.4801\n",
      "Epoch 146/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5202.1477 - val_loss: 12448.2563\n",
      "Epoch 147/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5200.1828 - val_loss: 12462.1501\n",
      "Epoch 148/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5198.4562 - val_loss: 12476.8370\n",
      "Epoch 149/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5198.5220 - val_loss: 12431.8119\n",
      "Epoch 150/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5195.1751 - val_loss: 12495.5864\n",
      "Epoch 151/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5195.6275 - val_loss: 12428.2323\n",
      "Epoch 152/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5192.2808 - val_loss: 12488.3494\n",
      "Epoch 153/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5192.3777 - val_loss: 12426.4316\n",
      "Epoch 154/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5191.1356 - val_loss: 12443.4717\n",
      "Epoch 155/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5188.5720 - val_loss: 12459.6958\n",
      "Epoch 156/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5189.1274 - val_loss: 12416.0173\n",
      "Epoch 157/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5185.2917 - val_loss: 12473.3754\n",
      "Epoch 158/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5186.5888 - val_loss: 12399.5723\n",
      "Epoch 159/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5182.7447 - val_loss: 12467.9851\n",
      "Epoch 160/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5183.8143 - val_loss: 12394.4814\n",
      "Epoch 161/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5181.2737 - val_loss: 12441.9533\n",
      "Epoch 162/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5178.5153 - val_loss: 12442.7160\n",
      "Epoch 163/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5180.4449 - val_loss: 12381.1582\n",
      "Epoch 164/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5175.2077 - val_loss: 12464.0870\n",
      "Epoch 165/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5178.3839 - val_loss: 12357.1794\n",
      "Epoch 166/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5172.2949 - val_loss: 12472.0267\n",
      "Epoch 167/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5175.3796 - val_loss: 12355.2800\n",
      "Epoch 168/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5171.1628 - val_loss: 12429.6362\n",
      "Epoch 169/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5171.8198 - val_loss: 12379.5880\n",
      "Epoch 170/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5169.2208 - val_loss: 12414.3808\n",
      "Epoch 171/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5167.7111 - val_loss: 12410.5000\n",
      "Epoch 172/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5166.9260 - val_loss: 12391.8535\n",
      "Epoch 173/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5165.0371 - val_loss: 12403.4231\n",
      "Epoch 174/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5164.6227 - val_loss: 12384.8226\n",
      "Epoch 175/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5162.1632 - val_loss: 12403.6783\n",
      "Epoch 176/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5161.8917 - val_loss: 12383.1718\n",
      "Epoch 177/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5159.2727 - val_loss: 12406.2081\n",
      "Epoch 178/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5158.4510 - val_loss: 12383.0573\n",
      "Epoch 179/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5156.9933 - val_loss: 12383.8472\n",
      "Epoch 180/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5156.3586 - val_loss: 12368.6307\n",
      "Epoch 181/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5153.8935 - val_loss: 12393.6968\n",
      "Epoch 182/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5154.0297 - val_loss: 12349.2257\n",
      "Epoch 183/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5151.3542 - val_loss: 12396.0739\n",
      "Epoch 184/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5151.6563 - val_loss: 12340.3590\n",
      "Epoch 185/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5147.9808 - val_loss: 12408.8954\n",
      "Epoch 186/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5149.3984 - val_loss: 12325.5518\n",
      "Epoch 187/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5146.3265 - val_loss: 12385.7140\n",
      "Epoch 188/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5146.1238 - val_loss: 12345.9259\n",
      "Epoch 189/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5142.7773 - val_loss: 12382.4174\n",
      "Epoch 190/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5144.3810 - val_loss: 12315.8000\n",
      "Epoch 191/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5140.3170 - val_loss: 12387.5954\n",
      "Epoch 192/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5140.7137 - val_loss: 12329.3868\n",
      "Epoch 193/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5139.3443 - val_loss: 12344.9733\n",
      "Epoch 194/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5136.7269 - val_loss: 12364.2500\n",
      "Epoch 195/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5136.7299 - val_loss: 12328.6023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 196/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5133.4610 - val_loss: 12372.9158\n",
      "Epoch 197/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5134.8439 - val_loss: 12299.1177\n",
      "Epoch 198/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5131.2906 - val_loss: 12359.9393\n",
      "Epoch 199/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5130.9491 - val_loss: 12320.2715\n",
      "Epoch 200/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5130.2303 - val_loss: 12311.3464\n",
      "Epoch 201/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5127.6857 - val_loss: 12351.3575\n",
      "Epoch 202/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5126.8505 - val_loss: 12310.7555\n",
      "Epoch 203/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5125.8806 - val_loss: 12326.9749\n",
      "Epoch 204/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5124.0893 - val_loss: 12314.9154\n",
      "Epoch 205/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5123.3257 - val_loss: 12323.0530\n",
      "Epoch 206/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5121.5759 - val_loss: 12315.9467\n",
      "Epoch 207/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5119.1779 - val_loss: 12334.9881\n",
      "Epoch 208/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5120.4208 - val_loss: 12270.9687\n",
      "Epoch 209/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5116.8823 - val_loss: 12337.1489\n",
      "Epoch 210/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5117.7656 - val_loss: 12276.1877\n",
      "Epoch 211/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5112.9287 - val_loss: 12357.1733\n",
      "Epoch 212/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5115.9543 - val_loss: 12241.2463\n",
      "Epoch 213/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5110.8551 - val_loss: 12346.3348\n",
      "Epoch 214/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5113.4209 - val_loss: 12238.4744\n",
      "Epoch 215/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5108.0319 - val_loss: 12354.5758\n",
      "Epoch 216/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5110.8401 - val_loss: 12230.7727\n",
      "Epoch 217/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5105.4207 - val_loss: 12353.2274\n",
      "Epoch 218/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5106.2699 - val_loss: 12257.0766\n",
      "Epoch 219/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5105.7788 - val_loss: 12261.7521\n",
      "Epoch 220/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5101.4591 - val_loss: 12323.9890\n",
      "Epoch 221/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5103.4493 - val_loss: 12227.0022\n",
      "Epoch 222/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5099.8792 - val_loss: 12313.5480\n",
      "Epoch 223/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5099.4038 - val_loss: 12252.3247\n",
      "Epoch 224/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5098.3933 - val_loss: 12271.8785\n",
      "Epoch 225/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5095.9049 - val_loss: 12276.8576\n",
      "Epoch 226/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5095.8204 - val_loss: 12252.2379\n",
      "Epoch 227/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5094.3415 - val_loss: 12262.9468\n",
      "Epoch 228/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5091.6034 - val_loss: 12279.3754\n",
      "Epoch 229/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5092.9622 - val_loss: 12228.0597\n",
      "Epoch 230/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5089.0212 - val_loss: 12288.5314\n",
      "Epoch 231/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5089.3720 - val_loss: 12230.7636\n",
      "Epoch 232/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5086.8811 - val_loss: 12271.6350\n",
      "Epoch 233/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5087.0024 - val_loss: 12221.8622\n",
      "Epoch 234/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5084.4688 - val_loss: 12267.2497\n",
      "Epoch 235/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5083.9122 - val_loss: 12234.5749\n",
      "Epoch 236/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5081.1631 - val_loss: 12263.0620\n",
      "Epoch 237/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5081.9755 - val_loss: 12211.6229\n",
      "Epoch 238/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5079.4877 - val_loss: 12249.4756\n",
      "Epoch 239/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5077.4126 - val_loss: 12241.7866\n",
      "Epoch 240/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5077.8338 - val_loss: 12216.8993\n",
      "Epoch 241/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5074.9228 - val_loss: 12250.9434\n",
      "Epoch 242/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5075.7839 - val_loss: 12189.1427\n",
      "Epoch 243/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5072.5731 - val_loss: 12265.6196\n",
      "Epoch 244/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5072.3391 - val_loss: 12200.4216\n",
      "Epoch 245/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5070.2552 - val_loss: 12248.3891\n",
      "Epoch 246/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5069.4077 - val_loss: 12205.3165\n",
      "Epoch 247/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5067.6629 - val_loss: 12236.0191\n",
      "Epoch 248/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5066.2849 - val_loss: 12220.3024\n",
      "Epoch 249/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5065.6044 - val_loss: 12206.8304\n",
      "Epoch 250/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5062.4535 - val_loss: 12238.3837\n",
      "Epoch 251/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5064.7574 - val_loss: 12163.4199\n",
      "Epoch 252/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5059.8349 - val_loss: 12246.6588\n",
      "Epoch 253/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5061.5858 - val_loss: 12169.9119\n",
      "Epoch 254/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5057.7043 - val_loss: 12236.9662\n",
      "Epoch 255/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5057.6570 - val_loss: 12181.4734\n",
      "Epoch 256/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5056.6665 - val_loss: 12198.7752\n",
      "Epoch 257/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5054.4649 - val_loss: 12203.1233\n",
      "Epoch 258/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5052.9861 - val_loss: 12200.2071\n",
      "Epoch 259/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5052.9087 - val_loss: 12179.2493\n",
      "Epoch 260/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5049.6454 - val_loss: 12217.0264\n",
      "Epoch 261/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5051.0157 - val_loss: 12150.1012\n",
      "Epoch 262/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5047.6446 - val_loss: 12210.1900\n",
      "Epoch 263/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5048.7443 - val_loss: 12143.3635\n",
      "Epoch 264/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5044.3664 - val_loss: 12233.9970\n",
      "Epoch 265/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5044.5068 - val_loss: 12162.6570\n",
      "Epoch 266/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5044.3035 - val_loss: 12154.9471\n",
      "Epoch 267/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5041.8833 - val_loss: 12189.1914\n",
      "Epoch 268/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5040.2865 - val_loss: 12180.5937\n",
      "Epoch 269/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5040.0606 - val_loss: 12164.2845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5036.2129 - val_loss: 12213.3564\n",
      "Epoch 271/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5039.7018 - val_loss: 12105.0560\n",
      "Epoch 272/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5033.7199 - val_loss: 12234.1040\n",
      "Epoch 273/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5037.5273 - val_loss: 12090.1573\n",
      "Epoch 274/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5031.3009 - val_loss: 12252.9792\n",
      "Epoch 275/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5032.5487 - val_loss: 12123.1219\n",
      "Epoch 276/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5030.7328 - val_loss: 12178.6265\n",
      "Epoch 277/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5028.0033 - val_loss: 12169.9261\n",
      "Epoch 278/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5027.6848 - val_loss: 12161.5143\n",
      "Epoch 279/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5026.2892 - val_loss: 12152.4782\n",
      "Epoch 280/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5024.4320 - val_loss: 12162.4968\n",
      "Epoch 281/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5022.6576 - val_loss: 12148.1563\n",
      "Epoch 282/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5024.7565 - val_loss: 12107.9181\n",
      "Epoch 283/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5018.7882 - val_loss: 12198.8052\n",
      "Epoch 284/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5023.8333 - val_loss: 12060.5781\n",
      "Epoch 285/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5016.3831 - val_loss: 12229.5117\n",
      "Epoch 286/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5020.0186 - val_loss: 12077.6012\n",
      "Epoch 287/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5014.1016 - val_loss: 12210.2631\n",
      "Epoch 288/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5014.8419 - val_loss: 12115.6895\n",
      "Epoch 289/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5013.7749 - val_loss: 12118.8396\n",
      "Epoch 290/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5012.4016 - val_loss: 12127.2766\n",
      "Epoch 291/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5010.6432 - val_loss: 12129.1883\n",
      "Epoch 292/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5010.1103 - val_loss: 12124.2603\n",
      "Epoch 293/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5006.9828 - val_loss: 12154.8832\n",
      "Epoch 294/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5008.7141 - val_loss: 12085.1265\n",
      "Epoch 295/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5004.6855 - val_loss: 12158.0851\n",
      "Epoch 296/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5005.0910 - val_loss: 12106.4695\n",
      "Epoch 297/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5001.7811 - val_loss: 12155.5604\n",
      "Epoch 298/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5003.0179 - val_loss: 12080.8714\n",
      "Epoch 299/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 4998.7251 - val_loss: 12169.2261\n",
      "Epoch 300/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 5000.6234 - val_loss: 12067.9824\n",
      "Epoch 301/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 4997.3071 - val_loss: 12139.0357\n",
      "Epoch 302/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 4995.9551 - val_loss: 12111.6596\n",
      "Epoch 303/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 4995.3920 - val_loss: 12099.7977\n",
      "Epoch 304/1000\n",
      "246/246 [==============================] - 0s 2ms/step - loss: 4994.0176 - val_loss: 12106.6514\n",
      "Train on 246 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "246/246 [==============================] - 4s 16ms/step - loss: 26744.8370 - val_loss: 177244.1895\n",
      "Epoch 2/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26735.2220 - val_loss: 177201.4368\n",
      "Epoch 3/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26715.9562 - val_loss: 177085.6976\n",
      "Epoch 4/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26644.9182 - val_loss: 176029.8132\n",
      "Epoch 5/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 25874.1921 - val_loss: 164455.8038\n",
      "Epoch 6/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 21101.1390 - val_loss: 120660.8891\n",
      "Epoch 7/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 14470.1644 - val_loss: 76997.2388\n",
      "Epoch 8/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 12747.5513 - val_loss: 66456.1084\n",
      "Epoch 9/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 11880.1347 - val_loss: 60534.6897\n",
      "Epoch 10/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 11280.1967 - val_loss: 54933.7330\n",
      "Epoch 11/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 10774.8596 - val_loss: 50096.7782\n",
      "Epoch 12/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 10347.9666 - val_loss: 45984.8909\n",
      "Epoch 13/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 9989.7980 - val_loss: 42452.7654\n",
      "Epoch 14/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 9683.0244 - val_loss: 39458.9046\n",
      "Epoch 15/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 9422.1493 - val_loss: 36875.1099\n",
      "Epoch 16/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 9197.4536 - val_loss: 34678.9766\n",
      "Epoch 17/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 9003.0341 - val_loss: 32808.4050\n",
      "Epoch 18/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8837.0465 - val_loss: 31132.0355\n",
      "Epoch 19/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8694.1556 - val_loss: 29697.1485\n",
      "Epoch 20/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8571.2298 - val_loss: 28418.9383\n",
      "Epoch 21/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8465.5328 - val_loss: 27263.0469\n",
      "Epoch 22/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8374.9296 - val_loss: 26280.1597\n",
      "Epoch 23/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8295.7090 - val_loss: 25426.1063\n",
      "Epoch 24/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8224.8243 - val_loss: 24689.1480\n",
      "Epoch 25/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8161.5442 - val_loss: 23981.8121\n",
      "Epoch 26/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8106.1881 - val_loss: 23422.7445\n",
      "Epoch 27/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8055.8605 - val_loss: 22914.0787\n",
      "Epoch 28/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8010.3702 - val_loss: 22401.2247\n",
      "Epoch 29/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7968.1041 - val_loss: 21969.1003\n",
      "Epoch 30/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7925.7658 - val_loss: 21588.3907\n",
      "Epoch 31/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7883.9862 - val_loss: 21198.7694\n",
      "Epoch 32/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7845.0632 - val_loss: 20825.8455\n",
      "Epoch 33/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7806.9544 - val_loss: 20472.2693\n",
      "Epoch 34/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7770.3980 - val_loss: 20144.6501\n",
      "Epoch 35/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7732.7851 - val_loss: 19839.3890\n",
      "Epoch 36/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7699.4730 - val_loss: 19494.9680\n",
      "Epoch 37/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7674.0418 - val_loss: 19199.7365\n",
      "Epoch 38/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7648.2083 - val_loss: 19033.2629\n",
      "Epoch 39/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 1s 2ms/step - loss: 7612.5144 - val_loss: 18673.2288\n",
      "Epoch 40/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7592.2542 - val_loss: 18449.8706\n",
      "Epoch 41/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7576.6069 - val_loss: 18373.5797\n",
      "Epoch 42/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7558.4756 - val_loss: 18278.7834\n",
      "Epoch 43/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7541.9807 - val_loss: 18080.1458\n",
      "Epoch 44/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7529.7070 - val_loss: 18024.8312\n",
      "Epoch 45/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7515.7033 - val_loss: 17943.8350\n",
      "Epoch 46/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7503.2518 - val_loss: 17851.5730\n",
      "Epoch 47/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7491.8286 - val_loss: 17824.4447\n",
      "Epoch 48/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7478.4413 - val_loss: 17772.8227\n",
      "Epoch 49/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7465.9682 - val_loss: 17705.2586\n",
      "Epoch 50/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7453.9739 - val_loss: 17665.1334\n",
      "Epoch 51/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7443.8509 - val_loss: 17568.4869\n",
      "Epoch 52/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7437.4235 - val_loss: 17572.9376\n",
      "Epoch 53/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7428.6919 - val_loss: 17510.6864\n",
      "Epoch 54/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7421.3009 - val_loss: 17484.6002\n",
      "Epoch 55/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7413.0060 - val_loss: 17500.8042\n",
      "Epoch 56/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7403.2610 - val_loss: 17456.7137\n",
      "Epoch 57/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7396.4640 - val_loss: 17397.1577\n",
      "Epoch 58/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7390.2198 - val_loss: 17414.1325\n",
      "Epoch 59/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7381.1779 - val_loss: 17413.9041\n",
      "Epoch 60/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7371.4584 - val_loss: 17437.5197\n",
      "Epoch 61/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7358.3172 - val_loss: 17404.1009\n",
      "Epoch 62/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7347.2632 - val_loss: 17372.4012\n",
      "Epoch 63/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7337.1972 - val_loss: 17303.9567\n",
      "Epoch 64/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7330.1607 - val_loss: 17221.2859\n",
      "Epoch 65/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7327.1520 - val_loss: 17250.0890\n",
      "Epoch 66/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7321.5480 - val_loss: 17198.9696\n",
      "Epoch 67/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7319.1211 - val_loss: 17244.5089\n",
      "Epoch 68/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7313.7923 - val_loss: 17200.1525\n",
      "Epoch 69/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7311.8206 - val_loss: 17228.2383\n",
      "Epoch 70/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7307.8037 - val_loss: 17243.7544\n",
      "Epoch 71/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7304.2261 - val_loss: 17238.7572\n",
      "Epoch 72/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7300.6891 - val_loss: 17284.5408\n",
      "Epoch 73/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7295.3661 - val_loss: 17305.8394\n",
      "Epoch 74/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7289.1542 - val_loss: 17276.9298\n",
      "Epoch 75/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7283.7246 - val_loss: 17291.4670\n",
      "Epoch 76/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7278.3342 - val_loss: 17217.0107\n",
      "Epoch 77/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7274.5858 - val_loss: 17292.7073\n",
      "Epoch 78/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7268.5458 - val_loss: 17207.1170\n",
      "Epoch 79/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7266.6574 - val_loss: 17247.8893\n",
      "Epoch 80/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7262.4835 - val_loss: 17183.6864\n",
      "Epoch 81/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7260.8548 - val_loss: 17241.8443\n",
      "Epoch 82/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7256.1324 - val_loss: 17203.7809\n",
      "Epoch 83/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7253.7948 - val_loss: 17235.5452\n",
      "Epoch 84/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7249.6553 - val_loss: 17167.9035\n",
      "Epoch 85/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7247.9393 - val_loss: 17188.8702\n",
      "Epoch 86/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7245.7005 - val_loss: 17197.0987\n",
      "Epoch 87/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7242.0097 - val_loss: 17165.8796\n",
      "Epoch 88/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7239.3889 - val_loss: 17233.9370\n",
      "Epoch 89/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7234.7187 - val_loss: 17136.1370\n",
      "Epoch 90/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7233.1012 - val_loss: 17230.7528\n",
      "Epoch 91/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7227.1593 - val_loss: 17152.3570\n",
      "Epoch 92/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7225.1981 - val_loss: 17192.5786\n",
      "Epoch 93/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7221.2259 - val_loss: 17143.1563\n",
      "Epoch 94/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7219.3249 - val_loss: 17203.5716\n",
      "Epoch 95/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7214.6686 - val_loss: 17085.0310\n",
      "Epoch 96/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7214.4304 - val_loss: 17154.8000\n",
      "Epoch 97/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7210.0582 - val_loss: 17124.6220\n",
      "Epoch 98/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7208.6843 - val_loss: 17121.6455\n",
      "Epoch 99/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7207.0214 - val_loss: 17111.5665\n",
      "Epoch 100/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7204.9434 - val_loss: 17117.0166\n",
      "Epoch 101/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7202.0742 - val_loss: 17123.8611\n",
      "Epoch 102/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7199.5627 - val_loss: 17087.2161\n",
      "Epoch 103/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7198.2141 - val_loss: 17148.4655\n",
      "Epoch 104/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7194.5738 - val_loss: 17072.5329\n",
      "Epoch 105/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7193.5960 - val_loss: 17138.1573\n",
      "Epoch 106/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7190.0768 - val_loss: 17084.1421\n",
      "Epoch 107/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7188.2547 - val_loss: 17101.5859\n",
      "Epoch 108/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7186.0314 - val_loss: 17052.9790\n",
      "Epoch 109/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7184.7138 - val_loss: 17117.8769\n",
      "Epoch 110/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7181.0084 - val_loss: 17001.6112\n",
      "Epoch 111/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7180.8637 - val_loss: 17111.5560\n",
      "Epoch 112/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7177.1493 - val_loss: 17045.8512\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 1s 2ms/step - loss: 7175.1566 - val_loss: 17072.3698\n",
      "Epoch 114/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7173.0881 - val_loss: 17045.4062\n",
      "Epoch 115/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7170.3123 - val_loss: 17031.1093\n",
      "Epoch 116/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7169.1485 - val_loss: 17055.9128\n",
      "Epoch 117/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7165.7705 - val_loss: 17023.8977\n",
      "Epoch 118/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7164.0800 - val_loss: 17031.8755\n",
      "Epoch 119/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7161.8600 - val_loss: 16966.1871\n",
      "Epoch 120/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7161.0617 - val_loss: 17044.0400\n",
      "Epoch 121/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7156.9775 - val_loss: 16989.2718\n",
      "Epoch 122/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7158.1401 - val_loss: 16961.7495\n",
      "Epoch 123/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7235.1609 - val_loss: 17921.7132\n",
      "Epoch 124/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7162.4859 - val_loss: 16588.1192\n",
      "Epoch 125/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7163.2465 - val_loss: 17006.5261\n",
      "Epoch 126/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7147.2839 - val_loss: 16926.0156\n",
      "Epoch 127/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7142.9138 - val_loss: 16926.3212\n",
      "Epoch 128/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7137.6860 - val_loss: 16881.0998\n",
      "Epoch 129/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7132.2383 - val_loss: 16931.5731\n",
      "Epoch 130/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7124.0906 - val_loss: 16825.0214\n",
      "Epoch 131/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7117.4654 - val_loss: 16870.3825\n",
      "Epoch 132/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7107.6371 - val_loss: 16761.0349\n",
      "Epoch 133/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7097.3070 - val_loss: 16754.9722\n",
      "Epoch 134/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7084.4132 - val_loss: 16678.8759\n",
      "Epoch 135/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7070.6520 - val_loss: 16647.6842\n",
      "Epoch 136/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7053.6534 - val_loss: 16527.7504\n",
      "Epoch 137/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7036.1383 - val_loss: 16515.8051\n",
      "Epoch 138/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7014.1035 - val_loss: 16402.3118\n",
      "Epoch 139/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6991.5907 - val_loss: 16305.0188\n",
      "Epoch 140/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6967.6693 - val_loss: 16221.8320\n",
      "Epoch 141/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6940.1053 - val_loss: 16157.2117\n",
      "Epoch 142/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6910.4792 - val_loss: 15991.9764\n",
      "Epoch 143/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6879.5645 - val_loss: 16047.4661\n",
      "Epoch 144/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6843.9930 - val_loss: 15747.7013\n",
      "Epoch 145/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6815.2509 - val_loss: 15841.6212\n",
      "Epoch 146/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6779.5028 - val_loss: 15496.2370\n",
      "Epoch 147/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6754.5849 - val_loss: 15685.0095\n",
      "Epoch 148/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6717.0915 - val_loss: 15443.0835\n",
      "Epoch 149/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6687.9374 - val_loss: 15532.2362\n",
      "Epoch 150/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6651.0264 - val_loss: 15285.2631\n",
      "Epoch 151/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6618.3892 - val_loss: 15435.2213\n",
      "Epoch 152/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6577.9445 - val_loss: 15042.1008\n",
      "Epoch 153/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6549.7628 - val_loss: 15274.1856\n",
      "Epoch 154/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6505.4638 - val_loss: 14956.7715\n",
      "Epoch 155/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6471.8581 - val_loss: 15080.5149\n",
      "Epoch 156/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6431.1236 - val_loss: 14940.2862\n",
      "Epoch 157/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6394.8326 - val_loss: 14914.3924\n",
      "Epoch 158/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6359.8822 - val_loss: 14888.9122\n",
      "Epoch 159/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6328.7744 - val_loss: 14738.9247\n",
      "Epoch 160/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6300.1553 - val_loss: 14809.4722\n",
      "Epoch 161/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6269.4506 - val_loss: 14703.9961\n",
      "Epoch 162/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6242.0873 - val_loss: 14810.6081\n",
      "Epoch 163/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6216.1633 - val_loss: 14789.1161\n",
      "Epoch 164/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6192.4823 - val_loss: 14882.6832\n",
      "Epoch 165/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6172.8310 - val_loss: 14819.9429\n",
      "Epoch 166/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6145.6316 - val_loss: 15018.7764\n",
      "Epoch 167/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6128.6060 - val_loss: 14911.9943\n",
      "Epoch 168/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6104.6336 - val_loss: 15092.2501\n",
      "Epoch 169/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6087.4149 - val_loss: 15039.2424\n",
      "Epoch 170/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6067.3443 - val_loss: 15180.4381\n",
      "Epoch 171/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6053.4594 - val_loss: 15162.5333\n",
      "Epoch 172/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6030.9648 - val_loss: 15264.5320\n",
      "Epoch 173/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6015.9404 - val_loss: 15384.4467\n",
      "Epoch 174/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6007.3052 - val_loss: 15264.0422\n",
      "Epoch 175/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5982.9042 - val_loss: 15576.8186\n",
      "Epoch 176/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5971.9314 - val_loss: 15445.6889\n",
      "Epoch 177/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5957.6304 - val_loss: 15656.2258\n",
      "Epoch 178/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5948.3655 - val_loss: 15594.3159\n",
      "Epoch 179/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5934.8209 - val_loss: 15739.7813\n",
      "Epoch 180/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5927.1773 - val_loss: 15717.3866\n",
      "Epoch 181/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5907.0005 - val_loss: 15982.5027\n",
      "Train on 245 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "245/245 [==============================] - 5s 21ms/step - loss: 26853.8758 - val_loss: 177241.2313\n",
      "Epoch 2/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 26841.8490 - val_loss: 177186.7651\n",
      "Epoch 3/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 26815.6750 - val_loss: 177027.3053\n",
      "Epoch 4/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 26695.3869 - val_loss: 175123.5956\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 3ms/step - loss: 25006.6105 - val_loss: 151319.4340\n",
      "Epoch 6/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 17588.4633 - val_loss: 87791.4839\n",
      "Epoch 7/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 13620.4292 - val_loss: 68274.5351\n",
      "Epoch 8/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 12384.4322 - val_loss: 60431.5085\n",
      "Epoch 9/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 11678.9445 - val_loss: 53582.3255\n",
      "Epoch 10/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 11122.1488 - val_loss: 48252.7174\n",
      "Epoch 11/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 10709.4882 - val_loss: 44119.3641\n",
      "Epoch 12/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 10399.5813 - val_loss: 40886.1362\n",
      "Epoch 13/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 10161.4360 - val_loss: 38295.3907\n",
      "Epoch 14/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9970.4879 - val_loss: 36288.2157\n",
      "Epoch 15/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9819.9513 - val_loss: 34523.6596\n",
      "Epoch 16/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9690.3137 - val_loss: 33170.6480\n",
      "Epoch 17/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9577.9343 - val_loss: 31862.5043\n",
      "Epoch 18/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9486.7716 - val_loss: 30772.0935\n",
      "Epoch 19/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9409.7138 - val_loss: 29961.5866\n",
      "Epoch 20/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9339.6045 - val_loss: 29190.0856\n",
      "Epoch 21/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9278.5647 - val_loss: 28450.5431\n",
      "Epoch 22/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9236.1597 - val_loss: 27810.5082\n",
      "Epoch 23/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9195.7773 - val_loss: 27355.0475\n",
      "Epoch 24/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9166.1820 - val_loss: 26942.2138\n",
      "Epoch 25/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9137.6022 - val_loss: 26756.9098\n",
      "Epoch 26/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9113.9574 - val_loss: 26485.0725\n",
      "Epoch 27/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9093.4750 - val_loss: 26298.3629\n",
      "Epoch 28/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9073.9760 - val_loss: 26153.8497\n",
      "Epoch 29/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9059.7331 - val_loss: 25948.2346\n",
      "Epoch 30/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9048.7856 - val_loss: 25767.3019\n",
      "Epoch 31/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9036.5059 - val_loss: 25776.0938\n",
      "Epoch 32/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9024.4416 - val_loss: 25687.1424\n",
      "Epoch 33/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9014.5256 - val_loss: 25614.5007\n",
      "Epoch 34/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 9004.9325 - val_loss: 25604.0223\n",
      "Epoch 35/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8997.2527 - val_loss: 25458.2018\n",
      "Epoch 36/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8989.1749 - val_loss: 25529.6904\n",
      "Epoch 37/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8980.4867 - val_loss: 25397.5583\n",
      "Epoch 38/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8975.7795 - val_loss: 25262.9289\n",
      "Epoch 39/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8969.1711 - val_loss: 25300.5874\n",
      "Epoch 40/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8961.0791 - val_loss: 25222.9987\n",
      "Epoch 41/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8956.7486 - val_loss: 25139.0502\n",
      "Epoch 42/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8950.5784 - val_loss: 25170.3912\n",
      "Epoch 43/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8943.8824 - val_loss: 25126.8673\n",
      "Epoch 44/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8938.8719 - val_loss: 25009.7843\n",
      "Epoch 45/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8934.8941 - val_loss: 25067.7084\n",
      "Epoch 46/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8928.3548 - val_loss: 25047.6208\n",
      "Epoch 47/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8924.4828 - val_loss: 24962.2565\n",
      "Epoch 48/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8920.1569 - val_loss: 24942.7938\n",
      "Epoch 49/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8916.2863 - val_loss: 24888.7615\n",
      "Epoch 50/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8912.3078 - val_loss: 24909.3880\n",
      "Epoch 51/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8907.0078 - val_loss: 24864.1447\n",
      "Epoch 52/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8904.0609 - val_loss: 24839.2192\n",
      "Epoch 53/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8899.0514 - val_loss: 24768.1421\n",
      "Epoch 54/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8896.8269 - val_loss: 24820.4559\n",
      "Epoch 55/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8890.8298 - val_loss: 24823.8808\n",
      "Epoch 56/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8887.0260 - val_loss: 24693.1786\n",
      "Epoch 57/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8884.6506 - val_loss: 24744.9316\n",
      "Epoch 58/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8880.5159 - val_loss: 24641.8022\n",
      "Epoch 59/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8876.9313 - val_loss: 24793.2466\n",
      "Epoch 60/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8872.4565 - val_loss: 24452.9530\n",
      "Epoch 61/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8872.6481 - val_loss: 24796.2487\n",
      "Epoch 62/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8864.1218 - val_loss: 24477.2194\n",
      "Epoch 63/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8863.4593 - val_loss: 24741.2777\n",
      "Epoch 64/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8859.1339 - val_loss: 24338.3658\n",
      "Epoch 65/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8858.8426 - val_loss: 24753.2565\n",
      "Epoch 66/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8850.0730 - val_loss: 24397.0250\n",
      "Epoch 67/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8850.5508 - val_loss: 24642.2824\n",
      "Epoch 68/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8843.5144 - val_loss: 24390.2850\n",
      "Epoch 69/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8843.6752 - val_loss: 24577.6686\n",
      "Epoch 70/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8838.9366 - val_loss: 24364.0418\n",
      "Epoch 71/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8836.5475 - val_loss: 24635.9944\n",
      "Epoch 72/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8829.6965 - val_loss: 24297.9399\n",
      "Epoch 73/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8829.9542 - val_loss: 24579.6531\n",
      "Epoch 74/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8824.0723 - val_loss: 24269.0982\n",
      "Epoch 75/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8822.9066 - val_loss: 24657.3530\n",
      "Epoch 76/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8816.2824 - val_loss: 24135.8791\n",
      "Epoch 77/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8817.6134 - val_loss: 24663.5928\n",
      "Epoch 78/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8810.0216 - val_loss: 24195.8431\n",
      "Epoch 79/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 3ms/step - loss: 8810.3430 - val_loss: 24621.4398\n",
      "Epoch 80/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8803.5691 - val_loss: 24081.3344\n",
      "Epoch 81/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8805.9146 - val_loss: 24579.8101\n",
      "Epoch 82/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8795.6949 - val_loss: 24184.2146\n",
      "Epoch 83/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8797.0726 - val_loss: 24491.0613\n",
      "Epoch 84/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8791.5397 - val_loss: 24153.1528\n",
      "Epoch 85/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8790.4897 - val_loss: 24549.6560\n",
      "Epoch 86/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8784.4204 - val_loss: 23984.0151\n",
      "Epoch 87/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8786.5870 - val_loss: 24609.0356\n",
      "Epoch 88/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8777.4913 - val_loss: 24030.6375\n",
      "Epoch 89/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8779.6344 - val_loss: 24409.7570\n",
      "Epoch 90/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8773.8032 - val_loss: 23996.4115\n",
      "Epoch 91/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8773.8475 - val_loss: 24585.6182\n",
      "Epoch 92/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8763.9646 - val_loss: 23867.9586\n",
      "Epoch 93/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8769.0150 - val_loss: 24507.7077\n",
      "Epoch 94/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8759.8027 - val_loss: 23947.9930\n",
      "Epoch 95/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8761.9675 - val_loss: 24422.1537\n",
      "Epoch 96/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8753.9567 - val_loss: 23973.9549\n",
      "Epoch 97/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8754.4468 - val_loss: 24449.8522\n",
      "Epoch 98/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8748.2734 - val_loss: 23809.5969\n",
      "Epoch 99/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8751.2757 - val_loss: 24447.1260\n",
      "Epoch 100/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8743.1883 - val_loss: 23871.9368\n",
      "Epoch 101/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8744.3829 - val_loss: 24445.0407\n",
      "Epoch 102/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8733.4598 - val_loss: 23813.4910\n",
      "Epoch 103/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8737.3142 - val_loss: 24329.5918\n",
      "Epoch 104/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8730.9885 - val_loss: 23822.1171\n",
      "Epoch 105/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8731.0240 - val_loss: 24430.8495\n",
      "Epoch 106/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8720.8490 - val_loss: 23649.9788\n",
      "Epoch 107/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8726.7913 - val_loss: 24358.6483\n",
      "Epoch 108/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8717.3761 - val_loss: 23796.2800\n",
      "Epoch 109/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8718.9814 - val_loss: 24200.8679\n",
      "Epoch 110/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8710.2714 - val_loss: 23728.9968\n",
      "Epoch 111/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8712.2383 - val_loss: 24368.7107\n",
      "Epoch 112/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8705.3438 - val_loss: 23603.9892\n",
      "Epoch 113/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8708.2787 - val_loss: 24385.3417\n",
      "Epoch 114/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8693.6832 - val_loss: 23664.1327\n",
      "Epoch 115/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8698.5574 - val_loss: 24015.9291\n",
      "Epoch 116/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8692.2680 - val_loss: 23745.6360\n",
      "Epoch 117/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8689.6202 - val_loss: 24118.7074\n",
      "Epoch 118/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8681.2434 - val_loss: 23564.8018\n",
      "Epoch 119/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8681.5908 - val_loss: 24164.4054\n",
      "Epoch 120/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8672.0005 - val_loss: 23450.1515\n",
      "Epoch 121/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8673.8430 - val_loss: 24094.5123\n",
      "Epoch 122/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8661.8945 - val_loss: 23404.0126\n",
      "Epoch 123/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8665.1526 - val_loss: 24035.9032\n",
      "Epoch 124/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8654.7460 - val_loss: 23379.5313\n",
      "Epoch 125/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8658.1278 - val_loss: 23974.9087\n",
      "Epoch 126/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8646.4987 - val_loss: 23432.2532\n",
      "Epoch 127/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8648.6968 - val_loss: 23943.9402\n",
      "Epoch 128/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8639.7625 - val_loss: 23307.6052\n",
      "Epoch 129/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8643.9215 - val_loss: 23980.8629\n",
      "Epoch 130/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8632.3360 - val_loss: 23332.9001\n",
      "Epoch 131/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8635.8512 - val_loss: 23951.4545\n",
      "Epoch 132/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8626.3144 - val_loss: 23340.9452\n",
      "Epoch 133/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8628.6012 - val_loss: 23954.5807\n",
      "Epoch 134/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8617.8274 - val_loss: 23281.0594\n",
      "Epoch 135/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8621.6262 - val_loss: 23974.3734\n",
      "Epoch 136/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8612.8064 - val_loss: 23226.4763\n",
      "Epoch 137/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8616.1488 - val_loss: 24021.0764\n",
      "Epoch 138/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8602.4123 - val_loss: 23241.6612\n",
      "Epoch 139/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8608.0572 - val_loss: 23876.6255\n",
      "Epoch 140/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8598.7759 - val_loss: 23305.8328\n",
      "Epoch 141/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8600.2497 - val_loss: 23920.2391\n",
      "Epoch 142/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8589.5506 - val_loss: 23290.2113\n",
      "Epoch 143/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8592.8737 - val_loss: 23857.9215\n",
      "Epoch 144/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8582.3483 - val_loss: 23347.9131\n",
      "Epoch 145/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8584.6685 - val_loss: 23771.5455\n",
      "Epoch 146/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8576.4107 - val_loss: 23155.6937\n",
      "Epoch 147/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8579.8761 - val_loss: 23947.8973\n",
      "Epoch 148/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8569.4163 - val_loss: 23199.5250\n",
      "Epoch 149/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8571.7762 - val_loss: 23879.6677\n",
      "Epoch 150/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8560.5252 - val_loss: 23232.9017\n",
      "Epoch 151/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8563.7816 - val_loss: 23653.4493\n",
      "Epoch 152/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8556.7403 - val_loss: 23338.9946\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 1s 3ms/step - loss: 8554.3979 - val_loss: 23867.2749\n",
      "Epoch 154/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8547.6212 - val_loss: 22998.1081\n",
      "Epoch 155/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8552.7738 - val_loss: 23862.8759\n",
      "Epoch 156/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8540.0321 - val_loss: 23168.2429\n",
      "Epoch 157/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8543.2003 - val_loss: 23751.9476\n",
      "Epoch 158/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8533.3143 - val_loss: 23172.9431\n",
      "Epoch 159/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8534.8711 - val_loss: 23735.5671\n",
      "Epoch 160/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8528.6891 - val_loss: 23046.1959\n",
      "Epoch 161/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8531.0553 - val_loss: 23904.7825\n",
      "Epoch 162/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8516.2688 - val_loss: 22991.4119\n",
      "Epoch 163/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8524.2548 - val_loss: 23635.1870\n",
      "Epoch 164/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8513.4150 - val_loss: 23246.7674\n",
      "Epoch 165/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8511.9996 - val_loss: 23717.3615\n",
      "Epoch 166/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8504.5486 - val_loss: 22989.4355\n",
      "Epoch 167/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8508.0042 - val_loss: 23742.8524\n",
      "Epoch 168/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8499.9520 - val_loss: 22980.6438\n",
      "Epoch 169/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8502.2357 - val_loss: 23789.9214\n",
      "Epoch 170/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8488.6730 - val_loss: 22991.0172\n",
      "Epoch 171/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8493.9297 - val_loss: 23593.6925\n",
      "Epoch 172/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8484.7427 - val_loss: 23150.1794\n",
      "Epoch 173/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8483.8461 - val_loss: 23658.7807\n",
      "Epoch 174/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8474.7073 - val_loss: 22892.2601\n",
      "Epoch 175/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8479.7243 - val_loss: 23709.7650\n",
      "Epoch 176/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8468.0091 - val_loss: 23089.3089\n",
      "Epoch 177/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8469.9991 - val_loss: 23511.0405\n",
      "Epoch 178/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8460.6822 - val_loss: 23132.5625\n",
      "Epoch 179/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8460.0625 - val_loss: 23560.3428\n",
      "Epoch 180/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8455.5187 - val_loss: 22771.2721\n",
      "Epoch 181/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8460.2018 - val_loss: 23747.0273\n",
      "Epoch 182/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8443.2227 - val_loss: 22932.3341\n",
      "Epoch 183/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8448.6235 - val_loss: 23605.7765\n",
      "Epoch 184/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8437.0403 - val_loss: 23081.1676\n",
      "Epoch 185/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8438.1164 - val_loss: 23468.5303\n",
      "Epoch 186/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8431.8715 - val_loss: 22845.1297\n",
      "Epoch 187/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8433.9226 - val_loss: 23683.7728\n",
      "Epoch 188/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8421.4047 - val_loss: 22842.8279\n",
      "Epoch 189/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8425.7984 - val_loss: 23599.8072\n",
      "Epoch 190/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8413.2264 - val_loss: 22954.0602\n",
      "Epoch 191/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8415.7583 - val_loss: 23419.2525\n",
      "Epoch 192/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8407.5628 - val_loss: 23018.3447\n",
      "Epoch 193/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8407.0509 - val_loss: 23484.0933\n",
      "Epoch 194/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8398.5784 - val_loss: 22832.4959\n",
      "Epoch 195/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8400.0917 - val_loss: 23562.0666\n",
      "Epoch 196/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8391.7578 - val_loss: 22759.9376\n",
      "Epoch 197/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8394.5157 - val_loss: 23544.2372\n",
      "Epoch 198/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8381.7337 - val_loss: 22804.7845\n",
      "Epoch 199/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8385.4982 - val_loss: 23424.0875\n",
      "Epoch 200/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8375.0627 - val_loss: 22888.2125\n",
      "Epoch 201/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8375.1590 - val_loss: 23452.0730\n",
      "Epoch 202/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8365.0944 - val_loss: 22760.9804\n",
      "Epoch 203/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8367.9260 - val_loss: 23423.4232\n",
      "Epoch 204/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8359.9656 - val_loss: 22781.1999\n",
      "Epoch 205/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8359.8397 - val_loss: 23498.1765\n",
      "Epoch 206/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8348.8522 - val_loss: 22616.8014\n",
      "Epoch 207/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8353.3021 - val_loss: 23437.9917\n",
      "Epoch 208/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8341.5184 - val_loss: 22825.0252\n",
      "Epoch 209/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8341.8805 - val_loss: 23281.7350\n",
      "Epoch 210/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8335.0440 - val_loss: 22698.6561\n",
      "Epoch 211/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8335.3043 - val_loss: 23457.8875\n",
      "Epoch 212/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8323.4621 - val_loss: 22654.2044\n",
      "Epoch 213/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8326.7709 - val_loss: 23367.6294\n",
      "Epoch 214/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8315.6047 - val_loss: 22791.6885\n",
      "Epoch 215/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8315.2373 - val_loss: 23294.7038\n",
      "Epoch 216/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8309.1211 - val_loss: 22591.1379\n",
      "Epoch 217/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8310.3721 - val_loss: 23423.8117\n",
      "Epoch 218/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8297.6451 - val_loss: 22597.7712\n",
      "Epoch 219/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8301.5158 - val_loss: 23322.6364\n",
      "Epoch 220/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8289.5233 - val_loss: 22713.4498\n",
      "Epoch 221/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8290.8704 - val_loss: 23280.9210\n",
      "Epoch 222/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8281.4595 - val_loss: 22673.4598\n",
      "Epoch 223/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8282.2997 - val_loss: 23281.2390\n",
      "Epoch 224/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8273.3559 - val_loss: 22528.1848\n",
      "Epoch 225/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8274.5992 - val_loss: 23350.0374\n",
      "Epoch 226/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8261.4300 - val_loss: 22704.3554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 227/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8262.0879 - val_loss: 23193.4369\n",
      "Epoch 228/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8254.1730 - val_loss: 22739.9263\n",
      "Epoch 229/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8251.2860 - val_loss: 23298.1256\n",
      "Epoch 230/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8246.8799 - val_loss: 22358.7485\n",
      "Epoch 231/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8248.1329 - val_loss: 23361.6780\n",
      "Epoch 232/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8233.5557 - val_loss: 22647.9351\n",
      "Epoch 233/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8234.4142 - val_loss: 23254.4449\n",
      "Epoch 234/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8223.0273 - val_loss: 22561.1300\n",
      "Epoch 235/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8224.3982 - val_loss: 23250.9418\n",
      "Epoch 236/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8215.9526 - val_loss: 22524.7998\n",
      "Epoch 237/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8215.6968 - val_loss: 23230.8750\n",
      "Epoch 238/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8205.3750 - val_loss: 22516.9280\n",
      "Epoch 239/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8205.1468 - val_loss: 23192.9558\n",
      "Epoch 240/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8196.2677 - val_loss: 22657.4124\n",
      "Epoch 241/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8193.1079 - val_loss: 23175.5112\n",
      "Epoch 242/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8187.4351 - val_loss: 22445.6556\n",
      "Epoch 243/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8186.2104 - val_loss: 23196.1821\n",
      "Epoch 244/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8178.0643 - val_loss: 22432.8152\n",
      "Epoch 245/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8177.2159 - val_loss: 23170.0389\n",
      "Epoch 246/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8166.4422 - val_loss: 22569.1710\n",
      "Epoch 247/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8164.7848 - val_loss: 23048.0488\n",
      "Epoch 248/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8157.5016 - val_loss: 22616.6148\n",
      "Epoch 249/1000\n",
      "245/245 [==============================] - 1s 2ms/step - loss: 8153.2918 - val_loss: 23112.9334\n",
      "Epoch 250/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8148.4025 - val_loss: 22449.4852\n",
      "Train on 244 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "244/244 [==============================] - 7s 28ms/step - loss: 26965.4001 - val_loss: 177252.6344\n",
      "Epoch 2/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26957.6059 - val_loss: 177215.4382\n",
      "Epoch 3/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26932.5408 - val_loss: 177026.4131\n",
      "Epoch 4/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26340.1093 - val_loss: 166983.0134\n",
      "Epoch 5/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 20186.4047 - val_loss: 105740.4832\n",
      "Epoch 6/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 16565.4822 - val_loss: 99293.2787\n",
      "Epoch 7/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 14810.7524 - val_loss: 83218.1590\n",
      "Epoch 8/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 14016.6745 - val_loss: 75183.4085\n",
      "Epoch 9/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 13294.9951 - val_loss: 67428.3254\n",
      "Epoch 10/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12743.7742 - val_loss: 60900.1917\n",
      "Epoch 11/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12284.6134 - val_loss: 55407.5616\n",
      "Epoch 12/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11919.1824 - val_loss: 50763.1450\n",
      "Epoch 13/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11628.6760 - val_loss: 47083.8514\n",
      "Epoch 14/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11409.7139 - val_loss: 44172.9667\n",
      "Epoch 15/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11249.2548 - val_loss: 41815.6533\n",
      "Epoch 16/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11124.1507 - val_loss: 40090.2257\n",
      "Epoch 17/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11020.4521 - val_loss: 38618.2391\n",
      "Epoch 18/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10946.6058 - val_loss: 37355.1186\n",
      "Epoch 19/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10894.9657 - val_loss: 36559.6875\n",
      "Epoch 20/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10857.1044 - val_loss: 35930.8884\n",
      "Epoch 21/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10828.6405 - val_loss: 35401.9321\n",
      "Epoch 22/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10805.0293 - val_loss: 35003.5026\n",
      "Epoch 23/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10785.2970 - val_loss: 34686.9371\n",
      "Epoch 24/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10769.0986 - val_loss: 34389.6638\n",
      "Epoch 25/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10754.8376 - val_loss: 34146.9999\n",
      "Epoch 26/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10742.3242 - val_loss: 33953.3283\n",
      "Epoch 27/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10729.9849 - val_loss: 33788.4665\n",
      "Epoch 28/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10719.0889 - val_loss: 33623.3304\n",
      "Epoch 29/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10708.5849 - val_loss: 33515.4052\n",
      "Epoch 30/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10698.8884 - val_loss: 33409.3757\n",
      "Epoch 31/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10689.5229 - val_loss: 33297.6023\n",
      "Epoch 32/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10681.4925 - val_loss: 33225.0208\n",
      "Epoch 33/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10673.4601 - val_loss: 33153.6588\n",
      "Epoch 34/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10665.5552 - val_loss: 33129.7242\n",
      "Epoch 35/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10657.5125 - val_loss: 33061.4933\n",
      "Epoch 36/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10650.7287 - val_loss: 33034.6566\n",
      "Epoch 37/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10643.5957 - val_loss: 32979.2002\n",
      "Epoch 38/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10636.3059 - val_loss: 32910.7889\n",
      "Epoch 39/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10630.3196 - val_loss: 32949.5763\n",
      "Epoch 40/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10622.7768 - val_loss: 32877.6709\n",
      "Epoch 41/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10616.9204 - val_loss: 32911.5989\n",
      "Epoch 42/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10610.0127 - val_loss: 32864.4802\n",
      "Epoch 43/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10604.4800 - val_loss: 32837.5961\n",
      "Epoch 44/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10598.7212 - val_loss: 32815.5694\n",
      "Epoch 45/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10593.4472 - val_loss: 32793.0519\n",
      "Epoch 46/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10587.6053 - val_loss: 32747.2797\n",
      "Epoch 47/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10582.9988 - val_loss: 32732.2501\n",
      "Epoch 48/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10578.3866 - val_loss: 32703.9725\n",
      "Epoch 49/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10573.0684 - val_loss: 32675.3397\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 1s 3ms/step - loss: 10569.0495 - val_loss: 32679.2610\n",
      "Epoch 51/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10564.2027 - val_loss: 32641.4260\n",
      "Epoch 52/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10559.2081 - val_loss: 32643.7154\n",
      "Epoch 53/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10555.0269 - val_loss: 32549.3006\n",
      "Epoch 54/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10551.2579 - val_loss: 32599.4101\n",
      "Epoch 55/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10546.0585 - val_loss: 32589.3390\n",
      "Epoch 56/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10540.9823 - val_loss: 32547.0475\n",
      "Epoch 57/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10537.7868 - val_loss: 32537.2585\n",
      "Epoch 58/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10532.8892 - val_loss: 32495.9302\n",
      "Epoch 59/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10528.9315 - val_loss: 32529.2515\n",
      "Epoch 60/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10524.9113 - val_loss: 32462.6660\n",
      "Epoch 61/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10520.4432 - val_loss: 32509.2973\n",
      "Epoch 62/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10516.8592 - val_loss: 32412.3001\n",
      "Epoch 63/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10513.7511 - val_loss: 32422.7890\n",
      "Epoch 64/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10508.0122 - val_loss: 32433.5202\n",
      "Epoch 65/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10505.3160 - val_loss: 32373.5986\n",
      "Epoch 66/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10500.7179 - val_loss: 32401.8143\n",
      "Epoch 67/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10497.0946 - val_loss: 32342.6010\n",
      "Epoch 68/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10493.4079 - val_loss: 32349.3257\n",
      "Epoch 69/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10489.6320 - val_loss: 32294.9760\n",
      "Epoch 70/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10486.0579 - val_loss: 32330.4878\n",
      "Epoch 71/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10480.6807 - val_loss: 32308.0115\n",
      "Epoch 72/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10478.4411 - val_loss: 32224.1251\n",
      "Epoch 73/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10474.3075 - val_loss: 32282.2440\n",
      "Epoch 74/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10470.2373 - val_loss: 32227.5132\n",
      "Epoch 75/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10466.6609 - val_loss: 32194.5818\n",
      "Epoch 76/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10463.1052 - val_loss: 32209.4103\n",
      "Epoch 77/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10458.7769 - val_loss: 32220.8191\n",
      "Epoch 78/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10454.4224 - val_loss: 32162.9589\n",
      "Epoch 79/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10450.6778 - val_loss: 32168.0595\n",
      "Epoch 80/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10447.1798 - val_loss: 32152.9945\n",
      "Epoch 81/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10442.9665 - val_loss: 32117.1990\n",
      "Epoch 82/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10440.1671 - val_loss: 32104.0116\n",
      "Epoch 83/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10435.3976 - val_loss: 32099.8455\n",
      "Epoch 84/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10431.7359 - val_loss: 32080.6380\n",
      "Epoch 85/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10427.5398 - val_loss: 32090.5661\n",
      "Epoch 86/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10424.3799 - val_loss: 32041.9403\n",
      "Epoch 87/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10419.4115 - val_loss: 32066.1670\n",
      "Epoch 88/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10415.8310 - val_loss: 32016.8087\n",
      "Epoch 89/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10412.2626 - val_loss: 32024.1991\n",
      "Epoch 90/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10408.2784 - val_loss: 31978.7920\n",
      "Epoch 91/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10403.8241 - val_loss: 31973.9773\n",
      "Epoch 92/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10400.9547 - val_loss: 31959.8106\n",
      "Epoch 93/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10396.8456 - val_loss: 31929.5444\n",
      "Epoch 94/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10392.4463 - val_loss: 31957.5799\n",
      "Epoch 95/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10388.8114 - val_loss: 31865.3157\n",
      "Epoch 96/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10385.1130 - val_loss: 31931.6592\n",
      "Epoch 97/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10380.2565 - val_loss: 31868.6098\n",
      "Epoch 98/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10376.4266 - val_loss: 31892.0018\n",
      "Epoch 99/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10371.9827 - val_loss: 31820.2334\n",
      "Epoch 100/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10368.7862 - val_loss: 31841.4657\n",
      "Epoch 101/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10363.4117 - val_loss: 31821.3912\n",
      "Epoch 102/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10361.1781 - val_loss: 31801.3079\n",
      "Epoch 103/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10355.3300 - val_loss: 31760.4936\n",
      "Epoch 104/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10353.2567 - val_loss: 31810.1883\n",
      "Epoch 105/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10347.7269 - val_loss: 31747.2386\n",
      "Epoch 106/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10343.4077 - val_loss: 31747.2074\n",
      "Epoch 107/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10338.6600 - val_loss: 31678.7540\n",
      "Epoch 108/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10336.7725 - val_loss: 31769.1441\n",
      "Epoch 109/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10331.1791 - val_loss: 31637.1647\n",
      "Epoch 110/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10326.0069 - val_loss: 31625.6366\n",
      "Epoch 111/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10324.5494 - val_loss: 31707.8736\n",
      "Epoch 112/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10318.4279 - val_loss: 31621.8333\n",
      "Epoch 113/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10312.5349 - val_loss: 31580.5692\n",
      "Epoch 114/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10311.6978 - val_loss: 31627.6201\n",
      "Epoch 115/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10304.6100 - val_loss: 31568.8735\n",
      "Epoch 116/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10299.1465 - val_loss: 31479.2550\n",
      "Epoch 117/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10298.6202 - val_loss: 31591.3614\n",
      "Epoch 118/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10290.9951 - val_loss: 31488.6634\n",
      "Epoch 119/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10284.7175 - val_loss: 31421.8925\n",
      "Epoch 120/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10285.1636 - val_loss: 31530.8509\n",
      "Epoch 121/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10275.9043 - val_loss: 31431.1146\n",
      "Epoch 122/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10272.6819 - val_loss: 31469.0452\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 1s 3ms/step - loss: 10266.0138 - val_loss: 31382.2762\n",
      "Epoch 124/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10261.7030 - val_loss: 31329.1532\n",
      "Epoch 125/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10257.9041 - val_loss: 31451.7563\n",
      "Epoch 126/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10250.0856 - val_loss: 31271.8696\n",
      "Epoch 127/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10248.0842 - val_loss: 31425.1907\n",
      "Epoch 128/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10239.1405 - val_loss: 31224.3467\n",
      "Epoch 129/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10237.8678 - val_loss: 31381.3355\n",
      "Epoch 130/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10227.1854 - val_loss: 31129.9094\n",
      "Epoch 131/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10228.2897 - val_loss: 31291.2850\n",
      "Epoch 132/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10212.7871 - val_loss: 31041.0750\n",
      "Epoch 133/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10217.9049 - val_loss: 31233.4526\n",
      "Epoch 134/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10208.1239 - val_loss: 31197.5223\n",
      "Epoch 135/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10194.0199 - val_loss: 31044.8508\n",
      "Epoch 136/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10196.4187 - val_loss: 31155.2190\n",
      "Epoch 137/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10187.5892 - val_loss: 31089.5785\n",
      "Epoch 138/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10176.8518 - val_loss: 31115.0743\n",
      "Epoch 139/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10172.7496 - val_loss: 30998.1486\n",
      "Epoch 140/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10165.1744 - val_loss: 31030.2666\n",
      "Epoch 141/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10155.0768 - val_loss: 30914.7434\n",
      "Epoch 142/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10148.8972 - val_loss: 30881.9731\n",
      "Epoch 143/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10141.3740 - val_loss: 30827.1849\n",
      "Epoch 144/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10129.4238 - val_loss: 30817.6730\n",
      "Epoch 145/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10122.9256 - val_loss: 30676.1899\n",
      "Epoch 146/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10113.5266 - val_loss: 30754.6722\n",
      "Epoch 147/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10102.5445 - val_loss: 30604.3666\n",
      "Epoch 148/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10091.2469 - val_loss: 30634.6281\n",
      "Epoch 149/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10081.1499 - val_loss: 30496.5223\n",
      "Epoch 150/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10067.5417 - val_loss: 30530.6494\n",
      "Epoch 151/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10055.1738 - val_loss: 30344.1941\n",
      "Epoch 152/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10040.1439 - val_loss: 30287.4838\n",
      "Epoch 153/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10021.6153 - val_loss: 30163.8454\n",
      "Epoch 154/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10009.1891 - val_loss: 30063.4396\n",
      "Epoch 155/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9988.9015 - val_loss: 30018.2425\n",
      "Epoch 156/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9988.5441 - val_loss: 30098.3649\n",
      "Epoch 157/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9955.2502 - val_loss: 30049.4127\n",
      "Epoch 158/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9952.4845 - val_loss: 30041.9881\n",
      "Epoch 159/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9916.3862 - val_loss: 29873.2609\n",
      "Epoch 160/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9915.2506 - val_loss: 29869.1574\n",
      "Epoch 161/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9875.7449 - val_loss: 29650.6396\n",
      "Epoch 162/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9879.2791 - val_loss: 29804.2849\n",
      "Epoch 163/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9832.3222 - val_loss: 29565.8144\n",
      "Epoch 164/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9832.1869 - val_loss: 29728.6713\n",
      "Epoch 165/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9809.2493 - val_loss: 29871.6853\n",
      "Epoch 166/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9761.0752 - val_loss: 29257.3763\n",
      "Epoch 167/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9764.8300 - val_loss: 29601.7286\n",
      "Epoch 168/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9732.5423 - val_loss: 29635.4694\n",
      "Epoch 169/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9713.5514 - val_loss: 29658.1468\n",
      "Epoch 170/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9681.2971 - val_loss: 29660.3497\n",
      "Epoch 171/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9662.6845 - val_loss: 29630.3474\n",
      "Epoch 172/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9628.3499 - val_loss: 29523.0617\n",
      "Epoch 173/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9611.0619 - val_loss: 29646.2721\n",
      "Epoch 174/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9534.9482 - val_loss: 28736.7741\n",
      "Epoch 175/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9560.5854 - val_loss: 29331.6409\n",
      "Epoch 176/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9519.7234 - val_loss: 29348.9622\n",
      "Epoch 177/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9444.9110 - val_loss: 28460.9531\n",
      "Epoch 178/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9481.8305 - val_loss: 29367.0023\n",
      "Epoch 179/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9435.2657 - val_loss: 29302.9056\n",
      "Epoch 180/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9352.5674 - val_loss: 28318.1140\n",
      "Epoch 181/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9406.3707 - val_loss: 29252.0350\n",
      "Epoch 182/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9335.2550 - val_loss: 29124.2864\n",
      "Epoch 183/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9256.0649 - val_loss: 28030.0594\n",
      "Epoch 184/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9306.6330 - val_loss: 28950.8728\n",
      "Epoch 185/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9236.2150 - val_loss: 28942.1857\n",
      "Epoch 186/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9137.7369 - val_loss: 28151.7251\n",
      "Epoch 187/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9113.7412 - val_loss: 28486.4024\n",
      "Epoch 188/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9089.0394 - val_loss: 28382.2757\n",
      "Epoch 189/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9062.6938 - val_loss: 28380.8447\n",
      "Epoch 190/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9042.8829 - val_loss: 28514.6897\n",
      "Epoch 191/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9024.7371 - val_loss: 28442.7883\n",
      "Epoch 192/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9103.5753 - val_loss: 29764.6158\n",
      "Epoch 193/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8975.0584 - val_loss: 28432.6261\n",
      "Epoch 194/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8953.8313 - val_loss: 28792.4554\n",
      "Epoch 195/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8937.3294 - val_loss: 28664.3433\n",
      "Epoch 196/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 1s 3ms/step - loss: 8919.5218 - val_loss: 28737.5848\n",
      "Epoch 197/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8908.9483 - val_loss: 29073.0706\n",
      "Epoch 198/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9003.0698 - val_loss: 29997.0597\n",
      "Epoch 199/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8859.7990 - val_loss: 28633.9969\n",
      "Epoch 200/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9068.0794 - val_loss: 29372.8107\n",
      "Epoch 201/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9819.1091 - val_loss: 42595.5317\n",
      "Epoch 202/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9274.7545 - val_loss: 32085.0971\n",
      "Epoch 203/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9048.0931 - val_loss: 29644.4741\n",
      "Train on 244 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "244/244 [==============================] - 8s 33ms/step - loss: 26964.5130 - val_loss: 179358.0793\n",
      "Epoch 2/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26912.5651 - val_loss: 179036.7670\n",
      "Epoch 3/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26575.0007 - val_loss: 173561.7946\n",
      "Epoch 4/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 20035.9447 - val_loss: 59336.8823\n",
      "Epoch 5/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 15715.3665 - val_loss: 99217.6902\n",
      "Epoch 6/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 14441.4675 - val_loss: 56511.3947\n",
      "Epoch 7/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 13533.6904 - val_loss: 60264.5865\n",
      "Epoch 8/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12987.3565 - val_loss: 48831.1371\n",
      "Epoch 9/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12758.7730 - val_loss: 49794.4509\n",
      "Epoch 10/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12603.1788 - val_loss: 46895.0137\n",
      "Epoch 11/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12525.6117 - val_loss: 46551.9834\n",
      "Epoch 12/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12438.7721 - val_loss: 45703.1474\n",
      "Epoch 13/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12377.4954 - val_loss: 45337.8841\n",
      "Epoch 14/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12319.3366 - val_loss: 45147.9255\n",
      "Epoch 15/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12258.8653 - val_loss: 45054.8122\n",
      "Epoch 16/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12201.5837 - val_loss: 45167.9672\n",
      "Epoch 17/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12140.3137 - val_loss: 44898.1997\n",
      "Epoch 18/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12081.5805 - val_loss: 45218.7108\n",
      "Epoch 19/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12029.2940 - val_loss: 44993.0430\n",
      "Epoch 20/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11983.9925 - val_loss: 45175.7477\n",
      "Epoch 21/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11912.6845 - val_loss: 45891.5331\n",
      "Epoch 22/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11822.9423 - val_loss: 45423.5190\n",
      "Epoch 23/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11761.4984 - val_loss: 46205.7004\n",
      "Epoch 24/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11668.5691 - val_loss: 45678.4711\n",
      "Epoch 25/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11582.8909 - val_loss: 46363.0096\n",
      "Epoch 26/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11504.7128 - val_loss: 47176.7724\n",
      "Epoch 27/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11380.4431 - val_loss: 46636.1298\n",
      "Epoch 28/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11297.5976 - val_loss: 48255.2198\n",
      "Epoch 29/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11160.6603 - val_loss: 47465.4728\n",
      "Epoch 30/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11067.2269 - val_loss: 51193.6733\n",
      "Epoch 31/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10927.8116 - val_loss: 48920.0801\n",
      "Epoch 32/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10779.7646 - val_loss: 51011.6475\n",
      "Epoch 33/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10665.4498 - val_loss: 51658.4225\n",
      "Epoch 34/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10488.3076 - val_loss: 51866.0308\n",
      "Epoch 35/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10371.1936 - val_loss: 54896.7442\n",
      "Epoch 36/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10207.1546 - val_loss: 52400.6583\n",
      "Epoch 37/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10001.1274 - val_loss: 57070.1942\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "243/243 [==============================] - 9s 38ms/step - loss: 27077.3967 - val_loss: 179378.2245\n",
      "Epoch 2/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 27039.4937 - val_loss: 179063.8301\n",
      "Epoch 3/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 26157.4725 - val_loss: 149195.0965\n",
      "Epoch 4/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17553.3452 - val_loss: 67913.3465\n",
      "Epoch 5/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15063.8337 - val_loss: 77677.8520\n",
      "Epoch 6/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14286.7968 - val_loss: 57847.5068\n",
      "Epoch 7/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13775.0727 - val_loss: 58524.7026\n",
      "Epoch 8/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13603.5297 - val_loss: 55147.8926\n",
      "Epoch 9/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13461.2937 - val_loss: 54795.2244\n",
      "Epoch 10/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13366.5382 - val_loss: 53772.3899\n",
      "Epoch 11/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13273.4005 - val_loss: 53414.4489\n",
      "Epoch 12/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13191.7310 - val_loss: 52844.2692\n",
      "Epoch 13/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13118.5963 - val_loss: 52475.9163\n",
      "Epoch 14/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13049.5264 - val_loss: 52319.9614\n",
      "Epoch 15/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12951.6484 - val_loss: 51749.9620\n",
      "Epoch 16/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12870.5236 - val_loss: 51289.4790\n",
      "Epoch 17/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12781.9125 - val_loss: 51144.7088\n",
      "Epoch 18/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12677.9268 - val_loss: 50709.3131\n",
      "Epoch 19/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12587.0246 - val_loss: 50568.1213\n",
      "Epoch 20/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12455.9308 - val_loss: 49864.7853\n",
      "Epoch 21/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12341.3217 - val_loss: 49849.2478\n",
      "Epoch 22/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12214.7471 - val_loss: 49584.8437\n",
      "Epoch 23/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12073.5173 - val_loss: 49639.5530\n",
      "Epoch 24/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11917.0645 - val_loss: 49488.9034\n",
      "Epoch 25/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11740.7824 - val_loss: 49223.9001\n",
      "Epoch 26/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11620.2210 - val_loss: 48547.5233\n",
      "Epoch 27/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11384.4336 - val_loss: 50897.2527\n",
      "Epoch 28/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11109.9217 - val_loss: 47987.0297\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 1s 4ms/step - loss: 10857.4573 - val_loss: 49474.1334\n",
      "Epoch 30/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10631.7782 - val_loss: 48721.8569\n",
      "Epoch 31/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10318.9676 - val_loss: 50110.7780\n",
      "Epoch 32/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10043.7878 - val_loss: 49351.9552\n",
      "Epoch 33/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9806.0621 - val_loss: 51009.2985\n",
      "Epoch 34/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9509.2426 - val_loss: 51330.5374\n",
      "Epoch 35/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9247.5123 - val_loss: 52779.3410\n",
      "Epoch 36/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8990.4639 - val_loss: 52850.9334\n",
      "Epoch 37/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8868.3756 - val_loss: 54348.8694\n",
      "Epoch 38/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9022.3287 - val_loss: 57233.2673\n",
      "Epoch 39/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9717.1245 - val_loss: 54179.1132\n",
      "Epoch 40/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9714.8719 - val_loss: 45257.6344\n",
      "Epoch 41/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8736.0639 - val_loss: 42166.0846\n",
      "Epoch 42/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8194.8064 - val_loss: 44308.1893\n",
      "Epoch 43/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8211.6190 - val_loss: 46485.4929\n",
      "Epoch 44/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8375.0305 - val_loss: 49248.1709\n",
      "Epoch 45/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9143.5950 - val_loss: 53582.5303\n",
      "Epoch 46/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9716.0158 - val_loss: 39556.4724\n",
      "Epoch 47/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8204.7684 - val_loss: 35375.2626\n",
      "Epoch 48/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7542.5741 - val_loss: 38489.8951\n",
      "Epoch 49/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7424.3380 - val_loss: 42381.5416\n",
      "Epoch 50/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7815.2459 - val_loss: 49803.1368\n",
      "Epoch 51/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8986.2570 - val_loss: 45350.7087\n",
      "Epoch 52/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8729.4475 - val_loss: 34630.6718\n",
      "Epoch 53/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7509.1953 - val_loss: 33837.0631\n",
      "Epoch 54/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7185.9723 - val_loss: 36618.6120\n",
      "Epoch 55/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7262.1396 - val_loss: 41316.6333\n",
      "Epoch 56/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7964.6416 - val_loss: 44099.0197\n",
      "Epoch 57/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8455.4581 - val_loss: 35621.7547\n",
      "Epoch 58/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7536.7344 - val_loss: 29732.3569\n",
      "Epoch 59/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6867.3724 - val_loss: 31800.9257\n",
      "Epoch 60/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7061.8386 - val_loss: 36042.3290\n",
      "Epoch 61/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7911.4789 - val_loss: 36171.6448\n",
      "Epoch 62/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8047.3294 - val_loss: 26575.9163\n",
      "Epoch 63/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6867.7174 - val_loss: 20690.6244\n",
      "Epoch 64/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6111.9140 - val_loss: 26321.2343\n",
      "Epoch 65/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5783.2015 - val_loss: 27808.1905\n",
      "Epoch 66/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5666.3293 - val_loss: 34880.9441\n",
      "Epoch 67/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7111.8660 - val_loss: 53197.4359\n",
      "Epoch 68/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9459.8026 - val_loss: 29387.3074\n",
      "Epoch 69/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6828.0890 - val_loss: 22183.3726\n",
      "Epoch 70/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5965.5287 - val_loss: 21464.4863\n",
      "Epoch 71/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5579.4029 - val_loss: 31245.2331\n",
      "Epoch 72/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5811.6236 - val_loss: 30126.0488\n",
      "Epoch 73/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6935.4746 - val_loss: 40334.8769\n",
      "Epoch 74/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8412.6206 - val_loss: 29353.6472\n",
      "Epoch 75/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7185.2395 - val_loss: 19442.5411\n",
      "Epoch 76/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5865.1014 - val_loss: 17313.4974\n",
      "Epoch 77/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5269.7887 - val_loss: 24232.0440\n",
      "Epoch 78/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5057.6494 - val_loss: 20653.3100\n",
      "Epoch 79/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4835.2799 - val_loss: 33095.0351\n",
      "Epoch 80/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5196.0601 - val_loss: 33595.5808\n",
      "Epoch 81/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6754.0701 - val_loss: 38476.6169\n",
      "Epoch 82/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8055.0331 - val_loss: 30101.3810\n",
      "Epoch 83/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6898.9576 - val_loss: 17408.1880\n",
      "Epoch 84/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5293.3806 - val_loss: 12814.9269\n",
      "Epoch 85/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5082.2149 - val_loss: 44276.8304\n",
      "Epoch 86/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5508.7289 - val_loss: 14017.7510\n",
      "Epoch 87/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6852.2516 - val_loss: 83251.5882\n",
      "Epoch 88/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8297.6032 - val_loss: 29501.5686\n",
      "Epoch 89/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4842.0788 - val_loss: 32466.7203\n",
      "Epoch 90/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6182.4116 - val_loss: 38518.4334\n",
      "Epoch 91/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7837.6136 - val_loss: 29253.5551\n",
      "Epoch 92/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6189.1243 - val_loss: 17930.0257\n",
      "Epoch 93/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4845.0770 - val_loss: 25340.1632\n",
      "Epoch 94/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4732.1134 - val_loss: 21073.2887\n",
      "Epoch 95/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4555.0457 - val_loss: 30474.4364\n",
      "Epoch 96/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5167.8950 - val_loss: 24368.0088\n",
      "Epoch 97/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5303.3364 - val_loss: 30709.7403\n",
      "Epoch 98/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6249.1967 - val_loss: 26090.6075\n",
      "Epoch 99/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6254.7723 - val_loss: 21274.9724\n",
      "Epoch 100/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5467.0859 - val_loss: 13420.4092\n",
      "Epoch 101/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4591.6686 - val_loss: 26147.4976\n",
      "Epoch 102/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4473.7951 - val_loss: 20172.6649\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 1s 4ms/step - loss: 4118.0538 - val_loss: 33996.7516\n",
      "Epoch 104/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4455.3787 - val_loss: 19637.2075\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "243/243 [==============================] - 11s 47ms/step - loss: 27132.4723 - val_loss: 194045.6739\n",
      "Epoch 2/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 27112.5798 - val_loss: 193888.7683\n",
      "Epoch 3/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 26313.8195 - val_loss: 151830.7049\n",
      "Epoch 4/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17298.8452 - val_loss: 53676.8638\n",
      "Epoch 5/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17111.0620 - val_loss: 102067.4298\n",
      "Epoch 6/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15084.1686 - val_loss: 59353.5044\n",
      "Epoch 7/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15363.8216 - val_loss: 82768.5253\n",
      "Epoch 8/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14942.6821 - val_loss: 69629.3331\n",
      "Epoch 9/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14995.8969 - val_loss: 75572.7577\n",
      "Epoch 10/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14911.3471 - val_loss: 72695.7610\n",
      "Epoch 11/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14890.0918 - val_loss: 73692.1600\n",
      "Epoch 12/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14859.2841 - val_loss: 72872.6915\n",
      "Epoch 13/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14834.0552 - val_loss: 72968.5828\n",
      "Epoch 14/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14820.0989 - val_loss: 72741.0855\n",
      "Epoch 15/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14792.6057 - val_loss: 72604.6342\n",
      "Epoch 16/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14778.9712 - val_loss: 72727.1127\n",
      "Epoch 17/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14753.8630 - val_loss: 72370.9162\n",
      "Epoch 18/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14735.6419 - val_loss: 72514.8726\n",
      "Epoch 19/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14708.7187 - val_loss: 71996.2731\n",
      "Epoch 20/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14693.8506 - val_loss: 71959.8906\n",
      "Epoch 21/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14667.1572 - val_loss: 71781.3725\n",
      "Epoch 22/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14639.6267 - val_loss: 71566.3492\n",
      "Epoch 23/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14605.4360 - val_loss: 71220.2308\n",
      "Epoch 24/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14583.0055 - val_loss: 71259.2645\n",
      "Train on 242 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "242/242 [==============================] - 12s 49ms/step - loss: 27242.0156 - val_loss: 194026.6287\n",
      "Epoch 2/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 27211.5894 - val_loss: 193798.3662\n",
      "Epoch 3/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 26704.7670 - val_loss: 172672.2099\n",
      "Epoch 4/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 18728.7247 - val_loss: 29814.7072\n",
      "Epoch 5/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 25042.8809 - val_loss: 134648.8883\n",
      "Epoch 6/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 18445.3553 - val_loss: 105735.4612\n",
      "Epoch 7/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15843.9698 - val_loss: 75645.1504\n",
      "Epoch 8/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15634.3169 - val_loss: 76089.7904\n",
      "Epoch 9/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15572.1561 - val_loss: 77902.5664\n",
      "Epoch 10/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15549.4988 - val_loss: 78106.2810\n",
      "Epoch 11/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15543.0950 - val_loss: 78553.1842\n",
      "Epoch 12/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15531.3554 - val_loss: 78932.2649\n",
      "Epoch 13/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15518.1287 - val_loss: 79189.1459\n",
      "Epoch 14/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15506.7491 - val_loss: 79411.6187\n",
      "Epoch 15/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15487.9987 - val_loss: 79495.0468\n",
      "Epoch 16/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15469.1986 - val_loss: 79562.3174\n",
      "Epoch 17/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15445.9952 - val_loss: 79433.3056\n",
      "Epoch 18/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15423.9652 - val_loss: 79417.9857\n",
      "Epoch 19/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15394.8254 - val_loss: 79214.9716\n",
      "Epoch 20/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15364.0160 - val_loss: 78965.0036\n",
      "Epoch 21/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15336.1096 - val_loss: 78880.1760\n",
      "Epoch 22/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15294.7404 - val_loss: 78545.8746\n",
      "Epoch 23/1000\n",
      "242/242 [==============================] - 1s 5ms/step - loss: 15256.8042 - val_loss: 78435.1960\n",
      "Epoch 24/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15218.5297 - val_loss: 78120.8526\n"
     ]
    }
   ],
   "source": [
    "# Sub model 2 - LSTM\n",
    "\n",
    "rmse = []\n",
    "r2 = []\n",
    "for ts in range(3, 11, 1):  \n",
    "    \n",
    "    # time step & lag\n",
    "    data_X, data_Y = time_step(data , ts, 1, 1)\n",
    "    \n",
    "    # 데이터 분할\n",
    "    NUM_TRAIN = int(data_X.shape[0] * 0.6)\n",
    "    NUM_VAL = int(data_X.shape[0] * 0.8)\n",
    "\n",
    "    train_X = data_X[:NUM_TRAIN]\n",
    "    train_Y = data_Y[:NUM_TRAIN]\n",
    "\n",
    "    val_X = data_X[NUM_TRAIN:NUM_VAL]\n",
    "    val_Y = data_Y[NUM_TRAIN:NUM_VAL]\n",
    "\n",
    "    test_X = data_X[NUM_VAL:]\n",
    "    test_Y =data_Y[NUM_VAL:]\n",
    "\n",
    "    train_X, val_X, test_X = normalization(train_X, val_X, test_X)\n",
    "    \n",
    "    # 함수형 API\n",
    "    input_tensor = Input(shape=(train_X.shape[1],))\n",
    "    x = layers.Reshape((train_X.shape[1], 1))(input_tensor)\n",
    "    x = layers.LSTM(32, activation='relu', return_sequences=True)(x)\n",
    "    x = layers.LSTM(16, activation='relu', return_sequences=True)(x)\n",
    "    x = layers.LSTM(8, activation='relu', return_sequences=True)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(4, activation='relu')(x)\n",
    "    output_tensor = layers.Dense(1)(x)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    mc = ModelCheckpoint('./model/LSTM/model_{}.h5'.format(ts), monitor='val_loss', save_best_only=True)\n",
    "    \n",
    "    model.fit(train_X, train_Y,\n",
    "              batch_size=8,\n",
    "              epochs=1000,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_X, val_Y),\n",
    "              callbacks=[early_stopping, mc],\n",
    "              verbose=1)\n",
    "    \n",
    "    best_model = load_model('./model/LSTM/model_{}.h5'.format(ts))\n",
    "    \n",
    "    y_pred = best_model.predict(test_X)\n",
    "    y_pred = y_pred.reshape(-1).astype('float32')\n",
    "    y_real = test_Y.reshape(-1).astype('float32')\n",
    "    \n",
    "    raw= {'Observed': list(y_real), 'Predicted': list(y_pred)}\n",
    "    rr = pd.DataFrame(raw)\n",
    "#     rr.to_csv(\"./Submodel/DNN/time_step/timse_step{}.csv\".format(ts))\n",
    "    reg = sm.OLS.from_formula(\"Observed ~ Predicted\",rr).fit()\n",
    "\n",
    "    try:\n",
    "        RMSE = round(math.sqrt(mean_squared_error(y_real, y_pred)), 3)\n",
    "        R2 = round(reg.rsquared, 3)   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    rmse.append(RMSE)\n",
    "    r2.append(R2)\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.plot(test_Y, label='Observed')\n",
    "#     plt.plot(y_predict, label='Predicted')\n",
    "#     plt.legend()\n",
    "#     plt.savefig('fig_{}.png'.format(ts), dpi=300)\n",
    " \n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[149.481, 148.917, 143.073, 142.718, 178.593, 197.441, 168.947, 286.894]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.783, 0.762, 0.768, 0.795, 0.816, 0.494, 0.756, 0.731]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.606, 0.615, 0.591, 0.589, 0.737, 0.815, 0.715, 1.215]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = list(np.array(rmse) / np.array(std_list))\n",
    "\n",
    "rmse_std = []\n",
    "for i in tmp:\n",
    "    rmse_std.append(round(i, 3))\n",
    "rmse_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 246 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "246/246 [==============================] - 43s 176ms/step - loss: 26729.8532 - val_loss: 163665.2006\n",
      "Epoch 2/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26700.7952 - val_loss: 163523.5640\n",
      "Epoch 3/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26616.7568 - val_loss: 163031.7586\n",
      "Epoch 4/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26261.0412 - val_loss: 160160.0739\n",
      "Epoch 5/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 24227.2225 - val_loss: 144038.8585\n",
      "Epoch 6/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 19060.9891 - val_loss: 111453.3030\n",
      "Epoch 7/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 15571.0021 - val_loss: 91143.8440\n",
      "Epoch 8/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 14375.6266 - val_loss: 83394.2496\n",
      "Epoch 9/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 13437.6267 - val_loss: 76690.9838\n",
      "Epoch 10/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 12633.2423 - val_loss: 70217.0913\n",
      "Epoch 11/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 11874.2494 - val_loss: 64131.7113\n",
      "Epoch 12/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 11141.6475 - val_loss: 58340.2574\n",
      "Epoch 13/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 10438.2396 - val_loss: 52621.6413\n",
      "Epoch 14/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 9746.3914 - val_loss: 47070.0927\n",
      "Epoch 15/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 9073.8647 - val_loss: 41570.3358\n",
      "Epoch 16/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 8426.9836 - val_loss: 36480.0354\n",
      "Epoch 17/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7839.3762 - val_loss: 32380.1022\n",
      "Epoch 18/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7293.8351 - val_loss: 27490.9027\n",
      "Epoch 19/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6809.9569 - val_loss: 24126.3993\n",
      "Epoch 20/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6431.3695 - val_loss: 21405.9966\n",
      "Epoch 21/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6115.8733 - val_loss: 19135.4646\n",
      "Epoch 22/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5856.7188 - val_loss: 17339.0248\n",
      "Epoch 23/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5702.1059 - val_loss: 15769.9241\n",
      "Epoch 24/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5489.7997 - val_loss: 14447.3290\n",
      "Epoch 25/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5375.3908 - val_loss: 13880.4496\n",
      "Epoch 26/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5297.3408 - val_loss: 13157.5786\n",
      "Epoch 27/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5249.3050 - val_loss: 12776.6814\n",
      "Epoch 28/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5217.5497 - val_loss: 12601.1120\n",
      "Epoch 29/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5195.5463 - val_loss: 12504.2624\n",
      "Epoch 30/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5170.7752 - val_loss: 12501.1087\n",
      "Epoch 31/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5149.4130 - val_loss: 12418.2555\n",
      "Epoch 32/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5131.4723 - val_loss: 12406.0539\n",
      "Epoch 33/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5110.5623 - val_loss: 12408.9794\n",
      "Epoch 34/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5089.2649 - val_loss: 12424.5453\n",
      "Epoch 35/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5071.9315 - val_loss: 12413.7386\n",
      "Epoch 36/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5052.7786 - val_loss: 12447.1394\n",
      "Epoch 37/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5035.0756 - val_loss: 12440.4010\n",
      "Epoch 38/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5017.6927 - val_loss: 12413.4269\n",
      "Epoch 39/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5001.3289 - val_loss: 12410.1598\n",
      "Epoch 40/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4983.5651 - val_loss: 12411.4553\n",
      "Epoch 41/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4969.2805 - val_loss: 12377.9625\n",
      "Epoch 42/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4953.9878 - val_loss: 12387.1319\n",
      "Epoch 43/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4937.7133 - val_loss: 12389.7477\n",
      "Epoch 44/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4916.1442 - val_loss: 12367.1801\n",
      "Epoch 45/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4895.1426 - val_loss: 12277.4178\n",
      "Epoch 46/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4876.6378 - val_loss: 12308.9137\n",
      "Epoch 47/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4863.2729 - val_loss: 12286.2957\n",
      "Epoch 48/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4844.0931 - val_loss: 12306.5267\n",
      "Epoch 49/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4830.7334 - val_loss: 12313.1098\n",
      "Epoch 50/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4813.0641 - val_loss: 12365.4673\n",
      "Epoch 51/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4799.0383 - val_loss: 12337.3203\n",
      "Epoch 52/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4784.3828 - val_loss: 12373.4818\n",
      "Epoch 53/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4769.3016 - val_loss: 12366.4527\n",
      "Epoch 54/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4755.0185 - val_loss: 12355.3443\n",
      "Epoch 55/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4743.3991 - val_loss: 12422.1272\n",
      "Epoch 56/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4727.8226 - val_loss: 12449.4136\n",
      "Epoch 57/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4718.3387 - val_loss: 12399.9082\n",
      "Epoch 58/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4701.2701 - val_loss: 12415.9618\n",
      "Epoch 59/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4690.7770 - val_loss: 12385.3557\n",
      "Epoch 60/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4676.2264 - val_loss: 12372.0704\n",
      "Epoch 61/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4664.3344 - val_loss: 12335.5108\n",
      "Epoch 62/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4658.0215 - val_loss: 12294.6013\n",
      "Epoch 63/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4642.7643 - val_loss: 12285.2567\n",
      "Epoch 64/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4639.5613 - val_loss: 12242.0830\n",
      "Epoch 65/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4626.1612 - val_loss: 12268.1464\n",
      "Epoch 66/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4620.6341 - val_loss: 12255.0461\n",
      "Epoch 67/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4609.8630 - val_loss: 12270.3746\n",
      "Epoch 68/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4609.5320 - val_loss: 12279.5842\n",
      "Epoch 69/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4597.6933 - val_loss: 12353.0680\n",
      "Epoch 70/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4592.6297 - val_loss: 12371.1884\n",
      "Epoch 71/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4579.5621 - val_loss: 12422.0879\n",
      "Epoch 72/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4572.8747 - val_loss: 12355.5499\n",
      "Epoch 73/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4562.0913 - val_loss: 12352.0568\n",
      "Epoch 74/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4554.8573 - val_loss: 12365.3656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4545.5155 - val_loss: 12375.8406\n",
      "Epoch 76/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4535.1591 - val_loss: 12350.9938\n",
      "Epoch 77/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4538.7444 - val_loss: 12411.9852\n",
      "Epoch 78/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4519.9754 - val_loss: 12465.8020\n",
      "Epoch 79/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4520.6285 - val_loss: 12464.3392\n",
      "Epoch 80/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4507.3240 - val_loss: 12665.0391\n",
      "Epoch 81/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4542.7170 - val_loss: 11802.5523\n",
      "Epoch 82/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4441.9845 - val_loss: 15128.1971\n",
      "Epoch 83/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4374.5789 - val_loss: 14896.9421\n",
      "Epoch 84/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4352.6811 - val_loss: 9693.1688\n",
      "Epoch 85/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4384.8973 - val_loss: 15564.5201\n",
      "Epoch 86/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4363.5062 - val_loss: 9731.3144\n",
      "Epoch 87/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4341.5202 - val_loss: 15243.9091\n",
      "Epoch 88/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4339.9938 - val_loss: 9856.8927\n",
      "Epoch 89/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4319.2546 - val_loss: 14829.0011\n",
      "Epoch 90/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4300.3628 - val_loss: 10024.0145\n",
      "Epoch 91/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4285.7078 - val_loss: 15259.6104\n",
      "Epoch 92/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4497.5640 - val_loss: 13825.5639\n",
      "Epoch 93/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4432.7267 - val_loss: 13331.9210\n",
      "Epoch 94/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4354.4410 - val_loss: 12276.5135\n",
      "Epoch 95/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4205.0947 - val_loss: 12084.1351\n",
      "Epoch 96/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4168.7266 - val_loss: 12459.0464\n",
      "Epoch 97/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4170.9370 - val_loss: 12092.0007\n",
      "Epoch 98/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4146.0589 - val_loss: 13383.9561\n",
      "Epoch 99/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4228.8666 - val_loss: 9123.5545\n",
      "Epoch 100/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4299.8628 - val_loss: 15809.7674\n",
      "Epoch 101/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4483.7416 - val_loss: 12178.2989\n",
      "Epoch 102/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4368.4537 - val_loss: 14980.0897\n",
      "Epoch 103/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4353.4519 - val_loss: 13231.8779\n",
      "Epoch 104/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4102.7213 - val_loss: 12569.9036\n",
      "Epoch 105/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4098.2107 - val_loss: 15322.3327\n",
      "Epoch 106/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4251.1800 - val_loss: 9209.8687\n",
      "Epoch 107/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4148.3377 - val_loss: 12597.9241\n",
      "Epoch 108/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4366.7648 - val_loss: 11364.6403\n",
      "Epoch 109/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4320.2292 - val_loss: 14371.2102\n",
      "Epoch 110/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4316.8399 - val_loss: 11954.8320\n",
      "Epoch 111/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4228.4309 - val_loss: 12627.7761\n",
      "Epoch 112/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4201.6243 - val_loss: 10830.5548\n",
      "Epoch 113/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 3969.0851 - val_loss: 10560.9564\n",
      "Epoch 114/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 3949.7521 - val_loss: 10607.3054\n",
      "Epoch 115/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 3951.3539 - val_loss: 9473.6731\n",
      "Epoch 116/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4081.0908 - val_loss: 11992.7297\n",
      "Epoch 117/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4226.7461 - val_loss: 11951.6425\n",
      "Epoch 118/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4196.0947 - val_loss: 11770.8393\n",
      "Epoch 119/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 4103.6831 - val_loss: 9489.1660\n",
      "Train on 246 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "246/246 [==============================] - 45s 182ms/step - loss: 26734.4930 - val_loss: 177144.0606\n",
      "Epoch 2/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26685.1921 - val_loss: 176862.4087\n",
      "Epoch 3/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26563.8210 - val_loss: 176019.7389\n",
      "Epoch 4/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 26140.6213 - val_loss: 171574.9658\n",
      "Epoch 5/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 23624.0633 - val_loss: 141387.3612\n",
      "Epoch 6/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 16125.8960 - val_loss: 85193.0628\n",
      "Epoch 7/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 12943.1908 - val_loss: 68435.3095\n",
      "Epoch 8/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 11541.0577 - val_loss: 59166.5035\n",
      "Epoch 9/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 10631.7265 - val_loss: 50195.7335\n",
      "Epoch 10/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 9897.8078 - val_loss: 43879.3362\n",
      "Epoch 11/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 9280.2100 - val_loss: 37974.1865\n",
      "Epoch 12/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 8837.1333 - val_loss: 33926.1203\n",
      "Epoch 13/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 8494.2052 - val_loss: 30842.9900\n",
      "Epoch 14/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 8226.8247 - val_loss: 28482.4022\n",
      "Epoch 15/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7993.2881 - val_loss: 26503.4842\n",
      "Epoch 16/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7818.2169 - val_loss: 24663.7576\n",
      "Epoch 17/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7653.3448 - val_loss: 23432.5080\n",
      "Epoch 18/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7524.2563 - val_loss: 22176.0812\n",
      "Epoch 19/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7418.4113 - val_loss: 21285.4329\n",
      "Epoch 20/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7328.8285 - val_loss: 20462.7204\n",
      "Epoch 21/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7268.4210 - val_loss: 19629.7865\n",
      "Epoch 22/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7227.4424 - val_loss: 19218.9551\n",
      "Epoch 23/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7196.5884 - val_loss: 18839.3586\n",
      "Epoch 24/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7169.0212 - val_loss: 18573.0408\n",
      "Epoch 25/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7145.5316 - val_loss: 18243.5853\n",
      "Epoch 26/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7125.5435 - val_loss: 18096.2014\n",
      "Epoch 27/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7110.3641 - val_loss: 17827.2940\n",
      "Epoch 28/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7098.2655 - val_loss: 17729.0125\n",
      "Epoch 29/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7085.7738 - val_loss: 17662.4364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7074.8316 - val_loss: 17498.2823\n",
      "Epoch 31/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7065.6135 - val_loss: 17506.7748\n",
      "Epoch 32/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7054.4202 - val_loss: 17299.3354\n",
      "Epoch 33/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7048.2673 - val_loss: 17317.5218\n",
      "Epoch 34/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7039.9313 - val_loss: 17197.1293\n",
      "Epoch 35/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7034.3437 - val_loss: 17242.0004\n",
      "Epoch 36/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 7051.3977 - val_loss: 17502.8730\n",
      "Epoch 37/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7013.2800 - val_loss: 17003.0785\n",
      "Epoch 38/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 7006.2970 - val_loss: 17023.1775\n",
      "Epoch 39/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6995.6934 - val_loss: 16850.6100\n",
      "Epoch 40/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6989.1553 - val_loss: 16993.2917\n",
      "Epoch 41/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6972.9431 - val_loss: 16898.5858\n",
      "Epoch 42/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6963.6236 - val_loss: 16850.0601\n",
      "Epoch 43/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6957.3548 - val_loss: 16656.3990\n",
      "Epoch 44/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6959.1914 - val_loss: 16953.8425\n",
      "Epoch 45/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6939.4885 - val_loss: 16821.4793\n",
      "Epoch 46/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6929.0252 - val_loss: 16720.7016\n",
      "Epoch 47/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6919.5429 - val_loss: 16684.7161\n",
      "Epoch 48/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6910.9750 - val_loss: 16607.1207\n",
      "Epoch 49/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6906.5653 - val_loss: 16679.6908\n",
      "Epoch 50/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6891.8019 - val_loss: 16681.9523\n",
      "Epoch 51/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6880.6845 - val_loss: 16434.4148\n",
      "Epoch 52/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6877.8952 - val_loss: 16571.1177\n",
      "Epoch 53/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6861.1842 - val_loss: 16459.6246\n",
      "Epoch 54/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6853.7311 - val_loss: 16419.0332\n",
      "Epoch 55/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6845.7040 - val_loss: 16429.5028\n",
      "Epoch 56/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6834.1898 - val_loss: 16411.2823\n",
      "Epoch 57/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6831.0493 - val_loss: 16436.5554\n",
      "Epoch 58/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6816.5610 - val_loss: 16440.4652\n",
      "Epoch 59/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6804.0259 - val_loss: 16275.4279\n",
      "Epoch 60/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6799.3922 - val_loss: 16398.7226\n",
      "Epoch 61/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6783.0711 - val_loss: 16200.2327\n",
      "Epoch 62/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6780.7092 - val_loss: 16427.2199\n",
      "Epoch 63/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6759.9136 - val_loss: 16267.8544\n",
      "Epoch 64/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6751.4945 - val_loss: 16092.0514\n",
      "Epoch 65/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6751.9376 - val_loss: 16426.7614\n",
      "Epoch 66/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6723.3782 - val_loss: 16179.2834\n",
      "Epoch 67/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6716.9995 - val_loss: 15914.0226\n",
      "Epoch 68/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6751.6558 - val_loss: 16678.6659\n",
      "Epoch 69/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6704.5292 - val_loss: 16383.8536\n",
      "Epoch 70/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6677.6776 - val_loss: 16166.3098\n",
      "Epoch 71/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6658.0506 - val_loss: 16032.4847\n",
      "Epoch 72/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6639.3621 - val_loss: 15865.4424\n",
      "Epoch 73/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6631.1708 - val_loss: 15944.1178\n",
      "Epoch 74/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6615.8394 - val_loss: 15753.3690\n",
      "Epoch 75/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6639.1056 - val_loss: 16520.1838\n",
      "Epoch 76/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6583.6452 - val_loss: 16012.1503\n",
      "Epoch 77/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6562.8723 - val_loss: 15807.8133\n",
      "Epoch 78/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6552.5983 - val_loss: 15742.2538\n",
      "Epoch 79/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6538.7520 - val_loss: 15932.9709\n",
      "Epoch 80/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6511.1503 - val_loss: 15768.8338\n",
      "Epoch 81/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6496.3313 - val_loss: 15731.5908\n",
      "Epoch 82/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6482.4764 - val_loss: 15857.5951\n",
      "Epoch 83/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6455.0578 - val_loss: 15563.3277\n",
      "Epoch 84/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6479.4971 - val_loss: 16463.5989\n",
      "Epoch 85/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6410.8216 - val_loss: 15683.7766\n",
      "Epoch 86/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6385.2631 - val_loss: 15363.2660\n",
      "Epoch 87/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6379.0926 - val_loss: 15739.0814\n",
      "Epoch 88/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6344.9502 - val_loss: 15193.0646\n",
      "Epoch 89/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6370.3584 - val_loss: 16296.9439\n",
      "Epoch 90/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6293.1135 - val_loss: 15422.7567\n",
      "Epoch 91/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6273.3686 - val_loss: 14898.8713\n",
      "Epoch 92/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6326.9766 - val_loss: 16490.0799\n",
      "Epoch 93/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6223.9057 - val_loss: 15327.3192\n",
      "Epoch 94/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6189.1860 - val_loss: 15157.4714\n",
      "Epoch 95/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 6164.5292 - val_loss: 15029.5886\n",
      "Epoch 96/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6143.1928 - val_loss: 15068.2387\n",
      "Epoch 97/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6129.1750 - val_loss: 15344.1730\n",
      "Epoch 98/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6088.4783 - val_loss: 15085.5471\n",
      "Epoch 99/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6068.6510 - val_loss: 15191.5914\n",
      "Epoch 100/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6047.3347 - val_loss: 14969.4237\n",
      "Epoch 101/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 6117.3750 - val_loss: 16438.6925\n",
      "Epoch 102/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5995.2079 - val_loss: 15145.8205\n",
      "Epoch 103/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5958.7786 - val_loss: 14516.2274\n",
      "Epoch 104/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 1s 2ms/step - loss: 5986.0856 - val_loss: 15624.0409\n",
      "Epoch 105/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 5925.7724 - val_loss: 15283.3838\n",
      "Epoch 106/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5905.6557 - val_loss: 15270.3450\n",
      "Epoch 107/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5886.4814 - val_loss: 15248.4972\n",
      "Epoch 108/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5872.7447 - val_loss: 15419.7092\n",
      "Epoch 109/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5842.3090 - val_loss: 15289.8367\n",
      "Epoch 110/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 5831.4930 - val_loss: 15442.3863\n",
      "Epoch 111/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5818.4321 - val_loss: 15393.2755\n",
      "Epoch 112/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5799.6764 - val_loss: 15544.1054\n",
      "Epoch 113/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5789.7737 - val_loss: 15730.2530\n",
      "Epoch 114/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5792.3666 - val_loss: 15031.5815\n",
      "Epoch 115/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5873.6283 - val_loss: 16395.8726\n",
      "Epoch 116/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5800.9504 - val_loss: 15977.5594\n",
      "Epoch 117/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5695.9578 - val_loss: 15308.6567\n",
      "Epoch 118/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5735.1317 - val_loss: 14995.2703\n",
      "Epoch 119/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 5822.9594 - val_loss: 16324.2861\n",
      "Epoch 120/1000\n",
      "246/246 [==============================] - 1s 3ms/step - loss: 5730.5192 - val_loss: 15745.5950\n",
      "Epoch 121/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5641.4348 - val_loss: 14988.9498\n",
      "Epoch 122/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5755.0023 - val_loss: 15945.5256\n",
      "Epoch 123/1000\n",
      "246/246 [==============================] - 1s 2ms/step - loss: 5775.2887 - val_loss: 16282.5605\n",
      "Train on 245 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "245/245 [==============================] - 45s 185ms/step - loss: 26848.8127 - val_loss: 177201.2773\n",
      "Epoch 2/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 26818.5766 - val_loss: 177027.4255\n",
      "Epoch 3/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 26716.5359 - val_loss: 176231.3659\n",
      "Epoch 4/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 25970.4707 - val_loss: 166346.4259\n",
      "Epoch 5/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 20385.3599 - val_loss: 108789.2004\n",
      "Epoch 6/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 15454.6716 - val_loss: 90407.9938\n",
      "Epoch 7/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 13767.2699 - val_loss: 77501.2107\n",
      "Epoch 8/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 12845.2919 - val_loss: 69352.0934\n",
      "Epoch 9/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 12083.6923 - val_loss: 61757.5561\n",
      "Epoch 10/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 11441.5679 - val_loss: 55062.3975\n",
      "Epoch 11/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 10896.5432 - val_loss: 49248.2105\n",
      "Epoch 12/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 10449.7280 - val_loss: 44488.2772\n",
      "Epoch 13/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 10088.4955 - val_loss: 40724.5394\n",
      "Epoch 14/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9787.1282 - val_loss: 37394.9061\n",
      "Epoch 15/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9575.9006 - val_loss: 35039.9362\n",
      "Epoch 16/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9419.3120 - val_loss: 33227.3239\n",
      "Epoch 17/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9288.6384 - val_loss: 31796.8549\n",
      "Epoch 18/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9202.4396 - val_loss: 30504.0146\n",
      "Epoch 19/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9130.7531 - val_loss: 29922.9647\n",
      "Epoch 20/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9080.3667 - val_loss: 29164.8631\n",
      "Epoch 21/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9040.1374 - val_loss: 28702.9918\n",
      "Epoch 22/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 9011.1385 - val_loss: 28100.9246\n",
      "Epoch 23/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8991.3108 - val_loss: 28013.1968\n",
      "Epoch 24/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8970.0004 - val_loss: 27717.1468\n",
      "Epoch 25/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8949.2435 - val_loss: 27501.8393\n",
      "Epoch 26/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8930.5732 - val_loss: 27223.3402\n",
      "Epoch 27/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8914.7901 - val_loss: 27031.5350\n",
      "Epoch 28/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8896.6424 - val_loss: 26809.6267\n",
      "Epoch 29/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8882.8603 - val_loss: 26695.3145\n",
      "Epoch 30/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8869.4686 - val_loss: 26562.6496\n",
      "Epoch 31/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8858.1459 - val_loss: 26433.5224\n",
      "Epoch 32/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8848.2385 - val_loss: 26363.5999\n",
      "Epoch 33/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8838.0483 - val_loss: 26275.5146\n",
      "Epoch 34/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8829.7946 - val_loss: 26184.0387\n",
      "Epoch 35/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8821.8485 - val_loss: 26127.1455\n",
      "Epoch 36/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8811.9720 - val_loss: 26080.2117\n",
      "Epoch 37/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8804.5087 - val_loss: 25983.3311\n",
      "Epoch 38/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8796.0419 - val_loss: 25910.5198\n",
      "Epoch 39/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8788.9942 - val_loss: 25931.6680\n",
      "Epoch 40/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8778.9235 - val_loss: 25787.7136\n",
      "Epoch 41/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8772.8091 - val_loss: 25804.9115\n",
      "Epoch 42/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8763.1652 - val_loss: 25711.6427\n",
      "Epoch 43/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8756.0227 - val_loss: 25668.4255\n",
      "Epoch 44/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8748.4709 - val_loss: 25612.4077\n",
      "Epoch 45/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8740.6721 - val_loss: 25555.2166\n",
      "Epoch 46/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8733.8503 - val_loss: 25499.9494\n",
      "Epoch 47/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8726.9342 - val_loss: 25460.7865\n",
      "Epoch 48/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8718.6623 - val_loss: 25374.4270\n",
      "Epoch 49/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8711.7307 - val_loss: 25352.9911\n",
      "Epoch 50/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8703.2778 - val_loss: 25275.2459\n",
      "Epoch 51/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8695.1754 - val_loss: 25270.9114\n",
      "Epoch 52/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8688.0683 - val_loss: 25145.6930\n",
      "Epoch 53/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8679.9533 - val_loss: 25217.2841\n",
      "Epoch 54/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8671.1450 - val_loss: 25095.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8664.5302 - val_loss: 25070.9961\n",
      "Epoch 56/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8655.1754 - val_loss: 25078.4593\n",
      "Epoch 57/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8647.3784 - val_loss: 24947.7191\n",
      "Epoch 58/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8640.3167 - val_loss: 25009.7562\n",
      "Epoch 59/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8630.6665 - val_loss: 24890.0500\n",
      "Epoch 60/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8622.2154 - val_loss: 24918.7974\n",
      "Epoch 61/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8613.6295 - val_loss: 24782.3198\n",
      "Epoch 62/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8606.2084 - val_loss: 24837.7361\n",
      "Epoch 63/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8596.6940 - val_loss: 24698.5594\n",
      "Epoch 64/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8587.0772 - val_loss: 24785.3457\n",
      "Epoch 65/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8578.6289 - val_loss: 24608.6563\n",
      "Epoch 66/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8568.7929 - val_loss: 24659.4981\n",
      "Epoch 67/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8560.4997 - val_loss: 24566.6643\n",
      "Epoch 68/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8548.5237 - val_loss: 24529.8471\n",
      "Epoch 69/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8538.2851 - val_loss: 24517.9680\n",
      "Epoch 70/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8525.3307 - val_loss: 24325.9222\n",
      "Epoch 71/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8514.6999 - val_loss: 24315.8606\n",
      "Epoch 72/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8502.1374 - val_loss: 24131.5872\n",
      "Epoch 73/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8494.5015 - val_loss: 24237.7494\n",
      "Epoch 74/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8478.2897 - val_loss: 24080.1803\n",
      "Epoch 75/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8462.3650 - val_loss: 24040.4860\n",
      "Epoch 76/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8507.5478 - val_loss: 23343.8008\n",
      "Epoch 77/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8472.7388 - val_loss: 24722.6745\n",
      "Epoch 78/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8424.6728 - val_loss: 23942.5532\n",
      "Epoch 79/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8409.6317 - val_loss: 23469.5563\n",
      "Epoch 80/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8384.4311 - val_loss: 23781.3369\n",
      "Epoch 81/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8345.2653 - val_loss: 23148.8614\n",
      "Epoch 82/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8416.7999 - val_loss: 22123.3961\n",
      "Epoch 83/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8386.4179 - val_loss: 24707.6606\n",
      "Epoch 84/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8284.0701 - val_loss: 23175.5418\n",
      "Epoch 85/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8264.0591 - val_loss: 22694.0563\n",
      "Epoch 86/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8265.4821 - val_loss: 23189.5089\n",
      "Epoch 87/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8218.3040 - val_loss: 22586.7454\n",
      "Epoch 88/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8179.0184 - val_loss: 22434.9657\n",
      "Epoch 89/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8136.6969 - val_loss: 22216.0681\n",
      "Epoch 90/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8132.4244 - val_loss: 22595.1744\n",
      "Epoch 91/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8089.1998 - val_loss: 22104.1227\n",
      "Epoch 92/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8058.2856 - val_loss: 22167.6058\n",
      "Epoch 93/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8015.6125 - val_loss: 22164.8127\n",
      "Epoch 94/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8013.0855 - val_loss: 22650.9376\n",
      "Epoch 95/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 8006.7228 - val_loss: 22873.2572\n",
      "Epoch 96/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7916.8514 - val_loss: 22324.7809\n",
      "Epoch 97/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7853.5931 - val_loss: 22363.7480\n",
      "Epoch 98/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7828.6433 - val_loss: 22505.6715\n",
      "Epoch 99/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7796.7111 - val_loss: 22675.2990\n",
      "Epoch 100/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7761.6660 - val_loss: 22480.8879\n",
      "Epoch 101/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7723.0707 - val_loss: 22722.9839\n",
      "Epoch 102/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7710.9967 - val_loss: 22784.0605\n",
      "Epoch 103/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7653.0350 - val_loss: 22505.2937\n",
      "Epoch 104/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7600.2330 - val_loss: 22421.3448\n",
      "Epoch 105/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7617.8763 - val_loss: 22854.4230\n",
      "Epoch 106/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7617.2845 - val_loss: 23002.9154\n",
      "Epoch 107/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7543.5577 - val_loss: 22471.4612\n",
      "Epoch 108/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7530.9752 - val_loss: 22776.2929\n",
      "Epoch 109/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7512.5923 - val_loss: 22536.5611\n",
      "Epoch 110/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7498.7349 - val_loss: 22742.1490\n",
      "Epoch 111/1000\n",
      "245/245 [==============================] - 1s 3ms/step - loss: 7487.9389 - val_loss: 22635.8231\n",
      "Train on 244 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "244/244 [==============================] - 48s 198ms/step - loss: 26963.2121 - val_loss: 177235.7829\n",
      "Epoch 2/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26950.3754 - val_loss: 177172.6538\n",
      "Epoch 3/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26921.2298 - val_loss: 176996.3724\n",
      "Epoch 4/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26817.5812 - val_loss: 175870.5430\n",
      "Epoch 5/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 25619.8747 - val_loss: 155735.4084\n",
      "Epoch 6/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 17832.0205 - val_loss: 83043.1648\n",
      "Epoch 7/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 14929.4400 - val_loss: 87225.2023\n",
      "Epoch 8/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 13563.7569 - val_loss: 72182.6337\n",
      "Epoch 9/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12917.3611 - val_loss: 66804.9823\n",
      "Epoch 10/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12423.7416 - val_loss: 61483.8813\n",
      "Epoch 11/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12065.2483 - val_loss: 57403.6493\n",
      "Epoch 12/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11777.3054 - val_loss: 53818.5427\n",
      "Epoch 13/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11547.6849 - val_loss: 50932.1167\n",
      "Epoch 14/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11368.4130 - val_loss: 48470.0858\n",
      "Epoch 15/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11231.4027 - val_loss: 46575.5796\n",
      "Epoch 16/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11123.9214 - val_loss: 44957.6470\n",
      "Epoch 17/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11041.8515 - val_loss: 43693.7647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10975.3939 - val_loss: 42662.1047\n",
      "Epoch 19/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10920.0495 - val_loss: 41813.1293\n",
      "Epoch 20/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10873.4244 - val_loss: 41008.7221\n",
      "Epoch 21/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10834.4810 - val_loss: 40355.9294\n",
      "Epoch 22/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10804.3340 - val_loss: 39816.5728\n",
      "Epoch 23/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10782.2951 - val_loss: 39358.2518\n",
      "Epoch 24/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10764.3158 - val_loss: 39036.1451\n",
      "Epoch 25/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10748.8283 - val_loss: 38737.8923\n",
      "Epoch 26/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10733.1497 - val_loss: 38501.6116\n",
      "Epoch 27/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10719.8387 - val_loss: 38237.0986\n",
      "Epoch 28/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10706.6669 - val_loss: 38020.1187\n",
      "Epoch 29/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10695.9666 - val_loss: 37826.0962\n",
      "Epoch 30/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10684.9601 - val_loss: 37690.5045\n",
      "Epoch 31/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10633.3512 - val_loss: 25274.1114\n",
      "Epoch 32/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11625.0667 - val_loss: 48945.0435\n",
      "Epoch 33/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10828.5151 - val_loss: 33750.5452\n",
      "Epoch 34/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10861.2385 - val_loss: 38825.6441\n",
      "Epoch 35/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10752.2222 - val_loss: 36486.5480\n",
      "Epoch 36/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10752.3719 - val_loss: 37217.3707\n",
      "Epoch 37/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10723.3738 - val_loss: 36879.1532\n",
      "Epoch 38/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10709.7806 - val_loss: 36902.8003\n",
      "Epoch 39/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10689.2469 - val_loss: 36806.5728\n",
      "Epoch 40/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10680.1568 - val_loss: 36736.2067\n",
      "Epoch 41/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10666.2642 - val_loss: 36790.6927\n",
      "Epoch 42/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10655.6605 - val_loss: 36666.5336\n",
      "Epoch 43/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10646.0372 - val_loss: 36629.2856\n",
      "Epoch 44/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10636.3706 - val_loss: 36582.9287\n",
      "Epoch 45/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10630.3551 - val_loss: 36523.0633\n",
      "Epoch 46/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10621.4606 - val_loss: 36517.4467\n",
      "Epoch 47/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10614.2511 - val_loss: 36444.1561\n",
      "Epoch 48/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10607.7878 - val_loss: 36436.9755\n",
      "Epoch 49/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10600.9576 - val_loss: 36390.5261\n",
      "Epoch 50/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10593.2802 - val_loss: 36374.2332\n",
      "Epoch 51/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10589.0829 - val_loss: 36344.3505\n",
      "Train on 244 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "244/244 [==============================] - 49s 200ms/step - loss: 26970.0589 - val_loss: 179410.0555\n",
      "Epoch 2/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26955.4031 - val_loss: 179323.8890\n",
      "Epoch 3/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26899.8755 - val_loss: 178889.2697\n",
      "Epoch 4/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 26358.1650 - val_loss: 169202.8961\n",
      "Epoch 5/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 19948.3388 - val_loss: 90711.8947\n",
      "Epoch 6/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 16203.1546 - val_loss: 98614.8274\n",
      "Epoch 7/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 14721.7055 - val_loss: 77701.3604\n",
      "Epoch 8/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 13982.0667 - val_loss: 72159.6217\n",
      "Epoch 9/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 13396.0424 - val_loss: 65102.4903\n",
      "Epoch 10/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12992.3442 - val_loss: 59858.1311\n",
      "Epoch 11/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12687.5324 - val_loss: 56140.1174\n",
      "Epoch 12/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 12487.5996 - val_loss: 53198.5817\n",
      "Epoch 13/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12336.1553 - val_loss: 51097.3118\n",
      "Epoch 14/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12226.5014 - val_loss: 49378.1716\n",
      "Epoch 15/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12220.5445 - val_loss: 47974.1480\n",
      "Epoch 16/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12063.0565 - val_loss: 46780.3902\n",
      "Epoch 17/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 12001.2626 - val_loss: 45759.4792\n",
      "Epoch 18/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11964.6526 - val_loss: 45013.4904\n",
      "Epoch 19/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11939.4493 - val_loss: 44711.7174\n",
      "Epoch 20/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11886.5095 - val_loss: 43681.9884\n",
      "Epoch 21/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11859.5399 - val_loss: 43314.9930\n",
      "Epoch 22/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11854.3943 - val_loss: 42865.3522\n",
      "Epoch 23/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11844.1681 - val_loss: 43485.6407\n",
      "Epoch 24/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11799.2324 - val_loss: 42645.7002\n",
      "Epoch 25/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11771.1696 - val_loss: 42401.9478\n",
      "Epoch 26/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11748.9974 - val_loss: 42132.8751\n",
      "Epoch 27/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11735.4451 - val_loss: 42128.3357\n",
      "Epoch 28/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11707.7248 - val_loss: 41717.1900\n",
      "Epoch 29/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11711.0677 - val_loss: 42294.9669\n",
      "Epoch 30/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11669.4221 - val_loss: 41567.5131\n",
      "Epoch 31/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11679.5241 - val_loss: 42319.6611\n",
      "Epoch 32/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11641.9449 - val_loss: 41692.0123\n",
      "Epoch 33/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11625.7746 - val_loss: 41497.1062\n",
      "Epoch 34/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11621.9298 - val_loss: 41847.9526\n",
      "Epoch 35/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11589.7200 - val_loss: 41163.6491\n",
      "Epoch 36/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11596.4942 - val_loss: 41811.5567\n",
      "Epoch 37/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11560.7753 - val_loss: 41085.8094\n",
      "Epoch 38/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11564.9942 - val_loss: 41606.8588\n",
      "Epoch 39/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11536.6725 - val_loss: 41134.1377\n",
      "Epoch 40/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 1s 3ms/step - loss: 11529.1869 - val_loss: 41361.0983\n",
      "Epoch 41/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11513.0930 - val_loss: 40954.4761\n",
      "Epoch 42/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11514.4739 - val_loss: 41339.9897\n",
      "Epoch 43/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11492.0900 - val_loss: 41027.2457\n",
      "Epoch 44/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11484.6709 - val_loss: 41002.0565\n",
      "Epoch 45/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11468.7905 - val_loss: 40693.7644\n",
      "Epoch 46/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11467.4251 - val_loss: 40901.5810\n",
      "Epoch 47/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11448.8206 - val_loss: 40742.2517\n",
      "Epoch 48/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11438.1475 - val_loss: 40799.8056\n",
      "Epoch 49/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11431.2845 - val_loss: 40839.8950\n",
      "Epoch 50/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11407.8456 - val_loss: 40478.2717\n",
      "Epoch 51/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11397.7118 - val_loss: 40508.0576\n",
      "Epoch 52/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11381.6628 - val_loss: 40313.8767\n",
      "Epoch 53/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11368.8621 - val_loss: 40277.8322\n",
      "Epoch 54/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11355.4088 - val_loss: 40050.5574\n",
      "Epoch 55/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11351.3110 - val_loss: 40260.9227\n",
      "Epoch 56/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11335.9178 - val_loss: 40083.9806\n",
      "Epoch 57/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11625.0540 - val_loss: 42631.9401\n",
      "Epoch 58/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11409.0091 - val_loss: 40234.6178\n",
      "Epoch 59/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11330.1011 - val_loss: 40304.4745\n",
      "Epoch 60/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11330.6244 - val_loss: 40734.3491\n",
      "Epoch 61/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11268.7407 - val_loss: 39827.3568\n",
      "Epoch 62/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11260.3929 - val_loss: 39925.0055\n",
      "Epoch 63/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11246.4580 - val_loss: 39856.9441\n",
      "Epoch 64/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11227.6989 - val_loss: 39842.0771\n",
      "Epoch 65/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11214.7664 - val_loss: 39745.9066\n",
      "Epoch 66/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11195.4453 - val_loss: 39724.0216\n",
      "Epoch 67/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11187.8823 - val_loss: 39719.1021\n",
      "Epoch 68/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11165.0116 - val_loss: 39628.9874\n",
      "Epoch 69/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11156.6350 - val_loss: 39598.9184\n",
      "Epoch 70/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11132.1921 - val_loss: 39521.1955\n",
      "Epoch 71/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11125.5350 - val_loss: 39437.4315\n",
      "Epoch 72/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11100.5941 - val_loss: 39379.7861\n",
      "Epoch 73/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11095.6987 - val_loss: 39562.3745\n",
      "Epoch 74/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11068.0986 - val_loss: 38678.3218\n",
      "Epoch 75/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11124.3361 - val_loss: 39580.2506\n",
      "Epoch 76/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11061.5781 - val_loss: 39331.5128\n",
      "Epoch 77/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11028.9458 - val_loss: 38575.5026\n",
      "Epoch 78/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11053.9260 - val_loss: 40050.4366\n",
      "Epoch 79/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11000.2779 - val_loss: 39196.6266\n",
      "Epoch 80/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11002.7305 - val_loss: 39713.1481\n",
      "Epoch 81/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10948.9042 - val_loss: 38846.6760\n",
      "Epoch 82/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 11066.6216 - val_loss: 38023.9652\n",
      "Epoch 83/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10957.3646 - val_loss: 39489.7853\n",
      "Epoch 84/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10907.1599 - val_loss: 38552.2425\n",
      "Epoch 85/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10906.1649 - val_loss: 39287.7246\n",
      "Epoch 86/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10858.0642 - val_loss: 37422.1271\n",
      "Epoch 87/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10949.3611 - val_loss: 40610.5386\n",
      "Epoch 88/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10799.2783 - val_loss: 38009.6905\n",
      "Epoch 89/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10815.3287 - val_loss: 37236.2561\n",
      "Epoch 90/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 10805.0426 - val_loss: 38654.5225\n",
      "Epoch 91/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 10743.7266 - val_loss: 37660.1255\n",
      "Epoch 92/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10747.4327 - val_loss: 37067.8484\n",
      "Epoch 93/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 10738.7664 - val_loss: 38099.2848\n",
      "Epoch 94/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10678.5149 - val_loss: 37793.5495\n",
      "Epoch 95/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10698.1469 - val_loss: 38030.7759\n",
      "Epoch 96/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10653.2586 - val_loss: 37777.8727\n",
      "Epoch 97/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10645.1386 - val_loss: 37302.8712\n",
      "Epoch 98/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10623.0828 - val_loss: 37773.7057\n",
      "Epoch 99/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10589.3602 - val_loss: 37468.0456\n",
      "Epoch 100/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10507.5137 - val_loss: 36371.0425\n",
      "Epoch 101/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10520.6591 - val_loss: 37394.3679\n",
      "Epoch 102/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 10465.3384 - val_loss: 35701.7162\n",
      "Epoch 103/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 10561.5626 - val_loss: 39137.2529\n",
      "Epoch 104/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10412.1465 - val_loss: 36380.1596\n",
      "Epoch 105/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10466.4376 - val_loss: 37830.6525\n",
      "Epoch 106/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10371.6462 - val_loss: 35664.8049\n",
      "Epoch 107/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10478.0851 - val_loss: 39657.7321\n",
      "Epoch 108/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10221.9681 - val_loss: 34944.1958\n",
      "Epoch 109/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10309.4851 - val_loss: 34401.2984\n",
      "Epoch 110/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10507.0833 - val_loss: 41092.4835\n",
      "Epoch 111/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10150.8167 - val_loss: 35053.8245\n",
      "Epoch 112/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10256.7977 - val_loss: 33394.7322\n",
      "Epoch 113/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10511.7965 - val_loss: 42346.9802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10070.4007 - val_loss: 34904.0220\n",
      "Epoch 115/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10166.3350 - val_loss: 32699.2021\n",
      "Epoch 116/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10323.6040 - val_loss: 40636.1081\n",
      "Epoch 117/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9941.1685 - val_loss: 34132.9853\n",
      "Epoch 118/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10164.7024 - val_loss: 31864.0159\n",
      "Epoch 119/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10155.8097 - val_loss: 39029.6478\n",
      "Epoch 120/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9827.7549 - val_loss: 31821.4181\n",
      "Epoch 121/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 10012.8081 - val_loss: 33403.1579\n",
      "Epoch 122/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9892.8678 - val_loss: 37027.4122\n",
      "Epoch 123/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9597.6683 - val_loss: 32052.8501\n",
      "Epoch 124/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9706.4210 - val_loss: 33437.0694\n",
      "Epoch 125/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9826.7970 - val_loss: 37913.3383\n",
      "Epoch 126/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9393.7773 - val_loss: 31286.5955\n",
      "Epoch 127/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9422.4811 - val_loss: 30241.7402\n",
      "Epoch 128/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9593.9990 - val_loss: 37010.6628\n",
      "Epoch 129/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9262.8258 - val_loss: 29115.6948\n",
      "Epoch 130/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9461.9973 - val_loss: 36434.3726\n",
      "Epoch 131/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 9147.2903 - val_loss: 31716.0936\n",
      "Epoch 132/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 10344.4002 - val_loss: 40930.7069\n",
      "Epoch 133/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 10247.1283 - val_loss: 103686.6629\n",
      "Epoch 134/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 11349.2711 - val_loss: 30486.6476\n",
      "Epoch 135/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9783.4405 - val_loss: 60076.6725\n",
      "Epoch 136/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9990.6445 - val_loss: 43234.6620\n",
      "Epoch 137/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9770.4597 - val_loss: 34505.6299\n",
      "Epoch 138/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9258.8509 - val_loss: 14460.3552\n",
      "Epoch 139/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9721.8139 - val_loss: 71464.5913\n",
      "Epoch 140/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9647.7189 - val_loss: 24528.4581\n",
      "Epoch 141/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8821.0309 - val_loss: 35050.5208\n",
      "Epoch 142/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8457.5269 - val_loss: 28237.3660\n",
      "Epoch 143/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8021.9364 - val_loss: 27629.5460\n",
      "Epoch 144/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7765.0969 - val_loss: 25041.3205\n",
      "Epoch 145/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7652.3453 - val_loss: 27646.7885\n",
      "Epoch 146/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7483.5729 - val_loss: 24962.8015\n",
      "Epoch 147/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7326.0961 - val_loss: 23713.4242\n",
      "Epoch 148/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8002.1576 - val_loss: 40330.4569\n",
      "Epoch 149/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7619.0937 - val_loss: 31312.5096\n",
      "Epoch 150/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7202.0599 - val_loss: 32114.5983\n",
      "Epoch 151/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7105.7242 - val_loss: 27916.0972\n",
      "Epoch 152/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7124.7085 - val_loss: 35699.0501\n",
      "Epoch 153/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 9049.1726 - val_loss: 25864.8094\n",
      "Epoch 154/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8537.2851 - val_loss: 28581.9643\n",
      "Epoch 155/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8460.3290 - val_loss: 28153.4008\n",
      "Epoch 156/1000\n",
      "244/244 [==============================] - 1s 4ms/step - loss: 8311.4702 - val_loss: 28388.0059\n",
      "Epoch 157/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 8139.5809 - val_loss: 27858.4719\n",
      "Epoch 158/1000\n",
      "244/244 [==============================] - 1s 3ms/step - loss: 7748.7746 - val_loss: 35642.3759\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "243/243 [==============================] - 50s 207ms/step - loss: 27070.4349 - val_loss: 179315.2896\n",
      "Epoch 2/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 27007.3191 - val_loss: 178851.3186\n",
      "Epoch 3/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 26623.7473 - val_loss: 173605.4455\n",
      "Epoch 4/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 20709.4455 - val_loss: 61296.7900\n",
      "Epoch 5/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 16272.3290 - val_loss: 109871.6109\n",
      "Epoch 6/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15303.3575 - val_loss: 69903.7520\n",
      "Epoch 7/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14610.8696 - val_loss: 76754.3550\n",
      "Epoch 8/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14139.1834 - val_loss: 65011.2951\n",
      "Epoch 9/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13864.4511 - val_loss: 64520.5112\n",
      "Epoch 10/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13680.0052 - val_loss: 60997.9335\n",
      "Epoch 11/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13568.0497 - val_loss: 60092.4412\n",
      "Epoch 12/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13479.5635 - val_loss: 58425.8387\n",
      "Epoch 13/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13418.7401 - val_loss: 57820.0474\n",
      "Epoch 14/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13364.7965 - val_loss: 56894.2819\n",
      "Epoch 15/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13326.3287 - val_loss: 56406.5523\n",
      "Epoch 16/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13290.9522 - val_loss: 55976.5328\n",
      "Epoch 17/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13258.8999 - val_loss: 55578.6654\n",
      "Epoch 18/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13231.4437 - val_loss: 55296.4076\n",
      "Epoch 19/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13203.7881 - val_loss: 54946.1698\n",
      "Epoch 20/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13180.8417 - val_loss: 54628.0422\n",
      "Epoch 21/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13159.1231 - val_loss: 54349.9305\n",
      "Epoch 22/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13138.9521 - val_loss: 54176.8032\n",
      "Epoch 23/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13116.8772 - val_loss: 53942.7716\n",
      "Epoch 24/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13097.9468 - val_loss: 53786.0990\n",
      "Epoch 25/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13080.3189 - val_loss: 53531.3366\n",
      "Epoch 26/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13067.3040 - val_loss: 53377.0735\n",
      "Epoch 27/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13039.4747 - val_loss: 53302.0202\n",
      "Epoch 28/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13012.6407 - val_loss: 53189.2346\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 1s 4ms/step - loss: 12988.8030 - val_loss: 52981.8507\n",
      "Epoch 30/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12966.9489 - val_loss: 52954.6472\n",
      "Epoch 31/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12938.2273 - val_loss: 52829.9651\n",
      "Epoch 32/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12907.3984 - val_loss: 52459.1255\n",
      "Epoch 33/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12880.2601 - val_loss: 52551.0321\n",
      "Epoch 34/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12843.4887 - val_loss: 52358.5551\n",
      "Epoch 35/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12805.0214 - val_loss: 52495.0296\n",
      "Epoch 36/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12751.9101 - val_loss: 52023.8550\n",
      "Epoch 37/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12715.5521 - val_loss: 51982.5153\n",
      "Epoch 38/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12654.6151 - val_loss: 52289.0846\n",
      "Epoch 39/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12573.5265 - val_loss: 51697.2936\n",
      "Epoch 40/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12506.2536 - val_loss: 51718.2983\n",
      "Epoch 41/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12422.2107 - val_loss: 51298.6169\n",
      "Epoch 42/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12337.8540 - val_loss: 51131.7560\n",
      "Epoch 43/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12241.6057 - val_loss: 50935.0859\n",
      "Epoch 44/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12133.6840 - val_loss: 50591.5005\n",
      "Epoch 45/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12016.1384 - val_loss: 50175.8251\n",
      "Epoch 46/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11886.9176 - val_loss: 49343.1337\n",
      "Epoch 47/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11779.1338 - val_loss: 49162.0120\n",
      "Epoch 48/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11621.7340 - val_loss: 48713.4911\n",
      "Epoch 49/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11458.4813 - val_loss: 48597.6983\n",
      "Epoch 50/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11251.0807 - val_loss: 46761.7261\n",
      "Epoch 51/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11084.5840 - val_loss: 47364.8712\n",
      "Epoch 52/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10871.6392 - val_loss: 45703.3623\n",
      "Epoch 53/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10685.9451 - val_loss: 46607.9428\n",
      "Epoch 54/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10468.8492 - val_loss: 47058.5627\n",
      "Epoch 55/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10656.4821 - val_loss: 48914.2735\n",
      "Epoch 56/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10066.7880 - val_loss: 47996.8563\n",
      "Epoch 57/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9707.1509 - val_loss: 47004.8272\n",
      "Epoch 58/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9338.2802 - val_loss: 47044.4200\n",
      "Epoch 59/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8957.3212 - val_loss: 49525.2305\n",
      "Epoch 60/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8706.0029 - val_loss: 51045.8681\n",
      "Epoch 61/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8328.8662 - val_loss: 53107.8747\n",
      "Epoch 62/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8137.9399 - val_loss: 57493.7077\n",
      "Epoch 63/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9562.0771 - val_loss: 72142.1890\n",
      "Epoch 64/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11172.5339 - val_loss: 40888.0928\n",
      "Epoch 65/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8056.5054 - val_loss: 47429.6962\n",
      "Epoch 66/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8277.4073 - val_loss: 50423.6262\n",
      "Epoch 67/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9025.3163 - val_loss: 52870.8895\n",
      "Epoch 68/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9505.5256 - val_loss: 44755.1591\n",
      "Epoch 69/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8618.0942 - val_loss: 42012.5322\n",
      "Epoch 70/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8202.5349 - val_loss: 42774.9609\n",
      "Epoch 71/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8246.3808 - val_loss: 44012.0089\n",
      "Epoch 72/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8476.7537 - val_loss: 44339.7565\n",
      "Epoch 73/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8620.7239 - val_loss: 42033.8738\n",
      "Epoch 74/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8402.3276 - val_loss: 39420.7272\n",
      "Epoch 75/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8082.4754 - val_loss: 38159.7462\n",
      "Epoch 76/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7901.2419 - val_loss: 38439.4296\n",
      "Epoch 77/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7968.5195 - val_loss: 39493.1245\n",
      "Epoch 78/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8184.6171 - val_loss: 38685.1319\n",
      "Epoch 79/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8147.3002 - val_loss: 35771.7419\n",
      "Epoch 80/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7767.0806 - val_loss: 33029.7251\n",
      "Epoch 81/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7372.8678 - val_loss: 32939.1044\n",
      "Epoch 82/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7218.6200 - val_loss: 35454.0814\n",
      "Epoch 83/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7606.5297 - val_loss: 41704.0898\n",
      "Epoch 84/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8608.5719 - val_loss: 39650.9783\n",
      "Epoch 85/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8328.0752 - val_loss: 28150.0432\n",
      "Epoch 86/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6995.3705 - val_loss: 24749.8846\n",
      "Epoch 87/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6576.3566 - val_loss: 26705.2276\n",
      "Epoch 88/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6599.9013 - val_loss: 32961.7716\n",
      "Epoch 89/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6611.3369 - val_loss: 41940.1651\n",
      "Epoch 90/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6118.8675 - val_loss: 43783.6258\n",
      "Epoch 91/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6261.7443 - val_loss: 61666.6947\n",
      "Epoch 92/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9567.3579 - val_loss: 73138.2167\n",
      "Epoch 93/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10645.1078 - val_loss: 36417.5208\n",
      "Epoch 94/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6063.6347 - val_loss: 42335.4346\n",
      "Epoch 95/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6824.1360 - val_loss: 58189.6010\n",
      "Epoch 96/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8630.0810 - val_loss: 38186.0487\n",
      "Epoch 97/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6957.7064 - val_loss: 45478.4496\n",
      "Epoch 98/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7854.9213 - val_loss: 38725.7013\n",
      "Epoch 99/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7224.8998 - val_loss: 32426.2065\n",
      "Epoch 100/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6653.6286 - val_loss: 29759.4751\n",
      "Epoch 101/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6287.8038 - val_loss: 29312.8176\n",
      "Epoch 102/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6334.7208 - val_loss: 37769.1445\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 1s 4ms/step - loss: 7379.7498 - val_loss: 38250.6203\n",
      "Epoch 104/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7353.8876 - val_loss: 24777.2785\n",
      "Epoch 105/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5906.8656 - val_loss: 19456.5672\n",
      "Epoch 106/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5729.2362 - val_loss: 21830.6304\n",
      "Epoch 107/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6205.3281 - val_loss: 41908.4966\n",
      "Epoch 108/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5696.8114 - val_loss: 34477.9644\n",
      "Epoch 109/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6077.1933 - val_loss: 49274.1862\n",
      "Epoch 110/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7851.9227 - val_loss: 37888.9144\n",
      "Epoch 111/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6855.7122 - val_loss: 32156.3298\n",
      "Epoch 112/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6338.5005 - val_loss: 26655.5058\n",
      "Epoch 113/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5768.9156 - val_loss: 23782.8495\n",
      "Epoch 114/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5419.3366 - val_loss: 24193.7449\n",
      "Epoch 115/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5305.5794 - val_loss: 25881.5628\n",
      "Epoch 116/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5341.3342 - val_loss: 26687.1698\n",
      "Epoch 117/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5476.9198 - val_loss: 32214.8444\n",
      "Epoch 118/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6320.7457 - val_loss: 38733.5036\n",
      "Epoch 119/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7179.5166 - val_loss: 28443.6633\n",
      "Epoch 120/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5989.5286 - val_loss: 20092.5082\n",
      "Epoch 121/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5263.2199 - val_loss: 18187.2395\n",
      "Epoch 122/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5799.6907 - val_loss: 34306.2889\n",
      "Epoch 123/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5675.8454 - val_loss: 23941.4496\n",
      "Epoch 124/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5590.7023 - val_loss: 46846.4016\n",
      "Epoch 125/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5680.0429 - val_loss: 40341.4105\n",
      "Epoch 126/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7213.3115 - val_loss: 51873.8479\n",
      "Epoch 127/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7981.1780 - val_loss: 27742.3535\n",
      "Epoch 128/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5008.6095 - val_loss: 28907.6298\n",
      "Epoch 129/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5322.3266 - val_loss: 35074.8180\n",
      "Epoch 130/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6452.1682 - val_loss: 36959.5733\n",
      "Epoch 131/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6439.8354 - val_loss: 24354.8266\n",
      "Epoch 132/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5147.0713 - val_loss: 21700.2234\n",
      "Epoch 133/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4861.0862 - val_loss: 22822.6083\n",
      "Epoch 134/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4748.7616 - val_loss: 28314.0130\n",
      "Epoch 135/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4667.3718 - val_loss: 24979.2839\n",
      "Epoch 136/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4548.5622 - val_loss: 30732.0238\n",
      "Epoch 137/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 5267.0638 - val_loss: 39246.4354\n",
      "Epoch 138/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6798.1334 - val_loss: 37061.6897\n",
      "Epoch 139/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6320.6497 - val_loss: 21811.7419\n",
      "Epoch 140/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4712.6234 - val_loss: 20695.6862\n",
      "Epoch 141/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 4647.2780 - val_loss: 27648.9303\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "243/243 [==============================] - 51s 210ms/step - loss: 27127.6213 - val_loss: 194004.1646\n",
      "Epoch 2/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 27088.6409 - val_loss: 193796.9909\n",
      "Epoch 3/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 26967.7287 - val_loss: 192913.1890\n",
      "Epoch 4/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 25939.9218 - val_loss: 174270.4846\n",
      "Epoch 5/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 19809.6662 - val_loss: 113110.0675\n",
      "Epoch 6/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 17521.1031 - val_loss: 116164.7546\n",
      "Epoch 7/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15978.5429 - val_loss: 76317.6495\n",
      "Epoch 8/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 15211.8619 - val_loss: 87141.8531\n",
      "Epoch 9/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14880.7299 - val_loss: 72408.5383\n",
      "Epoch 10/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14711.0697 - val_loss: 76478.9571\n",
      "Epoch 11/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14542.3280 - val_loss: 70933.4560\n",
      "Epoch 12/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14479.4155 - val_loss: 72383.4348\n",
      "Epoch 13/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14379.6746 - val_loss: 69852.4024\n",
      "Epoch 14/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14326.9028 - val_loss: 70386.0557\n",
      "Epoch 15/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14254.3897 - val_loss: 69130.3722\n",
      "Epoch 16/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14197.5673 - val_loss: 69035.1435\n",
      "Epoch 17/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14174.3986 - val_loss: 67928.7973\n",
      "Epoch 18/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14110.9167 - val_loss: 68345.9464\n",
      "Epoch 19/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14045.9411 - val_loss: 67235.7172\n",
      "Epoch 20/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 14001.9070 - val_loss: 67419.4286\n",
      "Epoch 21/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13954.9832 - val_loss: 66729.4056\n",
      "Epoch 22/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13906.4258 - val_loss: 66708.1093\n",
      "Epoch 23/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13856.7619 - val_loss: 65576.8256\n",
      "Epoch 24/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13824.1588 - val_loss: 66131.9761\n",
      "Epoch 25/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13779.1004 - val_loss: 65080.8754\n",
      "Epoch 26/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13750.5352 - val_loss: 65445.5481\n",
      "Epoch 27/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13683.3427 - val_loss: 63284.4333\n",
      "Epoch 28/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13671.7255 - val_loss: 65072.1414\n",
      "Epoch 29/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13594.2050 - val_loss: 62684.6531\n",
      "Epoch 30/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13586.9605 - val_loss: 64039.0064\n",
      "Epoch 31/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13526.3542 - val_loss: 62554.6990\n",
      "Epoch 32/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13516.2124 - val_loss: 63675.2865\n",
      "Epoch 33/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13449.0105 - val_loss: 62240.3309\n",
      "Epoch 34/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13433.6609 - val_loss: 63084.7656\n",
      "Epoch 35/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 1s 4ms/step - loss: 13364.7677 - val_loss: 60966.8806\n",
      "Epoch 36/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13374.4369 - val_loss: 63270.4498\n",
      "Epoch 37/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13291.3179 - val_loss: 61189.2558\n",
      "Epoch 38/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13264.9175 - val_loss: 61333.1430\n",
      "Epoch 39/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13234.4627 - val_loss: 61792.1261\n",
      "Epoch 40/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13180.2227 - val_loss: 60831.5474\n",
      "Epoch 41/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13127.3024 - val_loss: 60796.1315\n",
      "Epoch 42/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13083.9563 - val_loss: 59731.5705\n",
      "Epoch 43/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 13061.0379 - val_loss: 60733.2817\n",
      "Epoch 44/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12966.7906 - val_loss: 58935.2133\n",
      "Epoch 45/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12947.8639 - val_loss: 60467.0011\n",
      "Epoch 46/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12862.7621 - val_loss: 58908.8931\n",
      "Epoch 47/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12823.8015 - val_loss: 58162.3776\n",
      "Epoch 48/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12785.8729 - val_loss: 59227.6157\n",
      "Epoch 49/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12693.9453 - val_loss: 58058.0847\n",
      "Epoch 50/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12640.8440 - val_loss: 58466.1477\n",
      "Epoch 51/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12565.2162 - val_loss: 56722.9242\n",
      "Epoch 52/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12536.8482 - val_loss: 58421.0416\n",
      "Epoch 53/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12434.5642 - val_loss: 56470.7676\n",
      "Epoch 54/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12372.7904 - val_loss: 56759.9842\n",
      "Epoch 55/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12310.9544 - val_loss: 56532.1919\n",
      "Epoch 56/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12231.7365 - val_loss: 57535.6490\n",
      "Epoch 57/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12133.8981 - val_loss: 56437.0016\n",
      "Epoch 58/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12047.0582 - val_loss: 54782.8234\n",
      "Epoch 59/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 12016.4030 - val_loss: 59002.9841\n",
      "Epoch 60/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11867.7494 - val_loss: 51068.9175\n",
      "Epoch 61/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11896.8514 - val_loss: 62780.1391\n",
      "Epoch 62/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11731.9615 - val_loss: 50679.2340\n",
      "Epoch 63/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11586.9215 - val_loss: 57978.8435\n",
      "Epoch 64/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11528.4612 - val_loss: 52469.1104\n",
      "Epoch 65/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11353.1174 - val_loss: 62735.6225\n",
      "Epoch 66/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11245.6836 - val_loss: 49040.1613\n",
      "Epoch 67/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11312.1009 - val_loss: 67515.4636\n",
      "Epoch 68/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10793.8688 - val_loss: 37465.7189\n",
      "Epoch 69/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11231.5577 - val_loss: 88192.4318\n",
      "Epoch 70/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11351.8257 - val_loss: 55833.4417\n",
      "Epoch 71/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10320.7525 - val_loss: 48511.8823\n",
      "Epoch 72/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9893.5093 - val_loss: 59322.5815\n",
      "Epoch 73/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9149.0351 - val_loss: 62270.3662\n",
      "Epoch 74/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8755.8570 - val_loss: 61100.2576\n",
      "Epoch 75/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9178.9162 - val_loss: 75264.6461\n",
      "Epoch 76/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8714.4490 - val_loss: 49938.9056\n",
      "Epoch 77/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 9367.0466 - val_loss: 107423.3539\n",
      "Epoch 78/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 10037.6205 - val_loss: 48184.1133\n",
      "Epoch 79/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8341.0497 - val_loss: 55847.5783\n",
      "Epoch 80/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7216.8522 - val_loss: 78628.5424\n",
      "Epoch 81/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8266.3931 - val_loss: 111240.7890\n",
      "Epoch 82/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 11395.0287 - val_loss: 39943.8571\n",
      "Epoch 83/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7562.4152 - val_loss: 62624.4846\n",
      "Epoch 84/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6500.1282 - val_loss: 69507.6172\n",
      "Epoch 85/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6459.9856 - val_loss: 75904.8245\n",
      "Epoch 86/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 8151.1397 - val_loss: 68441.5200\n",
      "Epoch 87/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 7418.9824 - val_loss: 62998.7956\n",
      "Epoch 88/1000\n",
      "243/243 [==============================] - 1s 4ms/step - loss: 6693.9213 - val_loss: 62841.5281\n",
      "Train on 242 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "242/242 [==============================] - 52s 217ms/step - loss: 27245.0541 - val_loss: 194047.1620\n",
      "Epoch 2/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 27225.9153 - val_loss: 193918.7556\n",
      "Epoch 3/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 27143.4281 - val_loss: 193091.3703\n",
      "Epoch 4/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 24859.6766 - val_loss: 111677.8781\n",
      "Epoch 5/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 17656.1571 - val_loss: 121524.3312\n",
      "Epoch 6/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 17051.2942 - val_loss: 93195.7710\n",
      "Epoch 7/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 16655.0459 - val_loss: 101137.6814\n",
      "Epoch 8/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 16392.2231 - val_loss: 92683.2885\n",
      "Epoch 9/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 16269.9006 - val_loss: 93530.0244\n",
      "Epoch 10/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 16149.1830 - val_loss: 91207.3216\n",
      "Epoch 11/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 16076.5504 - val_loss: 90774.9755\n",
      "Epoch 12/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15998.6504 - val_loss: 89698.9458\n",
      "Epoch 13/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15942.4419 - val_loss: 88906.3323\n",
      "Epoch 14/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15906.6807 - val_loss: 88613.0838\n",
      "Epoch 15/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15866.7466 - val_loss: 88092.0591\n",
      "Epoch 16/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15828.6804 - val_loss: 87677.2602\n",
      "Epoch 17/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15795.5312 - val_loss: 87397.5903\n",
      "Epoch 18/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15767.9103 - val_loss: 87007.3135\n",
      "Epoch 19/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15740.7475 - val_loss: 86841.3216\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 1s 4ms/step - loss: 15718.3610 - val_loss: 86377.6755\n",
      "Epoch 21/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15701.0614 - val_loss: 86546.2173\n",
      "Epoch 22/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15673.2400 - val_loss: 86165.4358\n",
      "Epoch 23/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15659.2336 - val_loss: 86344.0391\n",
      "Epoch 24/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15627.1786 - val_loss: 86002.9020\n",
      "Epoch 25/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15615.0185 - val_loss: 86460.9750\n",
      "Epoch 26/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15584.2527 - val_loss: 86398.5247\n",
      "Epoch 27/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15546.8205 - val_loss: 86521.1918\n",
      "Epoch 28/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15513.3661 - val_loss: 87018.7667\n",
      "Epoch 29/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15477.8636 - val_loss: 87279.4546\n",
      "Epoch 30/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15425.1558 - val_loss: 87508.0813\n",
      "Epoch 31/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15353.1971 - val_loss: 87392.9112\n",
      "Epoch 32/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15286.8549 - val_loss: 87862.9928\n",
      "Epoch 33/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15200.6835 - val_loss: 87516.5726\n",
      "Epoch 34/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15130.3080 - val_loss: 88360.7663\n",
      "Epoch 35/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 15056.9299 - val_loss: 88647.8976\n",
      "Epoch 36/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 14948.5659 - val_loss: 89775.4006\n",
      "Epoch 37/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 14856.1924 - val_loss: 90326.3035\n",
      "Epoch 38/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 14711.0365 - val_loss: 90936.7670\n",
      "Epoch 39/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 14591.1885 - val_loss: 92047.2903\n",
      "Epoch 40/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 14429.9997 - val_loss: 91858.7636\n",
      "Epoch 41/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 14258.1320 - val_loss: 91729.8639\n",
      "Epoch 42/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 14091.0882 - val_loss: 92457.9304\n",
      "Epoch 43/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 13904.1082 - val_loss: 91209.9134\n",
      "Epoch 44/1000\n",
      "242/242 [==============================] - 1s 4ms/step - loss: 13699.5201 - val_loss: 91805.4423\n"
     ]
    }
   ],
   "source": [
    "# Sub model 3 - GRU\n",
    "\n",
    "rmse = []\n",
    "r2 = []\n",
    "for ts in range(3, 11, 1):  \n",
    "    \n",
    "#     train_X, train_Y = time_step(df_train, ts, 1, 1)\n",
    "#     val_X, val_Y = time_step(df_val, ts, 1, 1)\n",
    "#     test_X, test_Y = time_step(df_test, ts, 1, 1)\n",
    "\n",
    "#     train_X, val_X, test_X = normalization(train_X, val_X, test_X)\n",
    "\n",
    "    # time step & lag\n",
    "    data_X, data_Y = time_step(data , ts, 1, 1)\n",
    "    \n",
    "    # 데이터 분할\n",
    "    NUM_TRAIN = int(data_X.shape[0] * 0.6)\n",
    "    NUM_VAL = int(data_X.shape[0] * 0.8)\n",
    "\n",
    "    train_X = data_X[:NUM_TRAIN]\n",
    "    train_Y = data_Y[:NUM_TRAIN]\n",
    "\n",
    "    val_X = data_X[NUM_TRAIN:NUM_VAL]\n",
    "    val_Y = data_Y[NUM_TRAIN:NUM_VAL]\n",
    "\n",
    "    test_X = data_X[NUM_VAL:]\n",
    "    test_Y =data_Y[NUM_VAL:]\n",
    "\n",
    "    train_X, val_X, test_X = normalization(train_X, val_X, test_X)\n",
    "    \n",
    "    # 함수형 API\n",
    "    input_tensor = Input(shape=(train_X.shape[1],))\n",
    "    x = layers.Reshape((train_X.shape[1], 1))(input_tensor)\n",
    "    x = layers.GRU(32, activation='relu', return_sequences=True)(x)\n",
    "    x = layers.GRU(16, activation='relu', return_sequences=True)(x)\n",
    "    x = layers.GRU(8, activation='relu', return_sequences=True)(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(4, activation='relu')(x)\n",
    "    output_tensor = layers.Dense(1)(x)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    mc = ModelCheckpoint('./model/GRU/model_{}.h5'.format(ts), monitor='val_loss', save_best_only=True)\n",
    "    \n",
    "    model.fit(train_X, train_Y,\n",
    "              batch_size=8,\n",
    "              epochs=1000,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_X, val_Y),\n",
    "              callbacks=[early_stopping, mc],\n",
    "              verbose=1)\n",
    "    \n",
    "    best_model = load_model('./model/GRU/model_{}.h5'.format(ts))\n",
    "    \n",
    "    y_pred = best_model.predict(test_X)\n",
    "    y_pred = y_pred.reshape(-1).astype('float32')\n",
    "    y_real = test_Y.reshape(-1).astype('float32')\n",
    "    \n",
    "    raw= {'Observed': list(y_real), 'Predicted': list(y_pred)}\n",
    "    rr = pd.DataFrame(raw)\n",
    "#     rr.to_csv(\"./Submodel/DNN/time_step/timse_step{}.csv\".format(ts))\n",
    "    reg = sm.OLS.from_formula(\"Observed ~ Predicted\",rr).fit()\n",
    "\n",
    "    try:\n",
    "        RMSE = round(math.sqrt(mean_squared_error(y_real, y_pred)), 3)\n",
    "        R2 = round(reg.rsquared, 3)   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    rmse.append(RMSE)\n",
    "    r2.append(R2)\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.plot(test_Y, label='Observed')\n",
    "#     plt.plot(y_predict, label='Predicted')\n",
    "#     plt.legend()\n",
    "#     plt.savefig('fig_{}.png'.format(ts), dpi=300)\n",
    " \n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[108.166, 129.725, 138.381, 133.608, 138.672, 196.397, 202.349, 288.225]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.814, 0.758, 0.765, 0.786, 0.739, 0.575, 0.776, 0.719]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.438, 0.536, 0.571, 0.552, 0.573, 0.811, 0.857, 1.221]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = list(np.array(rmse) / np.array(std_list))\n",
    "\n",
    "rmse_std = []\n",
    "for i in tmp:\n",
    "    rmse_std.append(round(i, 3))\n",
    "rmse_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 246 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "246/246 [==============================] - 53s 216ms/step - loss: 26740.9232 - val_loss: 163731.8964\n",
      "Epoch 2/1000\n",
      "246/246 [==============================] - 0s 898us/step - loss: 26730.9894 - val_loss: 163691.3872\n",
      "Epoch 3/1000\n",
      "246/246 [==============================] - 0s 944us/step - loss: 26719.6162 - val_loss: 163648.2959\n",
      "Epoch 4/1000\n",
      "246/246 [==============================] - 0s 877us/step - loss: 26700.1973 - val_loss: 163557.0134\n",
      "Epoch 5/1000\n",
      "246/246 [==============================] - 0s 958us/step - loss: 26660.5631 - val_loss: 163373.5788\n",
      "Epoch 6/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26590.2598 - val_loss: 163049.5102\n",
      "Epoch 7/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26465.4001 - val_loss: 162463.1991\n",
      "Epoch 8/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26242.1362 - val_loss: 161410.5759\n",
      "Epoch 9/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 25863.6756 - val_loss: 159650.5868\n",
      "Epoch 10/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 25275.7426 - val_loss: 156950.7676\n",
      "Epoch 11/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 24442.5455 - val_loss: 153155.2850\n",
      "Epoch 12/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 23366.1077 - val_loss: 148246.6602\n",
      "Epoch 13/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 22094.7144 - val_loss: 142360.7016\n",
      "Epoch 14/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 20720.0947 - val_loss: 135791.0898\n",
      "Epoch 15/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 19357.4699 - val_loss: 128935.3410\n",
      "Epoch 16/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 18114.1893 - val_loss: 122207.5423\n",
      "Epoch 17/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 17061.6910 - val_loss: 115949.6609\n",
      "Epoch 18/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 16223.7536 - val_loss: 110371.8856\n",
      "Epoch 19/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 15584.1121 - val_loss: 105554.4653\n",
      "Epoch 20/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 15104.9612 - val_loss: 101469.4222\n",
      "Epoch 21/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 14743.6429 - val_loss: 98031.2626\n",
      "Epoch 22/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 14463.4112 - val_loss: 95132.3081\n",
      "Epoch 23/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 14236.6802 - val_loss: 92666.5741\n",
      "Epoch 24/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 14044.4439 - val_loss: 90541.0784\n",
      "Epoch 25/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 13874.2393 - val_loss: 88679.5550\n",
      "Epoch 26/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 13718.1434 - val_loss: 87021.3042\n",
      "Epoch 27/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 13571.1398 - val_loss: 85519.2289\n",
      "Epoch 28/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 13430.0578 - val_loss: 84137.1804\n",
      "Epoch 29/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 13292.8533 - val_loss: 82847.2861\n",
      "Epoch 30/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 13158.1940 - val_loss: 81628.3793\n",
      "Epoch 31/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 13025.1723 - val_loss: 80464.0227\n",
      "Epoch 32/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 12893.1544 - val_loss: 79341.5907\n",
      "Epoch 33/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 12761.6802 - val_loss: 78251.2250\n",
      "Epoch 34/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 12630.4020 - val_loss: 77185.2067\n",
      "Epoch 35/1000\n",
      "246/246 [==============================] - 0s 937us/step - loss: 12499.0474 - val_loss: 76137.4745\n",
      "Epoch 36/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 12367.3958 - val_loss: 75103.1611\n",
      "Epoch 37/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 12235.2698 - val_loss: 74078.2942\n",
      "Epoch 38/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 12102.4910 - val_loss: 73059.9509\n",
      "Epoch 39/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 11968.9485 - val_loss: 72045.4857\n",
      "Epoch 40/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 11834.5110 - val_loss: 71032.7351\n",
      "Epoch 41/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 11699.0721 - val_loss: 70020.0257\n",
      "Epoch 42/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11562.5351 - val_loss: 69005.8575\n",
      "Epoch 43/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11424.8109 - val_loss: 67989.0859\n",
      "Epoch 44/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11285.8196 - val_loss: 66968.6801\n",
      "Epoch 45/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11145.4907 - val_loss: 65943.7701\n",
      "Epoch 46/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 11003.7524 - val_loss: 64913.5850\n",
      "Epoch 47/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10860.5536 - val_loss: 63877.5332\n",
      "Epoch 48/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 10715.8361 - val_loss: 62835.1324\n",
      "Epoch 49/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10569.5564 - val_loss: 61785.9079\n",
      "Epoch 50/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 10421.6736 - val_loss: 60729.4855\n",
      "Epoch 51/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10272.1448 - val_loss: 59665.6275\n",
      "Epoch 52/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 10120.9579 - val_loss: 58594.0776\n",
      "Epoch 53/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 9968.0854 - val_loss: 57514.6888\n",
      "Epoch 54/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 9813.5184 - val_loss: 56427.3433\n",
      "Epoch 55/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 9657.2532 - val_loss: 55331.9681\n",
      "Epoch 56/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9501.7458 - val_loss: 54232.0889\n",
      "Epoch 57/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9339.5711 - val_loss: 53120.4124\n",
      "Epoch 58/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 9178.2818 - val_loss: 52000.6174\n",
      "Epoch 59/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9015.3690 - val_loss: 50873.3947\n",
      "Epoch 60/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8850.8857 - val_loss: 49738.9593\n",
      "Epoch 61/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8684.8884 - val_loss: 48597.6851\n",
      "Epoch 62/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8517.4550 - val_loss: 47449.9477\n",
      "Epoch 63/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8348.6722 - val_loss: 46296.1851\n",
      "Epoch 64/1000\n",
      "246/246 [==============================] - ETA: 0s - loss: 8568.929 - 0s 1ms/step - loss: 8178.6458 - val_loss: 45136.9852\n",
      "Epoch 65/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 8007.4954 - val_loss: 43973.0114\n",
      "Epoch 66/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 7835.3589 - val_loss: 42804.9722\n",
      "Epoch 67/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7662.3887 - val_loss: 41633.7102\n",
      "Epoch 68/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7488.7646 - val_loss: 40460.1771\n",
      "Epoch 69/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7314.6769 - val_loss: 39285.3725\n",
      "Epoch 70/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7140.3418 - val_loss: 38110.4444\n",
      "Epoch 71/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6965.9947 - val_loss: 36936.6098\n",
      "Epoch 72/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 6791.8888 - val_loss: 35765.2266\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 972us/step - loss: 6618.3033 - val_loss: 34597.7146\n",
      "Epoch 74/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 6446.0238 - val_loss: 33432.5356\n",
      "Epoch 75/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6277.7581 - val_loss: 32268.9494\n",
      "Epoch 76/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6111.5710 - val_loss: 31118.6544\n",
      "Epoch 77/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5949.0737 - val_loss: 29976.8960\n",
      "Epoch 78/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 5790.7049 - val_loss: 28854.0010\n",
      "Epoch 79/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 5635.4916 - val_loss: 27753.1387\n",
      "Epoch 80/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5483.3489 - val_loss: 26677.6086\n",
      "Epoch 81/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 5334.5740 - val_loss: 25626.1158\n",
      "Epoch 82/1000\n",
      "246/246 [==============================] - 0s 947us/step - loss: 5189.4762 - val_loss: 24600.5690\n",
      "Epoch 83/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5048.1819 - val_loss: 23602.2778\n",
      "Epoch 84/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4910.9399 - val_loss: 22631.5198\n",
      "Epoch 85/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4777.9932 - val_loss: 21688.8885\n",
      "Epoch 86/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4649.6506 - val_loss: 20775.3558\n",
      "Epoch 87/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4526.0290 - val_loss: 19892.3908\n",
      "Epoch 88/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4407.3826 - val_loss: 19040.1805\n",
      "Epoch 89/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4295.5846 - val_loss: 18213.4641\n",
      "Epoch 90/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4189.9552 - val_loss: 17422.4793\n",
      "Epoch 91/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4089.7151 - val_loss: 16669.9057\n",
      "Epoch 92/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3994.8046 - val_loss: 15953.9007\n",
      "Epoch 93/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3905.3929 - val_loss: 15273.0192\n",
      "Epoch 94/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3821.4304 - val_loss: 14627.1504\n",
      "Epoch 95/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 3742.8729 - val_loss: 14015.8514\n",
      "Epoch 96/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3669.6179 - val_loss: 13438.9704\n",
      "Epoch 97/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3601.6002 - val_loss: 12895.1561\n",
      "Epoch 98/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3538.6899 - val_loss: 12383.7583\n",
      "Epoch 99/1000\n",
      "246/246 [==============================] - 0s 915us/step - loss: 3480.7519 - val_loss: 11903.7137\n",
      "Epoch 100/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 3427.6176 - val_loss: 11454.2958\n",
      "Epoch 101/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3379.0932 - val_loss: 11034.6093\n",
      "Epoch 102/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 3334.9592 - val_loss: 10643.7824\n",
      "Epoch 103/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3294.9885 - val_loss: 10280.6656\n",
      "Epoch 104/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 3258.9500 - val_loss: 9943.9551\n",
      "Epoch 105/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3226.6023 - val_loss: 9632.3213\n",
      "Epoch 106/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 3197.6988 - val_loss: 9344.3653\n",
      "Epoch 107/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3171.9766 - val_loss: 9079.0213\n",
      "Epoch 108/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 3149.1849 - val_loss: 8834.9265\n",
      "Epoch 109/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 3129.0699 - val_loss: 8610.8123\n",
      "Epoch 110/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3111.3889 - val_loss: 8405.4641\n",
      "Epoch 111/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 3095.9045 - val_loss: 8217.6087\n",
      "Epoch 112/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3082.3935 - val_loss: 8046.0879\n",
      "Epoch 113/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3070.6440 - val_loss: 7889.7361\n",
      "Epoch 114/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3060.4591 - val_loss: 7747.3301\n",
      "Epoch 115/1000\n",
      "246/246 [==============================] - 0s 959us/step - loss: 3051.6549 - val_loss: 7617.9375\n",
      "Epoch 116/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3044.0625 - val_loss: 7500.4762\n",
      "Epoch 117/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 3037.5426 - val_loss: 7393.8262\n",
      "Epoch 118/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3032.0608 - val_loss: 7296.7220\n",
      "Epoch 119/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 3027.4196 - val_loss: 7209.0669\n",
      "Epoch 120/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3023.4324 - val_loss: 7130.6596\n",
      "Epoch 121/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3020.0026 - val_loss: 7060.3860\n",
      "Epoch 122/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3017.0462 - val_loss: 6997.4567\n",
      "Epoch 123/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3014.4944 - val_loss: 6940.9496\n",
      "Epoch 124/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3012.3228 - val_loss: 6889.6868\n",
      "Epoch 125/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3010.4854 - val_loss: 6843.6992\n",
      "Epoch 126/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3008.8817 - val_loss: 6803.1750\n",
      "Epoch 127/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3007.4893 - val_loss: 6767.0824\n",
      "Epoch 128/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3006.2544 - val_loss: 6734.8323\n",
      "Epoch 129/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3005.1560 - val_loss: 6706.1723\n",
      "Epoch 130/1000\n",
      "246/246 [==============================] - 0s 953us/step - loss: 3004.1832 - val_loss: 6680.3428\n",
      "Epoch 131/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3003.3022 - val_loss: 6657.3947\n",
      "Epoch 132/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3002.5046 - val_loss: 6636.9268\n",
      "Epoch 133/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3001.7765 - val_loss: 6618.6299\n",
      "Epoch 134/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 3001.1043 - val_loss: 6602.3306\n",
      "Epoch 135/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 3000.4809 - val_loss: 6587.5525\n",
      "Epoch 136/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 2999.8984 - val_loss: 6574.4461\n",
      "Epoch 137/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2999.3554 - val_loss: 6562.7866\n",
      "Epoch 138/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2998.8442 - val_loss: 6552.2993\n",
      "Epoch 139/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2998.3589 - val_loss: 6542.9386\n",
      "Epoch 140/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2997.8956 - val_loss: 6534.4824\n",
      "Epoch 141/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2997.4509 - val_loss: 6527.0709\n",
      "Epoch 142/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2997.0247 - val_loss: 6520.4502\n",
      "Epoch 143/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 2996.6074 - val_loss: 6514.5706\n",
      "Epoch 144/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2996.2069 - val_loss: 6509.1628\n",
      "Epoch 145/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2995.8213 - val_loss: 6504.0863\n",
      "Epoch 146/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2995.4434 - val_loss: 6499.7535\n",
      "Epoch 147/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 1ms/step - loss: 2995.0725 - val_loss: 6495.9554\n",
      "Epoch 148/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 2994.7074 - val_loss: 6492.6213\n",
      "Epoch 149/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2994.3486 - val_loss: 6489.5198\n",
      "Epoch 150/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2993.9918 - val_loss: 6486.9430\n",
      "Epoch 151/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2993.6354 - val_loss: 6484.8287\n",
      "Epoch 152/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2993.2850 - val_loss: 6483.0420\n",
      "Epoch 153/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2992.9398 - val_loss: 6481.4105\n",
      "Epoch 154/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2992.5979 - val_loss: 6479.9475\n",
      "Epoch 155/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 2992.2663 - val_loss: 6478.5903\n",
      "Epoch 156/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2991.9350 - val_loss: 6477.4442\n",
      "Epoch 157/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2991.6084 - val_loss: 6476.4516\n",
      "Epoch 158/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2991.2841 - val_loss: 6475.7156\n",
      "Epoch 159/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2990.9657 - val_loss: 6474.9029\n",
      "Epoch 160/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2990.6544 - val_loss: 6473.8756\n",
      "Epoch 161/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2990.3394 - val_loss: 6472.9450\n",
      "Epoch 162/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2990.0334 - val_loss: 6472.0292\n",
      "Epoch 163/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2989.7235 - val_loss: 6471.2174\n",
      "Epoch 164/1000\n",
      "246/246 [==============================] - 0s 973us/step - loss: 2989.4213 - val_loss: 6470.3468\n",
      "Epoch 165/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2989.1159 - val_loss: 6469.6373\n",
      "Epoch 166/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2988.8155 - val_loss: 6468.8595\n",
      "Epoch 167/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2988.5144 - val_loss: 6468.2609\n",
      "Epoch 168/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2988.2216 - val_loss: 6467.4155\n",
      "Epoch 169/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2987.9224 - val_loss: 6466.7815\n",
      "Epoch 170/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2987.6338 - val_loss: 6465.9258\n",
      "Epoch 171/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2987.3394 - val_loss: 6465.3024\n",
      "Epoch 172/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2987.0537 - val_loss: 6464.5616\n",
      "Epoch 173/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2986.7573 - val_loss: 6464.0840\n",
      "Epoch 174/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2986.4761 - val_loss: 6463.2127\n",
      "Epoch 175/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2986.1839 - val_loss: 6462.5401\n",
      "Epoch 176/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2985.9064 - val_loss: 6461.6626\n",
      "Epoch 177/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2985.6179 - val_loss: 6461.0261\n",
      "Epoch 178/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2985.3345 - val_loss: 6460.3312\n",
      "Epoch 179/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2985.0559 - val_loss: 6459.5085\n",
      "Epoch 180/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2984.7715 - val_loss: 6458.9053\n",
      "Epoch 181/1000\n",
      "246/246 [==============================] - 0s 959us/step - loss: 2984.4948 - val_loss: 6458.1492\n",
      "Epoch 182/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 2984.2178 - val_loss: 6457.4456\n",
      "Epoch 183/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 2983.9434 - val_loss: 6456.6748\n",
      "Epoch 184/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 2983.6737 - val_loss: 6455.7676\n",
      "Epoch 185/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2983.3977 - val_loss: 6455.0696\n",
      "Epoch 186/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2983.1305 - val_loss: 6454.2403\n",
      "Epoch 187/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2982.8593 - val_loss: 6453.5568\n",
      "Epoch 188/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2982.5879 - val_loss: 6452.9286\n",
      "Epoch 189/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2982.3156 - val_loss: 6452.3370\n",
      "Epoch 190/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2982.0478 - val_loss: 6451.5812\n",
      "Epoch 191/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2981.7781 - val_loss: 6450.8263\n",
      "Epoch 192/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2981.5127 - val_loss: 6449.9909\n",
      "Epoch 193/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2981.2428 - val_loss: 6449.2709\n",
      "Epoch 194/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2980.9769 - val_loss: 6448.5170\n",
      "Epoch 195/1000\n",
      "246/246 [==============================] - 0s 942us/step - loss: 2980.7101 - val_loss: 6447.8161\n",
      "Epoch 196/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2980.4477 - val_loss: 6447.0199\n",
      "Epoch 197/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2980.1855 - val_loss: 6446.1515\n",
      "Epoch 198/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 2979.9212 - val_loss: 6445.3286\n",
      "Epoch 199/1000\n",
      "246/246 [==============================] - 0s 951us/step - loss: 2979.6599 - val_loss: 6444.4791\n",
      "Epoch 200/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2979.3967 - val_loss: 6443.6688\n",
      "Epoch 201/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2979.1365 - val_loss: 6442.8156\n",
      "Epoch 202/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2978.8772 - val_loss: 6441.9412\n",
      "Epoch 203/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2978.6184 - val_loss: 6441.0714\n",
      "Epoch 204/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2978.3580 - val_loss: 6440.2947\n",
      "Epoch 205/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2978.1044 - val_loss: 6439.2786\n",
      "Epoch 206/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2977.8446 - val_loss: 6438.4198\n",
      "Epoch 207/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2977.5884 - val_loss: 6437.5699\n",
      "Epoch 208/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2977.3262 - val_loss: 6436.8973\n",
      "Epoch 209/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2977.0756 - val_loss: 6435.9060\n",
      "Epoch 210/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2976.8205 - val_loss: 6435.0014\n",
      "Epoch 211/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2976.5657 - val_loss: 6434.1613\n",
      "Epoch 212/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2976.3040 - val_loss: 6433.5494\n",
      "Epoch 213/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2976.0565 - val_loss: 6432.5802\n",
      "Epoch 214/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2975.8017 - val_loss: 6431.7422\n",
      "Epoch 215/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2975.5476 - val_loss: 6430.9887\n",
      "Epoch 216/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2975.2899 - val_loss: 6430.3589\n",
      "Epoch 217/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2975.0389 - val_loss: 6429.5146\n",
      "Epoch 218/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2974.7789 - val_loss: 6428.9498\n",
      "Epoch 219/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 2974.5276 - val_loss: 6428.1784\n",
      "Epoch 220/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2974.2819 - val_loss: 6427.2215\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 966us/step - loss: 2974.0274 - val_loss: 6426.4615\n",
      "Epoch 222/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2973.7748 - val_loss: 6425.7670\n",
      "Epoch 223/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2973.5162 - val_loss: 6425.2504\n",
      "Epoch 224/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2973.2707 - val_loss: 6424.3585\n",
      "Epoch 225/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2973.0187 - val_loss: 6423.6295\n",
      "Epoch 226/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2972.7636 - val_loss: 6423.1077\n",
      "Epoch 227/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2972.4987 - val_loss: 6422.7555\n",
      "Epoch 228/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 2972.2614 - val_loss: 6421.5181\n",
      "Epoch 229/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2972.0052 - val_loss: 6420.6530\n",
      "Epoch 230/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2971.7513 - val_loss: 6419.8418\n",
      "Epoch 231/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 2971.5068 - val_loss: 6418.7718\n",
      "Epoch 232/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 2971.2470 - val_loss: 6418.0989\n",
      "Epoch 233/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2971.0030 - val_loss: 6417.0479\n",
      "Epoch 234/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2970.7600 - val_loss: 6415.9217\n",
      "Epoch 235/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2970.5057 - val_loss: 6415.1453\n",
      "Epoch 236/1000\n",
      "246/246 [==============================] - 0s 928us/step - loss: 2970.2541 - val_loss: 6414.3953\n",
      "Epoch 237/1000\n",
      "246/246 [==============================] - 0s 962us/step - loss: 2970.0220 - val_loss: 6413.0440\n",
      "Epoch 238/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 2969.7558 - val_loss: 6412.6735\n",
      "Epoch 239/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2969.5335 - val_loss: 6411.2057\n",
      "Epoch 240/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2969.2677 - val_loss: 6410.8696\n",
      "Epoch 241/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2969.0346 - val_loss: 6409.8104\n",
      "Epoch 242/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2968.7755 - val_loss: 6409.3335\n",
      "Epoch 243/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2968.5552 - val_loss: 6407.9016\n",
      "Epoch 244/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2968.2895 - val_loss: 6407.6745\n",
      "Epoch 245/1000\n",
      "246/246 [==============================] - 0s 948us/step - loss: 2968.0605 - val_loss: 6406.6535\n",
      "Epoch 246/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 2967.8101 - val_loss: 6406.0817\n",
      "Epoch 247/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2967.5688 - val_loss: 6405.3557\n",
      "Epoch 248/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2967.3253 - val_loss: 6404.6630\n",
      "Epoch 249/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 2967.0910 - val_loss: 6403.7452\n",
      "Epoch 250/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2966.8334 - val_loss: 6403.4894\n",
      "Epoch 251/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2966.6117 - val_loss: 6402.3054\n",
      "Epoch 252/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 2966.3606 - val_loss: 6401.8390\n",
      "Epoch 253/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 2966.1221 - val_loss: 6401.2061\n",
      "Epoch 254/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2965.8840 - val_loss: 6400.4993\n",
      "Epoch 255/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 2965.6490 - val_loss: 6399.7308\n",
      "Epoch 256/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 2965.3904 - val_loss: 6399.6359\n",
      "Epoch 257/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2965.1749 - val_loss: 6398.3788\n",
      "Epoch 258/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2964.9295 - val_loss: 6397.8225\n",
      "Epoch 259/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2964.6903 - val_loss: 6397.3016\n",
      "Epoch 260/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2964.4519 - val_loss: 6396.7379\n",
      "Epoch 261/1000\n",
      "246/246 [==============================] - 0s 928us/step - loss: 2964.2188 - val_loss: 6395.9804\n",
      "Epoch 262/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2963.9698 - val_loss: 6395.6470\n",
      "Epoch 263/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 2963.7447 - val_loss: 6394.6708\n",
      "Epoch 264/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2963.5185 - val_loss: 6393.7325\n",
      "Epoch 265/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2963.2722 - val_loss: 6393.3846\n",
      "Epoch 266/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2963.0398 - val_loss: 6392.7551\n",
      "Epoch 267/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2962.8165 - val_loss: 6391.7909\n",
      "Epoch 268/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 2962.5580 - val_loss: 6391.8373\n",
      "Epoch 269/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2962.3545 - val_loss: 6390.3994\n",
      "Epoch 270/1000\n",
      "246/246 [==============================] - 0s 956us/step - loss: 2962.0963 - val_loss: 6390.3306\n",
      "Epoch 271/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2961.8859 - val_loss: 6389.1696\n",
      "Epoch 272/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2961.6353 - val_loss: 6389.0109\n",
      "Epoch 273/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2961.4245 - val_loss: 6387.8673\n",
      "Epoch 274/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 2961.1661 - val_loss: 6387.9263\n",
      "Epoch 275/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 2960.9575 - val_loss: 6386.7511\n",
      "Epoch 276/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2960.7215 - val_loss: 6386.1726\n",
      "Epoch 277/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2960.4977 - val_loss: 6385.4187\n",
      "Epoch 278/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2960.2571 - val_loss: 6385.1783\n",
      "Epoch 279/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2960.0398 - val_loss: 6384.3217\n",
      "Epoch 280/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 2959.8105 - val_loss: 6383.6959\n",
      "Epoch 281/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2959.5792 - val_loss: 6383.2502\n",
      "Epoch 282/1000\n",
      "246/246 [==============================] - 0s 958us/step - loss: 2959.3432 - val_loss: 6382.8845\n",
      "Epoch 283/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 2959.1329 - val_loss: 6381.7595\n",
      "Epoch 284/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2958.8922 - val_loss: 6381.4252\n",
      "Epoch 285/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2958.6781 - val_loss: 6380.4890\n",
      "Epoch 286/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2958.4484 - val_loss: 6379.8941\n",
      "Epoch 287/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 2958.2227 - val_loss: 6379.3532\n",
      "Epoch 288/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2958.0003 - val_loss: 6378.6462\n",
      "Epoch 289/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2957.7771 - val_loss: 6377.9706\n",
      "Epoch 290/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2957.5583 - val_loss: 6377.2991\n",
      "Epoch 291/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2957.3461 - val_loss: 6376.3895\n",
      "Epoch 292/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2957.0992 - val_loss: 6376.5313\n",
      "Epoch 293/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2956.9038 - val_loss: 6375.3364\n",
      "Epoch 294/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2956.6656 - val_loss: 6375.1198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2956.4529 - val_loss: 6374.4390\n",
      "Epoch 296/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2956.2367 - val_loss: 6373.7233\n",
      "Epoch 297/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2956.0113 - val_loss: 6373.3516\n",
      "Epoch 298/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2955.7900 - val_loss: 6372.8769\n",
      "Epoch 299/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2955.5821 - val_loss: 6372.0378\n",
      "Epoch 300/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 2955.3543 - val_loss: 6371.7131\n",
      "Epoch 301/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2955.1477 - val_loss: 6370.9114\n",
      "Epoch 302/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2954.9161 - val_loss: 6370.7482\n",
      "Epoch 303/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2954.7123 - val_loss: 6369.9019\n",
      "Epoch 304/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2954.4908 - val_loss: 6369.4256\n",
      "Epoch 305/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2954.2796 - val_loss: 6368.7943\n",
      "Epoch 306/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2954.0564 - val_loss: 6368.4380\n",
      "Epoch 307/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2953.8451 - val_loss: 6367.8267\n",
      "Epoch 308/1000\n",
      "246/246 [==============================] - 0s 955us/step - loss: 2953.6377 - val_loss: 6367.0228\n",
      "Epoch 309/1000\n",
      "246/246 [==============================] - 0s 924us/step - loss: 2953.4197 - val_loss: 6366.5889\n",
      "Epoch 310/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2953.2036 - val_loss: 6366.1798\n",
      "Epoch 311/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2952.9960 - val_loss: 6365.4970\n",
      "Epoch 312/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2952.7872 - val_loss: 6364.8396\n",
      "Epoch 313/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2952.5651 - val_loss: 6364.6163\n",
      "Epoch 314/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2952.3640 - val_loss: 6363.7960\n",
      "Epoch 315/1000\n",
      "246/246 [==============================] - 0s 940us/step - loss: 2952.1398 - val_loss: 6363.5707\n",
      "Epoch 316/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 2951.9443 - val_loss: 6362.5993\n",
      "Epoch 317/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2951.7317 - val_loss: 6362.0496\n",
      "Epoch 318/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 2951.5178 - val_loss: 6361.6821\n",
      "Epoch 319/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 2951.3055 - val_loss: 6361.2362\n",
      "Epoch 320/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2951.0970 - val_loss: 6360.5705\n",
      "Epoch 321/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2950.8978 - val_loss: 6359.6590\n",
      "Epoch 322/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2950.6960 - val_loss: 6358.9566\n",
      "Epoch 323/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2950.4896 - val_loss: 6358.4492\n",
      "Epoch 324/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2950.2800 - val_loss: 6358.0902\n",
      "Epoch 325/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2950.0747 - val_loss: 6357.6665\n",
      "Epoch 326/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2949.8728 - val_loss: 6357.0251\n",
      "Epoch 327/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 2949.6658 - val_loss: 6356.6190\n",
      "Epoch 328/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2949.4525 - val_loss: 6356.3452\n",
      "Epoch 329/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2949.2633 - val_loss: 6355.4146\n",
      "Epoch 330/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2949.0562 - val_loss: 6354.9207\n",
      "Epoch 331/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2948.8521 - val_loss: 6354.5161\n",
      "Epoch 332/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2948.6463 - val_loss: 6354.1224\n",
      "Epoch 333/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 2948.4528 - val_loss: 6353.3654\n",
      "Epoch 334/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2948.2394 - val_loss: 6353.1423\n",
      "Epoch 335/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2948.0499 - val_loss: 6352.3252\n",
      "Epoch 336/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2947.8383 - val_loss: 6352.0102\n",
      "Epoch 337/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2947.6503 - val_loss: 6351.2013\n",
      "Epoch 338/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2947.4484 - val_loss: 6350.7024\n",
      "Epoch 339/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2947.2458 - val_loss: 6350.3484\n",
      "Epoch 340/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2947.0448 - val_loss: 6349.9463\n",
      "Epoch 341/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2946.8587 - val_loss: 6349.0824\n",
      "Epoch 342/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2946.6490 - val_loss: 6348.8805\n",
      "Epoch 343/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2946.4640 - val_loss: 6348.1188\n",
      "Epoch 344/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2946.2532 - val_loss: 6348.0103\n",
      "Epoch 345/1000\n",
      "246/246 [==============================] - 0s 973us/step - loss: 2946.0680 - val_loss: 6347.2276\n",
      "Epoch 346/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2945.8700 - val_loss: 6346.7289\n",
      "Epoch 347/1000\n",
      "246/246 [==============================] - 0s 928us/step - loss: 2945.6720 - val_loss: 6346.3339\n",
      "Epoch 348/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 2945.4833 - val_loss: 6345.6610\n",
      "Epoch 349/1000\n",
      "246/246 [==============================] - 0s 958us/step - loss: 2945.2803 - val_loss: 6345.3990\n",
      "Epoch 350/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2945.0947 - val_loss: 6344.6887\n",
      "Epoch 351/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2944.8907 - val_loss: 6344.4270\n",
      "Epoch 352/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2944.7088 - val_loss: 6343.5572\n",
      "Epoch 353/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2944.5086 - val_loss: 6343.1902\n",
      "Epoch 354/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 2944.3125 - val_loss: 6342.7469\n",
      "Epoch 355/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2944.1318 - val_loss: 6341.8272\n",
      "Epoch 356/1000\n",
      "246/246 [==============================] - 0s 973us/step - loss: 2943.9252 - val_loss: 6341.6036\n",
      "Epoch 357/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2943.7425 - val_loss: 6340.7930\n",
      "Epoch 358/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2943.5628 - val_loss: 6339.8861\n",
      "Epoch 359/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2943.3630 - val_loss: 6339.6328\n",
      "Epoch 360/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2943.1753 - val_loss: 6339.1389\n",
      "Epoch 361/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2942.9838 - val_loss: 6338.6632\n",
      "Epoch 362/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2942.7999 - val_loss: 6337.9802\n",
      "Epoch 363/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2942.6098 - val_loss: 6337.4636\n",
      "Epoch 364/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2942.4302 - val_loss: 6336.7725\n",
      "Epoch 365/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2942.2384 - val_loss: 6336.4246\n",
      "Epoch 366/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2942.0448 - val_loss: 6336.1662\n",
      "Epoch 367/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2941.8690 - val_loss: 6335.3924\n",
      "Epoch 368/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 983us/step - loss: 2941.6827 - val_loss: 6334.8540\n",
      "Epoch 369/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2941.4910 - val_loss: 6334.5328\n",
      "Epoch 370/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2941.3199 - val_loss: 6333.7210\n",
      "Epoch 371/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2941.1125 - val_loss: 6333.7948\n",
      "Epoch 372/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 2940.9476 - val_loss: 6332.8190\n",
      "Epoch 373/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2940.7671 - val_loss: 6332.1462\n",
      "Epoch 374/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2940.5775 - val_loss: 6331.9173\n",
      "Epoch 375/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 2940.4040 - val_loss: 6331.3203\n",
      "Epoch 376/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2940.2191 - val_loss: 6330.9745\n",
      "Epoch 377/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2940.0298 - val_loss: 6330.7580\n",
      "Epoch 378/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2939.8567 - val_loss: 6330.1106\n",
      "Epoch 379/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2939.6842 - val_loss: 6329.3484\n",
      "Epoch 380/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2939.4928 - val_loss: 6329.2710\n",
      "Epoch 381/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2939.3200 - val_loss: 6328.6889\n",
      "Epoch 382/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2939.1353 - val_loss: 6328.3804\n",
      "Epoch 383/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2938.9534 - val_loss: 6328.0281\n",
      "Epoch 384/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2938.7815 - val_loss: 6327.3216\n",
      "Epoch 385/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2938.6029 - val_loss: 6326.8537\n",
      "Epoch 386/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2938.4235 - val_loss: 6326.4001\n",
      "Epoch 387/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2938.2502 - val_loss: 6325.8915\n",
      "Epoch 388/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2938.0776 - val_loss: 6325.3504\n",
      "Epoch 389/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2937.8859 - val_loss: 6325.3914\n",
      "Epoch 390/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2937.7240 - val_loss: 6324.5740\n",
      "Epoch 391/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2937.5458 - val_loss: 6324.1208\n",
      "Epoch 392/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2937.3702 - val_loss: 6323.7211\n",
      "Epoch 393/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2937.1949 - val_loss: 6323.3106\n",
      "Epoch 394/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2937.0160 - val_loss: 6322.9650\n",
      "Epoch 395/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2936.8473 - val_loss: 6322.3329\n",
      "Epoch 396/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2936.6813 - val_loss: 6321.6205\n",
      "Epoch 397/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2936.4940 - val_loss: 6321.6290\n",
      "Epoch 398/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2936.3360 - val_loss: 6320.8041\n",
      "Epoch 399/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2936.1532 - val_loss: 6320.6539\n",
      "Epoch 400/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2935.9803 - val_loss: 6320.2352\n",
      "Epoch 401/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2935.8106 - val_loss: 6319.6628\n",
      "Epoch 402/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2935.6475 - val_loss: 6318.8895\n",
      "Epoch 403/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2935.4610 - val_loss: 6318.8154\n",
      "Epoch 404/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2935.3043 - val_loss: 6317.9557\n",
      "Epoch 405/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2935.1334 - val_loss: 6317.4420\n",
      "Epoch 406/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2934.9629 - val_loss: 6317.0536\n",
      "Epoch 407/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 2934.7852 - val_loss: 6316.8435\n",
      "Epoch 408/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2934.6252 - val_loss: 6316.0996\n",
      "Epoch 409/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2934.4540 - val_loss: 6315.6294\n",
      "Epoch 410/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2934.2922 - val_loss: 6315.0075\n",
      "Epoch 411/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2934.1246 - val_loss: 6314.5676\n",
      "Epoch 412/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2933.9512 - val_loss: 6314.3408\n",
      "Epoch 413/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2933.7859 - val_loss: 6313.8666\n",
      "Epoch 414/1000\n",
      "246/246 [==============================] - 0s 959us/step - loss: 2933.6259 - val_loss: 6313.2243\n",
      "Epoch 415/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2933.4571 - val_loss: 6312.8175\n",
      "Epoch 416/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 2933.2905 - val_loss: 6312.4830\n",
      "Epoch 417/1000\n",
      "246/246 [==============================] - 0s 955us/step - loss: 2933.1291 - val_loss: 6311.9171\n",
      "Epoch 418/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2932.9609 - val_loss: 6311.5324\n",
      "Epoch 419/1000\n",
      "246/246 [==============================] - 0s 939us/step - loss: 2932.7996 - val_loss: 6311.0313\n",
      "Epoch 420/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2932.6396 - val_loss: 6310.4630\n",
      "Epoch 421/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 2932.4663 - val_loss: 6310.3133\n",
      "Epoch 422/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2932.3106 - val_loss: 6309.7027\n",
      "Epoch 423/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2932.1507 - val_loss: 6309.1241\n",
      "Epoch 424/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2931.9820 - val_loss: 6308.8667\n",
      "Epoch 425/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 2931.8206 - val_loss: 6308.4233\n",
      "Epoch 426/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2931.6590 - val_loss: 6307.9446\n",
      "Epoch 427/1000\n",
      "246/246 [==============================] - 0s 964us/step - loss: 2931.5024 - val_loss: 6307.3350\n",
      "Epoch 428/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2931.3394 - val_loss: 6306.9503\n",
      "Epoch 429/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2931.1908 - val_loss: 6306.2432\n",
      "Epoch 430/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2931.0098 - val_loss: 6306.4525\n",
      "Epoch 431/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2930.8669 - val_loss: 6305.6289\n",
      "Epoch 432/1000\n",
      "246/246 [==============================] - 0s 952us/step - loss: 2930.7096 - val_loss: 6305.0966\n",
      "Epoch 433/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2930.5472 - val_loss: 6304.8894\n",
      "Epoch 434/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2930.3859 - val_loss: 6304.6593\n",
      "Epoch 435/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2930.2263 - val_loss: 6304.2391\n",
      "Epoch 436/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2930.0689 - val_loss: 6303.7555\n",
      "Epoch 437/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2929.9153 - val_loss: 6303.1444\n",
      "Epoch 438/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2929.7560 - val_loss: 6302.7625\n",
      "Epoch 439/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2929.6024 - val_loss: 6302.2354\n",
      "Epoch 440/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2929.4423 - val_loss: 6301.9167\n",
      "Epoch 441/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2929.2965 - val_loss: 6301.2378\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 999us/step - loss: 2929.1262 - val_loss: 6301.2129\n",
      "Epoch 443/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 2928.9846 - val_loss: 6300.4574\n",
      "Epoch 444/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2928.8229 - val_loss: 6300.2137\n",
      "Epoch 445/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2928.6759 - val_loss: 6299.6144\n",
      "Epoch 446/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2928.5174 - val_loss: 6299.3878\n",
      "Epoch 447/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2928.3728 - val_loss: 6298.7712\n",
      "Epoch 448/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2928.2084 - val_loss: 6298.7233\n",
      "Epoch 449/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2928.0562 - val_loss: 6298.3662\n",
      "Epoch 450/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2927.9110 - val_loss: 6297.6915\n",
      "Epoch 451/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 2927.7487 - val_loss: 6297.5433\n",
      "Epoch 452/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2927.6103 - val_loss: 6296.7431\n",
      "Epoch 453/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2927.4558 - val_loss: 6296.4082\n",
      "Epoch 454/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2927.3020 - val_loss: 6296.1394\n",
      "Epoch 455/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2927.1447 - val_loss: 6295.9588\n",
      "Epoch 456/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2927.0076 - val_loss: 6295.1291\n",
      "Epoch 457/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2926.8526 - val_loss: 6294.8137\n",
      "Epoch 458/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2926.6993 - val_loss: 6294.5787\n",
      "Epoch 459/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2926.5511 - val_loss: 6294.1256\n",
      "Epoch 460/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2926.4059 - val_loss: 6293.5565\n",
      "Epoch 461/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2926.2589 - val_loss: 6293.0980\n",
      "Epoch 462/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2926.1158 - val_loss: 6292.6109\n",
      "Epoch 463/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2925.9542 - val_loss: 6292.6692\n",
      "Epoch 464/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2925.8144 - val_loss: 6292.0903\n",
      "Epoch 465/1000\n",
      "246/246 [==============================] - 0s 964us/step - loss: 2925.6698 - val_loss: 6291.5872\n",
      "Epoch 466/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2925.5240 - val_loss: 6291.1424\n",
      "Epoch 467/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2925.3632 - val_loss: 6291.2078\n",
      "Epoch 468/1000\n",
      "246/246 [==============================] - 0s 948us/step - loss: 2925.2355 - val_loss: 6290.2543\n",
      "Epoch 469/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2925.0797 - val_loss: 6290.0314\n",
      "Epoch 470/1000\n",
      "246/246 [==============================] - 0s 962us/step - loss: 2924.9373 - val_loss: 6289.5867\n",
      "Epoch 471/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2924.7927 - val_loss: 6289.1899\n",
      "Epoch 472/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2924.6509 - val_loss: 6288.7532\n",
      "Epoch 473/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2924.5079 - val_loss: 6288.3426\n",
      "Epoch 474/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2924.3660 - val_loss: 6287.9758\n",
      "Epoch 475/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2924.2038 - val_loss: 6288.1308\n",
      "Epoch 476/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2924.0810 - val_loss: 6287.1738\n",
      "Epoch 477/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 2923.9294 - val_loss: 6286.8948\n",
      "Epoch 478/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2923.7849 - val_loss: 6286.5813\n",
      "Epoch 479/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2923.6475 - val_loss: 6286.0342\n",
      "Epoch 480/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 2923.5150 - val_loss: 6285.3495\n",
      "Epoch 481/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2923.3600 - val_loss: 6285.4634\n",
      "Epoch 482/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2923.2277 - val_loss: 6284.9178\n",
      "Epoch 483/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2923.0737 - val_loss: 6284.8919\n",
      "Epoch 484/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2922.9411 - val_loss: 6284.2448\n",
      "Epoch 485/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 2922.7966 - val_loss: 6283.8782\n",
      "Epoch 486/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2922.6679 - val_loss: 6283.1530\n",
      "Epoch 487/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2922.5083 - val_loss: 6283.2798\n",
      "Epoch 488/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2922.3896 - val_loss: 6282.3460\n",
      "Epoch 489/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 2922.2447 - val_loss: 6282.0514\n",
      "Epoch 490/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 2922.1079 - val_loss: 6281.7606\n",
      "Epoch 491/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2921.9686 - val_loss: 6281.4956\n",
      "Epoch 492/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2921.8244 - val_loss: 6281.3122\n",
      "Epoch 493/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 2921.6879 - val_loss: 6280.8790\n",
      "Epoch 494/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2921.5580 - val_loss: 6280.2123\n",
      "Epoch 495/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2921.4196 - val_loss: 6279.9087\n",
      "Epoch 496/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2921.2798 - val_loss: 6279.6559\n",
      "Epoch 497/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2921.1429 - val_loss: 6279.3537\n",
      "Epoch 498/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2921.0180 - val_loss: 6278.6569\n",
      "Epoch 499/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2920.8633 - val_loss: 6278.8278\n",
      "Epoch 500/1000\n",
      "246/246 [==============================] - 0s 944us/step - loss: 2920.7398 - val_loss: 6278.1866\n",
      "Epoch 501/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2920.6117 - val_loss: 6277.5477\n",
      "Epoch 502/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2920.4627 - val_loss: 6277.6521\n",
      "Epoch 503/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2920.3389 - val_loss: 6277.0200\n",
      "Epoch 504/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2920.1905 - val_loss: 6276.9646\n",
      "Epoch 505/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2920.0622 - val_loss: 6276.4075\n",
      "Epoch 506/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2919.9423 - val_loss: 6275.5749\n",
      "Epoch 507/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2919.8008 - val_loss: 6275.4767\n",
      "Epoch 508/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2919.6655 - val_loss: 6275.3080\n",
      "Epoch 509/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2919.5392 - val_loss: 6274.7977\n",
      "Epoch 510/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2919.3888 - val_loss: 6274.8889\n",
      "Epoch 511/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2919.2704 - val_loss: 6274.1123\n",
      "Epoch 512/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2919.1449 - val_loss: 6273.4680\n",
      "Epoch 513/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2919.0108 - val_loss: 6273.2184\n",
      "Epoch 514/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2918.8741 - val_loss: 6273.1418\n",
      "Epoch 515/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2918.7399 - val_loss: 6272.8569\n",
      "Epoch 516/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 1ms/step - loss: 2918.6183 - val_loss: 6272.2014\n",
      "Epoch 517/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2918.4834 - val_loss: 6271.8969\n",
      "Epoch 518/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2918.3497 - val_loss: 6271.6526\n",
      "Epoch 519/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2918.2314 - val_loss: 6270.9505\n",
      "Epoch 520/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2918.0915 - val_loss: 6270.8449\n",
      "Epoch 521/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2917.9694 - val_loss: 6270.3432\n",
      "Epoch 522/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2917.8410 - val_loss: 6269.9772\n",
      "Epoch 523/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2917.7122 - val_loss: 6269.6666\n",
      "Epoch 524/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2917.5848 - val_loss: 6269.3630\n",
      "Epoch 525/1000\n",
      "246/246 [==============================] - 0s 964us/step - loss: 2917.4501 - val_loss: 6269.2021\n",
      "Epoch 526/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 2917.3228 - val_loss: 6268.7919\n",
      "Epoch 527/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 2917.2053 - val_loss: 6268.0896\n",
      "Epoch 528/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2917.0714 - val_loss: 6267.8852\n",
      "Epoch 529/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2916.9387 - val_loss: 6267.7363\n",
      "Epoch 530/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2916.8238 - val_loss: 6266.9927\n",
      "Epoch 531/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 2916.6963 - val_loss: 6266.6696\n",
      "Epoch 532/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2916.5737 - val_loss: 6266.3021\n",
      "Epoch 533/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2916.4409 - val_loss: 6266.2305\n",
      "Epoch 534/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2916.3247 - val_loss: 6265.6957\n",
      "Epoch 535/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2916.1891 - val_loss: 6265.6576\n",
      "Epoch 536/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2916.0755 - val_loss: 6265.0182\n",
      "Epoch 537/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2915.9422 - val_loss: 6264.8993\n",
      "Epoch 538/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2915.8173 - val_loss: 6264.5919\n",
      "Epoch 539/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2915.7003 - val_loss: 6263.9942\n",
      "Epoch 540/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2915.5740 - val_loss: 6263.6574\n",
      "Epoch 541/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2915.4490 - val_loss: 6263.4165\n",
      "Epoch 542/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 2915.3388 - val_loss: 6262.7160\n",
      "Epoch 543/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2915.2010 - val_loss: 6262.8670\n",
      "Epoch 544/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2915.0874 - val_loss: 6262.3380\n",
      "Epoch 545/1000\n",
      "246/246 [==============================] - 0s 964us/step - loss: 2914.9507 - val_loss: 6262.3673\n",
      "Epoch 546/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2914.8535 - val_loss: 6261.2825\n",
      "Epoch 547/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2914.7101 - val_loss: 6261.5085\n",
      "Epoch 548/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 2914.5979 - val_loss: 6260.9712\n",
      "Epoch 549/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 2914.4733 - val_loss: 6260.6548\n",
      "Epoch 550/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2914.3660 - val_loss: 6259.9405\n",
      "Epoch 551/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2914.2351 - val_loss: 6259.9682\n",
      "Epoch 552/1000\n",
      "246/246 [==============================] - 0s 939us/step - loss: 2914.1230 - val_loss: 6259.5228\n",
      "Epoch 553/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2913.9918 - val_loss: 6259.5596\n",
      "Epoch 554/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2913.8866 - val_loss: 6258.8517\n",
      "Epoch 555/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2913.7478 - val_loss: 6259.0544\n",
      "Epoch 556/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2913.6435 - val_loss: 6258.2703\n",
      "Epoch 557/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 2913.5162 - val_loss: 6258.0858\n",
      "Epoch 558/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2913.4026 - val_loss: 6257.6000\n",
      "Epoch 559/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2913.2829 - val_loss: 6257.2605\n",
      "Epoch 560/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2913.1688 - val_loss: 6256.8549\n",
      "Epoch 561/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2913.0517 - val_loss: 6256.5255\n",
      "Epoch 562/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.9419 - val_loss: 6256.0800\n",
      "Epoch 563/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.8044 - val_loss: 6256.4438\n",
      "Epoch 564/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.7021 - val_loss: 6255.7227\n",
      "Epoch 565/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.5811 - val_loss: 6255.4493\n",
      "Epoch 566/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 2912.4750 - val_loss: 6254.8558\n",
      "Epoch 567/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.3435 - val_loss: 6255.0162\n",
      "Epoch 568/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.2402 - val_loss: 6254.3763\n",
      "Epoch 569/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.1214 - val_loss: 6254.1258\n",
      "Epoch 570/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2912.0062 - val_loss: 6253.8636\n",
      "Epoch 571/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2911.8812 - val_loss: 6253.7718\n",
      "Epoch 572/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2911.7790 - val_loss: 6253.0566\n",
      "Epoch 573/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2911.6611 - val_loss: 6252.7705\n",
      "Epoch 574/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2911.5477 - val_loss: 6252.4631\n",
      "Epoch 575/1000\n",
      "246/246 [==============================] - 0s 973us/step - loss: 2911.4333 - val_loss: 6252.1964\n",
      "Epoch 576/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2911.3238 - val_loss: 6251.7825\n",
      "Epoch 577/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2911.2003 - val_loss: 6251.7941\n",
      "Epoch 578/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2911.1017 - val_loss: 6251.0740\n",
      "Epoch 579/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2910.9668 - val_loss: 6251.3399\n",
      "Epoch 580/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2910.8803 - val_loss: 6250.2702\n",
      "Epoch 581/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2910.7487 - val_loss: 6250.4601\n",
      "Epoch 582/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2910.6483 - val_loss: 6249.8627\n",
      "Epoch 583/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 2910.5360 - val_loss: 6249.5741\n",
      "Epoch 584/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2910.4177 - val_loss: 6249.5302\n",
      "Epoch 585/1000\n",
      "246/246 [==============================] - 0s 934us/step - loss: 2910.3067 - val_loss: 6249.2019\n",
      "Epoch 586/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2910.2034 - val_loss: 6248.6424\n",
      "Epoch 587/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2910.0783 - val_loss: 6248.6650\n",
      "Epoch 588/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.9819 - val_loss: 6247.9276\n",
      "Epoch 589/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 2909.8606 - val_loss: 6247.8259\n",
      "Epoch 590/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.7532 - val_loss: 6247.4346\n",
      "Epoch 591/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.6525 - val_loss: 6246.8739\n",
      "Epoch 592/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2909.5368 - val_loss: 6246.7372\n",
      "Epoch 593/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.4288 - val_loss: 6246.4754\n",
      "Epoch 594/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.3224 - val_loss: 6246.1140\n",
      "Epoch 595/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.2111 - val_loss: 6245.9109\n",
      "Epoch 596/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2909.1052 - val_loss: 6245.5542\n",
      "Epoch 597/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2908.9911 - val_loss: 6245.4677\n",
      "Epoch 598/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2908.8882 - val_loss: 6244.9903\n",
      "Epoch 599/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2908.7661 - val_loss: 6245.0401\n",
      "Epoch 600/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2908.6812 - val_loss: 6244.0291\n",
      "Epoch 601/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 2908.5654 - val_loss: 6243.9355\n",
      "Epoch 602/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2908.4573 - val_loss: 6243.7960\n",
      "Epoch 603/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2908.3484 - val_loss: 6243.5822\n",
      "Epoch 604/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2908.2419 - val_loss: 6243.2849\n",
      "Epoch 605/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2908.1429 - val_loss: 6242.7438\n",
      "Epoch 606/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2908.0279 - val_loss: 6242.6951\n",
      "Epoch 607/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 2907.9239 - val_loss: 6242.3501\n",
      "Epoch 608/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2907.8171 - val_loss: 6242.0200\n",
      "Epoch 609/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2907.7185 - val_loss: 6241.5250\n",
      "Epoch 610/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2907.6096 - val_loss: 6241.3534\n",
      "Epoch 611/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2907.5059 - val_loss: 6241.0896\n",
      "Epoch 612/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2907.3991 - val_loss: 6240.8858\n",
      "Epoch 613/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2907.2992 - val_loss: 6240.4583\n",
      "Epoch 614/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2907.1762 - val_loss: 6240.6356\n",
      "Epoch 615/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2907.0954 - val_loss: 6239.6383\n",
      "Epoch 616/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2906.9846 - val_loss: 6239.4814\n",
      "Epoch 617/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2906.8804 - val_loss: 6239.2937\n",
      "Epoch 618/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 2906.7825 - val_loss: 6238.9028\n",
      "Epoch 619/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2906.6704 - val_loss: 6238.9204\n",
      "Epoch 620/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2906.5754 - val_loss: 6238.4474\n",
      "Epoch 621/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2906.4604 - val_loss: 6238.4521\n",
      "Epoch 622/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 2906.3652 - val_loss: 6237.9114\n",
      "Epoch 623/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2906.2665 - val_loss: 6237.4487\n",
      "Epoch 624/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2906.1665 - val_loss: 6237.1136\n",
      "Epoch 625/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2906.0609 - val_loss: 6237.0164\n",
      "Epoch 626/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2905.9574 - val_loss: 6236.8414\n",
      "Epoch 627/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2905.8625 - val_loss: 6236.3685\n",
      "Epoch 628/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2905.7546 - val_loss: 6236.2602\n",
      "Epoch 629/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2905.6511 - val_loss: 6236.0507\n",
      "Epoch 630/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2905.5604 - val_loss: 6235.4334\n",
      "Epoch 631/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2905.4574 - val_loss: 6235.2183\n",
      "Epoch 632/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2905.3600 - val_loss: 6234.9398\n",
      "Epoch 633/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2905.2523 - val_loss: 6234.9301\n",
      "Epoch 634/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2905.1546 - val_loss: 6234.5561\n",
      "Epoch 635/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2905.0553 - val_loss: 6234.2138\n",
      "Epoch 636/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 2904.9533 - val_loss: 6233.9586\n",
      "Epoch 637/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2904.8635 - val_loss: 6233.3929\n",
      "Epoch 638/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2904.7579 - val_loss: 6233.2708\n",
      "Epoch 639/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2904.6698 - val_loss: 6232.7731\n",
      "Epoch 640/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2904.5636 - val_loss: 6232.8071\n",
      "Epoch 641/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2904.4659 - val_loss: 6232.6222\n",
      "Epoch 642/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 2904.3623 - val_loss: 6232.4665\n",
      "Epoch 643/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 2904.2717 - val_loss: 6231.9303\n",
      "Epoch 644/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2904.1771 - val_loss: 6231.5292\n",
      "Epoch 645/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2904.0686 - val_loss: 6231.5808\n",
      "Epoch 646/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.9829 - val_loss: 6230.9934\n",
      "Epoch 647/1000\n",
      "246/246 [==============================] - 0s 959us/step - loss: 2903.8764 - val_loss: 6230.9353\n",
      "Epoch 648/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.7893 - val_loss: 6230.3988\n",
      "Epoch 649/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.6932 - val_loss: 6230.1545\n",
      "Epoch 650/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2903.5896 - val_loss: 6230.1677\n",
      "Epoch 651/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.5027 - val_loss: 6229.6648\n",
      "Epoch 652/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.3896 - val_loss: 6229.8043\n",
      "Epoch 653/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.3106 - val_loss: 6229.0800\n",
      "Epoch 654/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2903.2111 - val_loss: 6228.8288\n",
      "Epoch 655/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.1169 - val_loss: 6228.6001\n",
      "Epoch 656/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2903.0252 - val_loss: 6228.2979\n",
      "Epoch 657/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 2902.9145 - val_loss: 6228.4619\n",
      "Epoch 658/1000\n",
      "246/246 [==============================] - 0s 973us/step - loss: 2902.8363 - val_loss: 6227.7176\n",
      "Epoch 659/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2902.7419 - val_loss: 6227.3999\n",
      "Epoch 660/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2902.6436 - val_loss: 6227.3282\n",
      "Epoch 661/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2902.5498 - val_loss: 6227.1093\n",
      "Epoch 662/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 2902.4549 - val_loss: 6226.8697\n",
      "Epoch 663/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2902.3602 - val_loss: 6226.6079\n",
      "Epoch 664/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 1ms/step - loss: 2902.2650 - val_loss: 6226.3490\n",
      "Epoch 665/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2902.1809 - val_loss: 6225.7752\n",
      "Epoch 666/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2902.0904 - val_loss: 6225.4784\n",
      "Epoch 667/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.9822 - val_loss: 6225.6967\n",
      "Epoch 668/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.9065 - val_loss: 6225.0086\n",
      "Epoch 669/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 2901.8027 - val_loss: 6225.0367\n",
      "Epoch 670/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 2901.7162 - val_loss: 6224.6569\n",
      "Epoch 671/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.6271 - val_loss: 6224.2912\n",
      "Epoch 672/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 2901.5318 - val_loss: 6224.1604\n",
      "Epoch 673/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.4397 - val_loss: 6223.9830\n",
      "Epoch 674/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.3477 - val_loss: 6223.7055\n",
      "Epoch 675/1000\n",
      "246/246 [==============================] - 0s 942us/step - loss: 2901.2588 - val_loss: 6223.3537\n",
      "Epoch 676/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.1722 - val_loss: 6222.9811\n",
      "Epoch 677/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2901.0730 - val_loss: 6222.9635\n",
      "Epoch 678/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.9847 - val_loss: 6222.6598\n",
      "Epoch 679/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.8983 - val_loss: 6222.2632\n",
      "Epoch 680/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.8110 - val_loss: 6221.9031\n",
      "Epoch 681/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2900.7171 - val_loss: 6221.8022\n",
      "Epoch 682/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.6269 - val_loss: 6221.6499\n",
      "Epoch 683/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.5400 - val_loss: 6221.3007\n",
      "Epoch 684/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.4580 - val_loss: 6220.8752\n",
      "Epoch 685/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2900.3497 - val_loss: 6221.2076\n",
      "Epoch 686/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.2844 - val_loss: 6220.3197\n",
      "Epoch 687/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.1711 - val_loss: 6220.7049\n",
      "Epoch 688/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2900.1050 - val_loss: 6219.8412\n",
      "Epoch 689/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 2900.0028 - val_loss: 6219.9240\n",
      "Epoch 690/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2899.9173 - val_loss: 6219.5993\n",
      "Epoch 691/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2899.8345 - val_loss: 6219.1839\n",
      "Epoch 692/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 2899.7383 - val_loss: 6219.1544\n",
      "Epoch 693/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2899.6613 - val_loss: 6218.6323\n",
      "Epoch 694/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2899.5669 - val_loss: 6218.5628\n",
      "Epoch 695/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2899.4723 - val_loss: 6218.5209\n",
      "Epoch 696/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2899.4055 - val_loss: 6217.6516\n",
      "Epoch 697/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2899.3063 - val_loss: 6217.7270\n",
      "Epoch 698/1000\n",
      "246/246 [==============================] - 0s 942us/step - loss: 2899.2181 - val_loss: 6217.6138\n",
      "Epoch 699/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2899.1440 - val_loss: 6217.0251\n",
      "Epoch 700/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2899.0543 - val_loss: 6216.9545\n",
      "Epoch 701/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2898.9643 - val_loss: 6216.9564\n",
      "Epoch 702/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 2898.8785 - val_loss: 6216.7639\n",
      "Epoch 703/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 2898.7985 - val_loss: 6216.3491\n",
      "Epoch 704/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 2898.6978 - val_loss: 6216.4915\n",
      "Epoch 705/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2898.6244 - val_loss: 6215.8485\n",
      "Epoch 706/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 2898.5444 - val_loss: 6215.3692\n",
      "Epoch 707/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2898.4483 - val_loss: 6215.4675\n",
      "Epoch 708/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2898.3669 - val_loss: 6215.1847\n",
      "Epoch 709/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2898.2902 - val_loss: 6214.6815\n",
      "Epoch 710/1000\n",
      "246/246 [==============================] - 0s 947us/step - loss: 2898.1967 - val_loss: 6214.6941\n",
      "Epoch 711/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2898.1173 - val_loss: 6214.3481\n",
      "Epoch 712/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2898.0361 - val_loss: 6214.0297\n",
      "Epoch 713/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2897.9503 - val_loss: 6213.9016\n",
      "Epoch 714/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2897.8629 - val_loss: 6213.7952\n",
      "Epoch 715/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2897.7669 - val_loss: 6213.8197\n",
      "Epoch 716/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 2897.7071 - val_loss: 6212.7974\n",
      "Epoch 717/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2897.6193 - val_loss: 6212.6416\n",
      "Epoch 718/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2897.5327 - val_loss: 6212.6224\n",
      "Epoch 719/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2897.4480 - val_loss: 6212.4792\n",
      "Epoch 720/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2897.3681 - val_loss: 6212.1749\n",
      "Epoch 721/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2897.2900 - val_loss: 6211.8214\n",
      "Epoch 722/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2897.2071 - val_loss: 6211.6710\n",
      "Epoch 723/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2897.1214 - val_loss: 6211.5961\n",
      "Epoch 724/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 2897.0351 - val_loss: 6211.4633\n",
      "Epoch 725/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2896.9683 - val_loss: 6210.7956\n",
      "Epoch 726/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 2896.8680 - val_loss: 6211.0672\n",
      "Epoch 727/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2896.8043 - val_loss: 6210.3729\n",
      "Epoch 728/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2896.7140 - val_loss: 6210.3716\n",
      "Epoch 729/1000\n",
      "246/246 [==============================] - 0s 951us/step - loss: 2896.6309 - val_loss: 6210.2397\n",
      "Epoch 730/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2896.5626 - val_loss: 6209.6308\n",
      "Epoch 731/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2896.4649 - val_loss: 6209.8413\n",
      "Epoch 732/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2896.3996 - val_loss: 6209.2145\n",
      "Epoch 733/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2896.3114 - val_loss: 6209.1482\n",
      "Epoch 734/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2896.2338 - val_loss: 6208.9004\n",
      "Epoch 735/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2896.1594 - val_loss: 6208.5175\n",
      "Epoch 736/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2896.0718 - val_loss: 6208.5597\n",
      "Epoch 737/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2896.0030 - val_loss: 6208.0848\n",
      "Epoch 738/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.9044 - val_loss: 6208.3654\n",
      "Epoch 739/1000\n",
      "246/246 [==============================] - 0s 949us/step - loss: 2895.8368 - val_loss: 6207.7953\n",
      "Epoch 740/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.7706 - val_loss: 6207.1214\n",
      "Epoch 741/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.6725 - val_loss: 6207.5336\n",
      "Epoch 742/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2895.6032 - val_loss: 6207.0775\n",
      "Epoch 743/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2895.5197 - val_loss: 6206.9532\n",
      "Epoch 744/1000\n",
      "246/246 [==============================] - 0s 930us/step - loss: 2895.4504 - val_loss: 6206.4652\n",
      "Epoch 745/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2895.3711 - val_loss: 6206.3242\n",
      "Epoch 746/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.2779 - val_loss: 6206.5581\n",
      "Epoch 747/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.2150 - val_loss: 6205.8896\n",
      "Epoch 748/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.1378 - val_loss: 6205.5894\n",
      "Epoch 749/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2895.0553 - val_loss: 6205.5685\n",
      "Epoch 750/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.9773 - val_loss: 6205.3720\n",
      "Epoch 751/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.9004 - val_loss: 6205.1244\n",
      "Epoch 752/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.8316 - val_loss: 6204.6456\n",
      "Epoch 753/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.7470 - val_loss: 6204.6830\n",
      "Epoch 754/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 2894.6684 - val_loss: 6204.5230\n",
      "Epoch 755/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2894.5976 - val_loss: 6204.0979\n",
      "Epoch 756/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.5087 - val_loss: 6204.1716\n",
      "Epoch 757/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.4528 - val_loss: 6203.3353\n",
      "Epoch 758/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2894.3712 - val_loss: 6203.3104\n",
      "Epoch 759/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.2860 - val_loss: 6203.4582\n",
      "Epoch 760/1000\n",
      "246/246 [==============================] - 0s 940us/step - loss: 2894.2199 - val_loss: 6202.9999\n",
      "Epoch 761/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2894.1385 - val_loss: 6202.8931\n",
      "Epoch 762/1000\n",
      "246/246 [==============================] - 0s 948us/step - loss: 2894.0595 - val_loss: 6202.7550\n",
      "Epoch 763/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2893.9929 - val_loss: 6202.2072\n",
      "Epoch 764/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2893.9196 - val_loss: 6201.9603\n",
      "Epoch 765/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2893.8422 - val_loss: 6201.8902\n",
      "Epoch 766/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2893.7748 - val_loss: 6201.5952\n",
      "Epoch 767/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2893.6878 - val_loss: 6201.8364\n",
      "Epoch 768/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2893.6222 - val_loss: 6201.3782\n",
      "Epoch 769/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2893.5374 - val_loss: 6201.3810\n",
      "Epoch 770/1000\n",
      "246/246 [==============================] - 0s 957us/step - loss: 2893.4716 - val_loss: 6200.8735\n",
      "Epoch 771/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 2893.3858 - val_loss: 6200.8795\n",
      "Epoch 772/1000\n",
      "246/246 [==============================] - 0s 926us/step - loss: 2893.3313 - val_loss: 6200.0817\n",
      "Epoch 773/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2893.2525 - val_loss: 6200.0153\n",
      "Epoch 774/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 2893.1721 - val_loss: 6200.1061\n",
      "Epoch 775/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2893.0974 - val_loss: 6199.9408\n",
      "Epoch 776/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2893.0385 - val_loss: 6199.3083\n",
      "Epoch 777/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2892.9585 - val_loss: 6199.3477\n",
      "Epoch 778/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 2892.8923 - val_loss: 6199.0820\n",
      "Epoch 779/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2892.7945 - val_loss: 6199.5372\n",
      "Epoch 780/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2892.7456 - val_loss: 6198.6274\n",
      "Epoch 781/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2892.6710 - val_loss: 6198.3456\n",
      "Epoch 782/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 2892.5946 - val_loss: 6198.3137\n",
      "Epoch 783/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2892.5238 - val_loss: 6198.1120\n",
      "Epoch 784/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2892.4514 - val_loss: 6197.9581\n",
      "Epoch 785/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 2892.3871 - val_loss: 6197.5694\n",
      "Epoch 786/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 2892.3090 - val_loss: 6197.5802\n",
      "Epoch 787/1000\n",
      "246/246 [==============================] - 0s 964us/step - loss: 2892.2223 - val_loss: 6197.7870\n",
      "Epoch 788/1000\n",
      "246/246 [==============================] - 0s 953us/step - loss: 2892.1790 - val_loss: 6196.6988\n",
      "Epoch 789/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2892.0919 - val_loss: 6196.8817\n",
      "Epoch 790/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2892.0327 - val_loss: 6196.4573\n",
      "Epoch 791/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.9473 - val_loss: 6196.6901\n",
      "Epoch 792/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.8868 - val_loss: 6196.2354\n",
      "Epoch 793/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2891.8113 - val_loss: 6196.1111\n",
      "Epoch 794/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.7398 - val_loss: 6195.9226\n",
      "Epoch 795/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.6708 - val_loss: 6195.6166\n",
      "Epoch 796/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 2891.6026 - val_loss: 6195.3215\n",
      "Epoch 797/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 2891.5408 - val_loss: 6194.8895\n",
      "Epoch 798/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.4666 - val_loss: 6194.9509\n",
      "Epoch 799/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 2891.3874 - val_loss: 6195.0989\n",
      "Epoch 800/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.3227 - val_loss: 6194.7140\n",
      "Epoch 801/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.2522 - val_loss: 6194.4230\n",
      "Epoch 802/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2891.1907 - val_loss: 6193.9670\n",
      "Epoch 803/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.1170 - val_loss: 6193.9099\n",
      "Epoch 804/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2891.0567 - val_loss: 6193.5528\n",
      "Epoch 805/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2890.9769 - val_loss: 6193.7536\n",
      "Epoch 806/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.9194 - val_loss: 6193.3110\n",
      "Epoch 807/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.8438 - val_loss: 6193.3701\n",
      "Epoch 808/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.7761 - val_loss: 6193.1899\n",
      "Epoch 809/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2890.7055 - val_loss: 6193.0011\n",
      "Epoch 810/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2890.6389 - val_loss: 6192.7189\n",
      "Epoch 811/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2890.5697 - val_loss: 6192.4430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 812/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.5016 - val_loss: 6192.2056\n",
      "Epoch 813/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.4449 - val_loss: 6191.6819\n",
      "Epoch 814/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.3687 - val_loss: 6191.8058\n",
      "Epoch 815/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 2890.2997 - val_loss: 6191.7007\n",
      "Epoch 816/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.2331 - val_loss: 6191.4497\n",
      "Epoch 817/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2890.1608 - val_loss: 6191.3004\n",
      "Epoch 818/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2890.1138 - val_loss: 6190.5193\n",
      "Epoch 819/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2890.0261 - val_loss: 6190.9385\n",
      "Epoch 820/1000\n",
      "246/246 [==============================] - 0s 962us/step - loss: 2889.9764 - val_loss: 6190.3402\n",
      "Epoch 821/1000\n",
      "246/246 [==============================] - 0s 973us/step - loss: 2889.8969 - val_loss: 6190.5127\n",
      "Epoch 822/1000\n",
      "246/246 [==============================] - 0s 947us/step - loss: 2889.8480 - val_loss: 6189.9078\n",
      "Epoch 823/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2889.7616 - val_loss: 6190.3219\n",
      "Epoch 824/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2889.6926 - val_loss: 6190.2023\n",
      "Epoch 825/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2889.6512 - val_loss: 6189.1731\n",
      "Epoch 826/1000\n",
      "246/246 [==============================] - 0s 950us/step - loss: 2889.5764 - val_loss: 6189.2616\n",
      "Epoch 827/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2889.5011 - val_loss: 6189.4663\n",
      "Epoch 828/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2889.4423 - val_loss: 6189.0719\n",
      "Epoch 829/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2889.3865 - val_loss: 6188.5975\n",
      "Epoch 830/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2889.3111 - val_loss: 6188.7972\n",
      "Epoch 831/1000\n",
      "246/246 [==============================] - 0s 949us/step - loss: 2889.2477 - val_loss: 6188.6283\n",
      "Epoch 832/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2889.1792 - val_loss: 6188.4771\n",
      "Epoch 833/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2889.1092 - val_loss: 6188.3166\n",
      "Epoch 834/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2889.0598 - val_loss: 6187.6190\n",
      "Epoch 835/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 2888.9966 - val_loss: 6187.4166\n",
      "Epoch 836/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2888.9231 - val_loss: 6187.6556\n",
      "Epoch 837/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2888.8603 - val_loss: 6187.4880\n",
      "Epoch 838/1000\n",
      "246/246 [==============================] - 0s 919us/step - loss: 2888.7987 - val_loss: 6187.1807\n",
      "Epoch 839/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2888.7259 - val_loss: 6187.1851\n",
      "Epoch 840/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 2888.6743 - val_loss: 6186.6384\n",
      "Epoch 841/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2888.5996 - val_loss: 6186.6864\n",
      "Epoch 842/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2888.5394 - val_loss: 6186.3916\n",
      "Epoch 843/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2888.4719 - val_loss: 6186.2046\n",
      "Epoch 844/1000\n",
      "246/246 [==============================] - 0s 932us/step - loss: 2888.4273 - val_loss: 6185.4790\n",
      "Epoch 845/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 2888.3465 - val_loss: 6185.8594\n",
      "Epoch 846/1000\n",
      "246/246 [==============================] - 0s 925us/step - loss: 2888.2970 - val_loss: 6185.4001\n",
      "Epoch 847/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2888.2241 - val_loss: 6185.5382\n",
      "Epoch 848/1000\n",
      "246/246 [==============================] - 0s 956us/step - loss: 2888.1629 - val_loss: 6185.3839\n",
      "Epoch 849/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2888.1029 - val_loss: 6185.0436\n",
      "Epoch 850/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2888.0383 - val_loss: 6184.9432\n",
      "Epoch 851/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.9822 - val_loss: 6184.5963\n",
      "Epoch 852/1000\n",
      "246/246 [==============================] - 0s 934us/step - loss: 2887.9172 - val_loss: 6184.5311\n",
      "Epoch 853/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2887.8432 - val_loss: 6184.6755\n",
      "Epoch 854/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 2887.8031 - val_loss: 6183.8763\n",
      "Epoch 855/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2887.7110 - val_loss: 6184.4471\n",
      "Epoch 856/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2887.6743 - val_loss: 6183.5158\n",
      "Epoch 857/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.6106 - val_loss: 6183.3035\n",
      "Epoch 858/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.5509 - val_loss: 6183.2405\n",
      "Epoch 859/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.4688 - val_loss: 6183.6781\n",
      "Epoch 860/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2887.4263 - val_loss: 6182.9435\n",
      "Epoch 861/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.3642 - val_loss: 6182.6949\n",
      "Epoch 862/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.3115 - val_loss: 6182.3919\n",
      "Epoch 863/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.2246 - val_loss: 6183.0241\n",
      "Epoch 864/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.1865 - val_loss: 6182.1884\n",
      "Epoch 865/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2887.1167 - val_loss: 6182.1648\n",
      "Epoch 866/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2887.0628 - val_loss: 6181.8370\n",
      "Epoch 867/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.9896 - val_loss: 6181.9769\n",
      "Epoch 868/1000\n",
      "246/246 [==============================] - 0s 948us/step - loss: 2886.9451 - val_loss: 6181.3763\n",
      "Epoch 869/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.8712 - val_loss: 6181.5321\n",
      "Epoch 870/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 2886.8121 - val_loss: 6181.2658\n",
      "Epoch 871/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.7689 - val_loss: 6180.5885\n",
      "Epoch 872/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.6935 - val_loss: 6180.8953\n",
      "Epoch 873/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.6460 - val_loss: 6180.4457\n",
      "Epoch 874/1000\n",
      "246/246 [==============================] - 0s 958us/step - loss: 2886.5856 - val_loss: 6180.3959\n",
      "Epoch 875/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.5137 - val_loss: 6180.6763\n",
      "Epoch 876/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 2886.4624 - val_loss: 6180.1864\n",
      "Epoch 877/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 2886.3992 - val_loss: 6180.0523\n",
      "Epoch 878/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2886.3488 - val_loss: 6179.6053\n",
      "Epoch 879/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.2816 - val_loss: 6179.6514\n",
      "Epoch 880/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2886.2190 - val_loss: 6179.5471\n",
      "Epoch 881/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2886.1759 - val_loss: 6178.8864\n",
      "Epoch 882/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2886.1047 - val_loss: 6179.0385\n",
      "Epoch 883/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 2886.0503 - val_loss: 6178.8174\n",
      "Epoch 884/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 2885.9982 - val_loss: 6178.4645\n",
      "Epoch 885/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 978us/step - loss: 2885.9320 - val_loss: 6178.5203\n",
      "Epoch 886/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2885.8786 - val_loss: 6178.2853\n",
      "Epoch 887/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.8200 - val_loss: 6178.1336\n",
      "Epoch 888/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2885.7711 - val_loss: 6177.7684\n",
      "Epoch 889/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.6969 - val_loss: 6178.1147\n",
      "Epoch 890/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.6489 - val_loss: 6177.7039\n",
      "Epoch 891/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2885.5888 - val_loss: 6177.5119\n",
      "Epoch 892/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2885.5398 - val_loss: 6177.1211\n",
      "Epoch 893/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.4687 - val_loss: 6177.3512\n",
      "Epoch 894/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.4184 - val_loss: 6176.9771\n",
      "Epoch 895/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.3698 - val_loss: 6176.5457\n",
      "Epoch 896/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2885.3020 - val_loss: 6176.7328\n",
      "Epoch 897/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 2885.2519 - val_loss: 6176.4204\n",
      "Epoch 898/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.1886 - val_loss: 6176.4041\n",
      "Epoch 899/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2885.1354 - val_loss: 6176.1425\n",
      "Epoch 900/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.0875 - val_loss: 6175.7099\n",
      "Epoch 901/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2885.0171 - val_loss: 6175.9585\n",
      "Epoch 902/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 2884.9652 - val_loss: 6175.6631\n",
      "Epoch 903/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2884.9101 - val_loss: 6175.3707\n",
      "Epoch 904/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.8678 - val_loss: 6174.8326\n",
      "Epoch 905/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.7932 - val_loss: 6175.2886\n",
      "Epoch 906/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 2884.7523 - val_loss: 6174.7885\n",
      "Epoch 907/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.6866 - val_loss: 6174.8912\n",
      "Epoch 908/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.6289 - val_loss: 6174.8036\n",
      "Epoch 909/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.5867 - val_loss: 6174.1674\n",
      "Epoch 910/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 2884.5311 - val_loss: 6174.0909\n",
      "Epoch 911/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.4528 - val_loss: 6174.6014\n",
      "Epoch 912/1000\n",
      "246/246 [==============================] - 0s 940us/step - loss: 2884.4243 - val_loss: 6173.6396\n",
      "Epoch 913/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.3511 - val_loss: 6173.8740\n",
      "Epoch 914/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.3098 - val_loss: 6173.3875\n",
      "Epoch 915/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.2547 - val_loss: 6173.2579\n",
      "Epoch 916/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.1981 - val_loss: 6173.2772\n",
      "Epoch 917/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.1370 - val_loss: 6173.3463\n",
      "Epoch 918/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.0966 - val_loss: 6172.7758\n",
      "Epoch 919/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2884.0259 - val_loss: 6173.0469\n",
      "Epoch 920/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 2883.9803 - val_loss: 6172.6317\n",
      "Epoch 921/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2883.9289 - val_loss: 6172.3141\n",
      "Epoch 922/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2883.8795 - val_loss: 6172.0851\n",
      "Epoch 923/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 2883.8065 - val_loss: 6172.4986\n",
      "Epoch 924/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2883.7647 - val_loss: 6171.9233\n",
      "Epoch 925/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2883.7102 - val_loss: 6171.6818\n",
      "Epoch 926/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2883.6629 - val_loss: 6171.3521\n",
      "Epoch 927/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 2883.6128 - val_loss: 6171.2333\n",
      "Epoch 928/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 2883.5441 - val_loss: 6171.5999\n",
      "Epoch 929/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2883.4934 - val_loss: 6171.3177\n",
      "Epoch 930/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2883.4527 - val_loss: 6170.7272\n",
      "Epoch 931/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2883.3908 - val_loss: 6170.7945\n",
      "Epoch 932/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2883.3380 - val_loss: 6170.6526\n",
      "Epoch 933/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2883.2924 - val_loss: 6170.3035\n",
      "Epoch 934/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 2883.2401 - val_loss: 6170.1991\n",
      "Epoch 935/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2883.1824 - val_loss: 6170.2641\n",
      "Epoch 936/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2883.1310 - val_loss: 6170.0809\n",
      "Epoch 937/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2883.0794 - val_loss: 6169.9186\n",
      "Epoch 938/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2883.0350 - val_loss: 6169.5704\n",
      "Epoch 939/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 2882.9715 - val_loss: 6169.7713\n",
      "Epoch 940/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2882.9253 - val_loss: 6169.4410\n",
      "Epoch 941/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2882.8712 - val_loss: 6169.3214\n",
      "Epoch 942/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2882.8163 - val_loss: 6169.1636\n",
      "Epoch 943/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2882.7704 - val_loss: 6168.8031\n",
      "Epoch 944/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2882.7209 - val_loss: 6168.5858\n",
      "Epoch 945/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 2882.6739 - val_loss: 6168.4217\n",
      "Epoch 946/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2882.6145 - val_loss: 6168.6320\n",
      "Epoch 947/1000\n",
      "246/246 [==============================] - 0s 947us/step - loss: 2882.5625 - val_loss: 6168.5123\n",
      "Epoch 948/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 2882.5114 - val_loss: 6168.2543\n",
      "Epoch 949/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2882.4612 - val_loss: 6168.0168\n",
      "Epoch 950/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 2882.4149 - val_loss: 6167.6935\n",
      "Epoch 951/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2882.3670 - val_loss: 6167.5046\n",
      "Epoch 952/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2882.3066 - val_loss: 6167.6886\n",
      "Epoch 953/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2882.2549 - val_loss: 6167.5639\n",
      "Epoch 954/1000\n",
      "246/246 [==============================] - 0s 980us/step - loss: 2882.2218 - val_loss: 6166.8610\n",
      "Epoch 955/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 2882.1579 - val_loss: 6167.1734\n",
      "Epoch 956/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2882.1038 - val_loss: 6167.1391\n",
      "Epoch 957/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2882.0623 - val_loss: 6166.6795\n",
      "Epoch 958/1000\n",
      "246/246 [==============================] - 0s 953us/step - loss: 2882.0173 - val_loss: 6166.3956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 959/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.9590 - val_loss: 6166.5748\n",
      "Epoch 960/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 2881.9064 - val_loss: 6166.5037\n",
      "Epoch 961/1000\n",
      "246/246 [==============================] - 0s 934us/step - loss: 2881.8572 - val_loss: 6166.2529\n",
      "Epoch 962/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 2881.8100 - val_loss: 6165.9443\n",
      "Epoch 963/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2881.7695 - val_loss: 6165.5139\n",
      "Epoch 964/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.7041 - val_loss: 6165.8243\n",
      "Epoch 965/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.6705 - val_loss: 6165.2784\n",
      "Epoch 966/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.6177 - val_loss: 6165.3019\n",
      "Epoch 967/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.5632 - val_loss: 6165.3774\n",
      "Epoch 968/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.5173 - val_loss: 6165.1260\n",
      "Epoch 969/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 2881.4630 - val_loss: 6165.1017\n",
      "Epoch 970/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.4264 - val_loss: 6164.5672\n",
      "Epoch 971/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.3731 - val_loss: 6164.6108\n",
      "Epoch 972/1000\n",
      "246/246 [==============================] - 0s 959us/step - loss: 2881.3140 - val_loss: 6164.7894\n",
      "Epoch 973/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 2881.2768 - val_loss: 6164.2715\n",
      "Epoch 974/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 2881.2274 - val_loss: 6164.1010\n",
      "Epoch 975/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.1802 - val_loss: 6163.9825\n",
      "Epoch 976/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2881.1232 - val_loss: 6164.0833\n",
      "Epoch 977/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2881.0716 - val_loss: 6163.9459\n",
      "Epoch 978/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 2881.0449 - val_loss: 6163.1409\n",
      "Epoch 979/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 2880.9839 - val_loss: 6163.4183\n",
      "Epoch 980/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2880.9331 - val_loss: 6163.4257\n",
      "Epoch 981/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 2880.8971 - val_loss: 6162.9762\n",
      "Epoch 982/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.8384 - val_loss: 6163.1587\n",
      "Epoch 983/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.8022 - val_loss: 6162.7513\n",
      "Epoch 984/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.7445 - val_loss: 6162.9129\n",
      "Epoch 985/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 2880.6936 - val_loss: 6162.8536\n",
      "Epoch 986/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2880.6651 - val_loss: 6162.1139\n",
      "Epoch 987/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.6026 - val_loss: 6162.4318\n",
      "Epoch 988/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.5553 - val_loss: 6162.2980\n",
      "Epoch 989/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 2880.5131 - val_loss: 6161.9702\n",
      "Epoch 990/1000\n",
      "246/246 [==============================] - 0s 950us/step - loss: 2880.4681 - val_loss: 6161.7525\n",
      "Epoch 991/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.4217 - val_loss: 6161.6427\n",
      "Epoch 992/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.3680 - val_loss: 6161.7055\n",
      "Epoch 993/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.3263 - val_loss: 6161.4316\n",
      "Epoch 994/1000\n",
      "246/246 [==============================] - 0s 957us/step - loss: 2880.2849 - val_loss: 6161.1470\n",
      "Epoch 995/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.2278 - val_loss: 6161.3333\n",
      "Epoch 996/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2880.1940 - val_loss: 6160.8603\n",
      "Epoch 997/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 2880.1417 - val_loss: 6160.9289\n",
      "Epoch 998/1000\n",
      "246/246 [==============================] - 0s 932us/step - loss: 2880.0861 - val_loss: 6161.0427\n",
      "Epoch 999/1000\n",
      "246/246 [==============================] - 0s 955us/step - loss: 2880.0562 - val_loss: 6160.3912\n",
      "Epoch 1000/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2879.9960 - val_loss: 6160.5947\n",
      "Train on 246 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "246/246 [==============================] - 54s 220ms/step - loss: 26733.1138 - val_loss: 177153.2185\n",
      "Epoch 2/1000\n",
      "246/246 [==============================] - 0s 883us/step - loss: 26718.2624 - val_loss: 177076.3006\n",
      "Epoch 3/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26691.1053 - val_loss: 176925.7142\n",
      "Epoch 4/1000\n",
      "246/246 [==============================] - 0s 957us/step - loss: 26647.0723 - val_loss: 176687.8021\n",
      "Epoch 5/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 26578.1988 - val_loss: 176316.4608\n",
      "Epoch 6/1000\n",
      "246/246 [==============================] - 0s 897us/step - loss: 26471.0342 - val_loss: 175739.9002\n",
      "Epoch 7/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 26306.8168 - val_loss: 174871.6957\n",
      "Epoch 8/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 26064.6638 - val_loss: 173616.1280\n",
      "Epoch 9/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 25721.8983 - val_loss: 171867.6025\n",
      "Epoch 10/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 25247.3736 - val_loss: 169461.6346\n",
      "Epoch 11/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 24576.4388 - val_loss: 165882.4496\n",
      "Epoch 12/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 23640.0708 - val_loss: 161158.2051\n",
      "Epoch 13/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 22487.9359 - val_loss: 155332.0354\n",
      "Epoch 14/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 21163.2150 - val_loss: 148503.9185\n",
      "Epoch 15/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 19765.5971 - val_loss: 141058.3109\n",
      "Epoch 16/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 18398.9464 - val_loss: 133360.5003\n",
      "Epoch 17/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 17156.2586 - val_loss: 125844.9160\n",
      "Epoch 18/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 16104.6230 - val_loss: 118872.9424\n",
      "Epoch 19/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 15264.5840 - val_loss: 112661.0640\n",
      "Epoch 20/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 14620.4692 - val_loss: 107296.5713\n",
      "Epoch 21/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 14134.2252 - val_loss: 102731.9291\n",
      "Epoch 22/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 13764.0892 - val_loss: 98876.7225\n",
      "Epoch 23/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 13473.2583 - val_loss: 95595.0913\n",
      "Epoch 24/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 13235.0817 - val_loss: 92753.9618\n",
      "Epoch 25/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 13027.5928 - val_loss: 90254.8061\n",
      "Epoch 26/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 12840.0452 - val_loss: 88034.8725\n",
      "Epoch 27/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 12665.0508 - val_loss: 86040.8299\n",
      "Epoch 28/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 12498.6101 - val_loss: 84220.3135\n",
      "Epoch 29/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 12337.9556 - val_loss: 82536.3534\n",
      "Epoch 30/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 12181.2186 - val_loss: 80959.1597\n",
      "Epoch 31/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 12027.0205 - val_loss: 79461.5562\n",
      "Epoch 32/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 1ms/step - loss: 11874.5337 - val_loss: 78021.9311\n",
      "Epoch 33/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 11723.0019 - val_loss: 76631.4304\n",
      "Epoch 34/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11571.9726 - val_loss: 75277.6548\n",
      "Epoch 35/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11421.1052 - val_loss: 73952.4143\n",
      "Epoch 36/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11270.1423 - val_loss: 72647.9715\n",
      "Epoch 37/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 11118.8967 - val_loss: 71358.2041\n",
      "Epoch 38/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 10967.2330 - val_loss: 70079.4860\n",
      "Epoch 39/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10814.9504 - val_loss: 68810.3840\n",
      "Epoch 40/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10661.9500 - val_loss: 67547.7278\n",
      "Epoch 41/1000\n",
      "246/246 [==============================] - 0s 940us/step - loss: 10508.1748 - val_loss: 66288.7035\n",
      "Epoch 42/1000\n",
      "246/246 [==============================] - 0s 953us/step - loss: 10353.5413 - val_loss: 65030.8745\n",
      "Epoch 43/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 10197.9999 - val_loss: 63772.9110\n",
      "Epoch 44/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 10041.5274 - val_loss: 62513.5662\n",
      "Epoch 45/1000\n",
      "246/246 [==============================] - 0s 973us/step - loss: 9884.0775 - val_loss: 61253.4354\n",
      "Epoch 46/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 9725.6075 - val_loss: 59991.6122\n",
      "Epoch 47/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9566.1460 - val_loss: 58727.1246\n",
      "Epoch 48/1000\n",
      "246/246 [==============================] - 0s 951us/step - loss: 9405.7021 - val_loss: 57459.5992\n",
      "Epoch 49/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 9244.3119 - val_loss: 56189.2188\n",
      "Epoch 50/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 9085.2296 - val_loss: 54904.7603\n",
      "Epoch 51/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8925.8268 - val_loss: 53621.3753\n",
      "Epoch 52/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8766.2876 - val_loss: 52340.0441\n",
      "Epoch 53/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8606.6233 - val_loss: 51060.5220\n",
      "Epoch 54/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8446.7988 - val_loss: 49785.0871\n",
      "Epoch 55/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 8286.8532 - val_loss: 48513.8044\n",
      "Epoch 56/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 8126.8575 - val_loss: 47247.7910\n",
      "Epoch 57/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7966.9254 - val_loss: 45988.3996\n",
      "Epoch 58/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 7807.1798 - val_loss: 44735.6247\n",
      "Epoch 59/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 7647.7659 - val_loss: 43490.0417\n",
      "Epoch 60/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 7488.8284 - val_loss: 42251.1702\n",
      "Epoch 61/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 7330.5331 - val_loss: 41019.6408\n",
      "Epoch 62/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 7173.0856 - val_loss: 39796.2615\n",
      "Epoch 63/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 7016.6552 - val_loss: 38583.0946\n",
      "Epoch 64/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 6861.4642 - val_loss: 37380.5603\n",
      "Epoch 65/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6707.6900 - val_loss: 36189.7507\n",
      "Epoch 66/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6555.5967 - val_loss: 35010.2959\n",
      "Epoch 67/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 6405.4498 - val_loss: 33844.8924\n",
      "Epoch 68/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 6257.3826 - val_loss: 32695.9165\n",
      "Epoch 69/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 6111.7158 - val_loss: 31564.5767\n",
      "Epoch 70/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 5968.6794 - val_loss: 30451.0372\n",
      "Epoch 71/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5828.5367 - val_loss: 29357.3729\n",
      "Epoch 72/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 5691.5214 - val_loss: 28284.8977\n",
      "Epoch 73/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 5557.9214 - val_loss: 27233.9693\n",
      "Epoch 74/1000\n",
      "246/246 [==============================] - 0s 956us/step - loss: 5427.9598 - val_loss: 26206.6686\n",
      "Epoch 75/1000\n",
      "246/246 [==============================] - 0s 956us/step - loss: 5301.8561 - val_loss: 25204.5314\n",
      "Epoch 76/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5180.4410 - val_loss: 24226.1516\n",
      "Epoch 77/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 5065.4611 - val_loss: 23273.2037\n",
      "Epoch 78/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4955.2283 - val_loss: 22354.3801\n",
      "Epoch 79/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 4849.6779 - val_loss: 21469.1980\n",
      "Epoch 80/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4748.9903 - val_loss: 20618.2002\n",
      "Epoch 81/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 4654.5413 - val_loss: 19795.7700\n",
      "Epoch 82/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4565.8310 - val_loss: 19010.4954\n",
      "Epoch 83/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 4482.0805 - val_loss: 18263.0160\n",
      "Epoch 84/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4403.2272 - val_loss: 17551.6378\n",
      "Epoch 85/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 4329.2094 - val_loss: 16876.6129\n",
      "Epoch 86/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4259.9121 - val_loss: 16236.6046\n",
      "Epoch 87/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 4195.1836 - val_loss: 15631.5572\n",
      "Epoch 88/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 4134.8828 - val_loss: 15060.0030\n",
      "Epoch 89/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4078.8640 - val_loss: 14521.6799\n",
      "Epoch 90/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 4026.9679 - val_loss: 14014.9147\n",
      "Epoch 91/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3979.0683 - val_loss: 13538.5193\n",
      "Epoch 92/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3935.0124 - val_loss: 13091.2363\n",
      "Epoch 93/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3894.6295 - val_loss: 12671.6353\n",
      "Epoch 94/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3857.7293 - val_loss: 12278.8816\n",
      "Epoch 95/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 3824.1277 - val_loss: 11911.8746\n",
      "Epoch 96/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3793.6285 - val_loss: 11569.5160\n",
      "Epoch 97/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3766.0228 - val_loss: 11250.9007\n",
      "Epoch 98/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3741.1165 - val_loss: 10954.4507\n",
      "Epoch 99/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3718.7041 - val_loss: 10679.2851\n",
      "Epoch 100/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 3698.5866 - val_loss: 10423.9967\n",
      "Epoch 101/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3680.5707 - val_loss: 10187.6828\n",
      "Epoch 102/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3664.4667 - val_loss: 9969.3348\n",
      "Epoch 103/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3650.0984 - val_loss: 9767.8448\n",
      "Epoch 104/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 3637.3148 - val_loss: 9582.3250\n",
      "Epoch 105/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3625.7943 - val_loss: 9411.6004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3615.6524 - val_loss: 9253.3138\n",
      "Epoch 107/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3607.3385 - val_loss: 9118.4367\n",
      "Epoch 108/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 3598.1630 - val_loss: 8963.9611\n",
      "Epoch 109/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3590.0854 - val_loss: 8841.4385\n",
      "Epoch 110/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 3583.6779 - val_loss: 8729.2738\n",
      "Epoch 111/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3577.9765 - val_loss: 8626.5102\n",
      "Epoch 112/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 3572.7975 - val_loss: 8533.5130\n",
      "Epoch 113/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3568.0610 - val_loss: 8449.2522\n",
      "Epoch 114/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3563.7917 - val_loss: 8372.4962\n",
      "Epoch 115/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3559.8960 - val_loss: 8302.6776\n",
      "Epoch 116/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3556.2599 - val_loss: 8239.8374\n",
      "Epoch 117/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 3552.9358 - val_loss: 8181.7369\n",
      "Epoch 118/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3549.7639 - val_loss: 8129.4875\n",
      "Epoch 119/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3546.7763 - val_loss: 8082.5619\n",
      "Epoch 120/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3543.9407 - val_loss: 8040.4236\n",
      "Epoch 121/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 3541.2450 - val_loss: 8002.8248\n",
      "Epoch 122/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 3538.6802 - val_loss: 7968.8253\n",
      "Epoch 123/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3536.1644 - val_loss: 7938.2108\n",
      "Epoch 124/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 3533.8307 - val_loss: 7910.0465\n",
      "Epoch 125/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3531.5173 - val_loss: 7885.2266\n",
      "Epoch 126/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3529.2795 - val_loss: 7863.0781\n",
      "Epoch 127/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3527.1026 - val_loss: 7843.1982\n",
      "Epoch 128/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 3524.8897 - val_loss: 7825.5016\n",
      "Epoch 129/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3522.8754 - val_loss: 7808.8512\n",
      "Epoch 130/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 3520.7458 - val_loss: 7794.4423\n",
      "Epoch 131/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3518.7878 - val_loss: 7780.3936\n",
      "Epoch 132/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3516.6655 - val_loss: 7768.8970\n",
      "Epoch 133/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3514.8560 - val_loss: 7756.7441\n",
      "Epoch 134/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3512.7915 - val_loss: 7747.0902\n",
      "Epoch 135/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3510.9390 - val_loss: 7737.8836\n",
      "Epoch 136/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 3508.9781 - val_loss: 7730.3901\n",
      "Epoch 137/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3507.0964 - val_loss: 7722.6917\n",
      "Epoch 138/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 3505.3094 - val_loss: 7714.7786\n",
      "Epoch 139/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 3503.3865 - val_loss: 7708.5066\n",
      "Epoch 140/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3501.5351 - val_loss: 7702.3791\n",
      "Epoch 141/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3499.7392 - val_loss: 7696.3471\n",
      "Epoch 142/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3497.9282 - val_loss: 7690.9286\n",
      "Epoch 143/1000\n",
      "246/246 [==============================] - 0s 945us/step - loss: 3496.0903 - val_loss: 7686.0301\n",
      "Epoch 144/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3494.3817 - val_loss: 7680.5891\n",
      "Epoch 145/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3492.5275 - val_loss: 7676.7632\n",
      "Epoch 146/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 3490.7516 - val_loss: 7672.5351\n",
      "Epoch 147/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3489.0230 - val_loss: 7667.8647\n",
      "Epoch 148/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 3487.2240 - val_loss: 7663.7623\n",
      "Epoch 149/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3485.5032 - val_loss: 7659.4980\n",
      "Epoch 150/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 3483.7143 - val_loss: 7655.8407\n",
      "Epoch 151/1000\n",
      "246/246 [==============================] - 0s 952us/step - loss: 3482.0033 - val_loss: 7651.8795\n",
      "Epoch 152/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3480.2248 - val_loss: 7648.4715\n",
      "Epoch 153/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 3478.4777 - val_loss: 7644.6872\n",
      "Epoch 154/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3476.8298 - val_loss: 7640.3860\n",
      "Epoch 155/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3475.0081 - val_loss: 7637.7939\n",
      "Epoch 156/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3473.2708 - val_loss: 7634.7445\n",
      "Epoch 157/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3471.5829 - val_loss: 7631.3045\n",
      "Epoch 158/1000\n",
      "246/246 [==============================] - 0s 941us/step - loss: 3469.8201 - val_loss: 7628.4380\n",
      "Epoch 159/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3468.0888 - val_loss: 7625.3106\n",
      "Epoch 160/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 3466.5009 - val_loss: 7621.2922\n",
      "Epoch 161/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 3464.6698 - val_loss: 7619.3521\n",
      "Epoch 162/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3462.9549 - val_loss: 7616.6652\n",
      "Epoch 163/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3461.2461 - val_loss: 7613.3335\n",
      "Epoch 164/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3459.5315 - val_loss: 7609.7011\n",
      "Epoch 165/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3457.9173 - val_loss: 7605.8281\n",
      "Epoch 166/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3456.1263 - val_loss: 7603.7444\n",
      "Epoch 167/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3454.4225 - val_loss: 7600.9638\n",
      "Epoch 168/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 3452.7213 - val_loss: 7597.8202\n",
      "Epoch 169/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3451.0706 - val_loss: 7594.2863\n",
      "Epoch 170/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 3449.3350 - val_loss: 7591.3622\n",
      "Epoch 171/1000\n",
      "246/246 [==============================] - 0s 950us/step - loss: 3447.6893 - val_loss: 7588.0176\n",
      "Epoch 172/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3445.9593 - val_loss: 7585.3155\n",
      "Epoch 173/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3444.3183 - val_loss: 7581.9653\n",
      "Epoch 174/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3442.5963 - val_loss: 7579.1716\n",
      "Epoch 175/1000\n",
      "246/246 [==============================] - 0s 939us/step - loss: 3440.9074 - val_loss: 7576.0901\n",
      "Epoch 176/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3439.3297 - val_loss: 7572.2405\n",
      "Epoch 177/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 3437.5665 - val_loss: 7570.0554\n",
      "Epoch 178/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3435.8925 - val_loss: 7567.1142\n",
      "Epoch 179/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3434.2232 - val_loss: 7563.7018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3432.5968 - val_loss: 7560.1805\n",
      "Epoch 181/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 3430.8891 - val_loss: 7557.3739\n",
      "Epoch 182/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 3429.2262 - val_loss: 7554.1601\n",
      "Epoch 183/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3427.6153 - val_loss: 7550.6093\n",
      "Epoch 184/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 3425.9114 - val_loss: 7547.8650\n",
      "Epoch 185/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3424.2564 - val_loss: 7544.7016\n",
      "Epoch 186/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3422.7068 - val_loss: 7541.2297\n",
      "Epoch 187/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3420.9629 - val_loss: 7539.4009\n",
      "Epoch 188/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 3419.3186 - val_loss: 7536.6195\n",
      "Epoch 189/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3417.6756 - val_loss: 7533.3690\n",
      "Epoch 190/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3416.0769 - val_loss: 7530.0638\n",
      "Epoch 191/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3414.3982 - val_loss: 7527.3979\n",
      "Epoch 192/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3412.7673 - val_loss: 7524.1434\n",
      "Epoch 193/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 3411.1866 - val_loss: 7520.7212\n",
      "Epoch 194/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3409.5106 - val_loss: 7518.1248\n",
      "Epoch 195/1000\n",
      "246/246 [==============================] - 0s 946us/step - loss: 3407.8857 - val_loss: 7515.0080\n",
      "Epoch 196/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3406.3681 - val_loss: 7511.5430\n",
      "Epoch 197/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3404.6046 - val_loss: 7509.9870\n",
      "Epoch 198/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3403.0890 - val_loss: 7506.2349\n",
      "Epoch 199/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3401.4373 - val_loss: 7503.2814\n",
      "Epoch 200/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 3399.8297 - val_loss: 7499.9866\n",
      "Epoch 201/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3398.2788 - val_loss: 7496.3432\n",
      "Epoch 202/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3396.6306 - val_loss: 7493.5323\n",
      "Epoch 203/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3395.0841 - val_loss: 7490.2913\n",
      "Epoch 204/1000\n",
      "246/246 [==============================] - 0s 958us/step - loss: 3393.4404 - val_loss: 7487.7998\n",
      "Epoch 205/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3391.8478 - val_loss: 7484.7475\n",
      "Epoch 206/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3390.3179 - val_loss: 7481.0667\n",
      "Epoch 207/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3388.6910 - val_loss: 7478.0563\n",
      "Epoch 208/1000\n",
      "246/246 [==============================] - 0s 944us/step - loss: 3387.1628 - val_loss: 7474.7132\n",
      "Epoch 209/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 3385.4836 - val_loss: 7472.2475\n",
      "Epoch 210/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3384.0986 - val_loss: 7467.5948\n",
      "Epoch 211/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3382.4173 - val_loss: 7465.1303\n",
      "Epoch 212/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3380.8536 - val_loss: 7462.1046\n",
      "Epoch 213/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3379.2961 - val_loss: 7458.6623\n",
      "Epoch 214/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 3377.8501 - val_loss: 7454.9152\n",
      "Epoch 215/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3376.1538 - val_loss: 7453.3883\n",
      "Epoch 216/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3374.6498 - val_loss: 7449.6263\n",
      "Epoch 217/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3373.1632 - val_loss: 7445.7577\n",
      "Epoch 218/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3371.5698 - val_loss: 7443.0253\n",
      "Epoch 219/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3370.0818 - val_loss: 7439.8745\n",
      "Epoch 220/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3368.5029 - val_loss: 7437.4068\n",
      "Epoch 221/1000\n",
      "246/246 [==============================] - 0s 951us/step - loss: 3366.9707 - val_loss: 7434.5266\n",
      "Epoch 222/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 3365.5080 - val_loss: 7431.0440\n",
      "Epoch 223/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3363.8678 - val_loss: 7428.8901\n",
      "Epoch 224/1000\n",
      "246/246 [==============================] - 0s 943us/step - loss: 3362.5613 - val_loss: 7424.5042\n",
      "Epoch 225/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 3360.9100 - val_loss: 7422.7468\n",
      "Epoch 226/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3359.3935 - val_loss: 7420.4635\n",
      "Epoch 227/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 3357.9403 - val_loss: 7417.5830\n",
      "Epoch 228/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3356.3136 - val_loss: 7415.7131\n",
      "Epoch 229/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3355.0188 - val_loss: 7411.8406\n",
      "Epoch 230/1000\n",
      "246/246 [==============================] - 0s 936us/step - loss: 3353.3849 - val_loss: 7410.1814\n",
      "Epoch 231/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3351.8884 - val_loss: 7407.7104\n",
      "Epoch 232/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 3350.5105 - val_loss: 7404.3629\n",
      "Epoch 233/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3348.8766 - val_loss: 7403.0989\n",
      "Epoch 234/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3347.5044 - val_loss: 7399.1111\n",
      "Epoch 235/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3345.9743 - val_loss: 7396.4700\n",
      "Epoch 236/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3344.4986 - val_loss: 7393.5202\n",
      "Epoch 237/1000\n",
      "246/246 [==============================] - 0s 938us/step - loss: 3343.1341 - val_loss: 7390.3022\n",
      "Epoch 238/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3341.5071 - val_loss: 7389.2748\n",
      "Epoch 239/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3340.1541 - val_loss: 7385.5749\n",
      "Epoch 240/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3338.6434 - val_loss: 7382.9308\n",
      "Epoch 241/1000\n",
      "246/246 [==============================] - 0s 956us/step - loss: 3337.2435 - val_loss: 7379.6484\n",
      "Epoch 242/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3335.7463 - val_loss: 7377.2567\n",
      "Epoch 243/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 3334.2976 - val_loss: 7374.4491\n",
      "Epoch 244/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3332.9067 - val_loss: 7371.3785\n",
      "Epoch 245/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3331.3612 - val_loss: 7369.3716\n",
      "Epoch 246/1000\n",
      "246/246 [==============================] - 0s 959us/step - loss: 3330.1251 - val_loss: 7365.0672\n",
      "Epoch 247/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3328.4915 - val_loss: 7363.6549\n",
      "Epoch 248/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3327.2710 - val_loss: 7359.6143\n",
      "Epoch 249/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3325.7435 - val_loss: 7357.7432\n",
      "Epoch 250/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3324.3209 - val_loss: 7355.5019\n",
      "Epoch 251/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3322.8977 - val_loss: 7353.2134\n",
      "Epoch 252/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 3321.5362 - val_loss: 7350.7020\n",
      "Epoch 253/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 3320.0108 - val_loss: 7349.1982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 254/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 3318.8169 - val_loss: 7345.3275\n",
      "Epoch 255/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 3317.2822 - val_loss: 7343.9364\n",
      "Epoch 256/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 3315.8847 - val_loss: 7341.8529\n",
      "Epoch 257/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3314.5366 - val_loss: 7339.3883\n",
      "Epoch 258/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3313.0307 - val_loss: 7337.7628\n",
      "Epoch 259/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3311.8672 - val_loss: 7333.6205\n",
      "Epoch 260/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 3310.2640 - val_loss: 7332.2565\n",
      "Epoch 261/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3309.1174 - val_loss: 7328.1971\n",
      "Epoch 262/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3307.5994 - val_loss: 7326.9475\n",
      "Epoch 263/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3306.2385 - val_loss: 7324.5186\n",
      "Epoch 264/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 3304.9229 - val_loss: 7321.7173\n",
      "Epoch 265/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3303.4417 - val_loss: 7319.9487\n",
      "Epoch 266/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 3302.3104 - val_loss: 7315.9102\n",
      "Epoch 267/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3300.8082 - val_loss: 7314.6146\n",
      "Epoch 268/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3299.4586 - val_loss: 7312.2392\n",
      "Epoch 269/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 3298.2291 - val_loss: 7309.6491\n",
      "Epoch 270/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 3296.7396 - val_loss: 7308.8232\n",
      "Epoch 271/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 3295.5651 - val_loss: 7305.2600\n",
      "Epoch 272/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3294.0641 - val_loss: 7304.1603\n",
      "Epoch 273/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3292.9257 - val_loss: 7300.1763\n",
      "Epoch 274/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 3291.3989 - val_loss: 7299.5407\n",
      "Epoch 275/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 3290.2891 - val_loss: 7295.6215\n",
      "Epoch 276/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3288.8448 - val_loss: 7294.7070\n",
      "Epoch 277/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3287.5270 - val_loss: 7292.7626\n",
      "Epoch 278/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 3286.2213 - val_loss: 7289.9426\n",
      "Epoch 279/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3284.9647 - val_loss: 7287.2846\n",
      "Epoch 280/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3283.5764 - val_loss: 7285.6473\n",
      "Epoch 281/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3282.4583 - val_loss: 7282.3055\n",
      "Epoch 282/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3280.9435 - val_loss: 7281.9504\n",
      "Epoch 283/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3279.8810 - val_loss: 7278.2812\n",
      "Epoch 284/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3278.4529 - val_loss: 7277.4210\n",
      "Epoch 285/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3277.1709 - val_loss: 7275.4792\n",
      "Epoch 286/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 3275.9377 - val_loss: 7273.0729\n",
      "Epoch 287/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3274.5257 - val_loss: 7271.4341\n",
      "Epoch 288/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 3273.5126 - val_loss: 7267.3333\n",
      "Epoch 289/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3272.1278 - val_loss: 7266.1026\n",
      "Epoch 290/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3270.7303 - val_loss: 7265.2946\n",
      "Epoch 291/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 3269.7157 - val_loss: 7261.5161\n",
      "Epoch 292/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 3268.2861 - val_loss: 7260.5976\n",
      "Epoch 293/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3267.1026 - val_loss: 7258.2324\n",
      "Epoch 294/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3265.7593 - val_loss: 7256.8782\n",
      "Epoch 295/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3264.7085 - val_loss: 7253.5755\n",
      "Epoch 296/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3263.2250 - val_loss: 7253.3822\n",
      "Epoch 297/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3262.2417 - val_loss: 7249.5211\n",
      "Epoch 298/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3260.8406 - val_loss: 7248.9219\n",
      "Epoch 299/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3259.6636 - val_loss: 7246.8043\n",
      "Epoch 300/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3258.3639 - val_loss: 7245.0618\n",
      "Epoch 301/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3257.3003 - val_loss: 7242.1904\n",
      "Epoch 302/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3255.8839 - val_loss: 7242.1279\n",
      "Epoch 303/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3254.8796 - val_loss: 7238.3674\n",
      "Epoch 304/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3253.4447 - val_loss: 7238.0690\n",
      "Epoch 305/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3252.4689 - val_loss: 7234.2077\n",
      "Epoch 306/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3251.0159 - val_loss: 7233.9872\n",
      "Epoch 307/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3250.0702 - val_loss: 7230.0815\n",
      "Epoch 308/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3248.6939 - val_loss: 7229.5067\n",
      "Epoch 309/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 3247.5642 - val_loss: 7227.2347\n",
      "Epoch 310/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3246.2782 - val_loss: 7225.7923\n",
      "Epoch 311/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 3245.2947 - val_loss: 7222.4756\n",
      "Epoch 312/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3243.8515 - val_loss: 7222.2739\n",
      "Epoch 313/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3242.9461 - val_loss: 7218.4962\n",
      "Epoch 314/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 3241.5726 - val_loss: 7217.8298\n",
      "Epoch 315/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3240.5686 - val_loss: 7215.3133\n",
      "Epoch 316/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3239.1746 - val_loss: 7215.6976\n",
      "Epoch 317/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3238.2442 - val_loss: 7212.0486\n",
      "Epoch 318/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3236.8262 - val_loss: 7211.8061\n",
      "Epoch 319/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3235.9380 - val_loss: 7207.8749\n",
      "Epoch 320/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3234.5871 - val_loss: 7207.2042\n",
      "Epoch 321/1000\n",
      "246/246 [==============================] - 0s 953us/step - loss: 3233.5992 - val_loss: 7204.6410\n",
      "Epoch 322/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3232.2271 - val_loss: 7204.9179\n",
      "Epoch 323/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3231.3242 - val_loss: 7201.2177\n",
      "Epoch 324/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 3229.9188 - val_loss: 7201.0412\n",
      "Epoch 325/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3229.0582 - val_loss: 7197.1178\n",
      "Epoch 326/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3227.7218 - val_loss: 7196.5100\n",
      "Epoch 327/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3226.7587 - val_loss: 7194.0393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 328/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3225.3947 - val_loss: 7194.2348\n",
      "Epoch 329/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 3224.5274 - val_loss: 7190.6122\n",
      "Epoch 330/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3223.1161 - val_loss: 7190.2621\n",
      "Epoch 331/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3222.3139 - val_loss: 7186.0968\n",
      "Epoch 332/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 3221.0527 - val_loss: 7185.5374\n",
      "Epoch 333/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3219.9363 - val_loss: 7184.6034\n",
      "Epoch 334/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3218.7394 - val_loss: 7183.7347\n",
      "Epoch 335/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3217.8421 - val_loss: 7180.6407\n",
      "Epoch 336/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3216.4548 - val_loss: 7180.8375\n",
      "Epoch 337/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 3215.6697 - val_loss: 7176.5777\n",
      "Epoch 338/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 3214.4271 - val_loss: 7176.1409\n",
      "Epoch 339/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3213.2389 - val_loss: 7175.5046\n",
      "Epoch 340/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 3212.3638 - val_loss: 7172.6472\n",
      "Epoch 341/1000\n",
      "246/246 [==============================] - 0s 956us/step - loss: 3210.9929 - val_loss: 7172.6287\n",
      "Epoch 342/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3210.2237 - val_loss: 7168.6507\n",
      "Epoch 343/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3208.9971 - val_loss: 7168.2437\n",
      "Epoch 344/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3207.8205 - val_loss: 7167.4931\n",
      "Epoch 345/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 3206.9703 - val_loss: 7164.6268\n",
      "Epoch 346/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3205.7034 - val_loss: 7164.4050\n",
      "Epoch 347/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 3204.8059 - val_loss: 7162.1686\n",
      "Epoch 348/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3203.4970 - val_loss: 7162.5127\n",
      "Epoch 349/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 3202.7136 - val_loss: 7158.5093\n",
      "Epoch 350/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3201.4249 - val_loss: 7158.1501\n",
      "Epoch 351/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3200.5975 - val_loss: 7155.1445\n",
      "Epoch 352/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 3199.2341 - val_loss: 7155.3979\n",
      "Epoch 353/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3198.5341 - val_loss: 7151.1808\n",
      "Epoch 354/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3197.4217 - val_loss: 7150.7338\n",
      "Epoch 355/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 3196.1261 - val_loss: 7151.7750\n",
      "Epoch 356/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 3195.3768 - val_loss: 7148.1008\n",
      "Epoch 357/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 3194.2105 - val_loss: 7147.4097\n",
      "Epoch 358/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3193.0808 - val_loss: 7146.7145\n",
      "Epoch 359/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 3192.2704 - val_loss: 7143.6852\n",
      "Epoch 360/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3190.9326 - val_loss: 7143.9343\n",
      "Epoch 361/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3190.2591 - val_loss: 7139.6159\n",
      "Epoch 362/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3189.1679 - val_loss: 7139.2522\n",
      "Epoch 363/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3187.8959 - val_loss: 7140.3551\n",
      "Epoch 364/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 3187.1750 - val_loss: 7136.5932\n",
      "Epoch 365/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 3186.0302 - val_loss: 7135.9451\n",
      "Epoch 366/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3184.9212 - val_loss: 7135.4622\n",
      "Epoch 367/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3184.1401 - val_loss: 7132.3130\n",
      "Epoch 368/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3182.9027 - val_loss: 7132.5805\n",
      "Epoch 369/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3182.1366 - val_loss: 7129.5864\n",
      "Epoch 370/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3180.8249 - val_loss: 7129.8766\n",
      "Epoch 371/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3180.1817 - val_loss: 7125.7270\n",
      "Epoch 372/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3179.1241 - val_loss: 7125.3569\n",
      "Epoch 373/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3177.8691 - val_loss: 7126.6747\n",
      "Epoch 374/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3177.1955 - val_loss: 7122.6429\n",
      "Epoch 375/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3176.0675 - val_loss: 7122.2544\n",
      "Epoch 376/1000\n",
      "246/246 [==============================] - 0s 961us/step - loss: 3174.9856 - val_loss: 7121.8231\n",
      "Epoch 377/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3174.2448 - val_loss: 7118.6025\n",
      "Epoch 378/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3173.0221 - val_loss: 7119.0677\n",
      "Epoch 379/1000\n",
      "246/246 [==============================] - 0s 962us/step - loss: 3172.2990 - val_loss: 7115.9965\n",
      "Epoch 380/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 3171.0823 - val_loss: 7116.4136\n",
      "Epoch 381/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3170.3642 - val_loss: 7113.5141\n",
      "Epoch 382/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3169.1826 - val_loss: 7113.6237\n",
      "Epoch 383/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3168.4185 - val_loss: 7111.4126\n",
      "Epoch 384/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3167.1756 - val_loss: 7112.1483\n",
      "Epoch 385/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3166.5439 - val_loss: 7107.9831\n",
      "Epoch 386/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3165.4260 - val_loss: 7107.9081\n",
      "Epoch 387/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3164.5988 - val_loss: 7106.6016\n",
      "Epoch 388/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3163.3723 - val_loss: 7107.5419\n",
      "Epoch 389/1000\n",
      "246/246 [==============================] - 0s 948us/step - loss: 3162.7539 - val_loss: 7103.3759\n",
      "Epoch 390/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3161.6363 - val_loss: 7103.3087\n",
      "Epoch 391/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3160.8332 - val_loss: 7101.9558\n",
      "Epoch 392/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3159.6128 - val_loss: 7102.9156\n",
      "Epoch 393/1000\n",
      "246/246 [==============================] - 0s 899us/step - loss: 3159.0109 - val_loss: 7098.6971\n",
      "Epoch 394/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 3158.0220 - val_loss: 7098.2932\n",
      "Epoch 395/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 3156.8316 - val_loss: 7099.6148\n",
      "Epoch 396/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3156.2177 - val_loss: 7095.5394\n",
      "Epoch 397/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 3155.0357 - val_loss: 7095.5110\n",
      "Epoch 398/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3154.3766 - val_loss: 7092.5516\n",
      "Epoch 399/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3153.3118 - val_loss: 7092.7729\n",
      "Epoch 400/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3152.2900 - val_loss: 7092.6424\n",
      "Epoch 401/1000\n",
      "246/246 [==============================] - 0s 953us/step - loss: 3151.6303 - val_loss: 7089.4059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 402/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 3150.4632 - val_loss: 7089.9076\n",
      "Epoch 403/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 3149.8157 - val_loss: 7087.0397\n",
      "Epoch 404/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3148.6480 - val_loss: 7087.6555\n",
      "Epoch 405/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3148.0148 - val_loss: 7084.7727\n",
      "Epoch 406/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3146.9714 - val_loss: 7084.8975\n",
      "Epoch 407/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3145.9606 - val_loss: 7084.9329\n",
      "Epoch 408/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3145.3230 - val_loss: 7081.7876\n",
      "Epoch 409/1000\n",
      "246/246 [==============================] - 0s 952us/step - loss: 3144.2664 - val_loss: 7082.1414\n",
      "Epoch 410/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3143.5075 - val_loss: 7080.9264\n",
      "Epoch 411/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3142.3354 - val_loss: 7081.9748\n",
      "Epoch 412/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3141.7933 - val_loss: 7077.4370\n",
      "Epoch 413/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3140.8490 - val_loss: 7077.1409\n",
      "Epoch 414/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3139.6973 - val_loss: 7078.6168\n",
      "Epoch 415/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3139.1513 - val_loss: 7074.2645\n",
      "Epoch 416/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3138.1019 - val_loss: 7074.4824\n",
      "Epoch 417/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3137.3645 - val_loss: 7073.1282\n",
      "Epoch 418/1000\n",
      "246/246 [==============================] - 0s 1000us/step - loss: 3136.1979 - val_loss: 7074.2152\n",
      "Epoch 419/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 3135.6846 - val_loss: 7069.7531\n",
      "Epoch 420/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3134.6284 - val_loss: 7070.0022\n",
      "Epoch 421/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3133.9164 - val_loss: 7068.6642\n",
      "Epoch 422/1000\n",
      "246/246 [==============================] - 0s 951us/step - loss: 3132.7307 - val_loss: 7069.8518\n",
      "Epoch 423/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 3132.2573 - val_loss: 7065.2641\n",
      "Epoch 424/1000\n",
      "246/246 [==============================] - 0s 959us/step - loss: 3131.3409 - val_loss: 7065.0188\n",
      "Epoch 425/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3130.1711 - val_loss: 7066.7991\n",
      "Epoch 426/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3130.0346 - val_loss: 7062.2114\n",
      "Epoch 427/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3128.6076 - val_loss: 7068.7038\n",
      "Epoch 428/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 3127.6716 - val_loss: 7066.6423\n",
      "Epoch 429/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3127.1817 - val_loss: 7060.4895\n",
      "Epoch 430/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 3126.1783 - val_loss: 7059.8223\n",
      "Epoch 431/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 3125.3255 - val_loss: 7059.3116\n",
      "Epoch 432/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3124.4688 - val_loss: 7058.9412\n",
      "Epoch 433/1000\n",
      "246/246 [==============================] - 0s 999us/step - loss: 3123.7690 - val_loss: 7057.4429\n",
      "Epoch 434/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3122.6322 - val_loss: 7058.6345\n",
      "Epoch 435/1000\n",
      "246/246 [==============================] - 0s 959us/step - loss: 3122.1687 - val_loss: 7053.9367\n",
      "Epoch 436/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3121.1493 - val_loss: 7054.1450\n",
      "Epoch 437/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3120.4723 - val_loss: 7053.0709\n",
      "Epoch 438/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3119.3187 - val_loss: 7054.1990\n",
      "Epoch 439/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 3119.2763 - val_loss: 7049.5107\n",
      "Epoch 440/1000\n",
      "246/246 [==============================] - 0s 973us/step - loss: 3117.8118 - val_loss: 7056.1348\n",
      "Epoch 441/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3117.0430 - val_loss: 7053.5906\n",
      "Epoch 442/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 3116.3082 - val_loss: 7050.0515\n",
      "Epoch 443/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3115.4474 - val_loss: 7048.9572\n",
      "Epoch 444/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3114.7843 - val_loss: 7047.2132\n",
      "Epoch 445/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 3113.6523 - val_loss: 7048.4454\n",
      "Epoch 446/1000\n",
      "246/246 [==============================] - 0s 951us/step - loss: 3113.6102 - val_loss: 7043.5596\n",
      "Epoch 447/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3112.1793 - val_loss: 7050.2879\n",
      "Epoch 448/1000\n",
      "246/246 [==============================] - 0s 964us/step - loss: 3111.2860 - val_loss: 7048.1848\n",
      "Epoch 449/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3110.8653 - val_loss: 7041.8945\n",
      "Epoch 450/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3109.8986 - val_loss: 7041.5053\n",
      "Epoch 451/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 3109.1920 - val_loss: 7041.0977\n",
      "Epoch 452/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3108.0933 - val_loss: 7042.7059\n",
      "Epoch 453/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 3108.0707 - val_loss: 7037.9205\n",
      "Epoch 454/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3106.6511 - val_loss: 7044.7401\n",
      "Epoch 455/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3105.7720 - val_loss: 7042.5721\n",
      "Epoch 456/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3105.3650 - val_loss: 7036.1960\n",
      "Epoch 457/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3104.4145 - val_loss: 7035.7759\n",
      "Epoch 458/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3103.7233 - val_loss: 7035.4178\n",
      "Epoch 459/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3102.6487 - val_loss: 7036.8581\n",
      "Epoch 460/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3102.6111 - val_loss: 7033.3081\n",
      "Epoch 461/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3101.1838 - val_loss: 7039.8839\n",
      "Epoch 462/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3100.3256 - val_loss: 7036.7620\n",
      "Epoch 463/1000\n",
      "246/246 [==============================] - 0s 917us/step - loss: 3100.2921 - val_loss: 7029.6507\n",
      "Epoch 464/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 3098.8937 - val_loss: 7035.8761\n",
      "Epoch 465/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3098.2018 - val_loss: 7032.7412\n",
      "Epoch 466/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 3097.4088 - val_loss: 7028.8697\n",
      "Epoch 467/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 3096.8350 - val_loss: 7025.5788\n",
      "Epoch 468/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 3095.7906 - val_loss: 7026.7360\n",
      "Epoch 469/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3095.7127 - val_loss: 7023.3257\n",
      "Epoch 470/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3094.3642 - val_loss: 7030.8756\n",
      "Epoch 471/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3093.5381 - val_loss: 7028.3314\n",
      "Epoch 472/1000\n",
      "246/246 [==============================] - 0s 966us/step - loss: 3093.1419 - val_loss: 7021.9943\n",
      "Epoch 473/1000\n",
      "246/246 [==============================] - 0s 957us/step - loss: 3092.1328 - val_loss: 7021.9835\n",
      "Epoch 474/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 3091.9778 - val_loss: 7020.1433\n",
      "Epoch 475/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3090.6715 - val_loss: 7028.4235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 476/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 3089.8491 - val_loss: 7026.3723\n",
      "Epoch 477/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3089.4467 - val_loss: 7020.2073\n",
      "Epoch 478/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 3088.4544 - val_loss: 7020.0999\n",
      "Epoch 479/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3088.3305 - val_loss: 7018.1047\n",
      "Epoch 480/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3087.0272 - val_loss: 7026.4159\n",
      "Epoch 481/1000\n",
      "246/246 [==============================] - 0s 936us/step - loss: 3086.1986 - val_loss: 7024.6421\n",
      "Epoch 482/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3086.1712 - val_loss: 7017.9627\n",
      "Epoch 483/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3084.8618 - val_loss: 7024.7473\n",
      "Epoch 484/1000\n",
      "246/246 [==============================] - 0s 956us/step - loss: 3084.1843 - val_loss: 7022.1640\n",
      "Epoch 485/1000\n",
      "246/246 [==============================] - 0s 933us/step - loss: 3083.4291 - val_loss: 7018.5191\n",
      "Epoch 486/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3083.2580 - val_loss: 7015.0928\n",
      "Epoch 487/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 3082.0143 - val_loss: 7022.8668\n",
      "Epoch 488/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3081.1976 - val_loss: 7020.8231\n",
      "Epoch 489/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 3080.7995 - val_loss: 7014.2766\n",
      "Epoch 490/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3079.8388 - val_loss: 7013.9477\n",
      "Epoch 491/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 3079.7573 - val_loss: 7011.6803\n",
      "Epoch 492/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 3078.4664 - val_loss: 7020.0316\n",
      "Epoch 493/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3077.6614 - val_loss: 7018.0886\n",
      "Epoch 494/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 3077.6928 - val_loss: 7011.1934\n",
      "Epoch 495/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 3076.3696 - val_loss: 7018.0819\n",
      "Epoch 496/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 3075.7131 - val_loss: 7015.3575\n",
      "Epoch 497/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 3074.9793 - val_loss: 7011.7196\n",
      "Epoch 498/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3074.8897 - val_loss: 7008.3437\n",
      "Epoch 499/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 3073.6133 - val_loss: 7016.3028\n",
      "Epoch 500/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3072.8148 - val_loss: 7014.2762\n",
      "Epoch 501/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3072.8715 - val_loss: 7007.2350\n",
      "Epoch 502/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3071.5444 - val_loss: 7014.3095\n",
      "Epoch 503/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3070.9096 - val_loss: 7011.3794\n",
      "Epoch 504/1000\n",
      "246/246 [==============================] - 0s 938us/step - loss: 3070.1854 - val_loss: 7007.7831\n",
      "Epoch 505/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3070.1300 - val_loss: 7004.5175\n",
      "Epoch 506/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3068.8398 - val_loss: 7012.6326\n",
      "Epoch 507/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3068.0583 - val_loss: 7010.5091\n",
      "Epoch 508/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3068.1631 - val_loss: 7003.5478\n",
      "Epoch 509/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 3066.8076 - val_loss: 7010.6855\n",
      "Epoch 510/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3066.1972 - val_loss: 7007.5550\n",
      "Epoch 511/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3065.4837 - val_loss: 7003.9944\n",
      "Epoch 512/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3065.4939 - val_loss: 7000.8587\n",
      "Epoch 513/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3064.1559 - val_loss: 7009.3090\n",
      "Epoch 514/1000\n",
      "246/246 [==============================] - 0s 943us/step - loss: 3063.3872 - val_loss: 7007.2120\n",
      "Epoch 515/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3063.5773 - val_loss: 7000.2464\n",
      "Epoch 516/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 3062.1645 - val_loss: 7007.4778\n",
      "Epoch 517/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3061.5620 - val_loss: 7004.3735\n",
      "Epoch 518/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 3061.2839 - val_loss: 7000.4892\n",
      "Epoch 519/1000\n",
      "246/246 [==============================] - 0s 998us/step - loss: 3060.1574 - val_loss: 7004.9999\n",
      "Epoch 520/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3059.9705 - val_loss: 7000.9105\n",
      "Epoch 521/1000\n",
      "246/246 [==============================] - 0s 955us/step - loss: 3058.8769 - val_loss: 7004.6396\n",
      "Epoch 522/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 3058.2986 - val_loss: 7000.4959\n",
      "Epoch 523/1000\n",
      "246/246 [==============================] - 0s 931us/step - loss: 3058.3557 - val_loss: 6996.5988\n",
      "Epoch 524/1000\n",
      "246/246 [==============================] - 0s 991us/step - loss: 3056.7086 - val_loss: 7005.1580\n",
      "Epoch 525/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3057.1389 - val_loss: 6996.7881\n",
      "Epoch 526/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3055.6966 - val_loss: 7003.0532\n",
      "Epoch 527/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3055.1299 - val_loss: 6999.8273\n",
      "Epoch 528/1000\n",
      "246/246 [==============================] - 0s 956us/step - loss: 3054.9996 - val_loss: 6995.9918\n",
      "Epoch 529/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3053.7969 - val_loss: 7002.2795\n",
      "Epoch 530/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 3053.2220 - val_loss: 6998.7632\n",
      "Epoch 531/1000\n",
      "246/246 [==============================] - 0s 965us/step - loss: 3053.1196 - val_loss: 6994.7973\n",
      "Epoch 532/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 3051.9113 - val_loss: 7001.1340\n",
      "Epoch 533/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3051.1624 - val_loss: 6998.1889\n",
      "Epoch 534/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 3051.5442 - val_loss: 6990.8722\n",
      "Epoch 535/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3049.9807 - val_loss: 6998.2044\n",
      "Epoch 536/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3049.4671 - val_loss: 6994.7854\n",
      "Epoch 537/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 3049.5688 - val_loss: 6990.8378\n",
      "Epoch 538/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3047.9111 - val_loss: 6999.6573\n",
      "Epoch 539/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 3048.4229 - val_loss: 6990.7723\n",
      "Epoch 540/1000\n",
      "246/246 [==============================] - 0s 944us/step - loss: 3046.9379 - val_loss: 6997.0260\n",
      "Epoch 541/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 3046.4206 - val_loss: 6993.6599\n",
      "Epoch 542/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 3046.3660 - val_loss: 6989.7582\n",
      "Epoch 543/1000\n",
      "246/246 [==============================] - 0s 972us/step - loss: 3045.1006 - val_loss: 6996.3340\n",
      "Epoch 544/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 3044.5805 - val_loss: 6992.6403\n",
      "Epoch 545/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3044.5641 - val_loss: 6988.6993\n",
      "Epoch 546/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 3043.2734 - val_loss: 6995.0154\n",
      "Epoch 547/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3043.1782 - val_loss: 6991.0874\n",
      "Epoch 548/1000\n",
      "246/246 [==============================] - 0s 985us/step - loss: 3042.0840 - val_loss: 6994.7693\n",
      "Epoch 549/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 1ms/step - loss: 3041.9968 - val_loss: 6989.9853\n",
      "Epoch 550/1000\n",
      "246/246 [==============================] - 0s 989us/step - loss: 3040.8817 - val_loss: 6993.7647\n",
      "Epoch 551/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3040.8156 - val_loss: 6988.8755\n",
      "Epoch 552/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3039.6890 - val_loss: 6992.3864\n",
      "Epoch 553/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3039.6379 - val_loss: 6987.5519\n",
      "Epoch 554/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3038.4964 - val_loss: 6990.9138\n",
      "Epoch 555/1000\n",
      "246/246 [==============================] - 0s 935us/step - loss: 3038.4657 - val_loss: 6986.1143\n",
      "Epoch 556/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3037.3119 - val_loss: 6990.0127\n",
      "Epoch 557/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3037.3031 - val_loss: 6985.3538\n",
      "Epoch 558/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3036.3117 - val_loss: 6988.5883\n",
      "Epoch 559/1000\n",
      "246/246 [==============================] - 0s 962us/step - loss: 3035.6812 - val_loss: 6987.3351\n",
      "Epoch 560/1000\n",
      "246/246 [==============================] - 0s 955us/step - loss: 3035.5556 - val_loss: 6984.2552\n",
      "Epoch 561/1000\n",
      "246/246 [==============================] - 0s 952us/step - loss: 3034.3871 - val_loss: 6988.8390\n",
      "Epoch 562/1000\n",
      "246/246 [==============================] - 0s 957us/step - loss: 3034.4319 - val_loss: 6984.0077\n",
      "Epoch 563/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 3033.2208 - val_loss: 6987.7032\n",
      "Epoch 564/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 3033.3080 - val_loss: 6982.7007\n",
      "Epoch 565/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3032.0545 - val_loss: 6986.4321\n",
      "Epoch 566/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 3032.2968 - val_loss: 6981.5278\n",
      "Epoch 567/1000\n",
      "246/246 [==============================] - 0s 986us/step - loss: 3030.6516 - val_loss: 6987.8093\n",
      "Epoch 568/1000\n",
      "246/246 [==============================] - 0s 891us/step - loss: 3031.5008 - val_loss: 6977.6931\n",
      "Epoch 569/1000\n",
      "246/246 [==============================] - 0s 977us/step - loss: 3029.9267 - val_loss: 6982.9462\n",
      "Epoch 570/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3029.8206 - val_loss: 6982.2549\n",
      "Epoch 571/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 3028.3843 - val_loss: 6987.3074\n",
      "Epoch 572/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 3029.2852 - val_loss: 6976.3284\n",
      "Epoch 573/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3027.6606 - val_loss: 6981.4305\n",
      "Epoch 574/1000\n",
      "246/246 [==============================] - 0s 931us/step - loss: 3027.5992 - val_loss: 6980.7870\n",
      "Epoch 575/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 3026.4402 - val_loss: 6985.5342\n",
      "Epoch 576/1000\n",
      "246/246 [==============================] - 0s 931us/step - loss: 3026.5546 - val_loss: 6980.3775\n",
      "Epoch 577/1000\n",
      "246/246 [==============================] - 0s 923us/step - loss: 3025.3130 - val_loss: 6983.8105\n",
      "Epoch 578/1000\n",
      "246/246 [==============================] - 0s 970us/step - loss: 3025.5829 - val_loss: 6978.6701\n",
      "Epoch 579/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 3023.9357 - val_loss: 6984.7182\n",
      "Epoch 580/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3024.8548 - val_loss: 6974.0098\n",
      "Epoch 581/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3023.2340 - val_loss: 6979.2211\n",
      "Epoch 582/1000\n",
      "246/246 [==============================] - 0s 993us/step - loss: 3023.2029 - val_loss: 6978.6016\n",
      "Epoch 583/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3021.7161 - val_loss: 6983.7647\n",
      "Epoch 584/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3022.7339 - val_loss: 6972.4252\n",
      "Epoch 585/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3021.4866 - val_loss: 6977.7784\n",
      "Epoch 586/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 3020.2461 - val_loss: 6985.5843\n",
      "Epoch 587/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 3020.9810 - val_loss: 6975.0177\n",
      "Epoch 588/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3019.0209 - val_loss: 6981.5173\n",
      "Epoch 589/1000\n",
      "246/246 [==============================] - 0s 957us/step - loss: 3020.0153 - val_loss: 6971.3924\n",
      "Epoch 590/1000\n",
      "246/246 [==============================] - 0s 974us/step - loss: 3018.8123 - val_loss: 6976.7239\n",
      "Epoch 591/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3017.5693 - val_loss: 6984.5172\n",
      "Epoch 592/1000\n",
      "246/246 [==============================] - 0s 969us/step - loss: 3018.3081 - val_loss: 6974.0369\n",
      "Epoch 593/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3016.5593 - val_loss: 6979.7150\n",
      "Epoch 594/1000\n",
      "246/246 [==============================] - 0s 971us/step - loss: 3017.1961 - val_loss: 6973.0642\n",
      "Epoch 595/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3015.3461 - val_loss: 6980.9199\n",
      "Epoch 596/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 3016.2734 - val_loss: 6970.8702\n",
      "Epoch 597/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3014.7373 - val_loss: 6976.0683\n",
      "Epoch 598/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3014.7107 - val_loss: 6975.3168\n",
      "Epoch 599/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3013.1995 - val_loss: 6980.4513\n",
      "Epoch 600/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 3014.2836 - val_loss: 6968.7560\n",
      "Epoch 601/1000\n",
      "246/246 [==============================] - 0s 994us/step - loss: 3013.0797 - val_loss: 6973.9129\n",
      "Epoch 602/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 3011.7739 - val_loss: 6981.7298\n",
      "Epoch 603/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 3012.6235 - val_loss: 6971.0228\n",
      "Epoch 604/1000\n",
      "246/246 [==============================] - 0s 983us/step - loss: 3011.1394 - val_loss: 6976.3750\n",
      "Epoch 605/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3011.0635 - val_loss: 6975.4734\n",
      "Epoch 606/1000\n",
      "246/246 [==============================] - 0s 963us/step - loss: 3009.7426 - val_loss: 6980.6961\n",
      "Epoch 607/1000\n",
      "246/246 [==============================] - 0s 996us/step - loss: 3010.5763 - val_loss: 6969.5726\n",
      "Epoch 608/1000\n",
      "246/246 [==============================] - 0s 950us/step - loss: 3009.0683 - val_loss: 6974.6769\n",
      "Epoch 609/1000\n",
      "246/246 [==============================] - 0s 995us/step - loss: 3009.0507 - val_loss: 6973.8889\n",
      "Epoch 610/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3007.6327 - val_loss: 6978.9337\n",
      "Epoch 611/1000\n",
      "246/246 [==============================] - 0s 968us/step - loss: 3008.6389 - val_loss: 6967.2965\n",
      "Epoch 612/1000\n",
      "246/246 [==============================] - 0s 976us/step - loss: 3007.4641 - val_loss: 6972.5027\n",
      "Epoch 613/1000\n",
      "246/246 [==============================] - 0s 978us/step - loss: 3006.2444 - val_loss: 6980.3990\n",
      "Epoch 614/1000\n",
      "246/246 [==============================] - 0s 947us/step - loss: 3007.0365 - val_loss: 6969.3242\n",
      "Epoch 615/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3005.2562 - val_loss: 6975.0883\n",
      "Epoch 616/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3005.9965 - val_loss: 6968.2088\n",
      "Epoch 617/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3004.0791 - val_loss: 6975.9472\n",
      "Epoch 618/1000\n",
      "246/246 [==============================] - 0s 937us/step - loss: 3005.1668 - val_loss: 6965.3076\n",
      "Epoch 619/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 3004.0088 - val_loss: 6970.7048\n",
      "Epoch 620/1000\n",
      "246/246 [==============================] - 0s 954us/step - loss: 3002.7306 - val_loss: 6978.5339\n",
      "Epoch 621/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 3003.5880 - val_loss: 6967.4020\n",
      "Epoch 622/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246/246 [==============================] - 0s 967us/step - loss: 3002.1039 - val_loss: 6972.3544\n",
      "Epoch 623/1000\n",
      "246/246 [==============================] - 0s 934us/step - loss: 3002.1151 - val_loss: 6971.4554\n",
      "Epoch 624/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3000.6900 - val_loss: 6976.4681\n",
      "Epoch 625/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3001.7475 - val_loss: 6964.4673\n",
      "Epoch 626/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 3000.5944 - val_loss: 6969.6999\n",
      "Epoch 627/1000\n",
      "246/246 [==============================] - 0s 960us/step - loss: 2999.3367 - val_loss: 6977.6731\n",
      "Epoch 628/1000\n",
      "246/246 [==============================] - 0s 920us/step - loss: 3000.1913 - val_loss: 6966.3665\n",
      "Epoch 629/1000\n",
      "246/246 [==============================] - 0s 931us/step - loss: 2998.3670 - val_loss: 6971.7423\n",
      "Epoch 630/1000\n",
      "246/246 [==============================] - 0s 979us/step - loss: 2999.2189 - val_loss: 6964.6160\n",
      "Epoch 631/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2998.1258 - val_loss: 6971.1723\n",
      "Epoch 632/1000\n",
      "246/246 [==============================] - 0s 941us/step - loss: 2997.0020 - val_loss: 6978.5822\n",
      "Epoch 633/1000\n",
      "246/246 [==============================] - 0s 897us/step - loss: 2997.8010 - val_loss: 6966.5970\n",
      "Epoch 634/1000\n",
      "246/246 [==============================] - 0s 935us/step - loss: 2996.0345 - val_loss: 6972.1642\n",
      "Epoch 635/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2996.7892 - val_loss: 6965.0384\n",
      "Epoch 636/1000\n",
      "246/246 [==============================] - 0s 992us/step - loss: 2994.8577 - val_loss: 6972.4643\n",
      "Epoch 637/1000\n",
      "246/246 [==============================] - 0s 997us/step - loss: 2996.0738 - val_loss: 6961.4418\n",
      "Epoch 638/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2994.9206 - val_loss: 6967.2284\n",
      "Epoch 639/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2993.5099 - val_loss: 6974.9573\n",
      "Epoch 640/1000\n",
      "246/246 [==============================] - 0s 982us/step - loss: 2994.6291 - val_loss: 6962.9013\n",
      "Epoch 641/1000\n",
      "246/246 [==============================] - 0s 929us/step - loss: 2993.5064 - val_loss: 6968.0314\n",
      "Epoch 642/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2992.2163 - val_loss: 6975.9272\n",
      "Epoch 643/1000\n",
      "246/246 [==============================] - 0s 949us/step - loss: 2993.1516 - val_loss: 6964.2812\n",
      "Epoch 644/1000\n",
      "246/246 [==============================] - 0s 984us/step - loss: 2992.0720 - val_loss: 6969.2761\n",
      "Epoch 645/1000\n",
      "246/246 [==============================] - 0s 981us/step - loss: 2990.9270 - val_loss: 6976.9138\n",
      "Epoch 646/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2991.6143 - val_loss: 6965.0944\n",
      "Epoch 647/1000\n",
      "246/246 [==============================] - 0s 962us/step - loss: 2990.7194 - val_loss: 6968.4493\n",
      "Epoch 648/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2989.5405 - val_loss: 6975.8351\n",
      "Epoch 649/1000\n",
      "246/246 [==============================] - 0s 988us/step - loss: 2990.2554 - val_loss: 6964.0490\n",
      "Epoch 650/1000\n",
      "246/246 [==============================] - 0s 967us/step - loss: 2989.3615 - val_loss: 6967.5527\n",
      "Epoch 651/1000\n",
      "246/246 [==============================] - 0s 975us/step - loss: 2988.1582 - val_loss: 6975.0616\n",
      "Epoch 652/1000\n",
      "246/246 [==============================] - 0s 945us/step - loss: 2989.0227 - val_loss: 6963.2622\n",
      "Epoch 653/1000\n",
      "246/246 [==============================] - 0s 1ms/step - loss: 2987.2885 - val_loss: 6968.9664\n",
      "Epoch 654/1000\n",
      "246/246 [==============================] - 0s 987us/step - loss: 2988.0948 - val_loss: 6962.0206\n",
      "Epoch 655/1000\n",
      "246/246 [==============================] - 0s 907us/step - loss: 2986.3384 - val_loss: 6969.2155\n",
      "Epoch 656/1000\n",
      "246/246 [==============================] - 0s 933us/step - loss: 2987.1923 - val_loss: 6962.1053\n",
      "Epoch 657/1000\n",
      "246/246 [==============================] - 0s 990us/step - loss: 2985.8370 - val_loss: 6969.1762\n",
      "Train on 245 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "245/245 [==============================] - 53s 216ms/step - loss: 26813.4566 - val_loss: 176939.3927\n",
      "Epoch 2/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 26763.6017 - val_loss: 176679.2092\n",
      "Epoch 3/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 26674.1016 - val_loss: 176228.9338\n",
      "Epoch 4/1000\n",
      "245/245 [==============================] - 0s 997us/step - loss: 26512.6876 - val_loss: 175409.5158\n",
      "Epoch 5/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 26240.6956 - val_loss: 174033.8381\n",
      "Epoch 6/1000\n",
      "245/245 [==============================] - 0s 943us/step - loss: 25817.7896 - val_loss: 171928.4283\n",
      "Epoch 7/1000\n",
      "245/245 [==============================] - 0s 978us/step - loss: 25197.8950 - val_loss: 168832.0630\n",
      "Epoch 8/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 24320.5899 - val_loss: 164370.4531\n",
      "Epoch 9/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 23129.3594 - val_loss: 158250.0741\n",
      "Epoch 10/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 21645.0083 - val_loss: 150508.3779\n",
      "Epoch 11/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 19977.7172 - val_loss: 141490.8354\n",
      "Epoch 12/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 18314.2504 - val_loss: 131926.6478\n",
      "Epoch 13/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 16863.9843 - val_loss: 122792.7570\n",
      "Epoch 14/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 15749.0045 - val_loss: 114799.2632\n",
      "Epoch 15/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 14962.6339 - val_loss: 108211.2596\n",
      "Epoch 16/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 14424.4040 - val_loss: 102953.3536\n",
      "Epoch 17/1000\n",
      "245/245 [==============================] - 0s 973us/step - loss: 14044.5715 - val_loss: 98778.0071\n",
      "Epoch 18/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 13756.0062 - val_loss: 95411.9435\n",
      "Epoch 19/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 13517.5165 - val_loss: 92623.7300\n",
      "Epoch 20/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 13306.2285 - val_loss: 90239.1122\n",
      "Epoch 21/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 13109.9367 - val_loss: 88134.0306\n",
      "Epoch 22/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 12922.1104 - val_loss: 86222.2707\n",
      "Epoch 23/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 12739.1381 - val_loss: 84444.2962\n",
      "Epoch 24/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 12558.9093 - val_loss: 82758.8736\n",
      "Epoch 25/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 12380.1048 - val_loss: 81137.1296\n",
      "Epoch 26/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 12201.8396 - val_loss: 79558.6308\n",
      "Epoch 27/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 12023.4791 - val_loss: 78008.6868\n",
      "Epoch 28/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 11844.5434 - val_loss: 76476.6009\n",
      "Epoch 29/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 11664.6534 - val_loss: 74954.4762\n",
      "Epoch 30/1000\n",
      "245/245 [==============================] - 0s 974us/step - loss: 11483.5034 - val_loss: 73436.3738\n",
      "Epoch 31/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 11300.8420 - val_loss: 71917.7985\n",
      "Epoch 32/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 11116.4599 - val_loss: 70395.3224\n",
      "Epoch 33/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 10930.1863 - val_loss: 68866.2766\n",
      "Epoch 34/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 10741.8826 - val_loss: 67328.6260\n",
      "Epoch 35/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 10551.4426 - val_loss: 65780.8487\n",
      "Epoch 36/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 10358.7921 - val_loss: 64221.7662\n",
      "Epoch 37/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 10163.8854 - val_loss: 62650.6110\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 1ms/step - loss: 9966.7096 - val_loss: 61066.9173\n",
      "Epoch 39/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 9768.2231 - val_loss: 59464.0563\n",
      "Epoch 40/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 9571.1060 - val_loss: 57841.5030\n",
      "Epoch 41/1000\n",
      "245/245 [==============================] - 0s 997us/step - loss: 9372.9048 - val_loss: 56214.5796\n",
      "Epoch 42/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 9173.5453 - val_loss: 54586.2296\n",
      "Epoch 43/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 8973.2677 - val_loss: 52954.2632\n",
      "Epoch 44/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 8772.1246 - val_loss: 51322.9862\n",
      "Epoch 45/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 8570.1961 - val_loss: 49695.1998\n",
      "Epoch 46/1000\n",
      "245/245 [==============================] - 0s 984us/step - loss: 8367.7690 - val_loss: 48071.0347\n",
      "Epoch 47/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 8165.2231 - val_loss: 46449.3779\n",
      "Epoch 48/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7962.8486 - val_loss: 44832.6600\n",
      "Epoch 49/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7763.0791 - val_loss: 43213.8307\n",
      "Epoch 50/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7566.2432 - val_loss: 41608.1607\n",
      "Epoch 51/1000\n",
      "245/245 [==============================] - 0s 1000us/step - loss: 7371.6906 - val_loss: 40018.9613\n",
      "Epoch 52/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 7179.8736 - val_loss: 38450.9131\n",
      "Epoch 53/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6991.0578 - val_loss: 36907.9252\n",
      "Epoch 54/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6805.5764 - val_loss: 35391.8987\n",
      "Epoch 55/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6623.8719 - val_loss: 33905.7949\n",
      "Epoch 56/1000\n",
      "245/245 [==============================] - 0s 981us/step - loss: 6446.4513 - val_loss: 32451.3875\n",
      "Epoch 57/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6273.9361 - val_loss: 31028.2541\n",
      "Epoch 58/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 6106.7920 - val_loss: 29642.4166\n",
      "Epoch 59/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5945.4517 - val_loss: 28295.8961\n",
      "Epoch 60/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5790.4561 - val_loss: 26991.5643\n",
      "Epoch 61/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5642.2250 - val_loss: 25732.4961\n",
      "Epoch 62/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5501.1622 - val_loss: 24520.5299\n",
      "Epoch 63/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5367.5864 - val_loss: 23358.1790\n",
      "Epoch 64/1000\n",
      "245/245 [==============================] - 0s 990us/step - loss: 5241.7898 - val_loss: 22247.1279\n",
      "Epoch 65/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5123.9873 - val_loss: 21188.7815\n",
      "Epoch 66/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 5014.2875 - val_loss: 20184.8931\n",
      "Epoch 67/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4912.7449 - val_loss: 19236.0356\n",
      "Epoch 68/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4819.3235 - val_loss: 18342.5346\n",
      "Epoch 69/1000\n",
      "245/245 [==============================] - 0s 983us/step - loss: 4733.8960 - val_loss: 17504.2865\n",
      "Epoch 70/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4656.2567 - val_loss: 16720.8183\n",
      "Epoch 71/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4586.1308 - val_loss: 15991.1938\n",
      "Epoch 72/1000\n",
      "245/245 [==============================] - 0s 976us/step - loss: 4523.1704 - val_loss: 15314.2354\n",
      "Epoch 73/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4466.9695 - val_loss: 14688.7695\n",
      "Epoch 74/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4417.0926 - val_loss: 14112.5547\n",
      "Epoch 75/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4373.0599 - val_loss: 13583.3842\n",
      "Epoch 76/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4334.5161 - val_loss: 13097.7847\n",
      "Epoch 77/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4301.0801 - val_loss: 12655.1206\n",
      "Epoch 78/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4272.0397 - val_loss: 12253.5571\n",
      "Epoch 79/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4246.8019 - val_loss: 11890.1773\n",
      "Epoch 80/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4224.8505 - val_loss: 11562.9438\n",
      "Epoch 81/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4205.7758 - val_loss: 11267.7041\n",
      "Epoch 82/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4189.1650 - val_loss: 11001.4096\n",
      "Epoch 83/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4174.7478 - val_loss: 10760.5887\n",
      "Epoch 84/1000\n",
      "245/245 [==============================] - 0s 984us/step - loss: 4162.2260 - val_loss: 10544.1450\n",
      "Epoch 85/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4151.1763 - val_loss: 10351.2524\n",
      "Epoch 86/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4141.4270 - val_loss: 10178.2984\n",
      "Epoch 87/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4132.7349 - val_loss: 10023.3567\n",
      "Epoch 88/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4124.8882 - val_loss: 9884.6069\n",
      "Epoch 89/1000\n",
      "245/245 [==============================] - 0s 999us/step - loss: 4117.7511 - val_loss: 9760.4529\n",
      "Epoch 90/1000\n",
      "245/245 [==============================] - 0s 981us/step - loss: 4111.1757 - val_loss: 9649.3709\n",
      "Epoch 91/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4105.0633 - val_loss: 9550.0749\n",
      "Epoch 92/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4099.3753 - val_loss: 9460.8187\n",
      "Epoch 93/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4094.0067 - val_loss: 9381.2349\n",
      "Epoch 94/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4088.8992 - val_loss: 9310.1795\n",
      "Epoch 95/1000\n",
      "245/245 [==============================] - 0s 986us/step - loss: 4083.9448 - val_loss: 9247.0694\n",
      "Epoch 96/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4079.1518 - val_loss: 9189.9818\n",
      "Epoch 97/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4074.4957 - val_loss: 9138.7316\n",
      "Epoch 98/1000\n",
      "245/245 [==============================] - 0s 993us/step - loss: 4069.9534 - val_loss: 9091.0047\n",
      "Epoch 99/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4065.4251 - val_loss: 9048.5231\n",
      "Epoch 100/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4060.9469 - val_loss: 9010.8429\n",
      "Epoch 101/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4056.5287 - val_loss: 8977.0539\n",
      "Epoch 102/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4052.1572 - val_loss: 8946.4869\n",
      "Epoch 103/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4047.8208 - val_loss: 8918.5495\n",
      "Epoch 104/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4043.5135 - val_loss: 8892.8608\n",
      "Epoch 105/1000\n",
      "245/245 [==============================] - 0s 992us/step - loss: 4039.2264 - val_loss: 8868.7068\n",
      "Epoch 106/1000\n",
      "245/245 [==============================] - 0s 980us/step - loss: 4034.9454 - val_loss: 8846.1193\n",
      "Epoch 107/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4030.6689 - val_loss: 8825.0170\n",
      "Epoch 108/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4026.3944 - val_loss: 8805.3437\n",
      "Epoch 109/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4022.1223 - val_loss: 8787.1112\n",
      "Epoch 110/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4017.8581 - val_loss: 8769.8945\n",
      "Epoch 111/1000\n",
      "245/245 [==============================] - 0s 1000us/step - loss: 4013.6004 - val_loss: 8753.6408\n",
      "Epoch 112/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 980us/step - loss: 4009.3418 - val_loss: 8737.9676\n",
      "Epoch 113/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 4005.0811 - val_loss: 8722.9223\n",
      "Epoch 114/1000\n",
      "245/245 [==============================] - 0s 976us/step - loss: 4000.8239 - val_loss: 8708.7436\n",
      "Epoch 115/1000\n",
      "245/245 [==============================] - 0s 985us/step - loss: 3996.5676 - val_loss: 8694.9041\n",
      "Epoch 116/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3992.3134 - val_loss: 8681.6872\n",
      "Epoch 117/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3988.0634 - val_loss: 8668.9390\n",
      "Epoch 118/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3983.8174 - val_loss: 8656.3797\n",
      "Epoch 119/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3979.5698 - val_loss: 8643.8355\n",
      "Epoch 120/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3975.3184 - val_loss: 8631.4806\n",
      "Epoch 121/1000\n",
      "245/245 [==============================] - 0s 978us/step - loss: 3971.0671 - val_loss: 8619.5707\n",
      "Epoch 122/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3966.8155 - val_loss: 8607.7885\n",
      "Epoch 123/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3962.5675 - val_loss: 8596.3002\n",
      "Epoch 124/1000\n",
      "245/245 [==============================] - 0s 999us/step - loss: 3958.3182 - val_loss: 8584.8648\n",
      "Epoch 125/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3954.0689 - val_loss: 8573.4125\n",
      "Epoch 126/1000\n",
      "245/245 [==============================] - 0s 997us/step - loss: 3949.8165 - val_loss: 8562.0062\n",
      "Epoch 127/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3945.5617 - val_loss: 8550.7805\n",
      "Epoch 128/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3941.3043 - val_loss: 8539.8781\n",
      "Epoch 129/1000\n",
      "245/245 [==============================] - 0s 980us/step - loss: 3937.0489 - val_loss: 8529.1123\n",
      "Epoch 130/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3932.8012 - val_loss: 8518.2842\n",
      "Epoch 131/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3928.5508 - val_loss: 8507.4372\n",
      "Epoch 132/1000\n",
      "245/245 [==============================] - 0s 985us/step - loss: 3924.3060 - val_loss: 8496.5517\n",
      "Epoch 133/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3920.0617 - val_loss: 8485.5681\n",
      "Epoch 134/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3915.8178 - val_loss: 8474.7003\n",
      "Epoch 135/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3911.5745 - val_loss: 8463.9321\n",
      "Epoch 136/1000\n",
      "245/245 [==============================] - 0s 991us/step - loss: 3907.3327 - val_loss: 8453.1911\n",
      "Epoch 137/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3903.0908 - val_loss: 8442.4442\n",
      "Epoch 138/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3898.8497 - val_loss: 8431.8911\n",
      "Epoch 139/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3894.6118 - val_loss: 8421.5159\n",
      "Epoch 140/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3890.3740 - val_loss: 8411.2042\n",
      "Epoch 141/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3886.1422 - val_loss: 8400.8226\n",
      "Epoch 142/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3881.9148 - val_loss: 8390.5265\n",
      "Epoch 143/1000\n",
      "245/245 [==============================] - 0s 968us/step - loss: 3877.6906 - val_loss: 8380.2400\n",
      "Epoch 144/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3873.4689 - val_loss: 8369.9647\n",
      "Epoch 145/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3869.2521 - val_loss: 8359.7235\n",
      "Epoch 146/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3865.0363 - val_loss: 8349.4796\n",
      "Epoch 147/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3860.8272 - val_loss: 8339.1626\n",
      "Epoch 148/1000\n",
      "245/245 [==============================] - 0s 969us/step - loss: 3856.6229 - val_loss: 8328.9585\n",
      "Epoch 149/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3852.4205 - val_loss: 8318.7497\n",
      "Epoch 150/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3848.2237 - val_loss: 8308.5178\n",
      "Epoch 151/1000\n",
      "245/245 [==============================] - 0s 930us/step - loss: 3844.0325 - val_loss: 8298.2558\n",
      "Epoch 152/1000\n",
      "245/245 [==============================] - 0s 992us/step - loss: 3839.8443 - val_loss: 8288.0846\n",
      "Epoch 153/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3835.6632 - val_loss: 8277.9047\n",
      "Epoch 154/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3831.4845 - val_loss: 8267.8204\n",
      "Epoch 155/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3827.3099 - val_loss: 8257.8015\n",
      "Epoch 156/1000\n",
      "245/245 [==============================] - 0s 973us/step - loss: 3823.1459 - val_loss: 8247.6704\n",
      "Epoch 157/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3818.9877 - val_loss: 8237.5341\n",
      "Epoch 158/1000\n",
      "245/245 [==============================] - 0s 990us/step - loss: 3814.8301 - val_loss: 8227.5537\n",
      "Epoch 159/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3810.6829 - val_loss: 8217.4729\n",
      "Epoch 160/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3806.5420 - val_loss: 8207.3935\n",
      "Epoch 161/1000\n",
      "245/245 [==============================] - 0s 987us/step - loss: 3802.4048 - val_loss: 8197.4268\n",
      "Epoch 162/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3798.2764 - val_loss: 8187.4536\n",
      "Epoch 163/1000\n",
      "245/245 [==============================] - 0s 983us/step - loss: 3794.1546 - val_loss: 8177.5041\n",
      "Epoch 164/1000\n",
      "245/245 [==============================] - 0s 1000us/step - loss: 3790.0388 - val_loss: 8167.6207\n",
      "Epoch 165/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3785.9293 - val_loss: 8157.7703\n",
      "Epoch 166/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3781.8257 - val_loss: 8148.0375\n",
      "Epoch 167/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3777.7270 - val_loss: 8138.4610\n",
      "Epoch 168/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3773.6397 - val_loss: 8128.7464\n",
      "Epoch 169/1000\n",
      "245/245 [==============================] - 0s 978us/step - loss: 3769.5601 - val_loss: 8119.0519\n",
      "Epoch 170/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3765.4844 - val_loss: 8109.4598\n",
      "Epoch 171/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3761.4151 - val_loss: 8099.9417\n",
      "Epoch 172/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3757.3583 - val_loss: 8090.2671\n",
      "Epoch 173/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3753.3098 - val_loss: 8080.5866\n",
      "Epoch 174/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3749.2680 - val_loss: 8070.9521\n",
      "Epoch 175/1000\n",
      "245/245 [==============================] - 0s 995us/step - loss: 3745.2334 - val_loss: 8061.3853\n",
      "Epoch 176/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3741.2067 - val_loss: 8051.9079\n",
      "Epoch 177/1000\n",
      "245/245 [==============================] - 0s 991us/step - loss: 3737.1870 - val_loss: 8042.4768\n",
      "Epoch 178/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3733.1764 - val_loss: 8033.0251\n",
      "Epoch 179/1000\n",
      "245/245 [==============================] - 0s 998us/step - loss: 3729.1749 - val_loss: 8023.5213\n",
      "Epoch 180/1000\n",
      "245/245 [==============================] - 0s 978us/step - loss: 3725.1797 - val_loss: 8014.0995\n",
      "Epoch 181/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3721.1956 - val_loss: 8004.6836\n",
      "Epoch 182/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3717.2192 - val_loss: 7995.2793\n",
      "Epoch 183/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3713.2508 - val_loss: 7985.9205\n",
      "Epoch 184/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3709.2909 - val_loss: 7976.6317\n",
      "Epoch 185/1000\n",
      "245/245 [==============================] - 0s 998us/step - loss: 3705.3366 - val_loss: 7967.4641\n",
      "Epoch 186/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 1ms/step - loss: 3701.3947 - val_loss: 7958.2618\n",
      "Epoch 187/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3697.4612 - val_loss: 7949.0898\n",
      "Epoch 188/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3693.5359 - val_loss: 7939.9454\n",
      "Epoch 189/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3689.6142 - val_loss: 7930.9693\n",
      "Epoch 190/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3685.7074 - val_loss: 7921.8519\n",
      "Epoch 191/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3681.8089 - val_loss: 7912.7146\n",
      "Epoch 192/1000\n",
      "245/245 [==============================] - 0s 980us/step - loss: 3677.9185 - val_loss: 7903.6382\n",
      "Epoch 193/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3674.0338 - val_loss: 7894.6927\n",
      "Epoch 194/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3670.1614 - val_loss: 7885.6922\n",
      "Epoch 195/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3666.2979 - val_loss: 7876.6898\n",
      "Epoch 196/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3662.4436 - val_loss: 7867.7462\n",
      "Epoch 197/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3658.5973 - val_loss: 7858.8528\n",
      "Epoch 198/1000\n",
      "245/245 [==============================] - 0s 1000us/step - loss: 3654.7608 - val_loss: 7850.0225\n",
      "Epoch 199/1000\n",
      "245/245 [==============================] - 0s 986us/step - loss: 3650.9294 - val_loss: 7841.3551\n",
      "Epoch 200/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3647.1056 - val_loss: 7832.6748\n",
      "Epoch 201/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3643.2966 - val_loss: 7823.7868\n",
      "Epoch 202/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3639.4990 - val_loss: 7814.8257\n",
      "Epoch 203/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3635.7050 - val_loss: 7806.0449\n",
      "Epoch 204/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3631.9222 - val_loss: 7797.3189\n",
      "Epoch 205/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3628.1494 - val_loss: 7788.6494\n",
      "Epoch 206/1000\n",
      "245/245 [==============================] - 0s 986us/step - loss: 3624.3848 - val_loss: 7780.0373\n",
      "Epoch 207/1000\n",
      "245/245 [==============================] - 0s 992us/step - loss: 3620.6266 - val_loss: 7771.5494\n",
      "Epoch 208/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3616.8814 - val_loss: 7763.0406\n",
      "Epoch 209/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3613.1444 - val_loss: 7754.5210\n",
      "Epoch 210/1000\n",
      "245/245 [==============================] - 0s 998us/step - loss: 3609.4166 - val_loss: 7746.0242\n",
      "Epoch 211/1000\n",
      "245/245 [==============================] - 0s 979us/step - loss: 3605.6978 - val_loss: 7737.5826\n",
      "Epoch 212/1000\n",
      "245/245 [==============================] - 0s 994us/step - loss: 3601.9882 - val_loss: 7729.1899\n",
      "Epoch 213/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3598.2873 - val_loss: 7720.8532\n",
      "Epoch 214/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3594.5958 - val_loss: 7712.5670\n",
      "Epoch 215/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3590.9141 - val_loss: 7704.3662\n",
      "Epoch 216/1000\n",
      "245/245 [==============================] - 0s 992us/step - loss: 3587.2408 - val_loss: 7696.1559\n",
      "Epoch 217/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3583.5763 - val_loss: 7687.9674\n",
      "Epoch 218/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3579.9205 - val_loss: 7679.8080\n",
      "Epoch 219/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3576.2743 - val_loss: 7671.7144\n",
      "Epoch 220/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3572.6375 - val_loss: 7663.6515\n",
      "Epoch 221/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3569.0088 - val_loss: 7655.6536\n",
      "Epoch 222/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3565.3858 - val_loss: 7647.7501\n",
      "Epoch 223/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3561.7760 - val_loss: 7639.7262\n",
      "Epoch 224/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3558.1753 - val_loss: 7631.6988\n",
      "Epoch 225/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3554.5860 - val_loss: 7623.6657\n",
      "Epoch 226/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3551.0008 - val_loss: 7615.8056\n",
      "Epoch 227/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3547.4268 - val_loss: 7607.9338\n",
      "Epoch 228/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3543.8621 - val_loss: 7600.0862\n",
      "Epoch 229/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3540.3058 - val_loss: 7592.2764\n",
      "Epoch 230/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3536.7590 - val_loss: 7584.5058\n",
      "Epoch 231/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3533.2203 - val_loss: 7576.7982\n",
      "Epoch 232/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3529.6879 - val_loss: 7569.1453\n",
      "Epoch 233/1000\n",
      "245/245 [==============================] - 0s 969us/step - loss: 3526.1687 - val_loss: 7561.4015\n",
      "Epoch 234/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3522.6555 - val_loss: 7553.7275\n",
      "Epoch 235/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3519.1531 - val_loss: 7546.0399\n",
      "Epoch 236/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3515.6578 - val_loss: 7538.4155\n",
      "Epoch 237/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3512.1733 - val_loss: 7530.7530\n",
      "Epoch 238/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3508.6976 - val_loss: 7523.1179\n",
      "Epoch 239/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3505.2272 - val_loss: 7515.5990\n",
      "Epoch 240/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3501.7685 - val_loss: 7508.0323\n",
      "Epoch 241/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3498.3197 - val_loss: 7500.4545\n",
      "Epoch 242/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3494.8796 - val_loss: 7492.9149\n",
      "Epoch 243/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3491.4479 - val_loss: 7485.4391\n",
      "Epoch 244/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3488.0204 - val_loss: 7478.0849\n",
      "Epoch 245/1000\n",
      "245/245 [==============================] - 0s 960us/step - loss: 3484.6099 - val_loss: 7470.5837\n",
      "Epoch 246/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3481.2049 - val_loss: 7463.2049\n",
      "Epoch 247/1000\n",
      "245/245 [==============================] - 0s 996us/step - loss: 3477.8025 - val_loss: 7455.9877\n",
      "Epoch 248/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3474.4174 - val_loss: 7448.6235\n",
      "Epoch 249/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3471.0359 - val_loss: 7441.3812\n",
      "Epoch 250/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3467.6675 - val_loss: 7434.0986\n",
      "Epoch 251/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3464.3017 - val_loss: 7426.9796\n",
      "Epoch 252/1000\n",
      "245/245 [==============================] - 0s 976us/step - loss: 3460.9511 - val_loss: 7419.7629\n",
      "Epoch 253/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3457.6014 - val_loss: 7412.7244\n",
      "Epoch 254/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3454.2689 - val_loss: 7405.5370\n",
      "Epoch 255/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3450.9340 - val_loss: 7398.5821\n",
      "Epoch 256/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3447.6178 - val_loss: 7391.4285\n",
      "Epoch 257/1000\n",
      "245/245 [==============================] - 0s 953us/step - loss: 3444.3101 - val_loss: 7384.2863\n",
      "Epoch 258/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3441.0013 - val_loss: 7377.4154\n",
      "Epoch 259/1000\n",
      "245/245 [==============================] - 0s 999us/step - loss: 3437.7102 - val_loss: 7370.3989\n",
      "Epoch 260/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 1ms/step - loss: 3434.4246 - val_loss: 7363.4475\n",
      "Epoch 261/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3431.1448 - val_loss: 7356.5986\n",
      "Epoch 262/1000\n",
      "245/245 [==============================] - 0s 972us/step - loss: 3427.8793 - val_loss: 7349.6665\n",
      "Epoch 263/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3424.6163 - val_loss: 7342.8877\n",
      "Epoch 264/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3421.3645 - val_loss: 7336.0803\n",
      "Epoch 265/1000\n",
      "245/245 [==============================] - 0s 991us/step - loss: 3418.1238 - val_loss: 7329.2694\n",
      "Epoch 266/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3414.8859 - val_loss: 7322.6852\n",
      "Epoch 267/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3411.6623 - val_loss: 7315.8818\n",
      "Epoch 268/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3408.4413 - val_loss: 7309.2371\n",
      "Epoch 269/1000\n",
      "245/245 [==============================] - 0s 977us/step - loss: 3405.2311 - val_loss: 7302.5814\n",
      "Epoch 270/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3402.0294 - val_loss: 7295.9610\n",
      "Epoch 271/1000\n",
      "245/245 [==============================] - 0s 921us/step - loss: 3398.8360 - val_loss: 7289.3634\n",
      "Epoch 272/1000\n",
      "245/245 [==============================] - 0s 999us/step - loss: 3395.6513 - val_loss: 7282.7739\n",
      "Epoch 273/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3392.4715 - val_loss: 7276.2930\n",
      "Epoch 274/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3389.3230 - val_loss: 7269.5019\n",
      "Epoch 275/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3386.1579 - val_loss: 7263.2881\n",
      "Epoch 276/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3383.0020 - val_loss: 7257.2240\n",
      "Epoch 277/1000\n",
      "245/245 [==============================] - 0s 986us/step - loss: 3379.8515 - val_loss: 7251.2325\n",
      "Epoch 278/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3376.7072 - val_loss: 7245.1885\n",
      "Epoch 279/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3373.5805 - val_loss: 7238.7729\n",
      "Epoch 280/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3370.4604 - val_loss: 7232.3169\n",
      "Epoch 281/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3367.3476 - val_loss: 7225.8995\n",
      "Epoch 282/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3364.2434 - val_loss: 7219.5564\n",
      "Epoch 283/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3361.1474 - val_loss: 7213.2577\n",
      "Epoch 284/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3358.0594 - val_loss: 7207.0117\n",
      "Epoch 285/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3354.9771 - val_loss: 7200.8331\n",
      "Epoch 286/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3351.9072 - val_loss: 7194.5799\n",
      "Epoch 287/1000\n",
      "245/245 [==============================] - 0s 996us/step - loss: 3348.8407 - val_loss: 7188.4498\n",
      "Epoch 288/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3345.7873 - val_loss: 7182.2791\n",
      "Epoch 289/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3342.7394 - val_loss: 7176.2264\n",
      "Epoch 290/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3339.6970 - val_loss: 7170.2228\n",
      "Epoch 291/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3336.6676 - val_loss: 7164.1357\n",
      "Epoch 292/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3333.6412 - val_loss: 7158.1657\n",
      "Epoch 293/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3330.6266 - val_loss: 7152.1580\n",
      "Epoch 294/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3327.6163 - val_loss: 7146.2388\n",
      "Epoch 295/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3324.6163 - val_loss: 7140.2879\n",
      "Epoch 296/1000\n",
      "245/245 [==============================] - 0s 986us/step - loss: 3321.6267 - val_loss: 7134.3724\n",
      "Epoch 297/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3318.6399 - val_loss: 7128.5081\n",
      "Epoch 298/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3315.6644 - val_loss: 7122.5968\n",
      "Epoch 299/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3312.6982 - val_loss: 7116.6812\n",
      "Epoch 300/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3309.7346 - val_loss: 7110.9171\n",
      "Epoch 301/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3306.7830 - val_loss: 7105.1360\n",
      "Epoch 302/1000\n",
      "245/245 [==============================] - 0s 979us/step - loss: 3303.8379 - val_loss: 7099.3732\n",
      "Epoch 303/1000\n",
      "245/245 [==============================] - 0s 988us/step - loss: 3300.9015 - val_loss: 7093.6429\n",
      "Epoch 304/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3297.9745 - val_loss: 7087.9207\n",
      "Epoch 305/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3295.0506 - val_loss: 7082.3432\n",
      "Epoch 306/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3292.1380 - val_loss: 7076.7325\n",
      "Epoch 307/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3289.2326 - val_loss: 7071.1279\n",
      "Epoch 308/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3286.3352 - val_loss: 7065.5594\n",
      "Epoch 309/1000\n",
      "245/245 [==============================] - 0s 997us/step - loss: 3283.4454 - val_loss: 7060.0177\n",
      "Epoch 310/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3280.5633 - val_loss: 7054.5365\n",
      "Epoch 311/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3277.6899 - val_loss: 7049.0438\n",
      "Epoch 312/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3274.8239 - val_loss: 7043.5681\n",
      "Epoch 313/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3271.9657 - val_loss: 7038.1238\n",
      "Epoch 314/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3269.1146 - val_loss: 7032.7213\n",
      "Epoch 315/1000\n",
      "245/245 [==============================] - 0s 977us/step - loss: 3266.2720 - val_loss: 7027.3244\n",
      "Epoch 316/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3263.4356 - val_loss: 7021.9735\n",
      "Epoch 317/1000\n",
      "245/245 [==============================] - 0s 997us/step - loss: 3260.6089 - val_loss: 7016.5414\n",
      "Epoch 318/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3257.7902 - val_loss: 7011.1902\n",
      "Epoch 319/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3254.9787 - val_loss: 7005.9120\n",
      "Epoch 320/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3252.1842 - val_loss: 7000.5276\n",
      "Epoch 321/1000\n",
      "245/245 [==============================] - 0s 979us/step - loss: 3249.3865 - val_loss: 6995.4404\n",
      "Epoch 322/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3246.5978 - val_loss: 6990.4357\n",
      "Epoch 323/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3243.8172 - val_loss: 6985.4285\n",
      "Epoch 324/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3241.0417 - val_loss: 6980.4516\n",
      "Epoch 325/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3238.2785 - val_loss: 6975.3727\n",
      "Epoch 326/1000\n",
      "245/245 [==============================] - 0s 993us/step - loss: 3235.5151 - val_loss: 6970.4054\n",
      "Epoch 327/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3232.7672 - val_loss: 6965.2072\n",
      "Epoch 328/1000\n",
      "245/245 [==============================] - 0s 980us/step - loss: 3230.0265 - val_loss: 6959.9687\n",
      "Epoch 329/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3227.2913 - val_loss: 6954.8291\n",
      "Epoch 330/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3224.5668 - val_loss: 6949.6576\n",
      "Epoch 331/1000\n",
      "245/245 [==============================] - 0s 976us/step - loss: 3221.8530 - val_loss: 6944.4888\n",
      "Epoch 332/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3219.1381 - val_loss: 6939.5829\n",
      "Epoch 333/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3216.4411 - val_loss: 6934.4958\n",
      "Epoch 334/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 996us/step - loss: 3213.7475 - val_loss: 6929.5328\n",
      "Epoch 335/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3211.0599 - val_loss: 6924.6663\n",
      "Epoch 336/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3208.3805 - val_loss: 6919.7684\n",
      "Epoch 337/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3205.7039 - val_loss: 6914.9178\n",
      "Epoch 338/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3203.0478 - val_loss: 6909.8027\n",
      "Epoch 339/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3200.3946 - val_loss: 6904.8864\n",
      "Epoch 340/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3197.7498 - val_loss: 6900.0716\n",
      "Epoch 341/1000\n",
      "245/245 [==============================] - 0s 975us/step - loss: 3195.1160 - val_loss: 6895.3002\n",
      "Epoch 342/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3192.4865 - val_loss: 6890.6552\n",
      "Epoch 343/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3189.8557 - val_loss: 6886.1764\n",
      "Epoch 344/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3187.2540 - val_loss: 6881.1990\n",
      "Epoch 345/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3184.6354 - val_loss: 6876.7102\n",
      "Epoch 346/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3182.0540 - val_loss: 6871.7024\n",
      "Epoch 347/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3179.4641 - val_loss: 6867.1791\n",
      "Epoch 348/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3176.8730 - val_loss: 6862.9375\n",
      "Epoch 349/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3174.3044 - val_loss: 6858.2481\n",
      "Epoch 350/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3171.7435 - val_loss: 6853.5886\n",
      "Epoch 351/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3169.2006 - val_loss: 6848.9113\n",
      "Epoch 352/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3166.6478 - val_loss: 6844.7635\n",
      "Epoch 353/1000\n",
      "245/245 [==============================] - 0s 993us/step - loss: 3164.1106 - val_loss: 6840.6088\n",
      "Epoch 354/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3161.5728 - val_loss: 6836.5810\n",
      "Epoch 355/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3159.0578 - val_loss: 6832.2070\n",
      "Epoch 356/1000\n",
      "245/245 [==============================] - 0s 998us/step - loss: 3156.5315 - val_loss: 6828.2340\n",
      "Epoch 357/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3154.0354 - val_loss: 6823.7546\n",
      "Epoch 358/1000\n",
      "245/245 [==============================] - 0s 990us/step - loss: 3151.5360 - val_loss: 6819.6479\n",
      "Epoch 359/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3149.0319 - val_loss: 6815.7866\n",
      "Epoch 360/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3146.5716 - val_loss: 6811.1558\n",
      "Epoch 361/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3144.0805 - val_loss: 6807.4528\n",
      "Epoch 362/1000\n",
      "245/245 [==============================] - 0s 991us/step - loss: 3141.6126 - val_loss: 6803.3537\n",
      "Epoch 363/1000\n",
      "245/245 [==============================] - 0s 963us/step - loss: 3139.1569 - val_loss: 6798.9345\n",
      "Epoch 364/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3136.7121 - val_loss: 6794.5138\n",
      "Epoch 365/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3134.2940 - val_loss: 6789.9878\n",
      "Epoch 366/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3131.8522 - val_loss: 6786.2624\n",
      "Epoch 367/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3129.4450 - val_loss: 6782.2631\n",
      "Epoch 368/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3127.0234 - val_loss: 6778.8618\n",
      "Epoch 369/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3124.6176 - val_loss: 6775.3539\n",
      "Epoch 370/1000\n",
      "245/245 [==============================] - 0s 983us/step - loss: 3122.2199 - val_loss: 6771.7362\n",
      "Epoch 371/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3119.8233 - val_loss: 6768.1677\n",
      "Epoch 372/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3117.4565 - val_loss: 6764.1022\n",
      "Epoch 373/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3115.0724 - val_loss: 6760.6219\n",
      "Epoch 374/1000\n",
      "245/245 [==============================] - 0s 983us/step - loss: 3112.7220 - val_loss: 6756.6746\n",
      "Epoch 375/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3110.3567 - val_loss: 6753.2597\n",
      "Epoch 376/1000\n",
      "245/245 [==============================] - 0s 999us/step - loss: 3108.0198 - val_loss: 6749.4182\n",
      "Epoch 377/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3105.6587 - val_loss: 6746.0364\n",
      "Epoch 378/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3103.3505 - val_loss: 6741.6120\n",
      "Epoch 379/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3101.0176 - val_loss: 6737.9260\n",
      "Epoch 380/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3098.7120 - val_loss: 6733.8376\n",
      "Epoch 381/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3096.4078 - val_loss: 6729.8799\n",
      "Epoch 382/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3094.1291 - val_loss: 6725.7234\n",
      "Epoch 383/1000\n",
      "245/245 [==============================] - 0s 958us/step - loss: 3091.8364 - val_loss: 6722.1896\n",
      "Epoch 384/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3089.5710 - val_loss: 6718.2903\n",
      "Epoch 385/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3087.3006 - val_loss: 6714.7217\n",
      "Epoch 386/1000\n",
      "245/245 [==============================] - 0s 978us/step - loss: 3085.0559 - val_loss: 6710.8841\n",
      "Epoch 387/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3082.8001 - val_loss: 6707.4888\n",
      "Epoch 388/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3080.5644 - val_loss: 6703.8183\n",
      "Epoch 389/1000\n",
      "245/245 [==============================] - 0s 971us/step - loss: 3078.3518 - val_loss: 6699.8920\n",
      "Epoch 390/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3076.1199 - val_loss: 6696.7096\n",
      "Epoch 391/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3073.9230 - val_loss: 6692.9819\n",
      "Epoch 392/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3071.7267 - val_loss: 6689.5628\n",
      "Epoch 393/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3069.5247 - val_loss: 6686.4498\n",
      "Epoch 394/1000\n",
      "245/245 [==============================] - 0s 979us/step - loss: 3067.3624 - val_loss: 6682.6643\n",
      "Epoch 395/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3065.1775 - val_loss: 6679.5906\n",
      "Epoch 396/1000\n",
      "245/245 [==============================] - 0s 992us/step - loss: 3063.0377 - val_loss: 6675.9035\n",
      "Epoch 397/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3060.8781 - val_loss: 6672.9876\n",
      "Epoch 398/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3058.7524 - val_loss: 6669.5651\n",
      "Epoch 399/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3056.6179 - val_loss: 6666.7127\n",
      "Epoch 400/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3054.4845 - val_loss: 6663.9254\n",
      "Epoch 401/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3052.3852 - val_loss: 6660.5067\n",
      "Epoch 402/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3050.2717 - val_loss: 6657.5466\n",
      "Epoch 403/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3048.2028 - val_loss: 6653.9770\n",
      "Epoch 404/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3046.0884 - val_loss: 6651.5828\n",
      "Epoch 405/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3044.0528 - val_loss: 6647.7717\n",
      "Epoch 406/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3041.9616 - val_loss: 6645.4497\n",
      "Epoch 407/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3039.9330 - val_loss: 6642.0125\n",
      "Epoch 408/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 1ms/step - loss: 3037.8727 - val_loss: 6639.4540\n",
      "Epoch 409/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3035.8527 - val_loss: 6636.2969\n",
      "Epoch 410/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3033.8342 - val_loss: 6633.3468\n",
      "Epoch 411/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3031.8129 - val_loss: 6630.7360\n",
      "Epoch 412/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3029.8273 - val_loss: 6627.5917\n",
      "Epoch 413/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3027.8296 - val_loss: 6625.0543\n",
      "Epoch 414/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3025.8489 - val_loss: 6622.3183\n",
      "Epoch 415/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3023.8874 - val_loss: 6619.4188\n",
      "Epoch 416/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3021.9208 - val_loss: 6616.9207\n",
      "Epoch 417/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3019.9739 - val_loss: 6614.1761\n",
      "Epoch 418/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3018.0400 - val_loss: 6611.4068\n",
      "Epoch 419/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3016.1098 - val_loss: 6608.8518\n",
      "Epoch 420/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3014.1967 - val_loss: 6606.1907\n",
      "Epoch 421/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3012.2820 - val_loss: 6603.7523\n",
      "Epoch 422/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3010.4033 - val_loss: 6600.8332\n",
      "Epoch 423/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3008.5035 - val_loss: 6598.6929\n",
      "Epoch 424/1000\n",
      "245/245 [==============================] - 0s 996us/step - loss: 3006.6423 - val_loss: 6595.9411\n",
      "Epoch 425/1000\n",
      "245/245 [==============================] - 0s 978us/step - loss: 3004.7733 - val_loss: 6593.6398\n",
      "Epoch 426/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3002.9218 - val_loss: 6591.1879\n",
      "Epoch 427/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 3001.0864 - val_loss: 6588.6442\n",
      "Epoch 428/1000\n",
      "245/245 [==============================] - 0s 990us/step - loss: 2999.2468 - val_loss: 6586.4292\n",
      "Epoch 429/1000\n",
      "245/245 [==============================] - 0s 990us/step - loss: 2997.4421 - val_loss: 6583.7137\n",
      "Epoch 430/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2995.6243 - val_loss: 6581.6295\n",
      "Epoch 431/1000\n",
      "245/245 [==============================] - 0s 991us/step - loss: 2993.8387 - val_loss: 6579.1670\n",
      "Epoch 432/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2992.0405 - val_loss: 6577.1936\n",
      "Epoch 433/1000\n",
      "245/245 [==============================] - 0s 986us/step - loss: 2990.2845 - val_loss: 6574.5987\n",
      "Epoch 434/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2988.4994 - val_loss: 6572.8574\n",
      "Epoch 435/1000\n",
      "245/245 [==============================] - 0s 980us/step - loss: 2986.7782 - val_loss: 6570.0784\n",
      "Epoch 436/1000\n",
      "245/245 [==============================] - 0s 999us/step - loss: 2985.0030 - val_loss: 6568.6929\n",
      "Epoch 437/1000\n",
      "245/245 [==============================] - 0s 995us/step - loss: 2983.3057 - val_loss: 6565.7699\n",
      "Epoch 438/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2981.5632 - val_loss: 6564.1639\n",
      "Epoch 439/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2979.8779 - val_loss: 6561.5955\n",
      "Epoch 440/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2978.1729 - val_loss: 6559.7705\n",
      "Epoch 441/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2976.5058 - val_loss: 6557.5985\n",
      "Epoch 442/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2974.8111 - val_loss: 6556.1576\n",
      "Epoch 443/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2973.1711 - val_loss: 6553.7440\n",
      "Epoch 444/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2971.5203 - val_loss: 6551.9234\n",
      "Epoch 445/1000\n",
      "245/245 [==============================] - 0s 976us/step - loss: 2969.8852 - val_loss: 6550.1418\n",
      "Epoch 446/1000\n",
      "245/245 [==============================] - 0s 999us/step - loss: 2968.2657 - val_loss: 6548.2920\n",
      "Epoch 447/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2966.6418 - val_loss: 6546.7230\n",
      "Epoch 448/1000\n",
      "245/245 [==============================] - 0s 963us/step - loss: 2965.0505 - val_loss: 6544.6265\n",
      "Epoch 449/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2963.4677 - val_loss: 6542.7717\n",
      "Epoch 450/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2961.8757 - val_loss: 6541.3526\n",
      "Epoch 451/1000\n",
      "245/245 [==============================] - 0s 998us/step - loss: 2960.3174 - val_loss: 6539.3471\n",
      "Epoch 452/1000\n",
      "245/245 [==============================] - 0s 991us/step - loss: 2958.7756 - val_loss: 6537.4077\n",
      "Epoch 453/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2957.2263 - val_loss: 6536.0630\n",
      "Epoch 454/1000\n",
      "245/245 [==============================] - 0s 987us/step - loss: 2955.7020 - val_loss: 6534.3627\n",
      "Epoch 455/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2954.1795 - val_loss: 6532.8329\n",
      "Epoch 456/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2952.6749 - val_loss: 6531.1457\n",
      "Epoch 457/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2951.1954 - val_loss: 6529.3514\n",
      "Epoch 458/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2949.7059 - val_loss: 6528.1355\n",
      "Epoch 459/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2948.2391 - val_loss: 6526.6051\n",
      "Epoch 460/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2946.7878 - val_loss: 6525.0555\n",
      "Epoch 461/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2945.3458 - val_loss: 6523.6681\n",
      "Epoch 462/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2943.9103 - val_loss: 6522.4324\n",
      "Epoch 463/1000\n",
      "245/245 [==============================] - 0s 998us/step - loss: 2942.4885 - val_loss: 6520.9764\n",
      "Epoch 464/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2941.0812 - val_loss: 6519.4067\n",
      "Epoch 465/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2939.7095 - val_loss: 6517.7042\n",
      "Epoch 466/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2938.3029 - val_loss: 6517.0517\n",
      "Epoch 467/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2936.9380 - val_loss: 6515.5113\n",
      "Epoch 468/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2935.5976 - val_loss: 6513.8791\n",
      "Epoch 469/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2934.2310 - val_loss: 6513.1148\n",
      "Epoch 470/1000\n",
      "245/245 [==============================] - 0s 971us/step - loss: 2932.9305 - val_loss: 6511.3982\n",
      "Epoch 471/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2931.5734 - val_loss: 6511.0721\n",
      "Epoch 472/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2930.2924 - val_loss: 6509.1935\n",
      "Epoch 473/1000\n",
      "245/245 [==============================] - 0s 958us/step - loss: 2928.9889 - val_loss: 6508.2519\n",
      "Epoch 474/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2927.7086 - val_loss: 6507.1188\n",
      "Epoch 475/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2926.4485 - val_loss: 6506.0160\n",
      "Epoch 476/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2925.1665 - val_loss: 6505.4054\n",
      "Epoch 477/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2923.9509 - val_loss: 6503.6969\n",
      "Epoch 478/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2922.6963 - val_loss: 6503.1884\n",
      "Epoch 479/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2921.4907 - val_loss: 6501.9221\n",
      "Epoch 480/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2920.2735 - val_loss: 6501.1823\n",
      "Epoch 481/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2919.0834 - val_loss: 6500.1546\n",
      "Epoch 482/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245/245 [==============================] - 0s 1ms/step - loss: 2917.9125 - val_loss: 6499.0975\n",
      "Epoch 483/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2916.7213 - val_loss: 6498.7048\n",
      "Epoch 484/1000\n",
      "245/245 [==============================] - 0s 987us/step - loss: 2915.5801 - val_loss: 6497.4185\n",
      "Epoch 485/1000\n",
      "245/245 [==============================] - 0s 999us/step - loss: 2914.4196 - val_loss: 6496.8660\n",
      "Epoch 486/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2913.3031 - val_loss: 6495.6912\n",
      "Epoch 487/1000\n",
      "245/245 [==============================] - 0s 992us/step - loss: 2912.1756 - val_loss: 6495.1574\n",
      "Epoch 488/1000\n",
      "245/245 [==============================] - 0s 989us/step - loss: 2911.0763 - val_loss: 6494.2980\n",
      "Epoch 489/1000\n",
      "245/245 [==============================] - 0s 948us/step - loss: 2909.9656 - val_loss: 6493.8886\n",
      "Epoch 490/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2908.8956 - val_loss: 6492.7881\n",
      "Epoch 491/1000\n",
      "245/245 [==============================] - 0s 989us/step - loss: 2907.8265 - val_loss: 6492.1571\n",
      "Epoch 492/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2906.7616 - val_loss: 6491.6318\n",
      "Epoch 493/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2905.7266 - val_loss: 6490.8571\n",
      "Epoch 494/1000\n",
      "245/245 [==============================] - 0s 962us/step - loss: 2904.6798 - val_loss: 6490.5335\n",
      "Epoch 495/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2903.6708 - val_loss: 6489.6355\n",
      "Epoch 496/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2902.6648 - val_loss: 6489.1228\n",
      "Epoch 497/1000\n",
      "245/245 [==============================] - 0s 997us/step - loss: 2901.6511 - val_loss: 6488.9542\n",
      "Epoch 498/1000\n",
      "245/245 [==============================] - 0s 968us/step - loss: 2900.6780 - val_loss: 6488.0914\n",
      "Epoch 499/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2899.7032 - val_loss: 6487.6103\n",
      "Epoch 500/1000\n",
      "245/245 [==============================] - 0s 992us/step - loss: 2898.7554 - val_loss: 6487.0177\n",
      "Epoch 501/1000\n",
      "245/245 [==============================] - 0s 981us/step - loss: 2897.7926 - val_loss: 6486.9364\n",
      "Epoch 502/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2896.8734 - val_loss: 6486.2365\n",
      "Epoch 503/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2895.9260 - val_loss: 6486.2841\n",
      "Epoch 504/1000\n",
      "245/245 [==============================] - 0s 959us/step - loss: 2895.0338 - val_loss: 6485.3012\n",
      "Epoch 505/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2894.1367 - val_loss: 6485.0415\n",
      "Epoch 506/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2893.2385 - val_loss: 6484.9871\n",
      "Epoch 507/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2892.3636 - val_loss: 6484.5393\n",
      "Epoch 508/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2891.5017 - val_loss: 6484.0997\n",
      "Epoch 509/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2890.6661 - val_loss: 6483.6614\n",
      "Epoch 510/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2889.8080 - val_loss: 6483.9237\n",
      "Epoch 511/1000\n",
      "245/245 [==============================] - 0s 950us/step - loss: 2888.9760 - val_loss: 6483.5378\n",
      "Epoch 512/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2888.1730 - val_loss: 6482.8670\n",
      "Epoch 513/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2887.3686 - val_loss: 6482.8535\n",
      "Epoch 514/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2886.5579 - val_loss: 6482.9907\n",
      "Epoch 515/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2885.7814 - val_loss: 6482.4499\n",
      "Epoch 516/1000\n",
      "245/245 [==============================] - 0s 974us/step - loss: 2885.0263 - val_loss: 6482.0939\n",
      "Epoch 517/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2884.2429 - val_loss: 6482.5480\n",
      "Epoch 518/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2883.5187 - val_loss: 6481.9458\n",
      "Epoch 519/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2882.7871 - val_loss: 6482.1623\n",
      "Epoch 520/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2882.0466 - val_loss: 6482.4294\n",
      "Epoch 521/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2881.3575 - val_loss: 6482.0642\n",
      "Epoch 522/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2880.6177 - val_loss: 6482.7360\n",
      "Epoch 523/1000\n",
      "245/245 [==============================] - 0s 977us/step - loss: 2879.9673 - val_loss: 6481.9704\n",
      "Epoch 524/1000\n",
      "245/245 [==============================] - 0s 973us/step - loss: 2879.2325 - val_loss: 6482.9451\n",
      "Epoch 525/1000\n",
      "245/245 [==============================] - 0s 965us/step - loss: 2878.6136 - val_loss: 6481.8791\n",
      "Epoch 526/1000\n",
      "245/245 [==============================] - 0s 930us/step - loss: 2877.9141 - val_loss: 6482.8039\n",
      "Epoch 527/1000\n",
      "245/245 [==============================] - 0s 940us/step - loss: 2877.2721 - val_loss: 6482.3165\n",
      "Epoch 528/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2876.6542 - val_loss: 6482.0439\n",
      "Epoch 529/1000\n",
      "245/245 [==============================] - 0s 987us/step - loss: 2875.9778 - val_loss: 6482.9224\n",
      "Epoch 530/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2875.3948 - val_loss: 6481.8528\n",
      "Epoch 531/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2874.7757 - val_loss: 6482.2128\n",
      "Epoch 532/1000\n",
      "245/245 [==============================] - 0s 985us/step - loss: 2874.1891 - val_loss: 6482.2347\n",
      "Epoch 533/1000\n",
      "245/245 [==============================] - 0s 995us/step - loss: 2873.5793 - val_loss: 6482.7734\n",
      "Epoch 534/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2873.0150 - val_loss: 6482.4448\n",
      "Epoch 535/1000\n",
      "245/245 [==============================] - 0s 998us/step - loss: 2872.4291 - val_loss: 6482.7473\n",
      "Epoch 536/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2871.9037 - val_loss: 6482.3391\n",
      "Epoch 537/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2871.3183 - val_loss: 6483.2468\n",
      "Epoch 538/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2870.8172 - val_loss: 6482.7123\n",
      "Epoch 539/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2870.2585 - val_loss: 6483.6411\n",
      "Epoch 540/1000\n",
      "245/245 [==============================] - 0s 959us/step - loss: 2869.7600 - val_loss: 6483.4317\n",
      "Epoch 541/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2869.2318 - val_loss: 6483.9997\n",
      "Epoch 542/1000\n",
      "245/245 [==============================] - 0s 998us/step - loss: 2868.7475 - val_loss: 6483.8365\n",
      "Epoch 543/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2868.2447 - val_loss: 6484.3376\n",
      "Epoch 544/1000\n",
      "245/245 [==============================] - 0s 985us/step - loss: 2867.7740 - val_loss: 6484.4388\n",
      "Epoch 545/1000\n",
      "245/245 [==============================] - 0s 984us/step - loss: 2867.2852 - val_loss: 6485.0261\n",
      "Epoch 546/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2866.8305 - val_loss: 6485.0324\n",
      "Epoch 547/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2866.3611 - val_loss: 6485.4650\n",
      "Epoch 548/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2865.9345 - val_loss: 6485.3677\n",
      "Epoch 549/1000\n",
      "245/245 [==============================] - 0s 1ms/step - loss: 2865.4778 - val_loss: 6486.0371\n",
      "Epoch 550/1000\n",
      "245/245 [==============================] - 0s 969us/step - loss: 2865.0691 - val_loss: 6486.0903\n",
      "Train on 244 samples, validate on 82 samples\n",
      "Epoch 1/1000\n",
      "244/244 [==============================] - 54s 220ms/step - loss: 26972.5874 - val_loss: 177271.5929\n",
      "Epoch 2/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26944.9113 - val_loss: 177153.0135\n",
      "Epoch 3/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26901.2543 - val_loss: 176925.9733\n",
      "Epoch 4/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26833.0333 - val_loss: 176583.3598\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 26714.7146 - val_loss: 175955.9806\n",
      "Epoch 6/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26488.3164 - val_loss: 174800.1494\n",
      "Epoch 7/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26098.4373 - val_loss: 172805.9301\n",
      "Epoch 8/1000\n",
      "244/244 [==============================] - 0s 990us/step - loss: 25471.7030 - val_loss: 169686.3617\n",
      "Epoch 9/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 24578.8524 - val_loss: 165331.5517\n",
      "Epoch 10/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 23426.6238 - val_loss: 159706.2263\n",
      "Epoch 11/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 22060.6305 - val_loss: 152857.9530\n",
      "Epoch 12/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 20561.0886 - val_loss: 145058.5106\n",
      "Epoch 13/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 19060.9703 - val_loss: 136796.2422\n",
      "Epoch 14/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 17701.0281 - val_loss: 128692.2571\n",
      "Epoch 15/1000\n",
      "244/244 [==============================] - 0s 998us/step - loss: 16577.6848 - val_loss: 121215.0189\n",
      "Epoch 16/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 15709.0865 - val_loss: 114649.5956\n",
      "Epoch 17/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 15072.1997 - val_loss: 109123.7350\n",
      "Epoch 18/1000\n",
      "244/244 [==============================] - 0s 979us/step - loss: 14611.1986 - val_loss: 104563.1375\n",
      "Epoch 19/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 14268.6276 - val_loss: 100806.7415\n",
      "Epoch 20/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 14000.1039 - val_loss: 97682.9643\n",
      "Epoch 21/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13776.1407 - val_loss: 95037.4951\n",
      "Epoch 22/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13578.4840 - val_loss: 92746.0554\n",
      "Epoch 23/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13396.3274 - val_loss: 90713.8626\n",
      "Epoch 24/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13223.3481 - val_loss: 88870.5281\n",
      "Epoch 25/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13055.8062 - val_loss: 87164.3816\n",
      "Epoch 26/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12891.4360 - val_loss: 85557.6481\n",
      "Epoch 27/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12728.8091 - val_loss: 84022.6063\n",
      "Epoch 28/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12568.4424 - val_loss: 82527.3992\n",
      "Epoch 29/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12408.9921 - val_loss: 81073.2800\n",
      "Epoch 30/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12249.7085 - val_loss: 79648.5760\n",
      "Epoch 31/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12090.4311 - val_loss: 78242.1449\n",
      "Epoch 32/1000\n",
      "244/244 [==============================] - 0s 1000us/step - loss: 11930.9550 - val_loss: 76848.4237\n",
      "Epoch 33/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11770.9711 - val_loss: 75467.1506\n",
      "Epoch 34/1000\n",
      "244/244 [==============================] - 0s 1000us/step - loss: 11610.3771 - val_loss: 74090.3317\n",
      "Epoch 35/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11448.8987 - val_loss: 72717.3065\n",
      "Epoch 36/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11286.4944 - val_loss: 71346.9584\n",
      "Epoch 37/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11123.1218 - val_loss: 69977.0292\n",
      "Epoch 38/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10958.7169 - val_loss: 68605.9357\n",
      "Epoch 39/1000\n",
      "244/244 [==============================] - 0s 980us/step - loss: 10793.2702 - val_loss: 67231.0053\n",
      "Epoch 40/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10626.7487 - val_loss: 65852.3631\n",
      "Epoch 41/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10459.1612 - val_loss: 64469.4462\n",
      "Epoch 42/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10290.5145 - val_loss: 63082.5120\n",
      "Epoch 43/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10120.8375 - val_loss: 61691.3704\n",
      "Epoch 44/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9950.2086 - val_loss: 60294.8304\n",
      "Epoch 45/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9778.6617 - val_loss: 58894.0639\n",
      "Epoch 46/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9606.2930 - val_loss: 57489.2607\n",
      "Epoch 47/1000\n",
      "244/244 [==============================] - 0s 995us/step - loss: 9433.2020 - val_loss: 56080.5207\n",
      "Epoch 48/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9259.5115 - val_loss: 54669.0382\n",
      "Epoch 49/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9085.3468 - val_loss: 53255.3776\n",
      "Epoch 50/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8910.8796 - val_loss: 51839.9891\n",
      "Epoch 51/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8736.2850 - val_loss: 50424.6571\n",
      "Epoch 52/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8561.7823 - val_loss: 49009.4201\n",
      "Epoch 53/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8387.5213 - val_loss: 47595.9801\n",
      "Epoch 54/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8216.4650 - val_loss: 46175.3286\n",
      "Epoch 55/1000\n",
      "244/244 [==============================] - 0s 994us/step - loss: 8047.3791 - val_loss: 44763.9900\n",
      "Epoch 56/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7879.7627 - val_loss: 43365.4720\n",
      "Epoch 57/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7713.9679 - val_loss: 41980.4063\n",
      "Epoch 58/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7550.0893 - val_loss: 40611.3587\n",
      "Epoch 59/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7388.6488 - val_loss: 39256.0297\n",
      "Epoch 60/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7229.8303 - val_loss: 37917.8100\n",
      "Epoch 61/1000\n",
      "244/244 [==============================] - 0s 984us/step - loss: 7073.8184 - val_loss: 36601.0961\n",
      "Epoch 62/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6920.8114 - val_loss: 35306.4205\n",
      "Epoch 63/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6771.1123 - val_loss: 34036.9409\n",
      "Epoch 64/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6625.0024 - val_loss: 32793.4521\n",
      "Epoch 65/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6482.8205 - val_loss: 31576.7652\n",
      "Epoch 66/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6344.8302 - val_loss: 30388.4799\n",
      "Epoch 67/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6211.2999 - val_loss: 29230.3686\n",
      "Epoch 68/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6082.4923 - val_loss: 28102.8099\n",
      "Epoch 69/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5958.6760 - val_loss: 27007.0826\n",
      "Epoch 70/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5840.0375 - val_loss: 25946.2488\n",
      "Epoch 71/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5726.7617 - val_loss: 24921.3356\n",
      "Epoch 72/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5619.0284 - val_loss: 23932.7664\n",
      "Epoch 73/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5516.9569 - val_loss: 22982.0296\n",
      "Epoch 74/1000\n",
      "244/244 [==============================] - 0s 992us/step - loss: 5420.6252 - val_loss: 22070.0421\n",
      "Epoch 75/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5330.0972 - val_loss: 21196.8671\n",
      "Epoch 76/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5245.4316 - val_loss: 20364.3044\n",
      "Epoch 77/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5166.4252 - val_loss: 19571.2606\n",
      "Epoch 78/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5093.1017 - val_loss: 18818.4992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5025.3202 - val_loss: 18105.8457\n",
      "Epoch 80/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4962.9290 - val_loss: 17432.9695\n",
      "Epoch 81/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4905.7293 - val_loss: 16799.2993\n",
      "Epoch 82/1000\n",
      "244/244 [==============================] - 0s 979us/step - loss: 4853.4982 - val_loss: 16204.1127\n",
      "Epoch 83/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4805.9835 - val_loss: 15646.4421\n",
      "Epoch 84/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4762.9136 - val_loss: 15125.0944\n",
      "Epoch 85/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4724.0021 - val_loss: 14639.0135\n",
      "Epoch 86/1000\n",
      "244/244 [==============================] - 0s 990us/step - loss: 4688.9493 - val_loss: 14186.9018\n",
      "Epoch 87/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4657.4566 - val_loss: 13767.7760\n",
      "Epoch 88/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4629.2243 - val_loss: 13379.3552\n",
      "Epoch 89/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4603.9555 - val_loss: 13020.3451\n",
      "Epoch 90/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4581.3582 - val_loss: 12688.9199\n",
      "Epoch 91/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4561.2302 - val_loss: 12382.9312\n",
      "Epoch 92/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4543.5103 - val_loss: 12099.9796\n",
      "Epoch 93/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4527.7038 - val_loss: 11841.5343\n",
      "Epoch 94/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4513.5350 - val_loss: 11606.2000\n",
      "Epoch 95/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4500.7519 - val_loss: 11391.8894\n",
      "Epoch 96/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4489.1706 - val_loss: 11196.6779\n",
      "Epoch 97/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4478.6459 - val_loss: 11018.3812\n",
      "Epoch 98/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4468.9737 - val_loss: 10855.9384\n",
      "Epoch 99/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4460.0437 - val_loss: 10707.5818\n",
      "Epoch 100/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4451.7446 - val_loss: 10572.2060\n",
      "Epoch 101/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4443.9811 - val_loss: 10448.7277\n",
      "Epoch 102/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4436.6737 - val_loss: 10335.8525\n",
      "Epoch 103/1000\n",
      "244/244 [==============================] - 0s 997us/step - loss: 4429.7458 - val_loss: 10232.4915\n",
      "Epoch 104/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4423.1353 - val_loss: 10137.8054\n",
      "Epoch 105/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4416.7871 - val_loss: 10051.1565\n",
      "Epoch 106/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4410.6616 - val_loss: 9971.8241\n",
      "Epoch 107/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4404.7263 - val_loss: 9899.3976\n",
      "Epoch 108/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4398.9644 - val_loss: 9832.5737\n",
      "Epoch 109/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4393.3199 - val_loss: 9771.7303\n",
      "Epoch 110/1000\n",
      "244/244 [==============================] - 0s 986us/step - loss: 4387.7580 - val_loss: 9716.1927\n",
      "Epoch 111/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4382.2933 - val_loss: 9665.1622\n",
      "Epoch 112/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4376.8855 - val_loss: 9618.6087\n",
      "Epoch 113/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4371.5054 - val_loss: 9576.3327\n",
      "Epoch 114/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4366.1880 - val_loss: 9537.0740\n",
      "Epoch 115/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4360.9144 - val_loss: 9500.1602\n",
      "Epoch 116/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4355.6659 - val_loss: 9465.7317\n",
      "Epoch 117/1000\n",
      "244/244 [==============================] - 0s 992us/step - loss: 4350.4336 - val_loss: 9433.9701\n",
      "Epoch 118/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4345.2212 - val_loss: 9404.3405\n",
      "Epoch 119/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4340.0230 - val_loss: 9376.5273\n",
      "Epoch 120/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4334.8363 - val_loss: 9350.4344\n",
      "Epoch 121/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4329.6608 - val_loss: 9325.9396\n",
      "Epoch 122/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4324.4990 - val_loss: 9302.5207\n",
      "Epoch 123/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4319.3357 - val_loss: 9280.3127\n",
      "Epoch 124/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4314.1732 - val_loss: 9259.1717\n",
      "Epoch 125/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4309.0176 - val_loss: 9239.4096\n",
      "Epoch 126/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4303.8714 - val_loss: 9220.2565\n",
      "Epoch 127/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4298.7364 - val_loss: 9202.1443\n",
      "Epoch 128/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4293.6050 - val_loss: 9184.3640\n",
      "Epoch 129/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4288.4709 - val_loss: 9166.8836\n",
      "Epoch 130/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4283.3346 - val_loss: 9149.8867\n",
      "Epoch 131/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4278.1970 - val_loss: 9133.4211\n",
      "Epoch 132/1000\n",
      "244/244 [==============================] - 0s 983us/step - loss: 4273.0603 - val_loss: 9117.3829\n",
      "Epoch 133/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4267.9253 - val_loss: 9101.9191\n",
      "Epoch 134/1000\n",
      "244/244 [==============================] - 0s 969us/step - loss: 4262.7921 - val_loss: 9086.5094\n",
      "Epoch 135/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4257.6592 - val_loss: 9071.4272\n",
      "Epoch 136/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4252.5256 - val_loss: 9056.5758\n",
      "Epoch 137/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4247.3933 - val_loss: 9041.9518\n",
      "Epoch 138/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4242.2617 - val_loss: 9027.5345\n",
      "Epoch 139/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4237.1315 - val_loss: 9013.2984\n",
      "Epoch 140/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4232.0014 - val_loss: 8999.1117\n",
      "Epoch 141/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4226.8693 - val_loss: 8984.8994\n",
      "Epoch 142/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4221.7339 - val_loss: 8970.7231\n",
      "Epoch 143/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4216.5958 - val_loss: 8956.6919\n",
      "Epoch 144/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4211.4554 - val_loss: 8942.8458\n",
      "Epoch 145/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4206.3122 - val_loss: 8929.1936\n",
      "Epoch 146/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4201.1687 - val_loss: 8915.7388\n",
      "Epoch 147/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4196.0235 - val_loss: 8902.4224\n",
      "Epoch 148/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4190.8785 - val_loss: 8889.3315\n",
      "Epoch 149/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4185.7334 - val_loss: 8876.3010\n",
      "Epoch 150/1000\n",
      "244/244 [==============================] - ETA: 0s - loss: 4579.53 - 0s 1ms/step - loss: 4180.5885 - val_loss: 8863.3702\n",
      "Epoch 151/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4175.4427 - val_loss: 8850.4329\n",
      "Epoch 152/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4170.2997 - val_loss: 8837.4083\n",
      "Epoch 153/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 4165.1556 - val_loss: 8824.7777\n",
      "Epoch 154/1000\n",
      "244/244 [==============================] - 0s 998us/step - loss: 4160.0108 - val_loss: 8812.3529\n",
      "Epoch 155/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4154.8676 - val_loss: 8799.9984\n",
      "Epoch 156/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4149.7279 - val_loss: 8787.6966\n",
      "Epoch 157/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4144.5888 - val_loss: 8775.5179\n",
      "Epoch 158/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4139.4519 - val_loss: 8763.3436\n",
      "Epoch 159/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4134.3170 - val_loss: 8751.1704\n",
      "Epoch 160/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4129.1844 - val_loss: 8739.0410\n",
      "Epoch 161/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4124.0555 - val_loss: 8726.8929\n",
      "Epoch 162/1000\n",
      "244/244 [==============================] - 0s 998us/step - loss: 4118.9285 - val_loss: 8714.7265\n",
      "Epoch 163/1000\n",
      "244/244 [==============================] - 0s 999us/step - loss: 4113.8031 - val_loss: 8702.7366\n",
      "Epoch 164/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4108.6850 - val_loss: 8690.6325\n",
      "Epoch 165/1000\n",
      "244/244 [==============================] - 0s 987us/step - loss: 4103.5692 - val_loss: 8678.4345\n",
      "Epoch 166/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4098.4567 - val_loss: 8666.2870\n",
      "Epoch 167/1000\n",
      "244/244 [==============================] - 0s 946us/step - loss: 4093.3460 - val_loss: 8654.1823\n",
      "Epoch 168/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4088.2417 - val_loss: 8642.2142\n",
      "Epoch 169/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4083.1401 - val_loss: 8630.2369\n",
      "Epoch 170/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4078.0405 - val_loss: 8618.3343\n",
      "Epoch 171/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4072.9489 - val_loss: 8606.3130\n",
      "Epoch 172/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4067.8556 - val_loss: 8594.4335\n",
      "Epoch 173/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4062.7724 - val_loss: 8582.5185\n",
      "Epoch 174/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4057.6926 - val_loss: 8570.6112\n",
      "Epoch 175/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4052.6156 - val_loss: 8558.8519\n",
      "Epoch 176/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4047.5455 - val_loss: 8546.9842\n",
      "Epoch 177/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4042.4818 - val_loss: 8535.0194\n",
      "Epoch 178/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4037.4204 - val_loss: 8523.1782\n",
      "Epoch 179/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4032.3662 - val_loss: 8511.2743\n",
      "Epoch 180/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4027.3164 - val_loss: 8499.3568\n",
      "Epoch 181/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4022.2710 - val_loss: 8487.5151\n",
      "Epoch 182/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4017.2319 - val_loss: 8475.7550\n",
      "Epoch 183/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4012.1976 - val_loss: 8463.9916\n",
      "Epoch 184/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4007.1682 - val_loss: 8452.2811\n",
      "Epoch 185/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4002.1444 - val_loss: 8440.6575\n",
      "Epoch 186/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3997.1272 - val_loss: 8429.1405\n",
      "Epoch 187/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3992.1133 - val_loss: 8417.6748\n",
      "Epoch 188/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3987.1058 - val_loss: 8406.1950\n",
      "Epoch 189/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3982.1073 - val_loss: 8394.7275\n",
      "Epoch 190/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3977.1134 - val_loss: 8383.2239\n",
      "Epoch 191/1000\n",
      "244/244 [==============================] - 0s 973us/step - loss: 3972.1257 - val_loss: 8371.7297\n",
      "Epoch 192/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3967.1431 - val_loss: 8360.3007\n",
      "Epoch 193/1000\n",
      "244/244 [==============================] - 0s 993us/step - loss: 3962.1670 - val_loss: 8348.9193\n",
      "Epoch 194/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3957.1976 - val_loss: 8337.6254\n",
      "Epoch 195/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3952.2349 - val_loss: 8326.3928\n",
      "Epoch 196/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3947.2776 - val_loss: 8315.1651\n",
      "Epoch 197/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3942.3266 - val_loss: 8304.0028\n",
      "Epoch 198/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3937.3815 - val_loss: 8292.8941\n",
      "Epoch 199/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3932.4443 - val_loss: 8281.7183\n",
      "Epoch 200/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3927.5130 - val_loss: 8270.6323\n",
      "Epoch 201/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3922.5871 - val_loss: 8259.5657\n",
      "Epoch 202/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3917.6690 - val_loss: 8248.6321\n",
      "Epoch 203/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3912.7567 - val_loss: 8237.8976\n",
      "Epoch 204/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3907.8550 - val_loss: 8226.9854\n",
      "Epoch 205/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3902.9560 - val_loss: 8216.1458\n",
      "Epoch 206/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3898.0674 - val_loss: 8205.2224\n",
      "Epoch 207/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3893.1832 - val_loss: 8194.3863\n",
      "Epoch 208/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3888.3038 - val_loss: 8183.6733\n",
      "Epoch 209/1000\n",
      "244/244 [==============================] - 0s 975us/step - loss: 3883.4352 - val_loss: 8172.9081\n",
      "Epoch 210/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3878.5711 - val_loss: 8162.3373\n",
      "Epoch 211/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3873.7165 - val_loss: 8151.7187\n",
      "Epoch 212/1000\n",
      "244/244 [==============================] - 0s 981us/step - loss: 3868.8701 - val_loss: 8141.0765\n",
      "Epoch 213/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3864.0280 - val_loss: 8130.5212\n",
      "Epoch 214/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3859.1919 - val_loss: 8120.1654\n",
      "Epoch 215/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3854.3662 - val_loss: 8109.7272\n",
      "Epoch 216/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3849.5420 - val_loss: 8099.4835\n",
      "Epoch 217/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3844.7297 - val_loss: 8089.1331\n",
      "Epoch 218/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3839.9266 - val_loss: 8078.7059\n",
      "Epoch 219/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3835.1223 - val_loss: 8068.5848\n",
      "Epoch 220/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3830.3378 - val_loss: 8058.1321\n",
      "Epoch 221/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3825.5541 - val_loss: 8047.8023\n",
      "Epoch 222/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3820.7745 - val_loss: 8037.5840\n",
      "Epoch 223/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3816.0129 - val_loss: 8027.0736\n",
      "Epoch 224/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3811.2477 - val_loss: 8016.8420\n",
      "Epoch 225/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3806.4880 - val_loss: 8006.7276\n",
      "Epoch 226/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3801.7493 - val_loss: 7996.2795\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 989us/step - loss: 3797.0090 - val_loss: 7986.0700\n",
      "Epoch 228/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3792.2729 - val_loss: 7976.0970\n",
      "Epoch 229/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3787.5517 - val_loss: 7965.9787\n",
      "Epoch 230/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3782.8306 - val_loss: 7956.1229\n",
      "Epoch 231/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3778.1242 - val_loss: 7946.1081\n",
      "Epoch 232/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3773.4169 - val_loss: 7936.2781\n",
      "Epoch 233/1000\n",
      "244/244 [==============================] - 0s 987us/step - loss: 3768.7246 - val_loss: 7926.3271\n",
      "Epoch 234/1000\n",
      "244/244 [==============================] - 0s 991us/step - loss: 3764.0318 - val_loss: 7916.6465\n",
      "Epoch 235/1000\n",
      "244/244 [==============================] - 0s 989us/step - loss: 3759.3540 - val_loss: 7906.8738\n",
      "Epoch 236/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3754.6794 - val_loss: 7897.1958\n",
      "Epoch 237/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3750.0098 - val_loss: 7887.6961\n",
      "Epoch 238/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3745.3550 - val_loss: 7877.9750\n",
      "Epoch 239/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3740.6994 - val_loss: 7868.4525\n",
      "Epoch 240/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3736.0591 - val_loss: 7858.7619\n",
      "Epoch 241/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3731.4207 - val_loss: 7849.2252\n",
      "Epoch 242/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3726.7876 - val_loss: 7839.8897\n",
      "Epoch 243/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3722.1692 - val_loss: 7830.3955\n",
      "Epoch 244/1000\n",
      "244/244 [==============================] - 0s 991us/step - loss: 3717.5539 - val_loss: 7821.0131\n",
      "Epoch 245/1000\n",
      "244/244 [==============================] - 0s 973us/step - loss: 3712.9416 - val_loss: 7811.8380\n",
      "Epoch 246/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3708.3463 - val_loss: 7802.4326\n",
      "Epoch 247/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3703.7538 - val_loss: 7793.1316\n",
      "Epoch 248/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3699.1645 - val_loss: 7784.0004\n",
      "Epoch 249/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3694.5875 - val_loss: 7774.7949\n",
      "Epoch 250/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3690.0143 - val_loss: 7765.6746\n",
      "Epoch 251/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3685.4548 - val_loss: 7756.3940\n",
      "Epoch 252/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3680.8999 - val_loss: 7747.1754\n",
      "Epoch 253/1000\n",
      "244/244 [==============================] - 0s 978us/step - loss: 3676.3476 - val_loss: 7738.1598\n",
      "Epoch 254/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3671.8103 - val_loss: 7728.9591\n",
      "Epoch 255/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3667.2755 - val_loss: 7719.8896\n",
      "Epoch 256/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3662.7554 - val_loss: 7710.6516\n",
      "Epoch 257/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3658.2373 - val_loss: 7701.5625\n",
      "Epoch 258/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3653.7246 - val_loss: 7692.6747\n",
      "Epoch 259/1000\n",
      "244/244 [==============================] - 0s 958us/step - loss: 3649.2272 - val_loss: 7683.6281\n",
      "Epoch 260/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3644.7259 - val_loss: 7674.8948\n",
      "Epoch 261/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3640.2428 - val_loss: 7665.9238\n",
      "Epoch 262/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3635.7592 - val_loss: 7657.1353\n",
      "Epoch 263/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3631.2927 - val_loss: 7648.1280\n",
      "Epoch 264/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3626.8254 - val_loss: 7639.3372\n",
      "Epoch 265/1000\n",
      "244/244 [==============================] - 0s 986us/step - loss: 3622.3731 - val_loss: 7630.4150\n",
      "Epoch 266/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3617.9209 - val_loss: 7621.7494\n",
      "Epoch 267/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3613.4802 - val_loss: 7613.0597\n",
      "Epoch 268/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3609.0506 - val_loss: 7604.2668\n",
      "Epoch 269/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3604.6200 - val_loss: 7595.7634\n",
      "Epoch 270/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3600.2051 - val_loss: 7587.1523\n",
      "Epoch 271/1000\n",
      "244/244 [==============================] - 0s 997us/step - loss: 3595.7906 - val_loss: 7578.7760\n",
      "Epoch 272/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3591.3913 - val_loss: 7570.2669\n",
      "Epoch 273/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3586.9891 - val_loss: 7562.0658\n",
      "Epoch 274/1000\n",
      "244/244 [==============================] - 0s 993us/step - loss: 3582.6016 - val_loss: 7553.7458\n",
      "Epoch 275/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3578.2268 - val_loss: 7545.2108\n",
      "Epoch 276/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3573.8510 - val_loss: 7536.9398\n",
      "Epoch 277/1000\n",
      "244/244 [==============================] - 0s 987us/step - loss: 3569.4900 - val_loss: 7528.5343\n",
      "Epoch 278/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3565.1306 - val_loss: 7520.2792\n",
      "Epoch 279/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3560.7838 - val_loss: 7511.9227\n",
      "Epoch 280/1000\n",
      "244/244 [==============================] - 0s 996us/step - loss: 3556.4476 - val_loss: 7503.4869\n",
      "Epoch 281/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3552.1110 - val_loss: 7495.3269\n",
      "Epoch 282/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3547.7869 - val_loss: 7487.1512\n",
      "Epoch 283/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3543.4731 - val_loss: 7478.9126\n",
      "Epoch 284/1000\n",
      "244/244 [==============================] - 0s 972us/step - loss: 3539.1599 - val_loss: 7470.9490\n",
      "Epoch 285/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3534.8593 - val_loss: 7462.9599\n",
      "Epoch 286/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3530.5694 - val_loss: 7454.8959\n",
      "Epoch 287/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3526.2801 - val_loss: 7447.1028\n",
      "Epoch 288/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3522.0028 - val_loss: 7439.2638\n",
      "Epoch 289/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3517.7363 - val_loss: 7431.3481\n",
      "Epoch 290/1000\n",
      "244/244 [==============================] - 0s 997us/step - loss: 3513.4704 - val_loss: 7423.6896\n",
      "Epoch 291/1000\n",
      "244/244 [==============================] - 0s 991us/step - loss: 3509.2174 - val_loss: 7416.0048\n",
      "Epoch 292/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3504.9753 - val_loss: 7408.2262\n",
      "Epoch 293/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3500.7337 - val_loss: 7400.7251\n",
      "Epoch 294/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3496.5067 - val_loss: 7393.0792\n",
      "Epoch 295/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3492.2812 - val_loss: 7385.6070\n",
      "Epoch 296/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3488.0683 - val_loss: 7378.0308\n",
      "Epoch 297/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3483.8662 - val_loss: 7370.3558\n",
      "Epoch 298/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3479.6656 - val_loss: 7362.9282\n",
      "Epoch 299/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3475.4773 - val_loss: 7355.4712\n",
      "Epoch 300/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3471.2986 - val_loss: 7347.9501\n",
      "Epoch 301/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 3467.1220 - val_loss: 7340.6604\n",
      "Epoch 302/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3462.9572 - val_loss: 7333.3438\n",
      "Epoch 303/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3458.8046 - val_loss: 7325.9262\n",
      "Epoch 304/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3454.6527 - val_loss: 7318.7598\n",
      "Epoch 305/1000\n",
      "244/244 [==============================] - 0s 996us/step - loss: 3450.5163 - val_loss: 7311.4716\n",
      "Epoch 306/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3446.3819 - val_loss: 7304.4037\n",
      "Epoch 307/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3442.2597 - val_loss: 7297.2744\n",
      "Epoch 308/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3438.1492 - val_loss: 7290.1361\n",
      "Epoch 309/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3434.0382 - val_loss: 7283.2152\n",
      "Epoch 310/1000\n",
      "244/244 [==============================] - 0s 969us/step - loss: 3429.9424 - val_loss: 7276.1484\n",
      "Epoch 311/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3425.8565 - val_loss: 7269.0013\n",
      "Epoch 312/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3421.7724 - val_loss: 7262.1091\n",
      "Epoch 313/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3417.7025 - val_loss: 7255.0969\n",
      "Epoch 314/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3413.6433 - val_loss: 7247.9758\n",
      "Epoch 315/1000\n",
      "244/244 [==============================] - 0s 997us/step - loss: 3409.5837 - val_loss: 7241.1450\n",
      "Epoch 316/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3405.5396 - val_loss: 7234.2179\n",
      "Epoch 317/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3401.5062 - val_loss: 7227.2074\n",
      "Epoch 318/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3397.4750 - val_loss: 7220.4472\n",
      "Epoch 319/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3393.4582 - val_loss: 7213.6550\n",
      "Epoch 320/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3389.4471 - val_loss: 7206.8909\n",
      "Epoch 321/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3385.4530 - val_loss: 7199.9290\n",
      "Epoch 322/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3381.4562 - val_loss: 7193.4225\n",
      "Epoch 323/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3377.4772 - val_loss: 7186.7185\n",
      "Epoch 324/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3373.5029 - val_loss: 7180.0790\n",
      "Epoch 325/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3369.5412 - val_loss: 7173.4019\n",
      "Epoch 326/1000\n",
      "244/244 [==============================] - 0s 994us/step - loss: 3365.5856 - val_loss: 7166.8439\n",
      "Epoch 327/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3361.6371 - val_loss: 7160.4522\n",
      "Epoch 328/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3357.7003 - val_loss: 7154.0539\n",
      "Epoch 329/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3353.7747 - val_loss: 7147.5771\n",
      "Epoch 330/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3349.8572 - val_loss: 7141.1487\n",
      "Epoch 331/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3345.9538 - val_loss: 7134.6422\n",
      "Epoch 332/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3342.0501 - val_loss: 7128.4924\n",
      "Epoch 333/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3338.1625 - val_loss: 7122.2813\n",
      "Epoch 334/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3334.2840 - val_loss: 7116.0649\n",
      "Epoch 335/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3330.4147 - val_loss: 7109.9018\n",
      "Epoch 336/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3326.5579 - val_loss: 7103.7183\n",
      "Epoch 337/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3322.7034 - val_loss: 7097.8294\n",
      "Epoch 338/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3318.8625 - val_loss: 7091.8795\n",
      "Epoch 339/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3315.0345 - val_loss: 7085.8310\n",
      "Epoch 340/1000\n",
      "244/244 [==============================] - 0s 993us/step - loss: 3311.2136 - val_loss: 7079.8676\n",
      "Epoch 341/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3307.4041 - val_loss: 7073.9327\n",
      "Epoch 342/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3303.6069 - val_loss: 7067.9890\n",
      "Epoch 343/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3299.8101 - val_loss: 7062.3643\n",
      "Epoch 344/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3296.0322 - val_loss: 7056.5653\n",
      "Epoch 345/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3292.2632 - val_loss: 7050.7290\n",
      "Epoch 346/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3288.5059 - val_loss: 7044.8850\n",
      "Epoch 347/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3284.7595 - val_loss: 7039.1358\n",
      "Epoch 348/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3281.0230 - val_loss: 7033.3569\n",
      "Epoch 349/1000\n",
      "244/244 [==============================] - 0s 992us/step - loss: 3277.2968 - val_loss: 7027.6178\n",
      "Epoch 350/1000\n",
      "244/244 [==============================] - 0s 985us/step - loss: 3273.5839 - val_loss: 7021.8833\n",
      "Epoch 351/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3269.8751 - val_loss: 7016.4242\n",
      "Epoch 352/1000\n",
      "244/244 [==============================] - 0s 986us/step - loss: 3266.1812 - val_loss: 7010.9362\n",
      "Epoch 353/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3262.4983 - val_loss: 7005.4720\n",
      "Epoch 354/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3258.8254 - val_loss: 7000.0625\n",
      "Epoch 355/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3255.1635 - val_loss: 6994.7090\n",
      "Epoch 356/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3251.5134 - val_loss: 6989.4226\n",
      "Epoch 357/1000\n",
      "244/244 [==============================] - 0s 984us/step - loss: 3247.8736 - val_loss: 6984.1857\n",
      "Epoch 358/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3244.2479 - val_loss: 6978.9377\n",
      "Epoch 359/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3240.6278 - val_loss: 6973.9654\n",
      "Epoch 360/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3237.0231 - val_loss: 6968.9084\n",
      "Epoch 361/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3233.4296 - val_loss: 6963.8524\n",
      "Epoch 362/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3229.8471 - val_loss: 6958.8350\n",
      "Epoch 363/1000\n",
      "244/244 [==============================] - 0s 999us/step - loss: 3226.2753 - val_loss: 6953.8850\n",
      "Epoch 364/1000\n",
      "244/244 [==============================] - 0s 998us/step - loss: 3222.7166 - val_loss: 6948.9428\n",
      "Epoch 365/1000\n",
      "244/244 [==============================] - 0s 978us/step - loss: 3219.1730 - val_loss: 6944.0174\n",
      "Epoch 366/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3215.6343 - val_loss: 6939.2826\n",
      "Epoch 367/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3212.1123 - val_loss: 6934.4947\n",
      "Epoch 368/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3208.6016 - val_loss: 6929.7099\n",
      "Epoch 369/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3205.1028 - val_loss: 6924.9309\n",
      "Epoch 370/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3201.6192 - val_loss: 6920.1752\n",
      "Epoch 371/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3198.1489 - val_loss: 6915.4251\n",
      "Epoch 372/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3194.6816 - val_loss: 6911.0154\n",
      "Epoch 373/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3191.2315 - val_loss: 6906.6511\n",
      "Epoch 374/1000\n",
      "244/244 [==============================] - 0s 943us/step - loss: 3187.7944 - val_loss: 6902.1796\n",
      "Epoch 375/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 994us/step - loss: 3184.3730 - val_loss: 6897.6309\n",
      "Epoch 376/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3180.9578 - val_loss: 6893.3262\n",
      "Epoch 377/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3177.5580 - val_loss: 6888.9747\n",
      "Epoch 378/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3174.1712 - val_loss: 6884.6317\n",
      "Epoch 379/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3170.8015 - val_loss: 6880.2286\n",
      "Epoch 380/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3167.4379 - val_loss: 6876.0505\n",
      "Epoch 381/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3164.0942 - val_loss: 6871.7963\n",
      "Epoch 382/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3160.7626 - val_loss: 6867.5736\n",
      "Epoch 383/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3157.4437 - val_loss: 6863.4459\n",
      "Epoch 384/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3154.1308 - val_loss: 6859.6240\n",
      "Epoch 385/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3150.8404 - val_loss: 6855.6115\n",
      "Epoch 386/1000\n",
      "244/244 [==============================] - 0s 989us/step - loss: 3147.5639 - val_loss: 6851.5764\n",
      "Epoch 387/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3144.2940 - val_loss: 6847.7895\n",
      "Epoch 388/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3141.0419 - val_loss: 6843.9568\n",
      "Epoch 389/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3137.8069 - val_loss: 6840.0434\n",
      "Epoch 390/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3134.5829 - val_loss: 6836.2841\n",
      "Epoch 391/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3131.3769 - val_loss: 6832.5151\n",
      "Epoch 392/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3128.1830 - val_loss: 6828.8690\n",
      "Epoch 393/1000\n",
      "244/244 [==============================] - 0s 993us/step - loss: 3124.9967 - val_loss: 6825.5067\n",
      "Epoch 394/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3121.8323 - val_loss: 6822.0127\n",
      "Epoch 395/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3118.6757 - val_loss: 6818.6801\n",
      "Epoch 396/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3115.5388 - val_loss: 6815.2530\n",
      "Epoch 397/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3112.4124 - val_loss: 6811.9018\n",
      "Epoch 398/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3109.3070 - val_loss: 6808.3919\n",
      "Epoch 399/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3106.2113 - val_loss: 6805.0131\n",
      "Epoch 400/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3103.1370 - val_loss: 6801.5124\n",
      "Epoch 401/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3100.0690 - val_loss: 6798.2530\n",
      "Epoch 402/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3097.0255 - val_loss: 6794.8040\n",
      "Epoch 403/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3093.9903 - val_loss: 6791.5640\n",
      "Epoch 404/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3090.9772 - val_loss: 6788.1904\n",
      "Epoch 405/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3087.9717 - val_loss: 6785.0408\n",
      "Epoch 406/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3084.9860 - val_loss: 6781.8155\n",
      "Epoch 407/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3082.0207 - val_loss: 6778.4302\n",
      "Epoch 408/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3079.0658 - val_loss: 6775.2193\n",
      "Epoch 409/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3076.1282 - val_loss: 6772.0280\n",
      "Epoch 410/1000\n",
      "244/244 [==============================] - 0s 955us/step - loss: 3073.2147 - val_loss: 6768.6635\n",
      "Epoch 411/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3070.3046 - val_loss: 6765.7127\n",
      "Epoch 412/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3067.4207 - val_loss: 6762.6055\n",
      "Epoch 413/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3064.5469 - val_loss: 6759.6820\n",
      "Epoch 414/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3061.6939 - val_loss: 6756.7304\n",
      "Epoch 415/1000\n",
      "244/244 [==============================] - 0s 990us/step - loss: 3058.8554 - val_loss: 6753.8743\n",
      "Epoch 416/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3056.0320 - val_loss: 6751.1124\n",
      "Epoch 417/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3053.2309 - val_loss: 6748.2055\n",
      "Epoch 418/1000\n",
      "244/244 [==============================] - 0s 990us/step - loss: 3050.4439 - val_loss: 6745.4466\n",
      "Epoch 419/1000\n",
      "244/244 [==============================] - 0s 977us/step - loss: 3047.6731 - val_loss: 6742.7985\n",
      "Epoch 420/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3044.9120 - val_loss: 6740.3970\n",
      "Epoch 421/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3042.1795 - val_loss: 6737.6294\n",
      "Epoch 422/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3039.4641 - val_loss: 6734.8026\n",
      "Epoch 423/1000\n",
      "244/244 [==============================] - 0s 997us/step - loss: 3036.7620 - val_loss: 6732.1672\n",
      "Epoch 424/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3034.0768 - val_loss: 6729.6710\n",
      "Epoch 425/1000\n",
      "244/244 [==============================] - 0s 989us/step - loss: 3031.4114 - val_loss: 6727.1649\n",
      "Epoch 426/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3028.7626 - val_loss: 6724.7379\n",
      "Epoch 427/1000\n",
      "244/244 [==============================] - 0s 987us/step - loss: 3026.1285 - val_loss: 6722.4185\n",
      "Epoch 428/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3023.5227 - val_loss: 6719.9070\n",
      "Epoch 429/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3020.9199 - val_loss: 6717.8275\n",
      "Epoch 430/1000\n",
      "244/244 [==============================] - 0s 995us/step - loss: 3018.3470 - val_loss: 6715.5427\n",
      "Epoch 431/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3015.7831 - val_loss: 6713.4603\n",
      "Epoch 432/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3013.2420 - val_loss: 6711.2815\n",
      "Epoch 433/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3010.7248 - val_loss: 6708.9998\n",
      "Epoch 434/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3008.2174 - val_loss: 6707.0221\n",
      "Epoch 435/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3005.7339 - val_loss: 6705.0230\n",
      "Epoch 436/1000\n",
      "244/244 [==============================] - 0s 990us/step - loss: 3003.2616 - val_loss: 6703.2560\n",
      "Epoch 437/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3000.8095 - val_loss: 6701.4709\n",
      "Epoch 438/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2998.3903 - val_loss: 6699.3273\n",
      "Epoch 439/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2995.9696 - val_loss: 6697.7681\n",
      "Epoch 440/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2993.5783 - val_loss: 6696.0675\n",
      "Epoch 441/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2991.2038 - val_loss: 6694.3836\n",
      "Epoch 442/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2988.8511 - val_loss: 6692.6816\n",
      "Epoch 443/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2986.5074 - val_loss: 6691.2811\n",
      "Epoch 444/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2984.1971 - val_loss: 6689.5455\n",
      "Epoch 445/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2981.9018 - val_loss: 6687.9452\n",
      "Epoch 446/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2979.6088 - val_loss: 6686.8791\n",
      "Epoch 447/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2977.3557 - val_loss: 6685.2752\n",
      "Epoch 448/1000\n",
      "244/244 [==============================] - 0s 994us/step - loss: 2975.1241 - val_loss: 6683.6031\n",
      "Epoch 449/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 2972.8863 - val_loss: 6682.7146\n",
      "Epoch 450/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2970.6929 - val_loss: 6681.2552\n",
      "Epoch 451/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2968.5099 - val_loss: 6679.9764\n",
      "Epoch 452/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2966.3396 - val_loss: 6678.9304\n",
      "Epoch 453/1000\n",
      "244/244 [==============================] - 0s 992us/step - loss: 2964.2022 - val_loss: 6677.5547\n",
      "Epoch 454/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2962.0772 - val_loss: 6676.4098\n",
      "Epoch 455/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2959.9691 - val_loss: 6675.4397\n",
      "Epoch 456/1000\n",
      "244/244 [==============================] - 0s 991us/step - loss: 2957.8877 - val_loss: 6674.3385\n",
      "Epoch 457/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2955.8176 - val_loss: 6673.4805\n",
      "Epoch 458/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2953.7715 - val_loss: 6672.5333\n",
      "Epoch 459/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2951.7448 - val_loss: 6671.5853\n",
      "Epoch 460/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2949.7383 - val_loss: 6670.6524\n",
      "Epoch 461/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2947.7549 - val_loss: 6669.7144\n",
      "Epoch 462/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2945.7828 - val_loss: 6669.0932\n",
      "Epoch 463/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2943.8357 - val_loss: 6668.3557\n",
      "Epoch 464/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2941.9065 - val_loss: 6667.6049\n",
      "Epoch 465/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2940.0008 - val_loss: 6666.8053\n",
      "Epoch 466/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2938.1150 - val_loss: 6666.0483\n",
      "Epoch 467/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2936.2342 - val_loss: 6665.7459\n",
      "Epoch 468/1000\n",
      "244/244 [==============================] - 0s 894us/step - loss: 2934.4034 - val_loss: 6664.7159\n",
      "Epoch 469/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2932.5548 - val_loss: 6664.5963\n",
      "Epoch 470/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2930.7610 - val_loss: 6663.7358\n",
      "Epoch 471/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2928.9648 - val_loss: 6663.3891\n",
      "Epoch 472/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2927.1959 - val_loss: 6662.9866\n",
      "Epoch 473/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2925.4467 - val_loss: 6662.5877\n",
      "Epoch 474/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2923.7107 - val_loss: 6662.3487\n",
      "Epoch 475/1000\n",
      "244/244 [==============================] - 0s 984us/step - loss: 2922.0082 - val_loss: 6661.7932\n",
      "Epoch 476/1000\n",
      "244/244 [==============================] - 0s 987us/step - loss: 2920.3094 - val_loss: 6661.6741\n",
      "Epoch 477/1000\n",
      "244/244 [==============================] - 0s 970us/step - loss: 2918.6475 - val_loss: 6661.1799\n",
      "Epoch 478/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2916.9820 - val_loss: 6661.2756\n",
      "Epoch 479/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2915.3660 - val_loss: 6660.6760\n",
      "Epoch 480/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2913.7380 - val_loss: 6660.8351\n",
      "Epoch 481/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2912.1602 - val_loss: 6660.3393\n",
      "Epoch 482/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2910.5718 - val_loss: 6660.5543\n",
      "Epoch 483/1000\n",
      "244/244 [==============================] - 0s 998us/step - loss: 2909.0320 - val_loss: 6660.1455\n",
      "Epoch 484/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2907.4911 - val_loss: 6660.3343\n",
      "Epoch 485/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2905.9754 - val_loss: 6660.3790\n",
      "Epoch 486/1000\n",
      "244/244 [==============================] - 0s 995us/step - loss: 2904.4827 - val_loss: 6660.2462\n",
      "Epoch 487/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2903.0034 - val_loss: 6660.2865\n",
      "Epoch 488/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2901.5462 - val_loss: 6660.2772\n",
      "Epoch 489/1000\n",
      "244/244 [==============================] - 0s 995us/step - loss: 2900.1101 - val_loss: 6660.2352\n",
      "Epoch 490/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2898.6939 - val_loss: 6660.2534\n",
      "Epoch 491/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2897.2893 - val_loss: 6660.5186\n",
      "Epoch 492/1000\n",
      "244/244 [==============================] - 0s 969us/step - loss: 2895.9129 - val_loss: 6660.6258\n",
      "Epoch 493/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2894.5465 - val_loss: 6660.9460\n",
      "Epoch 494/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2893.2081 - val_loss: 6661.0925\n",
      "Epoch 495/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2891.8744 - val_loss: 6661.5607\n",
      "Epoch 496/1000\n",
      "244/244 [==============================] - 0s 978us/step - loss: 2890.5812 - val_loss: 6661.5381\n",
      "Epoch 497/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2889.2803 - val_loss: 6662.1856\n",
      "Epoch 498/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2888.0202 - val_loss: 6662.3125\n",
      "Epoch 499/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2886.7615 - val_loss: 6662.8170\n",
      "Epoch 500/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2885.5379 - val_loss: 6662.9600\n",
      "Epoch 501/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2884.3172 - val_loss: 6663.5418\n",
      "Epoch 502/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2883.1261 - val_loss: 6663.9072\n",
      "Epoch 503/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2881.9417 - val_loss: 6664.5577\n",
      "Train on 244 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "244/244 [==============================] - 54s 223ms/step - loss: 26975.8883 - val_loss: 179439.1442\n",
      "Epoch 2/1000\n",
      "244/244 [==============================] - 0s 907us/step - loss: 26969.3308 - val_loss: 179420.8625\n",
      "Epoch 3/1000\n",
      "244/244 [==============================] - 0s 937us/step - loss: 26965.1400 - val_loss: 179407.3502\n",
      "Epoch 4/1000\n",
      "244/244 [==============================] - 0s 917us/step - loss: 26961.2828 - val_loss: 179394.9966\n",
      "Epoch 5/1000\n",
      "244/244 [==============================] - 0s 926us/step - loss: 26957.5396 - val_loss: 179383.1909\n",
      "Epoch 6/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26953.7701 - val_loss: 179371.2970\n",
      "Epoch 7/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26949.9982 - val_loss: 179359.2676\n",
      "Epoch 8/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26946.2154 - val_loss: 179346.9787\n",
      "Epoch 9/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26942.3870 - val_loss: 179333.3487\n",
      "Epoch 10/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26937.5309 - val_loss: 179305.2887\n",
      "Epoch 11/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26922.0033 - val_loss: 179183.0680\n",
      "Epoch 12/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26878.1524 - val_loss: 178900.9503\n",
      "Epoch 13/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26776.0398 - val_loss: 178157.8404\n",
      "Epoch 14/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 26515.2195 - val_loss: 176339.3800\n",
      "Epoch 15/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 25879.7199 - val_loss: 172036.0881\n",
      "Epoch 16/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 24527.1482 - val_loss: 163774.3266\n",
      "Epoch 17/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 22339.5309 - val_loss: 151294.2664\n",
      "Epoch 18/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 19637.4715 - val_loss: 135877.0358\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 17051.1649 - val_loss: 120357.0111\n",
      "Epoch 20/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 15186.4347 - val_loss: 107687.5478\n",
      "Epoch 21/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 14104.4682 - val_loss: 98705.7518\n",
      "Epoch 22/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13510.1470 - val_loss: 92651.1783\n",
      "Epoch 23/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 13141.8478 - val_loss: 88454.7474\n",
      "Epoch 24/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12868.0119 - val_loss: 85334.8812\n",
      "Epoch 25/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12635.3320 - val_loss: 82828.0690\n",
      "Epoch 26/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12422.8582 - val_loss: 80677.4102\n",
      "Epoch 27/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12221.6211 - val_loss: 78740.2980\n",
      "Epoch 28/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 12027.2383 - val_loss: 76935.6858\n",
      "Epoch 29/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11837.2680 - val_loss: 75215.4511\n",
      "Epoch 30/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11650.1621 - val_loss: 73549.9889\n",
      "Epoch 31/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11464.8686 - val_loss: 71920.3864\n",
      "Epoch 32/1000\n",
      "244/244 [==============================] - 0s 966us/step - loss: 11280.6222 - val_loss: 70313.9372\n",
      "Epoch 33/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 11096.8593 - val_loss: 68721.9859\n",
      "Epoch 34/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10913.1334 - val_loss: 67138.5764\n",
      "Epoch 35/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10729.1214 - val_loss: 65559.2713\n",
      "Epoch 36/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10544.5589 - val_loss: 63980.8269\n",
      "Epoch 37/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10359.2565 - val_loss: 62400.8636\n",
      "Epoch 38/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 10173.0879 - val_loss: 60817.7728\n",
      "Epoch 39/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9985.9694 - val_loss: 59230.4241\n",
      "Epoch 40/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9797.8696 - val_loss: 57638.1230\n",
      "Epoch 41/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9608.8072 - val_loss: 56040.5619\n",
      "Epoch 42/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9418.8411 - val_loss: 54437.9216\n",
      "Epoch 43/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 9228.0856 - val_loss: 52830.5645\n",
      "Epoch 44/1000\n",
      "244/244 [==============================] - 0s 992us/step - loss: 9036.6992 - val_loss: 51219.2495\n",
      "Epoch 45/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8844.8836 - val_loss: 49605.1258\n",
      "Epoch 46/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8652.9024 - val_loss: 47989.5523\n",
      "Epoch 47/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8461.0560 - val_loss: 46374.4346\n",
      "Epoch 48/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8269.7096 - val_loss: 44761.7589\n",
      "Epoch 49/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 8079.2733 - val_loss: 43154.0468\n",
      "Epoch 50/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7890.2091 - val_loss: 41554.0373\n",
      "Epoch 51/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7703.0208 - val_loss: 39964.9025\n",
      "Epoch 52/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7518.2690 - val_loss: 38390.0054\n",
      "Epoch 53/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7336.5415 - val_loss: 36833.0546\n",
      "Epoch 54/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 7158.4613 - val_loss: 35297.9880\n",
      "Epoch 55/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6987.6520 - val_loss: 33780.0270\n",
      "Epoch 56/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6822.7618 - val_loss: 32301.4595\n",
      "Epoch 57/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6666.5931 - val_loss: 30855.4935\n",
      "Epoch 58/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6518.0138 - val_loss: 29467.1153\n",
      "Epoch 59/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6376.2325 - val_loss: 28136.6586\n",
      "Epoch 60/1000\n",
      "244/244 [==============================] - 0s 994us/step - loss: 6241.6847 - val_loss: 26864.3442\n",
      "Epoch 61/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 6114.5181 - val_loss: 25649.4135\n",
      "Epoch 62/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5994.7334 - val_loss: 24493.6799\n",
      "Epoch 63/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5882.3153 - val_loss: 23397.5338\n",
      "Epoch 64/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5777.2702 - val_loss: 22360.4873\n",
      "Epoch 65/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5679.5852 - val_loss: 21380.5375\n",
      "Epoch 66/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5589.1430 - val_loss: 20458.7379\n",
      "Epoch 67/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5505.9068 - val_loss: 19593.0917\n",
      "Epoch 68/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5430.6668 - val_loss: 18781.2558\n",
      "Epoch 69/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5362.3641 - val_loss: 18026.9140\n",
      "Epoch 70/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5300.1503 - val_loss: 17329.5096\n",
      "Epoch 71/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5243.6476 - val_loss: 16686.5067\n",
      "Epoch 72/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5192.4096 - val_loss: 16093.9059\n",
      "Epoch 73/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5145.9304 - val_loss: 15549.0566\n",
      "Epoch 74/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5103.9127 - val_loss: 15047.0691\n",
      "Epoch 75/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5065.8215 - val_loss: 14587.9149\n",
      "Epoch 76/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 5031.1920 - val_loss: 14167.5445\n",
      "Epoch 77/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4999.6237 - val_loss: 13784.1100\n",
      "Epoch 78/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4970.6985 - val_loss: 13434.6878\n",
      "Epoch 79/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4944.0725 - val_loss: 13115.6636\n",
      "Epoch 80/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4919.4448 - val_loss: 12824.6542\n",
      "Epoch 81/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4896.5342 - val_loss: 12559.1898\n",
      "Epoch 82/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4875.0879 - val_loss: 12317.5532\n",
      "Epoch 83/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4854.8994 - val_loss: 12096.5329\n",
      "Epoch 84/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4835.7639 - val_loss: 11895.1064\n",
      "Epoch 85/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4817.5579 - val_loss: 11710.5089\n",
      "Epoch 86/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4800.0896 - val_loss: 11542.5335\n",
      "Epoch 87/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4783.2306 - val_loss: 11389.1943\n",
      "Epoch 88/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4766.8848 - val_loss: 11249.5433\n",
      "Epoch 89/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4750.9571 - val_loss: 11121.4255\n",
      "Epoch 90/1000\n",
      "244/244 [==============================] - 0s 998us/step - loss: 4735.3580 - val_loss: 11003.5447\n",
      "Epoch 91/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4720.0235 - val_loss: 10894.7915\n",
      "Epoch 92/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4704.9102 - val_loss: 10794.1808\n",
      "Epoch 93/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 4689.9774 - val_loss: 10701.1736\n",
      "Epoch 94/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4675.1978 - val_loss: 10614.9982\n",
      "Epoch 95/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4660.5555 - val_loss: 10535.2328\n",
      "Epoch 96/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4646.0267 - val_loss: 10460.6385\n",
      "Epoch 97/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4631.6079 - val_loss: 10390.1066\n",
      "Epoch 98/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4617.2600 - val_loss: 10324.1329\n",
      "Epoch 99/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4602.9845 - val_loss: 10261.7405\n",
      "Epoch 100/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4588.7565 - val_loss: 10202.7400\n",
      "Epoch 101/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4574.5696 - val_loss: 10146.8791\n",
      "Epoch 102/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4560.4442 - val_loss: 10093.4398\n",
      "Epoch 103/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4546.3384 - val_loss: 10043.1129\n",
      "Epoch 104/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4532.2654 - val_loss: 9995.6147\n",
      "Epoch 105/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4518.2024 - val_loss: 9950.4993\n",
      "Epoch 106/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4504.1901 - val_loss: 9906.7546\n",
      "Epoch 107/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4490.1949 - val_loss: 9864.9801\n",
      "Epoch 108/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4476.2285 - val_loss: 9824.5634\n",
      "Epoch 109/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4462.2753 - val_loss: 9785.6912\n",
      "Epoch 110/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4448.3465 - val_loss: 9747.7243\n",
      "Epoch 111/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4434.4480 - val_loss: 9710.4762\n",
      "Epoch 112/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4420.5831 - val_loss: 9674.1495\n",
      "Epoch 113/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4406.7552 - val_loss: 9638.1634\n",
      "Epoch 114/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4392.9481 - val_loss: 9603.0797\n",
      "Epoch 115/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4379.1606 - val_loss: 9568.6634\n",
      "Epoch 116/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4365.3970 - val_loss: 9535.0269\n",
      "Epoch 117/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4351.6619 - val_loss: 9502.3918\n",
      "Epoch 118/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4337.9593 - val_loss: 9470.1316\n",
      "Epoch 119/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4324.2863 - val_loss: 9438.3845\n",
      "Epoch 120/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4310.6489 - val_loss: 9406.7431\n",
      "Epoch 121/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4297.0268 - val_loss: 9375.6979\n",
      "Epoch 122/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4283.4412 - val_loss: 9344.5284\n",
      "Epoch 123/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4269.8699 - val_loss: 9313.7484\n",
      "Epoch 124/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4256.3243 - val_loss: 9283.5437\n",
      "Epoch 125/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4242.8049 - val_loss: 9253.5959\n",
      "Epoch 126/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4229.3081 - val_loss: 9223.9549\n",
      "Epoch 127/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4215.8390 - val_loss: 9194.8144\n",
      "Epoch 128/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4202.3945 - val_loss: 9165.7957\n",
      "Epoch 129/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4188.9745 - val_loss: 9137.0964\n",
      "Epoch 130/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4175.5785 - val_loss: 9108.6614\n",
      "Epoch 131/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4162.2055 - val_loss: 9080.5805\n",
      "Epoch 132/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4148.8606 - val_loss: 9052.9145\n",
      "Epoch 133/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4135.5422 - val_loss: 9025.5983\n",
      "Epoch 134/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4122.2484 - val_loss: 8998.4250\n",
      "Epoch 135/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4108.9822 - val_loss: 8971.6561\n",
      "Epoch 136/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4095.7439 - val_loss: 8945.1208\n",
      "Epoch 137/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4082.5387 - val_loss: 8918.9696\n",
      "Epoch 138/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4069.3579 - val_loss: 8893.0668\n",
      "Epoch 139/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4056.2106 - val_loss: 8867.1554\n",
      "Epoch 140/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4043.0868 - val_loss: 8841.7735\n",
      "Epoch 141/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4029.9973 - val_loss: 8816.4559\n",
      "Epoch 142/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4016.9377 - val_loss: 8791.2855\n",
      "Epoch 143/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 4003.9063 - val_loss: 8766.3773\n",
      "Epoch 144/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3990.9061 - val_loss: 8741.7461\n",
      "Epoch 145/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3977.9378 - val_loss: 8717.3707\n",
      "Epoch 146/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3965.0015 - val_loss: 8693.2241\n",
      "Epoch 147/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3952.0977 - val_loss: 8669.2712\n",
      "Epoch 148/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3939.2249 - val_loss: 8645.5299\n",
      "Epoch 149/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3926.3870 - val_loss: 8622.1788\n",
      "Epoch 150/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3913.5840 - val_loss: 8598.9721\n",
      "Epoch 151/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3900.8147 - val_loss: 8575.9405\n",
      "Epoch 152/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3888.0795 - val_loss: 8553.1720\n",
      "Epoch 153/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3875.3803 - val_loss: 8530.6867\n",
      "Epoch 154/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3862.7183 - val_loss: 8508.4818\n",
      "Epoch 155/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3850.0944 - val_loss: 8486.5198\n",
      "Epoch 156/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3837.5069 - val_loss: 8464.5517\n",
      "Epoch 157/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3824.9526 - val_loss: 8442.7833\n",
      "Epoch 158/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3812.4387 - val_loss: 8421.6257\n",
      "Epoch 159/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3799.9648 - val_loss: 8400.6800\n",
      "Epoch 160/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3787.5334 - val_loss: 8380.0548\n",
      "Epoch 161/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3775.1432 - val_loss: 8359.6236\n",
      "Epoch 162/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3762.7957 - val_loss: 8339.3708\n",
      "Epoch 163/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3750.4908 - val_loss: 8319.4411\n",
      "Epoch 164/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3738.2305 - val_loss: 8299.5801\n",
      "Epoch 165/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3726.0157 - val_loss: 8279.7476\n",
      "Epoch 166/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3713.8435 - val_loss: 8260.1835\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 3701.7186 - val_loss: 8240.8335\n",
      "Epoch 168/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3689.6423 - val_loss: 8221.8764\n",
      "Epoch 169/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3677.6151 - val_loss: 8203.0381\n",
      "Epoch 170/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3665.6362 - val_loss: 8184.3978\n",
      "Epoch 171/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3653.7060 - val_loss: 8165.9189\n",
      "Epoch 172/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3641.8278 - val_loss: 8147.7933\n",
      "Epoch 173/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3630.0002 - val_loss: 8129.7905\n",
      "Epoch 174/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3618.2236 - val_loss: 8112.1181\n",
      "Epoch 175/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3606.5035 - val_loss: 8094.5901\n",
      "Epoch 176/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3594.8372 - val_loss: 8077.3755\n",
      "Epoch 177/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3583.2272 - val_loss: 8060.3499\n",
      "Epoch 178/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3571.6717 - val_loss: 8043.5751\n",
      "Epoch 179/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3560.1749 - val_loss: 8026.9880\n",
      "Epoch 180/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3548.7377 - val_loss: 8010.7482\n",
      "Epoch 181/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3537.3592 - val_loss: 7994.7207\n",
      "Epoch 182/1000\n",
      "244/244 [==============================] - 0s 996us/step - loss: 3526.0426 - val_loss: 7978.8685\n",
      "Epoch 183/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3514.7890 - val_loss: 7963.0989\n",
      "Epoch 184/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3503.5933 - val_loss: 7947.7828\n",
      "Epoch 185/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3492.4618 - val_loss: 7932.7791\n",
      "Epoch 186/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3481.3975 - val_loss: 7918.1120\n",
      "Epoch 187/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3470.3988 - val_loss: 7903.6573\n",
      "Epoch 188/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3459.4688 - val_loss: 7889.3589\n",
      "Epoch 189/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3448.6082 - val_loss: 7875.3898\n",
      "Epoch 190/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3437.8154 - val_loss: 7861.6532\n",
      "Epoch 191/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3427.0945 - val_loss: 7848.2389\n",
      "Epoch 192/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3416.4535 - val_loss: 7834.8207\n",
      "Epoch 193/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3405.8860 - val_loss: 7821.4985\n",
      "Epoch 194/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3395.3880 - val_loss: 7808.5783\n",
      "Epoch 195/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3384.9672 - val_loss: 7796.0146\n",
      "Epoch 196/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3374.6261 - val_loss: 7783.6840\n",
      "Epoch 197/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3364.3636 - val_loss: 7771.6601\n",
      "Epoch 198/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3354.1864 - val_loss: 7759.6122\n",
      "Epoch 199/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3344.0842 - val_loss: 7747.9438\n",
      "Epoch 200/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3334.0675 - val_loss: 7736.4527\n",
      "Epoch 201/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3324.1301 - val_loss: 7725.2987\n",
      "Epoch 202/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3314.2838 - val_loss: 7714.2469\n",
      "Epoch 203/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3304.5218 - val_loss: 7703.4718\n",
      "Epoch 204/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3294.8523 - val_loss: 7692.8386\n",
      "Epoch 205/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3285.2681 - val_loss: 7682.5977\n",
      "Epoch 206/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3275.7789 - val_loss: 7672.4369\n",
      "Epoch 207/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3266.3758 - val_loss: 7662.6072\n",
      "Epoch 208/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3257.0692 - val_loss: 7652.9298\n",
      "Epoch 209/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3247.8528 - val_loss: 7643.6615\n",
      "Epoch 210/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3238.7372 - val_loss: 7634.5276\n",
      "Epoch 211/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3229.7193 - val_loss: 7625.5659\n",
      "Epoch 212/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3220.8038 - val_loss: 7616.6009\n",
      "Epoch 213/1000\n",
      "244/244 [==============================] - 0s 986us/step - loss: 3211.9800 - val_loss: 7608.0479\n",
      "Epoch 214/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3203.2582 - val_loss: 7599.6676\n",
      "Epoch 215/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3194.6391 - val_loss: 7591.4377\n",
      "Epoch 216/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3186.1259 - val_loss: 7583.3632\n",
      "Epoch 217/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3177.7036 - val_loss: 7575.8388\n",
      "Epoch 218/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3169.3928 - val_loss: 7568.5208\n",
      "Epoch 219/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3161.1947 - val_loss: 7561.3086\n",
      "Epoch 220/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3153.0998 - val_loss: 7554.2863\n",
      "Epoch 221/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3145.1107 - val_loss: 7547.5764\n",
      "Epoch 222/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3137.2329 - val_loss: 7540.9575\n",
      "Epoch 223/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3129.4574 - val_loss: 7534.6836\n",
      "Epoch 224/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3121.7965 - val_loss: 7528.5584\n",
      "Epoch 225/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3114.2438 - val_loss: 7522.6528\n",
      "Epoch 226/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3106.8078 - val_loss: 7516.7537\n",
      "Epoch 227/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3099.4834 - val_loss: 7510.9638\n",
      "Epoch 228/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3092.2746 - val_loss: 7505.3147\n",
      "Epoch 229/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3085.1774 - val_loss: 7499.9898\n",
      "Epoch 230/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3078.1971 - val_loss: 7494.7605\n",
      "Epoch 231/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3071.3220 - val_loss: 7489.9257\n",
      "Epoch 232/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3064.5678 - val_loss: 7485.1754\n",
      "Epoch 233/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3057.9269 - val_loss: 7480.7184\n",
      "Epoch 234/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3051.4044 - val_loss: 7476.3353\n",
      "Epoch 235/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3044.9923 - val_loss: 7472.2208\n",
      "Epoch 236/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3038.7051 - val_loss: 7468.1196\n",
      "Epoch 237/1000\n",
      "244/244 [==============================] - 0s 988us/step - loss: 3032.5229 - val_loss: 7464.4159\n",
      "Epoch 238/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3026.4654 - val_loss: 7460.8133\n",
      "Epoch 239/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3020.5221 - val_loss: 7457.3464\n",
      "Epoch 240/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3014.6889 - val_loss: 7454.2412\n",
      "Epoch 241/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244/244 [==============================] - 0s 1ms/step - loss: 3008.9725 - val_loss: 7451.3338\n",
      "Epoch 242/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 3003.3766 - val_loss: 7448.4117\n",
      "Epoch 243/1000\n",
      "244/244 [==============================] - 0s 999us/step - loss: 2997.8946 - val_loss: 7445.7381\n",
      "Epoch 244/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2992.5305 - val_loss: 7443.1258\n",
      "Epoch 245/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2987.2786 - val_loss: 7440.8208\n",
      "Epoch 246/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2982.1348 - val_loss: 7438.7269\n",
      "Epoch 247/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2977.1079 - val_loss: 7436.7580\n",
      "Epoch 248/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2972.1952 - val_loss: 7434.8953\n",
      "Epoch 249/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2967.4060 - val_loss: 7432.8297\n",
      "Epoch 250/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2962.7190 - val_loss: 7431.0911\n",
      "Epoch 251/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2958.1408 - val_loss: 7429.6322\n",
      "Epoch 252/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2953.6720 - val_loss: 7428.3777\n",
      "Epoch 253/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2949.3120 - val_loss: 7427.3231\n",
      "Epoch 254/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2945.0591 - val_loss: 7426.4214\n",
      "Epoch 255/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2940.9136 - val_loss: 7425.6519\n",
      "Epoch 256/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2936.8710 - val_loss: 7425.0088\n",
      "Epoch 257/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2932.9416 - val_loss: 7424.2155\n",
      "Epoch 258/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2929.1158 - val_loss: 7423.3569\n",
      "Epoch 259/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2925.3946 - val_loss: 7422.5646\n",
      "Epoch 260/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2921.7750 - val_loss: 7421.7955\n",
      "Epoch 261/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2918.2517 - val_loss: 7421.2776\n",
      "Epoch 262/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2914.8403 - val_loss: 7420.3513\n",
      "Epoch 263/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2911.5134 - val_loss: 7419.8914\n",
      "Epoch 264/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2908.2902 - val_loss: 7419.5651\n",
      "Epoch 265/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2905.1511 - val_loss: 7419.7069\n",
      "Epoch 266/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2902.0976 - val_loss: 7420.2686\n",
      "Epoch 267/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2899.1417 - val_loss: 7420.8010\n",
      "Epoch 268/1000\n",
      "244/244 [==============================] - 0s 978us/step - loss: 2896.2726 - val_loss: 7421.4150\n",
      "Epoch 269/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2893.4952 - val_loss: 7421.8855\n",
      "Epoch 270/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2890.8069 - val_loss: 7422.2151\n",
      "Epoch 271/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2888.2040 - val_loss: 7422.6611\n",
      "Epoch 272/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2885.6754 - val_loss: 7423.3118\n",
      "Epoch 273/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2883.2515 - val_loss: 7423.3256\n",
      "Epoch 274/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2880.8886 - val_loss: 7423.7792\n",
      "Epoch 275/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2878.6035 - val_loss: 7424.4720\n",
      "Epoch 276/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2876.3950 - val_loss: 7425.2611\n",
      "Epoch 277/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2874.2589 - val_loss: 7426.1300\n",
      "Epoch 278/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2872.1986 - val_loss: 7426.9601\n",
      "Epoch 279/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2870.2009 - val_loss: 7428.0014\n",
      "Epoch 280/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2868.2842 - val_loss: 7428.7257\n",
      "Epoch 281/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2866.4342 - val_loss: 7429.4297\n",
      "Epoch 282/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2864.6485 - val_loss: 7430.1630\n",
      "Epoch 283/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2862.9265 - val_loss: 7430.9583\n",
      "Epoch 284/1000\n",
      "244/244 [==============================] - 0s 1ms/step - loss: 2861.2662 - val_loss: 7431.8218\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "243/243 [==============================] - 55s 227ms/step - loss: 27080.9432 - val_loss: 179392.7036\n",
      "Epoch 2/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 27066.5974 - val_loss: 179322.8114\n",
      "Epoch 3/1000\n",
      "243/243 [==============================] - 0s 981us/step - loss: 27039.3189 - val_loss: 179156.2536\n",
      "Epoch 4/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26972.5127 - val_loss: 178749.0936\n",
      "Epoch 5/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26818.8702 - val_loss: 177843.0403\n",
      "Epoch 6/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26502.2948 - val_loss: 176073.5457\n",
      "Epoch 7/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 25937.0406 - val_loss: 173062.3264\n",
      "Epoch 8/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 25034.5645 - val_loss: 168350.3101\n",
      "Epoch 9/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 23742.0150 - val_loss: 161703.7421\n",
      "Epoch 10/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 22114.7522 - val_loss: 153255.9464\n",
      "Epoch 11/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 20302.5625 - val_loss: 143590.2841\n",
      "Epoch 12/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 18543.4042 - val_loss: 133597.2762\n",
      "Epoch 13/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 17045.7582 - val_loss: 124219.3518\n",
      "Epoch 14/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 15912.9385 - val_loss: 116034.4426\n",
      "Epoch 15/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 15111.8160 - val_loss: 109266.3074\n",
      "Epoch 16/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 14563.9889 - val_loss: 103846.7804\n",
      "Epoch 17/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 14176.4521 - val_loss: 99545.1872\n",
      "Epoch 18/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 13882.6856 - val_loss: 96081.5292\n",
      "Epoch 19/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 13637.9208 - val_loss: 93203.9270\n",
      "Epoch 20/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 13417.0633 - val_loss: 90710.6518\n",
      "Epoch 21/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 13205.5009 - val_loss: 88473.4358\n",
      "Epoch 22/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12996.0127 - val_loss: 86393.2974\n",
      "Epoch 23/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12784.6613 - val_loss: 84383.7617\n",
      "Epoch 24/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12568.2172 - val_loss: 82399.3098\n",
      "Epoch 25/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12344.8285 - val_loss: 80398.8735\n",
      "Epoch 26/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12113.2734 - val_loss: 78362.0609\n",
      "Epoch 27/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11874.7004 - val_loss: 76317.8451\n",
      "Epoch 28/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11626.5003 - val_loss: 74275.3766\n",
      "Epoch 29/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11368.0877 - val_loss: 72137.2069\n",
      "Epoch 30/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11104.7987 - val_loss: 69975.9454\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10835.0234 - val_loss: 67792.6205\n",
      "Epoch 32/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10558.4575 - val_loss: 65630.5006\n",
      "Epoch 33/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10271.7889 - val_loss: 64133.7233\n",
      "Epoch 34/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9960.2150 - val_loss: 61168.2751\n",
      "Epoch 35/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9625.5768 - val_loss: 58307.9095\n",
      "Epoch 36/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9292.1297 - val_loss: 55601.5623\n",
      "Epoch 37/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8958.2344 - val_loss: 52931.6302\n",
      "Epoch 38/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8628.9244 - val_loss: 50294.6701\n",
      "Epoch 39/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8301.1984 - val_loss: 47745.6775\n",
      "Epoch 40/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7982.7824 - val_loss: 45106.4559\n",
      "Epoch 41/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7673.8019 - val_loss: 42510.8324\n",
      "Epoch 42/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7378.7972 - val_loss: 39952.8935\n",
      "Epoch 43/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7100.6749 - val_loss: 37463.4807\n",
      "Epoch 44/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6842.1354 - val_loss: 35105.5523\n",
      "Epoch 45/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6606.6490 - val_loss: 32860.6179\n",
      "Epoch 46/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6394.7556 - val_loss: 30754.8245\n",
      "Epoch 47/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6207.0561 - val_loss: 28816.6792\n",
      "Epoch 48/1000\n",
      "243/243 [==============================] - 0s 980us/step - loss: 6043.9213 - val_loss: 27024.4508\n",
      "Epoch 49/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5902.5112 - val_loss: 25463.7162\n",
      "Epoch 50/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5784.0476 - val_loss: 23939.1492\n",
      "Epoch 51/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5679.7282 - val_loss: 22692.5822\n",
      "Epoch 52/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5594.7546 - val_loss: 21533.9697\n",
      "Epoch 53/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5523.1440 - val_loss: 20523.5119\n",
      "Epoch 54/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5462.8283 - val_loss: 19647.2912\n",
      "Epoch 55/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5411.5988 - val_loss: 18885.7890\n",
      "Epoch 56/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5367.5246 - val_loss: 18224.6500\n",
      "Epoch 57/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5329.3517 - val_loss: 17638.1931\n",
      "Epoch 58/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5294.9651 - val_loss: 17155.6220\n",
      "Epoch 59/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5263.3529 - val_loss: 16734.1796\n",
      "Epoch 60/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5233.4734 - val_loss: 16366.4681\n",
      "Epoch 61/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5203.6990 - val_loss: 16146.9075\n",
      "Epoch 62/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5171.5765 - val_loss: 15982.0845\n",
      "Epoch 63/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5140.2172 - val_loss: 15735.6989\n",
      "Epoch 64/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5112.5294 - val_loss: 15529.2465\n",
      "Epoch 65/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5085.0614 - val_loss: 15376.6964\n",
      "Epoch 66/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5058.5759 - val_loss: 15253.8480\n",
      "Epoch 67/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5032.3290 - val_loss: 15114.3882\n",
      "Epoch 68/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5007.8328 - val_loss: 14994.2114\n",
      "Epoch 69/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4985.1422 - val_loss: 14800.6274\n",
      "Epoch 70/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4961.7680 - val_loss: 14662.1168\n",
      "Epoch 71/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4940.2071 - val_loss: 14536.0477\n",
      "Epoch 72/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4917.8957 - val_loss: 14442.3269\n",
      "Epoch 73/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4896.0214 - val_loss: 14355.0431\n",
      "Epoch 74/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4874.0396 - val_loss: 14281.4600\n",
      "Epoch 75/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4853.4338 - val_loss: 14195.3658\n",
      "Epoch 76/1000\n",
      "243/243 [==============================] - 0s 998us/step - loss: 4832.2715 - val_loss: 14108.5628\n",
      "Epoch 77/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4811.0004 - val_loss: 14039.1130\n",
      "Epoch 78/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4789.8499 - val_loss: 13963.4845\n",
      "Epoch 79/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4769.2202 - val_loss: 13889.6077\n",
      "Epoch 80/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4747.9780 - val_loss: 13831.7554\n",
      "Epoch 81/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4727.4141 - val_loss: 13769.3686\n",
      "Epoch 82/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4705.8782 - val_loss: 13757.4518\n",
      "Epoch 83/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4686.4808 - val_loss: 13648.0629\n",
      "Epoch 84/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4664.1681 - val_loss: 13594.2195\n",
      "Epoch 85/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4642.2007 - val_loss: 13548.4497\n",
      "Epoch 86/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4622.4735 - val_loss: 13475.4008\n",
      "Epoch 87/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4602.3785 - val_loss: 13405.7345\n",
      "Epoch 88/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4582.3114 - val_loss: 13338.2175\n",
      "Epoch 89/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4562.1311 - val_loss: 13279.3393\n",
      "Epoch 90/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4542.1352 - val_loss: 13225.8850\n",
      "Epoch 91/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4521.9106 - val_loss: 13182.4841\n",
      "Epoch 92/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4501.7611 - val_loss: 13140.4835\n",
      "Epoch 93/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4482.1717 - val_loss: 13066.9606\n",
      "Epoch 94/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4461.5951 - val_loss: 13019.0548\n",
      "Epoch 95/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4442.3376 - val_loss: 12969.1985\n",
      "Epoch 96/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4422.5996 - val_loss: 12911.4344\n",
      "Epoch 97/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4402.0884 - val_loss: 12849.7532\n",
      "Epoch 98/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4383.1881 - val_loss: 12803.6534\n",
      "Epoch 99/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4363.2148 - val_loss: 12768.4117\n",
      "Epoch 100/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4342.9946 - val_loss: 12709.7103\n",
      "Epoch 101/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4324.0737 - val_loss: 12666.5925\n",
      "Epoch 102/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4304.0766 - val_loss: 12637.6256\n",
      "Epoch 103/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4284.1556 - val_loss: 12586.9840\n",
      "Epoch 104/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4265.5157 - val_loss: 12530.7629\n",
      "Epoch 105/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 1ms/step - loss: 4244.7797 - val_loss: 12491.4265\n",
      "Epoch 106/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4225.7798 - val_loss: 12462.5290\n",
      "Epoch 107/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4206.6170 - val_loss: 12407.7913\n",
      "Epoch 108/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4186.3368 - val_loss: 12362.2918\n",
      "Epoch 109/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4167.4155 - val_loss: 12335.9754\n",
      "Epoch 110/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4148.0171 - val_loss: 12298.5784\n",
      "Epoch 111/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4128.0620 - val_loss: 12258.3147\n",
      "Epoch 112/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4109.5642 - val_loss: 12196.6591\n",
      "Epoch 113/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4089.6371 - val_loss: 12164.9650\n",
      "Epoch 114/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4070.1900 - val_loss: 12131.7887\n",
      "Epoch 115/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4050.9469 - val_loss: 12100.6428\n",
      "Epoch 116/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4031.9026 - val_loss: 12054.8284\n",
      "Epoch 117/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4012.4559 - val_loss: 12018.5294\n",
      "Epoch 118/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3993.1176 - val_loss: 11990.0945\n",
      "Epoch 119/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3974.4194 - val_loss: 11944.3820\n",
      "Epoch 120/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3955.2811 - val_loss: 11899.8333\n",
      "Epoch 121/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3935.4978 - val_loss: 11859.0514\n",
      "Epoch 122/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3916.7153 - val_loss: 11849.6463\n",
      "Epoch 123/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3898.1143 - val_loss: 11811.2012\n",
      "Epoch 124/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3879.2459 - val_loss: 11758.8416\n",
      "Epoch 125/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3859.3018 - val_loss: 11724.5706\n",
      "Epoch 126/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3841.0143 - val_loss: 11708.8780\n",
      "Epoch 127/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3822.3892 - val_loss: 11664.7500\n",
      "Epoch 128/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3803.3261 - val_loss: 11616.5378\n",
      "Epoch 129/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3785.1705 - val_loss: 11604.0401\n",
      "Epoch 130/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3766.4175 - val_loss: 11575.7522\n",
      "Epoch 131/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3748.1692 - val_loss: 11532.0082\n",
      "Epoch 132/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3728.5669 - val_loss: 11505.4386\n",
      "Epoch 133/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3710.7860 - val_loss: 11489.6375\n",
      "Epoch 134/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3692.8105 - val_loss: 11447.0545\n",
      "Epoch 135/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3674.0718 - val_loss: 11418.0390\n",
      "Epoch 136/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3655.9498 - val_loss: 11408.8499\n",
      "Epoch 137/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3638.0270 - val_loss: 11376.4111\n",
      "Epoch 138/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3619.6624 - val_loss: 11337.6388\n",
      "Epoch 139/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3601.4294 - val_loss: 11298.0317\n",
      "Epoch 140/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3584.0589 - val_loss: 11282.0719\n",
      "Epoch 141/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3565.7462 - val_loss: 11244.3250\n",
      "Epoch 142/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3547.4650 - val_loss: 11233.7998\n",
      "Epoch 143/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3530.5592 - val_loss: 11181.6866\n",
      "Epoch 144/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3512.8807 - val_loss: 11131.5780\n",
      "Epoch 145/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3494.4061 - val_loss: 11144.1666\n",
      "Epoch 146/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3478.1106 - val_loss: 11095.9332\n",
      "Epoch 147/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3460.5827 - val_loss: 11058.3450\n",
      "Epoch 148/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3442.5859 - val_loss: 11072.0641\n",
      "Epoch 149/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3426.6185 - val_loss: 11020.4922\n",
      "Epoch 150/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3408.7383 - val_loss: 11025.9961\n",
      "Epoch 151/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3392.9367 - val_loss: 10980.0118\n",
      "Epoch 152/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3375.9751 - val_loss: 10941.0255\n",
      "Epoch 153/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3358.5740 - val_loss: 10954.0113\n",
      "Epoch 154/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3343.3159 - val_loss: 10899.8471\n",
      "Epoch 155/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3326.1372 - val_loss: 10909.2141\n",
      "Epoch 156/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3310.9371 - val_loss: 10865.9817\n",
      "Epoch 157/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3294.6076 - val_loss: 10831.9211\n",
      "Epoch 158/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3278.0168 - val_loss: 10842.2858\n",
      "Epoch 159/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3263.6022 - val_loss: 10785.4597\n",
      "Epoch 160/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3247.1606 - val_loss: 10800.8296\n",
      "Epoch 161/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3232.7275 - val_loss: 10758.3637\n",
      "Epoch 162/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3217.2302 - val_loss: 10722.9161\n",
      "Epoch 163/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3201.6742 - val_loss: 10735.8961\n",
      "Epoch 164/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3187.6497 - val_loss: 10683.2266\n",
      "Epoch 165/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3172.5289 - val_loss: 10710.1037\n",
      "Epoch 166/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3158.7181 - val_loss: 10661.2466\n",
      "Epoch 167/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3144.6500 - val_loss: 10668.1112\n",
      "Epoch 168/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3129.8923 - val_loss: 10644.8225\n",
      "Epoch 169/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3116.1059 - val_loss: 10663.6961\n",
      "Epoch 170/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3103.0756 - val_loss: 10612.0471\n",
      "Epoch 171/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3088.7003 - val_loss: 10599.7268\n",
      "Epoch 172/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3076.0774 - val_loss: 10557.2804\n",
      "Epoch 173/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3062.8754 - val_loss: 10584.8746\n",
      "Epoch 174/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3050.5301 - val_loss: 10531.7352\n",
      "Epoch 175/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3037.1838 - val_loss: 10525.4151\n",
      "Epoch 176/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3025.6091 - val_loss: 10485.9189\n",
      "Epoch 177/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3014.0287 - val_loss: 10544.0852\n",
      "Epoch 178/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3001.1449 - val_loss: 10517.8766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2990.4576 - val_loss: 10461.5314\n",
      "Epoch 180/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2977.4565 - val_loss: 10476.4164\n",
      "Epoch 181/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2967.8193 - val_loss: 10427.6750\n",
      "Epoch 182/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2955.2716 - val_loss: 10445.3257\n",
      "Epoch 183/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2946.8161 - val_loss: 10407.0907\n",
      "Epoch 184/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2935.1930 - val_loss: 10468.7138\n",
      "Epoch 185/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2924.4274 - val_loss: 10420.2411\n",
      "Epoch 186/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2915.1861 - val_loss: 10423.0220\n",
      "Epoch 187/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2905.6407 - val_loss: 10372.2011\n",
      "Epoch 188/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2896.5102 - val_loss: 10424.8603\n",
      "Epoch 189/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2886.8377 - val_loss: 10395.0858\n",
      "Epoch 190/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2876.4597 - val_loss: 10368.5003\n",
      "Epoch 191/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2869.7206 - val_loss: 10330.5019\n",
      "Epoch 192/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2858.4313 - val_loss: 10365.8714\n",
      "Epoch 193/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2854.0967 - val_loss: 10330.4399\n",
      "Epoch 194/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2841.8232 - val_loss: 10379.9302\n",
      "Epoch 195/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2836.0284 - val_loss: 10295.0727\n",
      "Epoch 196/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2829.0811 - val_loss: 10335.1422\n",
      "Epoch 197/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2819.7203 - val_loss: 10297.2059\n",
      "Epoch 198/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2815.6109 - val_loss: 10352.6426\n",
      "Epoch 199/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2805.6322 - val_loss: 10328.6794\n",
      "Epoch 200/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2800.2503 - val_loss: 10337.0890\n",
      "Epoch 201/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2794.0449 - val_loss: 10285.0091\n",
      "Epoch 202/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2786.8529 - val_loss: 10328.3201\n",
      "Epoch 203/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2781.8790 - val_loss: 10282.5432\n",
      "Epoch 204/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2773.6889 - val_loss: 10308.1937\n",
      "Epoch 205/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2769.4587 - val_loss: 10304.9753\n",
      "Epoch 206/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2764.5198 - val_loss: 10307.0122\n",
      "Epoch 207/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2758.3002 - val_loss: 10346.5127\n",
      "Epoch 208/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2753.4571 - val_loss: 10288.3397\n",
      "Epoch 209/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2748.1091 - val_loss: 10311.0211\n",
      "Epoch 210/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2743.4907 - val_loss: 10271.1865\n",
      "Epoch 211/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2740.0565 - val_loss: 10317.1157\n",
      "Epoch 212/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2732.6975 - val_loss: 10325.6616\n",
      "Epoch 213/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2732.5466 - val_loss: 10272.2202\n",
      "Epoch 214/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2725.7239 - val_loss: 10338.1396\n",
      "Epoch 215/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2720.5046 - val_loss: 10336.6636\n",
      "Epoch 216/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2719.5633 - val_loss: 10244.9699\n",
      "Epoch 217/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2715.8289 - val_loss: 10339.3875\n",
      "Epoch 218/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2709.5786 - val_loss: 10318.7995\n",
      "Epoch 219/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2707.1904 - val_loss: 10341.1207\n",
      "Epoch 220/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2706.8454 - val_loss: 10313.8103\n",
      "Epoch 221/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2700.0077 - val_loss: 10331.8169\n",
      "Epoch 222/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2697.7656 - val_loss: 10349.6910\n",
      "Epoch 223/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2697.7536 - val_loss: 10322.4994\n",
      "Epoch 224/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2691.2734 - val_loss: 10349.4010\n",
      "Epoch 225/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2688.4374 - val_loss: 10338.6924\n",
      "Epoch 226/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2689.0986 - val_loss: 10304.2879\n",
      "Epoch 227/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2683.9909 - val_loss: 10394.4991\n",
      "Epoch 228/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2683.1196 - val_loss: 10318.0017\n",
      "Epoch 229/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2679.5628 - val_loss: 10374.0812\n",
      "Epoch 230/1000\n",
      "243/243 [==============================] - 0s 1000us/step - loss: 2678.6689 - val_loss: 10369.9629\n",
      "Epoch 231/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2673.9196 - val_loss: 10372.6916\n",
      "Epoch 232/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2675.7030 - val_loss: 10330.5298\n",
      "Epoch 233/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2670.9458 - val_loss: 10420.2162\n",
      "Epoch 234/1000\n",
      "243/243 [==============================] - 0s 988us/step - loss: 2669.2315 - val_loss: 10351.2045\n",
      "Epoch 235/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2667.2382 - val_loss: 10393.3657\n",
      "Epoch 236/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2667.8390 - val_loss: 10361.1851\n",
      "Train on 243 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "243/243 [==============================] - 56s 232ms/step - loss: 27127.1381 - val_loss: 193982.0333\n",
      "Epoch 2/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 27089.5627 - val_loss: 193707.3622\n",
      "Epoch 3/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26983.2489 - val_loss: 193021.7949\n",
      "Epoch 4/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26723.5430 - val_loss: 191395.6780\n",
      "Epoch 5/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 26170.9152 - val_loss: 188041.0115\n",
      "Epoch 6/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 25163.4337 - val_loss: 182130.2005\n",
      "Epoch 7/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 23543.0815 - val_loss: 172378.3086\n",
      "Epoch 8/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 21267.9322 - val_loss: 158938.1899\n",
      "Epoch 9/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 18807.0926 - val_loss: 143791.6967\n",
      "Epoch 10/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 16757.1716 - val_loss: 129752.5895\n",
      "Epoch 11/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 15413.7455 - val_loss: 118684.3358\n",
      "Epoch 12/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 14646.4923 - val_loss: 110754.9201\n",
      "Epoch 13/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 14193.2205 - val_loss: 105167.6712\n",
      "Epoch 14/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 13877.1201 - val_loss: 101044.4199\n",
      "Epoch 15/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 13617.4470 - val_loss: 97774.7354\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 1ms/step - loss: 13382.1347 - val_loss: 94984.1285\n",
      "Epoch 17/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 13158.8095 - val_loss: 92475.9242\n",
      "Epoch 18/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12941.7307 - val_loss: 90127.9360\n",
      "Epoch 19/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12728.3070 - val_loss: 87854.0102\n",
      "Epoch 20/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12516.4109 - val_loss: 85646.3456\n",
      "Epoch 21/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12305.5108 - val_loss: 83460.7506\n",
      "Epoch 22/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 12094.3902 - val_loss: 81300.1623\n",
      "Epoch 23/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11882.9724 - val_loss: 79133.6923\n",
      "Epoch 24/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11670.3824 - val_loss: 76975.3209\n",
      "Epoch 25/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11456.7899 - val_loss: 74808.9336\n",
      "Epoch 26/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11241.8953 - val_loss: 72631.4372\n",
      "Epoch 27/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 11025.6567 - val_loss: 70441.7474\n",
      "Epoch 28/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10808.1330 - val_loss: 68239.7476\n",
      "Epoch 29/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10589.4748 - val_loss: 66026.1717\n",
      "Epoch 30/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10369.9226 - val_loss: 63802.5955\n",
      "Epoch 31/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 10149.8135 - val_loss: 61571.3251\n",
      "Epoch 32/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9929.5725 - val_loss: 59335.3543\n",
      "Epoch 33/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9709.5450 - val_loss: 57127.6735\n",
      "Epoch 34/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9491.2686 - val_loss: 54886.5187\n",
      "Epoch 35/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9274.1247 - val_loss: 52687.2030\n",
      "Epoch 36/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 9059.9822 - val_loss: 50498.6442\n",
      "Epoch 37/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8849.3357 - val_loss: 48328.0190\n",
      "Epoch 38/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8645.7880 - val_loss: 46176.9623\n",
      "Epoch 39/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8448.6055 - val_loss: 44077.7167\n",
      "Epoch 40/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8258.5495 - val_loss: 42032.4579\n",
      "Epoch 41/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 8076.2802 - val_loss: 40057.2961\n",
      "Epoch 42/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7902.0282 - val_loss: 38157.9112\n",
      "Epoch 43/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7736.3838 - val_loss: 36337.6853\n",
      "Epoch 44/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7580.3821 - val_loss: 34596.6599\n",
      "Epoch 45/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7435.4378 - val_loss: 32942.8591\n",
      "Epoch 46/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7300.7106 - val_loss: 31389.4151\n",
      "Epoch 47/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7175.6094 - val_loss: 29935.6992\n",
      "Epoch 48/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 7060.0841 - val_loss: 28545.3084\n",
      "Epoch 49/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6953.1315 - val_loss: 27308.2092\n",
      "Epoch 50/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6854.9794 - val_loss: 26112.1747\n",
      "Epoch 51/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6764.1432 - val_loss: 25050.1428\n",
      "Epoch 52/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6680.7035 - val_loss: 24036.3183\n",
      "Epoch 53/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6603.3114 - val_loss: 23143.2693\n",
      "Epoch 54/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6532.0758 - val_loss: 22268.5967\n",
      "Epoch 55/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6465.5080 - val_loss: 21528.7439\n",
      "Epoch 56/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6403.8520 - val_loss: 20792.0399\n",
      "Epoch 57/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6345.6991 - val_loss: 20165.0031\n",
      "Epoch 58/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6291.4749 - val_loss: 19557.2975\n",
      "Epoch 59/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6239.9081 - val_loss: 19039.8696\n",
      "Epoch 60/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6191.1655 - val_loss: 18532.1531\n",
      "Epoch 61/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6144.3761 - val_loss: 18074.5860\n",
      "Epoch 62/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6099.4833 - val_loss: 17689.4201\n",
      "Epoch 63/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6056.1681 - val_loss: 17299.5176\n",
      "Epoch 64/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 6014.0094 - val_loss: 16945.9046\n",
      "Epoch 65/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5972.9748 - val_loss: 16623.5266\n",
      "Epoch 66/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5932.9378 - val_loss: 16356.0112\n",
      "Epoch 67/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5893.7658 - val_loss: 16068.0191\n",
      "Epoch 68/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5855.2016 - val_loss: 15808.2433\n",
      "Epoch 69/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5817.2640 - val_loss: 15571.0457\n",
      "Epoch 70/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5779.7990 - val_loss: 15351.7605\n",
      "Epoch 71/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5742.8108 - val_loss: 15145.2651\n",
      "Epoch 72/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5709.2601 - val_loss: 14978.9411\n",
      "Epoch 73/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5670.8865 - val_loss: 14730.1161\n",
      "Epoch 74/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5632.5078 - val_loss: 14565.1578\n",
      "Epoch 75/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5596.4777 - val_loss: 14408.2333\n",
      "Epoch 76/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5561.4134 - val_loss: 14253.8393\n",
      "Epoch 77/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5525.7820 - val_loss: 14110.9669\n",
      "Epoch 78/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5491.3360 - val_loss: 13968.7992\n",
      "Epoch 79/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5456.1331 - val_loss: 13836.5147\n",
      "Epoch 80/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5422.3485 - val_loss: 13705.0446\n",
      "Epoch 81/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5387.5005 - val_loss: 13585.3487\n",
      "Epoch 82/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5354.1944 - val_loss: 13462.1709\n",
      "Epoch 83/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5319.7100 - val_loss: 13351.6914\n",
      "Epoch 84/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5286.9337 - val_loss: 13235.9189\n",
      "Epoch 85/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5252.7987 - val_loss: 13133.2107\n",
      "Epoch 86/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5220.2934 - val_loss: 13026.1326\n",
      "Epoch 87/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5186.6300 - val_loss: 12929.2882\n",
      "Epoch 88/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5154.7138 - val_loss: 12847.2469\n",
      "Epoch 89/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5121.4658 - val_loss: 12740.9770\n",
      "Epoch 90/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 1ms/step - loss: 5089.7102 - val_loss: 12637.2516\n",
      "Epoch 91/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5056.8313 - val_loss: 12548.2060\n",
      "Epoch 92/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 5025.6556 - val_loss: 12453.8296\n",
      "Epoch 93/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4993.0955 - val_loss: 12372.0572\n",
      "Epoch 94/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4962.2260 - val_loss: 12282.6796\n",
      "Epoch 95/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4930.1768 - val_loss: 12227.3105\n",
      "Epoch 96/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4899.2561 - val_loss: 12129.6801\n",
      "Epoch 97/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4868.4041 - val_loss: 12041.2621\n",
      "Epoch 98/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4837.1349 - val_loss: 11985.3042\n",
      "Epoch 99/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4807.3528 - val_loss: 11895.3194\n",
      "Epoch 100/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4776.2179 - val_loss: 11823.9109\n",
      "Epoch 101/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4746.1049 - val_loss: 11765.9777\n",
      "Epoch 102/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4716.2019 - val_loss: 11682.5013\n",
      "Epoch 103/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4686.2834 - val_loss: 11607.0010\n",
      "Epoch 104/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4656.5707 - val_loss: 11558.1100\n",
      "Epoch 105/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4627.2182 - val_loss: 11473.2045\n",
      "Epoch 106/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4597.6220 - val_loss: 11428.2772\n",
      "Epoch 107/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4569.4249 - val_loss: 11343.3645\n",
      "Epoch 108/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4539.8146 - val_loss: 11308.6426\n",
      "Epoch 109/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4511.0472 - val_loss: 11227.0477\n",
      "Epoch 110/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4482.9644 - val_loss: 11179.5618\n",
      "Epoch 111/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4454.1315 - val_loss: 11125.0259\n",
      "Epoch 112/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4427.0695 - val_loss: 11045.2119\n",
      "Epoch 113/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4398.2975 - val_loss: 11016.5907\n",
      "Epoch 114/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4370.4980 - val_loss: 10934.0926\n",
      "Epoch 115/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4343.5568 - val_loss: 10894.5265\n",
      "Epoch 116/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4316.0273 - val_loss: 10848.2956\n",
      "Epoch 117/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4288.6318 - val_loss: 10792.5989\n",
      "Epoch 118/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4262.6808 - val_loss: 10735.5591\n",
      "Epoch 119/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4235.4347 - val_loss: 10702.6997\n",
      "Epoch 120/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4208.8900 - val_loss: 10649.9255\n",
      "Epoch 121/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4182.8968 - val_loss: 10594.4823\n",
      "Epoch 122/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4156.9104 - val_loss: 10545.7719\n",
      "Epoch 123/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4130.8751 - val_loss: 10500.1652\n",
      "Epoch 124/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4106.3194 - val_loss: 10451.8315\n",
      "Epoch 125/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4080.2961 - val_loss: 10418.8908\n",
      "Epoch 126/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4055.1749 - val_loss: 10374.1641\n",
      "Epoch 127/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4030.6881 - val_loss: 10333.6850\n",
      "Epoch 128/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 4006.0870 - val_loss: 10288.7217\n",
      "Epoch 129/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3981.7510 - val_loss: 10248.8033\n",
      "Epoch 130/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3957.4092 - val_loss: 10210.5348\n",
      "Epoch 131/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3934.5589 - val_loss: 10169.6224\n",
      "Epoch 132/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3910.3418 - val_loss: 10143.6295\n",
      "Epoch 133/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3886.9261 - val_loss: 10103.7617\n",
      "Epoch 134/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3864.1921 - val_loss: 10061.3276\n",
      "Epoch 135/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3841.4555 - val_loss: 10033.0949\n",
      "Epoch 136/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3818.9612 - val_loss: 9996.7925\n",
      "Epoch 137/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3796.7875 - val_loss: 9963.0558\n",
      "Epoch 138/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3774.9076 - val_loss: 9931.0954\n",
      "Epoch 139/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3753.3225 - val_loss: 9900.3270\n",
      "Epoch 140/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3732.0273 - val_loss: 9870.4383\n",
      "Epoch 141/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3711.0263 - val_loss: 9841.4432\n",
      "Epoch 142/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3690.3195 - val_loss: 9813.4561\n",
      "Epoch 143/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3669.9161 - val_loss: 9786.2929\n",
      "Epoch 144/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3649.8131 - val_loss: 9760.1105\n",
      "Epoch 145/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3630.0168 - val_loss: 9734.8449\n",
      "Epoch 146/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3610.5262 - val_loss: 9710.5675\n",
      "Epoch 147/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3591.3529 - val_loss: 9687.0171\n",
      "Epoch 148/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3572.5001 - val_loss: 9664.1421\n",
      "Epoch 149/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3553.8710 - val_loss: 9641.4471\n",
      "Epoch 150/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3536.3657 - val_loss: 9620.0908\n",
      "Epoch 151/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3517.8444 - val_loss: 9608.5589\n",
      "Epoch 152/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3500.3759 - val_loss: 9581.8579\n",
      "Epoch 153/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3483.0675 - val_loss: 9559.6962\n",
      "Epoch 154/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3466.1713 - val_loss: 9538.4176\n",
      "Epoch 155/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3449.7337 - val_loss: 9518.1151\n",
      "Epoch 156/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3433.3834 - val_loss: 9500.7922\n",
      "Epoch 157/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3418.1974 - val_loss: 9485.7833\n",
      "Epoch 158/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3402.0308 - val_loss: 9480.5961\n",
      "Epoch 159/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3386.4511 - val_loss: 9455.8822\n",
      "Epoch 160/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3373.1474 - val_loss: 9431.8725\n",
      "Epoch 161/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3357.2957 - val_loss: 9428.9556\n",
      "Epoch 162/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3343.1122 - val_loss: 9410.0873\n",
      "Epoch 163/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3329.8207 - val_loss: 9396.4550\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243/243 [==============================] - 0s 1ms/step - loss: 3315.7495 - val_loss: 9392.8719\n",
      "Epoch 165/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3302.4917 - val_loss: 9375.0410\n",
      "Epoch 166/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3289.5911 - val_loss: 9361.1912\n",
      "Epoch 167/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3277.0367 - val_loss: 9349.5287\n",
      "Epoch 168/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3264.7400 - val_loss: 9339.9325\n",
      "Epoch 169/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3253.4078 - val_loss: 9334.7211\n",
      "Epoch 170/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3241.2059 - val_loss: 9319.9088\n",
      "Epoch 171/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3229.6284 - val_loss: 9310.4275\n",
      "Epoch 172/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3220.2634 - val_loss: 9298.6610\n",
      "Epoch 173/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3208.3015 - val_loss: 9305.7986\n",
      "Epoch 174/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3198.0221 - val_loss: 9275.8795\n",
      "Epoch 175/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3187.9940 - val_loss: 9275.9481\n",
      "Epoch 176/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3178.2359 - val_loss: 9273.7372\n",
      "Epoch 177/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3168.8464 - val_loss: 9252.2815\n",
      "Epoch 178/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3160.2534 - val_loss: 9262.7384\n",
      "Epoch 179/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3150.8546 - val_loss: 9255.3618\n",
      "Epoch 180/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3142.2682 - val_loss: 9249.1049\n",
      "Epoch 181/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3134.5068 - val_loss: 9251.7658\n",
      "Epoch 182/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3126.0570 - val_loss: 9243.2699\n",
      "Epoch 183/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3117.8118 - val_loss: 9234.1417\n",
      "Epoch 184/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3111.9898 - val_loss: 9212.3544\n",
      "Epoch 185/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3103.3158 - val_loss: 9235.3713\n",
      "Epoch 186/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3097.0313 - val_loss: 9222.6820\n",
      "Epoch 187/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3089.6133 - val_loss: 9241.9569\n",
      "Epoch 188/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3083.6510 - val_loss: 9218.0180\n",
      "Epoch 189/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3076.8120 - val_loss: 9237.0339\n",
      "Epoch 190/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3070.3257 - val_loss: 9203.5659\n",
      "Epoch 191/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3065.9867 - val_loss: 9212.0414\n",
      "Epoch 192/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3058.8589 - val_loss: 9210.6009\n",
      "Epoch 193/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3054.5616 - val_loss: 9203.6200\n",
      "Epoch 194/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3048.1374 - val_loss: 9230.4921\n",
      "Epoch 195/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3044.0457 - val_loss: 9210.2448\n",
      "Epoch 196/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3038.1829 - val_loss: 9235.5272\n",
      "Epoch 197/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3034.2272 - val_loss: 9214.1991\n",
      "Epoch 198/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3028.9608 - val_loss: 9219.6639\n",
      "Epoch 199/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3025.1275 - val_loss: 9209.7518\n",
      "Epoch 200/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3020.3109 - val_loss: 9235.2874\n",
      "Epoch 201/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3016.8423 - val_loss: 9212.7233\n",
      "Epoch 202/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3012.2867 - val_loss: 9221.0827\n",
      "Epoch 203/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3008.5575 - val_loss: 9208.7053\n",
      "Epoch 204/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3004.2057 - val_loss: 9228.1006\n",
      "Epoch 205/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 3002.4108 - val_loss: 9207.4725\n",
      "Epoch 206/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2997.2611 - val_loss: 9221.0910\n",
      "Epoch 207/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2995.3533 - val_loss: 9215.4249\n",
      "Epoch 208/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2990.7177 - val_loss: 9226.3098\n",
      "Epoch 209/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2988.9765 - val_loss: 9219.9035\n",
      "Epoch 210/1000\n",
      "243/243 [==============================] - 0s 1ms/step - loss: 2984.5758 - val_loss: 9251.6976\n",
      "Train on 242 samples, validate on 81 samples\n",
      "Epoch 1/1000\n",
      "242/242 [==============================] - 56s 232ms/step - loss: 27241.1865 - val_loss: 193980.9508\n",
      "Epoch 2/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 27192.5972 - val_loss: 193668.2163\n",
      "Epoch 3/1000\n",
      "242/242 [==============================] - 0s 995us/step - loss: 27093.5980 - val_loss: 193051.8340\n",
      "Epoch 4/1000\n",
      "242/242 [==============================] - 0s 912us/step - loss: 26907.3862 - val_loss: 191903.2113\n",
      "Epoch 5/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 26567.2185 - val_loss: 189820.8023\n",
      "Epoch 6/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 25962.5850 - val_loss: 186204.8641\n",
      "Epoch 7/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 24980.2113 - val_loss: 180530.9815\n",
      "Epoch 8/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 23565.8419 - val_loss: 172483.8459\n",
      "Epoch 9/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 21777.7476 - val_loss: 162257.2593\n",
      "Epoch 10/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 19818.4127 - val_loss: 150664.7538\n",
      "Epoch 11/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 17977.5819 - val_loss: 138959.3140\n",
      "Epoch 12/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 16495.9669 - val_loss: 128363.9043\n",
      "Epoch 13/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 15454.7340 - val_loss: 119599.4204\n",
      "Epoch 14/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 14785.1386 - val_loss: 112773.8005\n",
      "Epoch 15/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 14361.6821 - val_loss: 107594.4567\n",
      "Epoch 16/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 14077.5448 - val_loss: 103644.9152\n",
      "Epoch 17/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13865.9208 - val_loss: 100551.1579\n",
      "Epoch 18/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13691.2074 - val_loss: 98032.4714\n",
      "Epoch 19/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13535.7173 - val_loss: 95895.2655\n",
      "Epoch 20/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13390.7797 - val_loss: 94011.5084\n",
      "Epoch 21/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13252.0374 - val_loss: 92297.4270\n",
      "Epoch 22/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 13117.1780 - val_loss: 90698.3313\n",
      "Epoch 23/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12984.8910 - val_loss: 89177.6463\n",
      "Epoch 24/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12854.3177 - val_loss: 87711.2024\n",
      "Epoch 25/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12724.9288 - val_loss: 86282.2662\n",
      "Epoch 26/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12596.3447 - val_loss: 84879.3596\n",
      "Epoch 27/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12468.2841 - val_loss: 83494.5213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12340.5570 - val_loss: 82122.0945\n",
      "Epoch 29/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12213.0041 - val_loss: 80758.1090\n",
      "Epoch 30/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 12085.4787 - val_loss: 79399.5623\n",
      "Epoch 31/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11958.0337 - val_loss: 78044.4065\n",
      "Epoch 32/1000\n",
      "242/242 [==============================] - 0s 999us/step - loss: 11830.3589 - val_loss: 76691.3401\n",
      "Epoch 33/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11702.5829 - val_loss: 75339.1138\n",
      "Epoch 34/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11574.6454 - val_loss: 73986.9944\n",
      "Epoch 35/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11446.5446 - val_loss: 72634.5932\n",
      "Epoch 36/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11318.2890 - val_loss: 71281.8342\n",
      "Epoch 37/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11189.9088 - val_loss: 69928.4094\n",
      "Epoch 38/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 11061.4436 - val_loss: 68574.7555\n",
      "Epoch 39/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10932.9464 - val_loss: 67221.1091\n",
      "Epoch 40/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10804.4822 - val_loss: 65867.9138\n",
      "Epoch 41/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10676.1274 - val_loss: 64515.7168\n",
      "Epoch 42/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10548.0211 - val_loss: 63165.2606\n",
      "Epoch 43/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10420.1964 - val_loss: 61817.4230\n",
      "Epoch 44/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10292.7701 - val_loss: 60472.9786\n",
      "Epoch 45/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10166.1096 - val_loss: 59133.0417\n",
      "Epoch 46/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 10039.8887 - val_loss: 57799.0284\n",
      "Epoch 47/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9914.5244 - val_loss: 56471.6715\n",
      "Epoch 48/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9790.1149 - val_loss: 55152.2522\n",
      "Epoch 49/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9666.8177 - val_loss: 53842.0863\n",
      "Epoch 50/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9544.8237 - val_loss: 52542.6909\n",
      "Epoch 51/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9424.3087 - val_loss: 51255.6039\n",
      "Epoch 52/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9305.3322 - val_loss: 49982.1601\n",
      "Epoch 53/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9188.4930 - val_loss: 48724.0819\n",
      "Epoch 54/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 9073.2986 - val_loss: 47483.4403\n",
      "Epoch 55/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8960.1731 - val_loss: 46261.0030\n",
      "Epoch 56/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8849.2747 - val_loss: 45058.2765\n",
      "Epoch 57/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8740.7543 - val_loss: 43876.7836\n",
      "Epoch 58/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8634.7453 - val_loss: 42718.0085\n",
      "Epoch 59/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8531.3625 - val_loss: 41583.3869\n",
      "Epoch 60/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8430.7130 - val_loss: 40474.1811\n",
      "Epoch 61/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8332.8846 - val_loss: 39391.6026\n",
      "Epoch 62/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8238.0399 - val_loss: 38336.8355\n",
      "Epoch 63/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8146.0960 - val_loss: 37311.0266\n",
      "Epoch 64/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 8057.2436 - val_loss: 36314.8286\n",
      "Epoch 65/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7971.3259 - val_loss: 35349.3182\n",
      "Epoch 66/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7888.4042 - val_loss: 34414.6611\n",
      "Epoch 67/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7808.5132 - val_loss: 33511.4606\n",
      "Epoch 68/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7731.6157 - val_loss: 32639.9043\n",
      "Epoch 69/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7657.7956 - val_loss: 31800.6647\n",
      "Epoch 70/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7586.4692 - val_loss: 30992.9369\n",
      "Epoch 71/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7517.8491 - val_loss: 30216.5745\n",
      "Epoch 72/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7451.8490 - val_loss: 29471.3342\n",
      "Epoch 73/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7388.7630 - val_loss: 28757.0606\n",
      "Epoch 74/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7327.9032 - val_loss: 28073.8113\n",
      "Epoch 75/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7269.1653 - val_loss: 27420.0625\n",
      "Epoch 76/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7212.5623 - val_loss: 26795.0881\n",
      "Epoch 77/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7157.9857 - val_loss: 26198.1135\n",
      "Epoch 78/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7106.6767 - val_loss: 25628.6434\n",
      "Epoch 79/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7055.5703 - val_loss: 25086.9758\n",
      "Epoch 80/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 7006.4901 - val_loss: 24570.4816\n",
      "Epoch 81/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6958.9152 - val_loss: 24078.1462\n",
      "Epoch 82/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6912.7604 - val_loss: 23609.0519\n",
      "Epoch 83/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6867.9147 - val_loss: 23162.2587\n",
      "Epoch 84/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6824.2711 - val_loss: 22736.7792\n",
      "Epoch 85/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6781.7337 - val_loss: 22331.6236\n",
      "Epoch 86/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6740.2080 - val_loss: 21945.8481\n",
      "Epoch 87/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6699.6078 - val_loss: 21578.4397\n",
      "Epoch 88/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6659.8535 - val_loss: 21228.4316\n",
      "Epoch 89/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6621.0096 - val_loss: 20894.9615\n",
      "Epoch 90/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6582.7905 - val_loss: 20577.2692\n",
      "Epoch 91/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6545.3752 - val_loss: 20274.3311\n",
      "Epoch 92/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6508.4141 - val_loss: 19985.5051\n",
      "Epoch 93/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6472.0809 - val_loss: 19709.7356\n",
      "Epoch 94/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6436.2374 - val_loss: 19446.4524\n",
      "Epoch 95/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6400.7930 - val_loss: 19194.6768\n",
      "Epoch 96/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6365.8325 - val_loss: 18953.8825\n",
      "Epoch 97/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6331.4676 - val_loss: 18723.3753\n",
      "Epoch 98/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6297.3633 - val_loss: 18502.9756\n",
      "Epoch 99/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6263.3674 - val_loss: 18291.4046\n",
      "Epoch 100/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6229.6615 - val_loss: 18088.1390\n",
      "Epoch 101/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6196.5568 - val_loss: 17892.8978\n",
      "Epoch 102/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 6163.7141 - val_loss: 17705.6724\n",
      "Epoch 103/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6130.8445 - val_loss: 17525.2732\n",
      "Epoch 104/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6098.1920 - val_loss: 17351.3042\n",
      "Epoch 105/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6066.0887 - val_loss: 17183.6150\n",
      "Epoch 106/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6034.1931 - val_loss: 17022.2979\n",
      "Epoch 107/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6002.2103 - val_loss: 16866.2829\n",
      "Epoch 108/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5970.3995 - val_loss: 16715.2354\n",
      "Epoch 109/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5939.1421 - val_loss: 16569.1085\n",
      "Epoch 110/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5907.9863 - val_loss: 16428.1093\n",
      "Epoch 111/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5876.7401 - val_loss: 16291.2181\n",
      "Epoch 112/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5845.6402 - val_loss: 16158.1987\n",
      "Epoch 113/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5815.4050 - val_loss: 16029.1813\n",
      "Epoch 114/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5785.1962 - val_loss: 15904.9616\n",
      "Epoch 115/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5754.6517 - val_loss: 15783.8316\n",
      "Epoch 116/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5724.2211 - val_loss: 15665.6142\n",
      "Epoch 117/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5693.9379 - val_loss: 15550.2584\n",
      "Epoch 118/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5663.7990 - val_loss: 15437.6745\n",
      "Epoch 119/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5633.8014 - val_loss: 15327.7796\n",
      "Epoch 120/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5603.9452 - val_loss: 15220.4447\n",
      "Epoch 121/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5574.3659 - val_loss: 15115.6318\n",
      "Epoch 122/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5544.8791 - val_loss: 15013.3949\n",
      "Epoch 123/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5515.7415 - val_loss: 14913.5465\n",
      "Epoch 124/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5486.7117 - val_loss: 14816.3157\n",
      "Epoch 125/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5457.5609 - val_loss: 14720.9432\n",
      "Epoch 126/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5428.5319 - val_loss: 14627.3431\n",
      "Epoch 127/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5399.9990 - val_loss: 14535.7118\n",
      "Epoch 128/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5371.4448 - val_loss: 14446.3440\n",
      "Epoch 129/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5342.8336 - val_loss: 14358.5031\n",
      "Epoch 130/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5314.3492 - val_loss: 14272.1200\n",
      "Epoch 131/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5286.4322 - val_loss: 14187.4248\n",
      "Epoch 132/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5258.3385 - val_loss: 14104.7396\n",
      "Epoch 133/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5230.2709 - val_loss: 14023.3378\n",
      "Epoch 134/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5202.3353 - val_loss: 13943.1449\n",
      "Epoch 135/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5175.0425 - val_loss: 13864.4344\n",
      "Epoch 136/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5147.4151 - val_loss: 13787.5318\n",
      "Epoch 137/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5119.9028 - val_loss: 13711.7301\n",
      "Epoch 138/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5092.5763 - val_loss: 13637.0612\n",
      "Epoch 139/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5065.4762 - val_loss: 13563.6777\n",
      "Epoch 140/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5038.7382 - val_loss: 13491.5268\n",
      "Epoch 141/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5011.9650 - val_loss: 13420.9451\n",
      "Epoch 142/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4985.1774 - val_loss: 13350.4417\n",
      "Epoch 143/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4958.5007 - val_loss: 13281.9024\n",
      "Epoch 144/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4932.5484 - val_loss: 13214.6360\n",
      "Epoch 145/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4906.8156 - val_loss: 13149.4847\n",
      "Epoch 146/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4880.6573 - val_loss: 13084.9293\n",
      "Epoch 147/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4854.6221 - val_loss: 13020.9712\n",
      "Epoch 148/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4828.7437 - val_loss: 12957.7601\n",
      "Epoch 149/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4803.0254 - val_loss: 12895.3655\n",
      "Epoch 150/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4777.4693 - val_loss: 12833.8172\n",
      "Epoch 151/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4752.0775 - val_loss: 12773.1663\n",
      "Epoch 152/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4726.8530 - val_loss: 12713.3959\n",
      "Epoch 153/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4701.9041 - val_loss: 12654.5573\n",
      "Epoch 154/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4677.0848 - val_loss: 12596.7969\n",
      "Epoch 155/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4652.4971 - val_loss: 12539.9550\n",
      "Epoch 156/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4628.0262 - val_loss: 12484.1109\n",
      "Epoch 157/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4603.7794 - val_loss: 12429.1039\n",
      "Epoch 158/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4579.6708 - val_loss: 12375.0550\n",
      "Epoch 159/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4555.7746 - val_loss: 12321.7878\n",
      "Epoch 160/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4532.0348 - val_loss: 12269.4510\n",
      "Epoch 161/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4508.5342 - val_loss: 12217.9472\n",
      "Epoch 162/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4485.2607 - val_loss: 12167.4576\n",
      "Epoch 163/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4462.0216 - val_loss: 12117.5971\n",
      "Epoch 164/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4438.9822 - val_loss: 12068.3616\n",
      "Epoch 165/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4416.4046 - val_loss: 12020.0360\n",
      "Epoch 166/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4393.7916 - val_loss: 11972.8069\n",
      "Epoch 167/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4371.3489 - val_loss: 11926.1711\n",
      "Epoch 168/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4349.1098 - val_loss: 11880.1540\n",
      "Epoch 169/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4327.2514 - val_loss: 11835.0104\n",
      "Epoch 170/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4305.5935 - val_loss: 11790.9620\n",
      "Epoch 171/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4283.9869 - val_loss: 11747.4803\n",
      "Epoch 172/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4262.5897 - val_loss: 11704.5725\n",
      "Epoch 173/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4241.4141 - val_loss: 11662.2983\n",
      "Epoch 174/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4220.5627 - val_loss: 11620.4662\n",
      "Epoch 175/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4199.8700 - val_loss: 11579.9043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4179.3743 - val_loss: 11539.9380\n",
      "Epoch 177/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4159.2081 - val_loss: 11500.7131\n",
      "Epoch 178/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4139.2074 - val_loss: 11462.3271\n",
      "Epoch 179/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4119.4023 - val_loss: 11424.5029\n",
      "Epoch 180/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4099.9064 - val_loss: 11391.7851\n",
      "Epoch 181/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4080.8139 - val_loss: 11351.7199\n",
      "Epoch 182/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4061.5175 - val_loss: 11316.4516\n",
      "Epoch 183/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4042.7205 - val_loss: 11280.7094\n",
      "Epoch 184/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4024.1600 - val_loss: 11246.9752\n",
      "Epoch 185/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4005.7929 - val_loss: 11212.8618\n",
      "Epoch 186/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3987.7164 - val_loss: 11180.3668\n",
      "Epoch 187/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3969.8880 - val_loss: 11147.4541\n",
      "Epoch 188/1000\n",
      "242/242 [==============================] - 0s 997us/step - loss: 3952.2825 - val_loss: 11116.2967\n",
      "Epoch 189/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3934.9418 - val_loss: 11084.6096\n",
      "Epoch 190/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3917.8583 - val_loss: 11054.7730\n",
      "Epoch 191/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3901.0340 - val_loss: 11023.2812\n",
      "Epoch 192/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3884.4885 - val_loss: 10994.0927\n",
      "Epoch 193/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3868.1901 - val_loss: 10965.6504\n",
      "Epoch 194/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3852.1173 - val_loss: 10937.7160\n",
      "Epoch 195/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3836.3050 - val_loss: 10910.3062\n",
      "Epoch 196/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3820.7716 - val_loss: 10883.5043\n",
      "Epoch 197/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3805.4986 - val_loss: 10857.3975\n",
      "Epoch 198/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3790.4686 - val_loss: 10831.8069\n",
      "Epoch 199/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3775.7010 - val_loss: 10806.7298\n",
      "Epoch 200/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3761.1968 - val_loss: 10782.1878\n",
      "Epoch 201/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3746.9572 - val_loss: 10758.1855\n",
      "Epoch 202/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3732.9835 - val_loss: 10734.8179\n",
      "Epoch 203/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3719.2653 - val_loss: 10711.9677\n",
      "Epoch 204/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3705.8087 - val_loss: 10689.6351\n",
      "Epoch 205/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3692.6126 - val_loss: 10667.8165\n",
      "Epoch 206/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3679.6768 - val_loss: 10646.5205\n",
      "Epoch 207/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3666.9997 - val_loss: 10625.7423\n",
      "Epoch 208/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3654.5797 - val_loss: 10605.4732\n",
      "Epoch 209/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3642.4157 - val_loss: 10585.7013\n",
      "Epoch 210/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3630.5074 - val_loss: 10566.4336\n",
      "Epoch 211/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3618.8502 - val_loss: 10547.6456\n",
      "Epoch 212/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3607.4439 - val_loss: 10529.3493\n",
      "Epoch 213/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3596.2871 - val_loss: 10511.5136\n",
      "Epoch 214/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3585.3759 - val_loss: 10494.1351\n",
      "Epoch 215/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3574.7087 - val_loss: 10477.2187\n",
      "Epoch 216/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3564.2830 - val_loss: 10460.7454\n",
      "Epoch 217/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3554.0971 - val_loss: 10444.7107\n",
      "Epoch 218/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3544.1472 - val_loss: 10429.1016\n",
      "Epoch 219/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3534.4305 - val_loss: 10413.9086\n",
      "Epoch 220/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3524.9461 - val_loss: 10399.1206\n",
      "Epoch 221/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3515.6874 - val_loss: 10384.7315\n",
      "Epoch 222/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3506.6547 - val_loss: 10370.7362\n",
      "Epoch 223/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3497.8424 - val_loss: 10357.1123\n",
      "Epoch 224/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3489.2483 - val_loss: 10343.8530\n",
      "Epoch 225/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3480.8689 - val_loss: 10330.9648\n",
      "Epoch 226/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3472.7006 - val_loss: 10318.4141\n",
      "Epoch 227/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3464.7402 - val_loss: 10306.2191\n",
      "Epoch 228/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3456.9833 - val_loss: 10294.3516\n",
      "Epoch 229/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3449.4260 - val_loss: 10282.8104\n",
      "Epoch 230/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3442.0655 - val_loss: 10271.5825\n",
      "Epoch 231/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3434.9325 - val_loss: 10260.5803\n",
      "Epoch 232/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3428.0235 - val_loss: 10249.7580\n",
      "Epoch 233/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3421.3090 - val_loss: 10239.1343\n",
      "Epoch 234/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3414.7835 - val_loss: 10228.7340\n",
      "Epoch 235/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3408.4442 - val_loss: 10218.5664\n",
      "Epoch 236/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3402.2873 - val_loss: 10208.6534\n",
      "Epoch 237/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3396.3087 - val_loss: 10198.9735\n",
      "Epoch 238/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3390.5041 - val_loss: 10189.5095\n",
      "Epoch 239/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3384.8685 - val_loss: 10180.2682\n",
      "Epoch 240/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3379.3998 - val_loss: 10171.2509\n",
      "Epoch 241/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3374.0918 - val_loss: 10162.4315\n",
      "Epoch 242/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3368.9410 - val_loss: 10153.8166\n",
      "Epoch 243/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3363.9443 - val_loss: 10145.3923\n",
      "Epoch 244/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3359.0968 - val_loss: 10137.1543\n",
      "Epoch 245/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3354.3946 - val_loss: 10129.1012\n",
      "Epoch 246/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3349.8332 - val_loss: 10121.2124\n",
      "Epoch 247/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3345.4083 - val_loss: 10113.4851\n",
      "Epoch 248/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3341.1172 - val_loss: 10105.9154\n",
      "Epoch 249/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3336.9538 - val_loss: 10098.4880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3332.9159 - val_loss: 10091.2141\n",
      "Epoch 251/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3328.9987 - val_loss: 10084.0657\n",
      "Epoch 252/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3325.2000 - val_loss: 10077.0602\n",
      "Epoch 253/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3321.5125 - val_loss: 10070.1681\n",
      "Epoch 254/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3317.9364 - val_loss: 10063.4014\n",
      "Epoch 255/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3314.4647 - val_loss: 10056.7386\n",
      "Epoch 256/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3311.0957 - val_loss: 10050.1888\n",
      "Epoch 257/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3307.8252 - val_loss: 10043.7299\n",
      "Epoch 258/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3304.6500 - val_loss: 10037.3709\n",
      "Epoch 259/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3301.5661 - val_loss: 10031.1052\n",
      "Epoch 260/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3298.5701 - val_loss: 10024.9299\n",
      "Epoch 261/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3295.6599 - val_loss: 10018.8256\n",
      "Epoch 262/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3292.8304 - val_loss: 10012.7981\n",
      "Epoch 263/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3290.0792 - val_loss: 10006.8421\n",
      "Epoch 264/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3287.4044 - val_loss: 10000.9472\n",
      "Epoch 265/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3284.8013 - val_loss: 9995.1217\n",
      "Epoch 266/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3282.2681 - val_loss: 9989.3584\n",
      "Epoch 267/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3279.8014 - val_loss: 9983.6439\n",
      "Epoch 268/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3277.3992 - val_loss: 9977.9887\n",
      "Epoch 269/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3275.0574 - val_loss: 9972.3681\n",
      "Epoch 270/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3272.7748 - val_loss: 9966.7901\n",
      "Epoch 271/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3270.5492 - val_loss: 9961.2603\n",
      "Epoch 272/1000\n",
      "242/242 [==============================] - ETA: 0s - loss: 3616.33 - 0s 1ms/step - loss: 3268.3760 - val_loss: 9955.7667\n",
      "Epoch 273/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3266.2548 - val_loss: 9950.3120\n",
      "Epoch 274/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3264.1824 - val_loss: 9944.8883\n",
      "Epoch 275/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3262.1575 - val_loss: 9939.4876\n",
      "Epoch 276/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3260.1773 - val_loss: 9934.1141\n",
      "Epoch 277/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3258.2405 - val_loss: 9928.7788\n",
      "Epoch 278/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3256.3432 - val_loss: 9923.4534\n",
      "Epoch 279/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3254.4858 - val_loss: 9918.1427\n",
      "Epoch 280/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3252.6658 - val_loss: 9912.8523\n",
      "Epoch 281/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3250.8810 - val_loss: 9907.5823\n",
      "Epoch 282/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3249.1297 - val_loss: 9902.3177\n",
      "Epoch 283/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3247.4113 - val_loss: 9897.0679\n",
      "Epoch 284/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3245.7230 - val_loss: 9891.8355\n",
      "Epoch 285/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3244.0642 - val_loss: 9886.6134\n",
      "Epoch 286/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3242.4325 - val_loss: 9881.3973\n",
      "Epoch 287/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3240.8282 - val_loss: 9876.1867\n",
      "Epoch 288/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3239.2482 - val_loss: 9870.9806\n",
      "Epoch 289/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3237.6922 - val_loss: 9865.7783\n",
      "Epoch 290/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3236.1595 - val_loss: 9860.5810\n",
      "Epoch 291/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3234.6481 - val_loss: 9855.3834\n",
      "Epoch 292/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3233.1576 - val_loss: 9850.1915\n",
      "Epoch 293/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3231.6863 - val_loss: 9844.9931\n",
      "Epoch 294/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3230.2341 - val_loss: 9839.8055\n",
      "Epoch 295/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3228.7990 - val_loss: 9834.6070\n",
      "Epoch 296/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3227.3809 - val_loss: 9829.4208\n",
      "Epoch 297/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3225.9787 - val_loss: 9824.2378\n",
      "Epoch 298/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3224.5914 - val_loss: 9819.0368\n",
      "Epoch 299/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3223.2189 - val_loss: 9813.8309\n",
      "Epoch 300/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3221.8604 - val_loss: 9808.6234\n",
      "Epoch 301/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3220.5153 - val_loss: 9803.4247\n",
      "Epoch 302/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3219.1812 - val_loss: 9798.2205\n",
      "Epoch 303/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3217.8599 - val_loss: 9792.9984\n",
      "Epoch 304/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3216.5493 - val_loss: 9787.7900\n",
      "Epoch 305/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3215.2498 - val_loss: 9782.5802\n",
      "Epoch 306/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3213.9606 - val_loss: 9777.3609\n",
      "Epoch 307/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3212.6806 - val_loss: 9772.1314\n",
      "Epoch 308/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3211.4099 - val_loss: 9766.9091\n",
      "Epoch 309/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3210.1482 - val_loss: 9761.6759\n",
      "Epoch 310/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3208.8952 - val_loss: 9756.4420\n",
      "Epoch 311/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3207.6497 - val_loss: 9751.1983\n",
      "Epoch 312/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3206.4121 - val_loss: 9745.9624\n",
      "Epoch 313/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3205.1807 - val_loss: 9740.7167\n",
      "Epoch 314/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3203.9578 - val_loss: 9735.4703\n",
      "Epoch 315/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3202.7417 - val_loss: 9730.2253\n",
      "Epoch 316/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3201.5311 - val_loss: 9724.9725\n",
      "Epoch 317/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3200.3264 - val_loss: 9719.7185\n",
      "Epoch 318/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3199.1281 - val_loss: 9714.4616\n",
      "Epoch 319/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3197.9352 - val_loss: 9709.1961\n",
      "Epoch 320/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3196.7479 - val_loss: 9703.9319\n",
      "Epoch 321/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3195.5657 - val_loss: 9698.6719\n",
      "Epoch 322/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3194.3883 - val_loss: 9693.4044\n",
      "Epoch 323/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3193.2154 - val_loss: 9688.1349\n",
      "Epoch 324/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 3192.0479 - val_loss: 9682.8650\n",
      "Epoch 325/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3190.8848 - val_loss: 9677.5837\n",
      "Epoch 326/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3189.7257 - val_loss: 9672.3110\n",
      "Epoch 327/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3188.5694 - val_loss: 9666.7954\n",
      "Epoch 328/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3187.4197 - val_loss: 9661.6242\n",
      "Epoch 329/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3186.2726 - val_loss: 9656.4228\n",
      "Epoch 330/1000\n",
      "242/242 [==============================] - 0s 998us/step - loss: 3185.1293 - val_loss: 9651.1690\n",
      "Epoch 331/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3183.9897 - val_loss: 9645.9096\n",
      "Epoch 332/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3182.8545 - val_loss: 9640.6453\n",
      "Epoch 333/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3181.7218 - val_loss: 9635.3912\n",
      "Epoch 334/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3180.5925 - val_loss: 9630.1216\n",
      "Epoch 335/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3179.4671 - val_loss: 9624.8599\n",
      "Epoch 336/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3178.3446 - val_loss: 9619.5905\n",
      "Epoch 337/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3177.2247 - val_loss: 9614.3261\n",
      "Epoch 338/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3176.1087 - val_loss: 9609.0661\n",
      "Epoch 339/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3174.9958 - val_loss: 9603.8045\n",
      "Epoch 340/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3173.8854 - val_loss: 9598.5467\n",
      "Epoch 341/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3172.7779 - val_loss: 9593.2952\n",
      "Epoch 342/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3171.6732 - val_loss: 9588.0428\n",
      "Epoch 343/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3170.5717 - val_loss: 9582.7972\n",
      "Epoch 344/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3169.4733 - val_loss: 9577.5573\n",
      "Epoch 345/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3168.3768 - val_loss: 9572.3134\n",
      "Epoch 346/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3167.2834 - val_loss: 9567.0681\n",
      "Epoch 347/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3166.1924 - val_loss: 9561.8213\n",
      "Epoch 348/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3165.1044 - val_loss: 9556.5884\n",
      "Epoch 349/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3164.0185 - val_loss: 9551.3743\n",
      "Epoch 350/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3162.9352 - val_loss: 9546.1603\n",
      "Epoch 351/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3161.8544 - val_loss: 9540.9516\n",
      "Epoch 352/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3160.7770 - val_loss: 9535.7421\n",
      "Epoch 353/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3159.7014 - val_loss: 9530.5357\n",
      "Epoch 354/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3158.6281 - val_loss: 9525.3293\n",
      "Epoch 355/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3157.5576 - val_loss: 9520.1410\n",
      "Epoch 356/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3156.4891 - val_loss: 9514.9493\n",
      "Epoch 357/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3155.4234 - val_loss: 9509.7606\n",
      "Epoch 358/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3154.3600 - val_loss: 9504.5870\n",
      "Epoch 359/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3153.2989 - val_loss: 9499.4184\n",
      "Epoch 360/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3152.2399 - val_loss: 9494.2458\n",
      "Epoch 361/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3151.1841 - val_loss: 9489.0813\n",
      "Epoch 362/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3150.1294 - val_loss: 9483.9327\n",
      "Epoch 363/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3149.0778 - val_loss: 9478.7861\n",
      "Epoch 364/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3148.0293 - val_loss: 9473.6523\n",
      "Epoch 365/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3146.9818 - val_loss: 9468.5220\n",
      "Epoch 366/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3145.9363 - val_loss: 9463.3941\n",
      "Epoch 367/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3144.8941 - val_loss: 9458.2831\n",
      "Epoch 368/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3143.8542 - val_loss: 9453.1764\n",
      "Epoch 369/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3142.8164 - val_loss: 9448.0693\n",
      "Epoch 370/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3141.7800 - val_loss: 9442.9724\n",
      "Epoch 371/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3140.7474 - val_loss: 9437.8847\n",
      "Epoch 372/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3139.7162 - val_loss: 9432.8025\n",
      "Epoch 373/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3138.6860 - val_loss: 9427.4849\n",
      "Epoch 374/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3137.6608 - val_loss: 9422.5256\n",
      "Epoch 375/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3136.6364 - val_loss: 9417.5296\n",
      "Epoch 376/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3135.6139 - val_loss: 9412.5093\n",
      "Epoch 377/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3134.5939 - val_loss: 9407.4902\n",
      "Epoch 378/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3133.5763 - val_loss: 9402.4693\n",
      "Epoch 379/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3132.5613 - val_loss: 9397.4523\n",
      "Epoch 380/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3131.5480 - val_loss: 9392.4442\n",
      "Epoch 381/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3130.5370 - val_loss: 9387.4403\n",
      "Epoch 382/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3129.5287 - val_loss: 9382.4436\n",
      "Epoch 383/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3128.5216 - val_loss: 9377.4512\n",
      "Epoch 384/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3127.5179 - val_loss: 9372.4660\n",
      "Epoch 385/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3126.5159 - val_loss: 9367.5026\n",
      "Epoch 386/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3125.5165 - val_loss: 9362.5512\n",
      "Epoch 387/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3124.5186 - val_loss: 9357.6058\n",
      "Epoch 388/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3123.5234 - val_loss: 9352.6585\n",
      "Epoch 389/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3122.5303 - val_loss: 9347.7213\n",
      "Epoch 390/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3121.5397 - val_loss: 9342.7927\n",
      "Epoch 391/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3120.5510 - val_loss: 9337.8826\n",
      "Epoch 392/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3119.5645 - val_loss: 9332.9741\n",
      "Epoch 393/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3118.5808 - val_loss: 9328.0715\n",
      "Epoch 394/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3117.5986 - val_loss: 9323.1824\n",
      "Epoch 395/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3116.6192 - val_loss: 9318.3021\n",
      "Epoch 396/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3115.6409 - val_loss: 9313.4302\n",
      "Epoch 397/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3114.6659 - val_loss: 9308.5678\n",
      "Epoch 398/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 3113.6928 - val_loss: 9303.7120\n",
      "Epoch 399/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3112.7217 - val_loss: 9298.8619\n",
      "Epoch 400/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3111.7533 - val_loss: 9294.0249\n",
      "Epoch 401/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3110.7869 - val_loss: 9289.2040\n",
      "Epoch 402/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3109.8229 - val_loss: 9284.3904\n",
      "Epoch 403/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3108.8606 - val_loss: 9279.5823\n",
      "Epoch 404/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3107.9004 - val_loss: 9274.7849\n",
      "Epoch 405/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3106.9431 - val_loss: 9269.9972\n",
      "Epoch 406/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3105.9875 - val_loss: 9265.2256\n",
      "Epoch 407/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3105.0341 - val_loss: 9260.4591\n",
      "Epoch 408/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3104.0831 - val_loss: 9255.6930\n",
      "Epoch 409/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3103.1342 - val_loss: 9250.9389\n",
      "Epoch 410/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3102.1877 - val_loss: 9246.1931\n",
      "Epoch 411/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3101.2431 - val_loss: 9241.4619\n",
      "Epoch 412/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3100.2995 - val_loss: 9236.4932\n",
      "Epoch 413/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3099.3609 - val_loss: 9231.8943\n",
      "Epoch 414/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3098.4227 - val_loss: 9227.2643\n",
      "Epoch 415/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3097.4872 - val_loss: 9222.6041\n",
      "Epoch 416/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3096.5538 - val_loss: 9217.9338\n",
      "Epoch 417/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3095.6223 - val_loss: 9213.2748\n",
      "Epoch 418/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3094.6926 - val_loss: 9208.6151\n",
      "Epoch 419/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3093.7659 - val_loss: 9203.9586\n",
      "Epoch 420/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3092.8409 - val_loss: 9199.3198\n",
      "Epoch 421/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3091.9188 - val_loss: 9194.6903\n",
      "Epoch 422/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3090.9976 - val_loss: 9190.0649\n",
      "Epoch 423/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3090.0800 - val_loss: 9185.4508\n",
      "Epoch 424/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3089.1640 - val_loss: 9180.8475\n",
      "Epoch 425/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3088.2499 - val_loss: 9176.2536\n",
      "Epoch 426/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3087.3383 - val_loss: 9171.6699\n",
      "Epoch 427/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3086.4290 - val_loss: 9167.0904\n",
      "Epoch 428/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3085.5217 - val_loss: 9162.5294\n",
      "Epoch 429/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3084.6160 - val_loss: 9157.9745\n",
      "Epoch 430/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3083.7132 - val_loss: 9153.4276\n",
      "Epoch 431/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3082.8124 - val_loss: 9148.8892\n",
      "Epoch 432/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3081.9139 - val_loss: 9144.3662\n",
      "Epoch 433/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3081.0173 - val_loss: 9139.8458\n",
      "Epoch 434/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3080.1229 - val_loss: 9135.3369\n",
      "Epoch 435/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3079.2306 - val_loss: 9130.8379\n",
      "Epoch 436/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3078.3403 - val_loss: 9126.3471\n",
      "Epoch 437/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3077.4529 - val_loss: 9121.8479\n",
      "Epoch 438/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3076.5672 - val_loss: 9117.3733\n",
      "Epoch 439/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3075.6836 - val_loss: 9112.9262\n",
      "Epoch 440/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3074.8021 - val_loss: 9108.4802\n",
      "Epoch 441/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3073.9222 - val_loss: 9104.0347\n",
      "Epoch 442/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3073.0447 - val_loss: 9099.6022\n",
      "Epoch 443/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3072.1704 - val_loss: 9095.1762\n",
      "Epoch 444/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3071.2972 - val_loss: 9090.7650\n",
      "Epoch 445/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3070.4270 - val_loss: 9086.3617\n",
      "Epoch 446/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3069.5583 - val_loss: 9081.9713\n",
      "Epoch 447/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3068.6915 - val_loss: 9077.5790\n",
      "Epoch 448/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3067.8276 - val_loss: 9073.2010\n",
      "Epoch 449/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3066.9651 - val_loss: 9068.8328\n",
      "Epoch 450/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3066.1048 - val_loss: 9064.4837\n",
      "Epoch 451/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3065.2469 - val_loss: 9060.1407\n",
      "Epoch 452/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3064.3909 - val_loss: 9055.8067\n",
      "Epoch 453/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3063.5374 - val_loss: 9051.4790\n",
      "Epoch 454/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3062.6856 - val_loss: 9047.1600\n",
      "Epoch 455/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3061.8361 - val_loss: 9042.8458\n",
      "Epoch 456/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3060.9888 - val_loss: 9038.5478\n",
      "Epoch 457/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3060.1434 - val_loss: 9034.2638\n",
      "Epoch 458/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3059.3006 - val_loss: 9029.9870\n",
      "Epoch 459/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3058.4591 - val_loss: 9025.7187\n",
      "Epoch 460/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3057.6203 - val_loss: 9021.4535\n",
      "Epoch 461/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3056.7833 - val_loss: 9017.1963\n",
      "Epoch 462/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3055.9489 - val_loss: 9012.9502\n",
      "Epoch 463/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3055.1162 - val_loss: 9008.7196\n",
      "Epoch 464/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3054.2855 - val_loss: 9004.4935\n",
      "Epoch 465/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3053.4569 - val_loss: 9000.2770\n",
      "Epoch 466/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3052.6301 - val_loss: 8996.0715\n",
      "Epoch 467/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3051.8061 - val_loss: 8991.8765\n",
      "Epoch 468/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3050.9839 - val_loss: 8987.6878\n",
      "Epoch 469/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3050.1642 - val_loss: 8983.5114\n",
      "Epoch 470/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3049.3454 - val_loss: 8979.3373\n",
      "Epoch 471/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3048.5300 - val_loss: 8975.1710\n",
      "Epoch 472/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 3047.7159 - val_loss: 8971.0272\n",
      "Epoch 473/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3046.9042 - val_loss: 8966.8861\n",
      "Epoch 474/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3046.0943 - val_loss: 8962.7531\n",
      "Epoch 475/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3045.2866 - val_loss: 8958.6388\n",
      "Epoch 476/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3044.4815 - val_loss: 8954.5252\n",
      "Epoch 477/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3043.6779 - val_loss: 8950.4238\n",
      "Epoch 478/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3042.8756 - val_loss: 8946.3222\n",
      "Epoch 479/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3042.0765 - val_loss: 8942.2348\n",
      "Epoch 480/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3041.2791 - val_loss: 8938.1581\n",
      "Epoch 481/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3040.4838 - val_loss: 8934.0956\n",
      "Epoch 482/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3039.6906 - val_loss: 8930.0298\n",
      "Epoch 483/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3038.8995 - val_loss: 8925.9721\n",
      "Epoch 484/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3038.1101 - val_loss: 8921.9242\n",
      "Epoch 485/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3037.3234 - val_loss: 8917.8894\n",
      "Epoch 486/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3036.5382 - val_loss: 8913.8769\n",
      "Epoch 487/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3035.7549 - val_loss: 8909.8664\n",
      "Epoch 488/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3034.9736 - val_loss: 8905.8637\n",
      "Epoch 489/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3034.1949 - val_loss: 8901.8724\n",
      "Epoch 490/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3033.4179 - val_loss: 8897.8818\n",
      "Epoch 491/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3032.6425 - val_loss: 8893.9029\n",
      "Epoch 492/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3031.8693 - val_loss: 8889.9380\n",
      "Epoch 493/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3031.0991 - val_loss: 8885.9826\n",
      "Epoch 494/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3030.3295 - val_loss: 8882.0336\n",
      "Epoch 495/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3029.5631 - val_loss: 8878.0921\n",
      "Epoch 496/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3028.7981 - val_loss: 8874.1639\n",
      "Epoch 497/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3028.0354 - val_loss: 8870.2395\n",
      "Epoch 498/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3027.2738 - val_loss: 8866.3223\n",
      "Epoch 499/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3026.5150 - val_loss: 8862.4131\n",
      "Epoch 500/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3025.7581 - val_loss: 8858.5133\n",
      "Epoch 501/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3025.0034 - val_loss: 8854.6289\n",
      "Epoch 502/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3024.2506 - val_loss: 8850.7473\n",
      "Epoch 503/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3023.4993 - val_loss: 8846.8685\n",
      "Epoch 504/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3022.7505 - val_loss: 8843.0054\n",
      "Epoch 505/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3022.0040 - val_loss: 8839.1497\n",
      "Epoch 506/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3021.2588 - val_loss: 8835.3125\n",
      "Epoch 507/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3020.5160 - val_loss: 8831.4685\n",
      "Epoch 508/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3019.7753 - val_loss: 8827.6345\n",
      "Epoch 509/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3019.0359 - val_loss: 8823.8303\n",
      "Epoch 510/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3018.2987 - val_loss: 8820.0264\n",
      "Epoch 511/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3017.5633 - val_loss: 8816.2257\n",
      "Epoch 512/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3016.8301 - val_loss: 8812.4369\n",
      "Epoch 513/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3016.0994 - val_loss: 8808.6558\n",
      "Epoch 514/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3015.3704 - val_loss: 8804.8798\n",
      "Epoch 515/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3014.6432 - val_loss: 8801.1112\n",
      "Epoch 516/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3013.9180 - val_loss: 8797.3450\n",
      "Epoch 517/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3013.1948 - val_loss: 8793.5931\n",
      "Epoch 518/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3012.4731 - val_loss: 8789.8543\n",
      "Epoch 519/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3011.7542 - val_loss: 8786.1271\n",
      "Epoch 520/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3011.0363 - val_loss: 8782.4067\n",
      "Epoch 521/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3010.3205 - val_loss: 8778.6887\n",
      "Epoch 522/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3009.6069 - val_loss: 8774.9846\n",
      "Epoch 523/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3008.8956 - val_loss: 8771.2828\n",
      "Epoch 524/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3008.1856 - val_loss: 8767.5951\n",
      "Epoch 525/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3007.4782 - val_loss: 8763.9115\n",
      "Epoch 526/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3006.7721 - val_loss: 8760.2375\n",
      "Epoch 527/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3006.0681 - val_loss: 8756.5763\n",
      "Epoch 528/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3005.3661 - val_loss: 8752.9231\n",
      "Epoch 529/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3004.6665 - val_loss: 8749.2786\n",
      "Epoch 530/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3003.9678 - val_loss: 8745.6368\n",
      "Epoch 531/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3003.2718 - val_loss: 8742.0022\n",
      "Epoch 532/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3002.5769 - val_loss: 8738.3834\n",
      "Epoch 533/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3001.8850 - val_loss: 8734.7712\n",
      "Epoch 534/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3001.1948 - val_loss: 8731.1626\n",
      "Epoch 535/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3000.5061 - val_loss: 8727.5692\n",
      "Epoch 536/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2999.8191 - val_loss: 8723.9832\n",
      "Epoch 537/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2999.1345 - val_loss: 8720.4061\n",
      "Epoch 538/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2998.4517 - val_loss: 8716.8357\n",
      "Epoch 539/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2997.7705 - val_loss: 8713.2696\n",
      "Epoch 540/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2997.0915 - val_loss: 8709.7263\n",
      "Epoch 541/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2996.4139 - val_loss: 8706.1784\n",
      "Epoch 542/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2995.7387 - val_loss: 8702.6388\n",
      "Epoch 543/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2995.0648 - val_loss: 8699.1123\n",
      "Epoch 544/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2994.3934 - val_loss: 8695.5889\n",
      "Epoch 545/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2993.7240 - val_loss: 8692.0651\n",
      "Epoch 546/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2993.0565 - val_loss: 8688.5680\n",
      "Epoch 547/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2992.3901 - val_loss: 8685.0779\n",
      "Epoch 548/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2991.7257 - val_loss: 8681.5887\n",
      "Epoch 549/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2991.0638 - val_loss: 8678.1093\n",
      "Epoch 550/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2990.4032 - val_loss: 8674.6345\n",
      "Epoch 551/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2989.7442 - val_loss: 8671.1715\n",
      "Epoch 552/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2989.0883 - val_loss: 8667.7177\n",
      "Epoch 553/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2988.4333 - val_loss: 8664.2657\n",
      "Epoch 554/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2987.7806 - val_loss: 8660.8302\n",
      "Epoch 555/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2987.1287 - val_loss: 8657.3988\n",
      "Epoch 556/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2986.4795 - val_loss: 8653.9751\n",
      "Epoch 557/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2985.8322 - val_loss: 8650.5577\n",
      "Epoch 558/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2985.1870 - val_loss: 8647.1528\n",
      "Epoch 559/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2984.5437 - val_loss: 8643.7500\n",
      "Epoch 560/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2983.9011 - val_loss: 8640.3550\n",
      "Epoch 561/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2983.2613 - val_loss: 8636.9699\n",
      "Epoch 562/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2982.6229 - val_loss: 8633.6050\n",
      "Epoch 563/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2981.9861 - val_loss: 8630.2473\n",
      "Epoch 564/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2981.3518 - val_loss: 8626.8913\n",
      "Epoch 565/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2980.7187 - val_loss: 8623.5372\n",
      "Epoch 566/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2980.0879 - val_loss: 8620.1930\n",
      "Epoch 567/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2979.4588 - val_loss: 8616.8593\n",
      "Epoch 568/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2978.8317 - val_loss: 8613.5334\n",
      "Epoch 569/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2978.2058 - val_loss: 8610.2110\n",
      "Epoch 570/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2977.5824 - val_loss: 8606.8981\n",
      "Epoch 571/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2976.9602 - val_loss: 8603.5997\n",
      "Epoch 572/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2976.3403 - val_loss: 8600.3076\n",
      "Epoch 573/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2975.7217 - val_loss: 8597.0182\n",
      "Epoch 574/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2975.1052 - val_loss: 8593.7373\n",
      "Epoch 575/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2974.4908 - val_loss: 8590.4636\n",
      "Epoch 576/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2973.8776 - val_loss: 8587.2012\n",
      "Epoch 577/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2973.2659 - val_loss: 8583.9420\n",
      "Epoch 578/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2972.6569 - val_loss: 8580.6912\n",
      "Epoch 579/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2972.0490 - val_loss: 8577.4527\n",
      "Epoch 580/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2971.4435 - val_loss: 8574.2217\n",
      "Epoch 581/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2970.8391 - val_loss: 8570.9973\n",
      "Epoch 582/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2970.2366 - val_loss: 8567.7817\n",
      "Epoch 583/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2969.6364 - val_loss: 8564.5724\n",
      "Epoch 584/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2969.0374 - val_loss: 8561.3690\n",
      "Epoch 585/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2968.4404 - val_loss: 8558.1764\n",
      "Epoch 586/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2967.8450 - val_loss: 8554.9871\n",
      "Epoch 587/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2967.2518 - val_loss: 8551.8113\n",
      "Epoch 588/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2966.6600 - val_loss: 8548.6416\n",
      "Epoch 589/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2966.0702 - val_loss: 8545.4736\n",
      "Epoch 590/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2965.4815 - val_loss: 8542.3098\n",
      "Epoch 591/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2964.8951 - val_loss: 8539.1605\n",
      "Epoch 592/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2964.3102 - val_loss: 8536.0184\n",
      "Epoch 593/1000\n",
      "242/242 [==============================] - 0s 968us/step - loss: 2963.7270 - val_loss: 8532.8886\n",
      "Epoch 594/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2963.1465 - val_loss: 8529.7675\n",
      "Epoch 595/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2962.5666 - val_loss: 8526.6550\n",
      "Epoch 596/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2961.9886 - val_loss: 8523.5491\n",
      "Epoch 597/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2961.4128 - val_loss: 8520.4443\n",
      "Epoch 598/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2960.8383 - val_loss: 8517.3516\n",
      "Epoch 599/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2960.2655 - val_loss: 8514.2690\n",
      "Epoch 600/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2959.6948 - val_loss: 8511.1909\n",
      "Epoch 601/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2959.1256 - val_loss: 8508.1089\n",
      "Epoch 602/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2958.5581 - val_loss: 8505.0495\n",
      "Epoch 603/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2957.9925 - val_loss: 8501.9927\n",
      "Epoch 604/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2957.4280 - val_loss: 8498.9479\n",
      "Epoch 605/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2956.8656 - val_loss: 8495.9063\n",
      "Epoch 606/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2956.3055 - val_loss: 8492.8699\n",
      "Epoch 607/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2955.7461 - val_loss: 8489.8375\n",
      "Epoch 608/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2955.1892 - val_loss: 8486.8169\n",
      "Epoch 609/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2954.6330 - val_loss: 8483.8027\n",
      "Epoch 610/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2954.0789 - val_loss: 8480.7977\n",
      "Epoch 611/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2953.5270 - val_loss: 8477.7968\n",
      "Epoch 612/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2952.9765 - val_loss: 8474.8042\n",
      "Epoch 613/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2952.4274 - val_loss: 8471.8255\n",
      "Epoch 614/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2951.8807 - val_loss: 8468.8473\n",
      "Epoch 615/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2951.3349 - val_loss: 8465.8841\n",
      "Epoch 616/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2950.7908 - val_loss: 8462.9288\n",
      "Epoch 617/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2950.2487 - val_loss: 8459.9792\n",
      "Epoch 618/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2949.7086 - val_loss: 8457.0340\n",
      "Epoch 619/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2949.1697 - val_loss: 8454.0899\n",
      "Epoch 620/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2948.6321 - val_loss: 8451.1440\n",
      "Epoch 621/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2948.0974 - val_loss: 8448.2246\n",
      "Epoch 622/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2947.5626 - val_loss: 8445.3142\n",
      "Epoch 623/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2947.0310 - val_loss: 8442.4138\n",
      "Epoch 624/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2946.4999 - val_loss: 8439.5169\n",
      "Epoch 625/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2945.9709 - val_loss: 8436.6188\n",
      "Epoch 626/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2945.4439 - val_loss: 8433.7203\n",
      "Epoch 627/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2944.9183 - val_loss: 8430.8341\n",
      "Epoch 628/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2944.3941 - val_loss: 8427.9597\n",
      "Epoch 629/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2943.8717 - val_loss: 8425.0900\n",
      "Epoch 630/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2943.3516 - val_loss: 8422.2318\n",
      "Epoch 631/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2942.8323 - val_loss: 8419.3794\n",
      "Epoch 632/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2942.3145 - val_loss: 8416.5308\n",
      "Epoch 633/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2941.7988 - val_loss: 8413.6896\n",
      "Epoch 634/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2941.2845 - val_loss: 8410.8627\n",
      "Epoch 635/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2940.7715 - val_loss: 8408.0397\n",
      "Epoch 636/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2940.2609 - val_loss: 8405.2219\n",
      "Epoch 637/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2939.7513 - val_loss: 8402.4088\n",
      "Epoch 638/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2939.2441 - val_loss: 8399.6032\n",
      "Epoch 639/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2938.7372 - val_loss: 8396.8106\n",
      "Epoch 640/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2938.2331 - val_loss: 8394.0232\n",
      "Epoch 641/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2937.7296 - val_loss: 8391.2499\n",
      "Epoch 642/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2937.2285 - val_loss: 8388.4844\n",
      "Epoch 643/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2936.7287 - val_loss: 8385.7176\n",
      "Epoch 644/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2936.2306 - val_loss: 8382.9513\n",
      "Epoch 645/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2935.7340 - val_loss: 8380.1915\n",
      "Epoch 646/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2935.2391 - val_loss: 8377.4466\n",
      "Epoch 647/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2934.7456 - val_loss: 8374.7091\n",
      "Epoch 648/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2934.2530 - val_loss: 8371.9682\n",
      "Epoch 649/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2933.7630 - val_loss: 8369.2396\n",
      "Epoch 650/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2933.2741 - val_loss: 8366.5187\n",
      "Epoch 651/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2932.7874 - val_loss: 8363.8066\n",
      "Epoch 652/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2932.3014 - val_loss: 8361.0987\n",
      "Epoch 653/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2931.8175 - val_loss: 8358.4044\n",
      "Epoch 654/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2931.3342 - val_loss: 8355.7176\n",
      "Epoch 655/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2930.8535 - val_loss: 8353.0270\n",
      "Epoch 656/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2930.3744 - val_loss: 8350.3412\n",
      "Epoch 657/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2929.8960 - val_loss: 8347.6746\n",
      "Epoch 658/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2929.4199 - val_loss: 8345.0135\n",
      "Epoch 659/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2928.9453 - val_loss: 8342.3567\n",
      "Epoch 660/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2928.4722 - val_loss: 8339.7033\n",
      "Epoch 661/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2928.0008 - val_loss: 8337.0632\n",
      "Epoch 662/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2927.5304 - val_loss: 8334.4188\n",
      "Epoch 663/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2927.0617 - val_loss: 8331.7893\n",
      "Epoch 664/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2926.5945 - val_loss: 8329.1677\n",
      "Epoch 665/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2926.1292 - val_loss: 8326.5462\n",
      "Epoch 666/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2925.6649 - val_loss: 8323.9341\n",
      "Epoch 667/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2925.2028 - val_loss: 8321.3278\n",
      "Epoch 668/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2924.7415 - val_loss: 8318.7311\n",
      "Epoch 669/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2924.2818 - val_loss: 8316.1476\n",
      "Epoch 670/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2923.8240 - val_loss: 8313.5662\n",
      "Epoch 671/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2923.3671 - val_loss: 8310.9848\n",
      "Epoch 672/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2922.9122 - val_loss: 8308.4171\n",
      "Epoch 673/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2922.4585 - val_loss: 8305.8562\n",
      "Epoch 674/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2922.0068 - val_loss: 8303.2972\n",
      "Epoch 675/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2921.5565 - val_loss: 8300.7413\n",
      "Epoch 676/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2921.1077 - val_loss: 8298.2012\n",
      "Epoch 677/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2920.6596 - val_loss: 8295.6649\n",
      "Epoch 678/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2920.2134 - val_loss: 8293.1294\n",
      "Epoch 679/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2919.7739 - val_loss: 8290.2374\n",
      "Epoch 680/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2919.3270 - val_loss: 8287.9682\n",
      "Epoch 681/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2918.8841 - val_loss: 8285.5579\n",
      "Epoch 682/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2918.4435 - val_loss: 8283.0784\n",
      "Epoch 683/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2918.0049 - val_loss: 8280.5832\n",
      "Epoch 684/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2917.5675 - val_loss: 8278.0889\n",
      "Epoch 685/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2917.1314 - val_loss: 8275.6080\n",
      "Epoch 686/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2916.6971 - val_loss: 8273.1251\n",
      "Epoch 687/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2916.2649 - val_loss: 8270.6497\n",
      "Epoch 688/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2915.8336 - val_loss: 8268.1860\n",
      "Epoch 689/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2915.4033 - val_loss: 8265.7300\n",
      "Epoch 690/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2914.9749 - val_loss: 8263.2789\n",
      "Epoch 691/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2914.5482 - val_loss: 8260.8328\n",
      "Epoch 692/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2914.1224 - val_loss: 8258.3903\n",
      "Epoch 693/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2913.6982 - val_loss: 8255.9531\n",
      "Epoch 694/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2913.2751 - val_loss: 8253.5224\n",
      "Epoch 695/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2912.8541 - val_loss: 8251.0985\n",
      "Epoch 696/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2912.4341 - val_loss: 8248.6811\n",
      "Epoch 697/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2912.0161 - val_loss: 8246.2717\n",
      "Epoch 698/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2911.5988 - val_loss: 8243.8674\n",
      "Epoch 699/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2911.1831 - val_loss: 8241.4719\n",
      "Epoch 700/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2910.7685 - val_loss: 8239.0905\n",
      "Epoch 701/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2910.3557 - val_loss: 8236.7115\n",
      "Epoch 702/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2909.9447 - val_loss: 8234.3349\n",
      "Epoch 703/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2909.5353 - val_loss: 8231.9596\n",
      "Epoch 704/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2909.1260 - val_loss: 8229.5901\n",
      "Epoch 705/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2908.7192 - val_loss: 8227.2250\n",
      "Epoch 706/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2908.3131 - val_loss: 8224.8720\n",
      "Epoch 707/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2907.9096 - val_loss: 8222.5313\n",
      "Epoch 708/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2907.5057 - val_loss: 8220.1928\n",
      "Epoch 709/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2907.1044 - val_loss: 8217.8555\n",
      "Epoch 710/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2906.7039 - val_loss: 8215.5245\n",
      "Epoch 711/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2906.3051 - val_loss: 8213.2107\n",
      "Epoch 712/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2905.9074 - val_loss: 8210.8883\n",
      "Epoch 713/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2905.5117 - val_loss: 8208.5767\n",
      "Epoch 714/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2905.1171 - val_loss: 8206.2835\n",
      "Epoch 715/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2904.7235 - val_loss: 8203.9829\n",
      "Epoch 716/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2904.3312 - val_loss: 8201.6869\n",
      "Epoch 717/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2903.9406 - val_loss: 8199.4104\n",
      "Epoch 718/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2903.5515 - val_loss: 8197.1321\n",
      "Epoch 719/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2903.1633 - val_loss: 8194.8565\n",
      "Epoch 720/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2902.7769 - val_loss: 8192.5921\n",
      "Epoch 721/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2902.3916 - val_loss: 8190.3296\n",
      "Epoch 722/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2902.0075 - val_loss: 8188.0699\n",
      "Epoch 723/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2901.6253 - val_loss: 8185.8215\n",
      "Epoch 724/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2901.2441 - val_loss: 8183.5809\n",
      "Epoch 725/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2900.8645 - val_loss: 8181.3540\n",
      "Epoch 726/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2900.4855 - val_loss: 8179.1308\n",
      "Epoch 727/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2900.1087 - val_loss: 8176.9064\n",
      "Epoch 728/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2899.7327 - val_loss: 8174.6851\n",
      "Epoch 729/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2899.3580 - val_loss: 8172.4674\n",
      "Epoch 730/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2898.9843 - val_loss: 8170.2580\n",
      "Epoch 731/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2898.6126 - val_loss: 8168.0573\n",
      "Epoch 732/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2898.2416 - val_loss: 8165.8629\n",
      "Epoch 733/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2897.8726 - val_loss: 8163.6731\n",
      "Epoch 734/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2897.5041 - val_loss: 8161.4838\n",
      "Epoch 735/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2897.1381 - val_loss: 8159.3064\n",
      "Epoch 736/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2896.7728 - val_loss: 8157.1416\n",
      "Epoch 737/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2896.4084 - val_loss: 8154.9732\n",
      "Epoch 738/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2896.0454 - val_loss: 8152.8138\n",
      "Epoch 739/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2895.6839 - val_loss: 8150.6595\n",
      "Epoch 740/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2895.3236 - val_loss: 8148.5128\n",
      "Epoch 741/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2894.9647 - val_loss: 8146.3652\n",
      "Epoch 742/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2894.6071 - val_loss: 8144.2324\n",
      "Epoch 743/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2894.2506 - val_loss: 8142.0988\n",
      "Epoch 744/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2893.8955 - val_loss: 8139.9693\n",
      "Epoch 745/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2893.5420 - val_loss: 8137.8500\n",
      "Epoch 746/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2893.1892 - val_loss: 8135.7408\n",
      "Epoch 747/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2892.8373 - val_loss: 8133.6289\n",
      "Epoch 748/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2892.4871 - val_loss: 8131.5326\n",
      "Epoch 749/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2892.1434 - val_loss: 8129.0690\n",
      "Epoch 750/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2891.7919 - val_loss: 8127.2249\n",
      "Epoch 751/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2891.4442 - val_loss: 8125.2344\n",
      "Epoch 752/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2891.0986 - val_loss: 8123.1782\n",
      "Epoch 753/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2890.7552 - val_loss: 8121.1046\n",
      "Epoch 754/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2890.4126 - val_loss: 8119.0301\n",
      "Epoch 755/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2890.0713 - val_loss: 8116.9576\n",
      "Epoch 756/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2889.7308 - val_loss: 8114.9021\n",
      "Epoch 757/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2889.3919 - val_loss: 8112.8509\n",
      "Epoch 758/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2889.0545 - val_loss: 8110.8108\n",
      "Epoch 759/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2888.7178 - val_loss: 8108.7719\n",
      "Epoch 760/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2888.3821 - val_loss: 8106.7365\n",
      "Epoch 761/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2888.0486 - val_loss: 8104.7029\n",
      "Epoch 762/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2887.7156 - val_loss: 8102.6777\n",
      "Epoch 763/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2887.3842 - val_loss: 8100.6511\n",
      "Epoch 764/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2887.0540 - val_loss: 8098.6406\n",
      "Epoch 765/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2886.7249 - val_loss: 8096.6316\n",
      "Epoch 766/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2886.3969 - val_loss: 8094.6335\n",
      "Epoch 767/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2886.0699 - val_loss: 8092.6412\n",
      "Epoch 768/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2885.7444 - val_loss: 8090.6550\n",
      "Epoch 769/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2885.4198 - val_loss: 8088.6703\n",
      "Epoch 770/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2885.0970 - val_loss: 8086.6890\n",
      "Epoch 771/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2884.7748 - val_loss: 8084.7153\n",
      "Epoch 772/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2884.4537 - val_loss: 8082.7461\n",
      "Epoch 773/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2884.1340 - val_loss: 8080.7784\n",
      "Epoch 774/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2883.8154 - val_loss: 8078.8161\n",
      "Epoch 775/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2883.4986 - val_loss: 8076.8655\n",
      "Epoch 776/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2883.1821 - val_loss: 8074.9179\n",
      "Epoch 777/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2882.8668 - val_loss: 8072.9749\n",
      "Epoch 778/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2882.5534 - val_loss: 8071.0352\n",
      "Epoch 779/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2882.2404 - val_loss: 8069.1025\n",
      "Epoch 780/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2881.9287 - val_loss: 8067.1748\n",
      "Epoch 781/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2881.6189 - val_loss: 8065.2549\n",
      "Epoch 782/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2881.3098 - val_loss: 8063.3446\n",
      "Epoch 783/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2881.0016 - val_loss: 8061.4343\n",
      "Epoch 784/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2880.6944 - val_loss: 8059.5206\n",
      "Epoch 785/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2880.3887 - val_loss: 8057.6222\n",
      "Epoch 786/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2880.0839 - val_loss: 8055.7297\n",
      "Epoch 787/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2879.7807 - val_loss: 8053.8392\n",
      "Epoch 788/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2879.4780 - val_loss: 8051.9564\n",
      "Epoch 789/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2879.1769 - val_loss: 8050.0743\n",
      "Epoch 790/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2878.8766 - val_loss: 8048.2009\n",
      "Epoch 791/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2878.5778 - val_loss: 8046.3327\n",
      "Epoch 792/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2878.2799 - val_loss: 8044.4627\n",
      "Epoch 793/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2877.9828 - val_loss: 8042.6030\n",
      "Epoch 794/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2877.6871 - val_loss: 8040.7504\n",
      "Epoch 795/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2877.3930 - val_loss: 8038.9071\n",
      "Epoch 796/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2877.0997 - val_loss: 8037.0604\n",
      "Epoch 797/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2876.8065 - val_loss: 8035.2167\n",
      "Epoch 798/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2876.5152 - val_loss: 8033.3848\n",
      "Epoch 799/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2876.2254 - val_loss: 8031.5616\n",
      "Epoch 800/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2875.9361 - val_loss: 8029.7361\n",
      "Epoch 801/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2875.6483 - val_loss: 8027.9186\n",
      "Epoch 802/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2875.3608 - val_loss: 8026.1038\n",
      "Epoch 803/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2875.0752 - val_loss: 8024.2909\n",
      "Epoch 804/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2874.7906 - val_loss: 8022.4864\n",
      "Epoch 805/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2874.5070 - val_loss: 8020.6924\n",
      "Epoch 806/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2874.2243 - val_loss: 8018.8984\n",
      "Epoch 807/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2873.9424 - val_loss: 8017.1095\n",
      "Epoch 808/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2873.6621 - val_loss: 8015.3271\n",
      "Epoch 809/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2873.3828 - val_loss: 8013.5539\n",
      "Epoch 810/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2873.1043 - val_loss: 8011.7803\n",
      "Epoch 811/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2872.8270 - val_loss: 8010.0070\n",
      "Epoch 812/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2872.5507 - val_loss: 8008.2511\n",
      "Epoch 813/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2872.2752 - val_loss: 8006.4922\n",
      "Epoch 814/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2872.0010 - val_loss: 8004.7421\n",
      "Epoch 815/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2871.7281 - val_loss: 8002.9932\n",
      "Epoch 816/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2871.4559 - val_loss: 8001.2475\n",
      "Epoch 817/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2871.1846 - val_loss: 7999.5075\n",
      "Epoch 818/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2870.9145 - val_loss: 7997.7671\n",
      "Epoch 819/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2870.6455 - val_loss: 7996.0307\n",
      "Epoch 820/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2870.3774 - val_loss: 7994.3050\n",
      "Epoch 821/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2870.1106 - val_loss: 7992.5852\n",
      "Epoch 822/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2869.8446 - val_loss: 7990.8700\n",
      "Epoch 823/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2869.5795 - val_loss: 7989.1580\n",
      "Epoch 824/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2869.3157 - val_loss: 7987.4518\n",
      "Epoch 825/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2869.0526 - val_loss: 7985.7529\n",
      "Epoch 826/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2868.7909 - val_loss: 7984.0620\n",
      "Epoch 827/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2868.5300 - val_loss: 7982.3744\n",
      "Epoch 828/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2868.2698 - val_loss: 7980.6873\n",
      "Epoch 829/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2868.0108 - val_loss: 7979.0030\n",
      "Epoch 830/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2867.7530 - val_loss: 7977.3349\n",
      "Epoch 831/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2867.4963 - val_loss: 7975.6559\n",
      "Epoch 832/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2867.2401 - val_loss: 7973.9864\n",
      "Epoch 833/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2866.9851 - val_loss: 7972.3185\n",
      "Epoch 834/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2866.7312 - val_loss: 7970.6654\n",
      "Epoch 835/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2866.4783 - val_loss: 7969.0121\n",
      "Epoch 836/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2866.2262 - val_loss: 7967.3634\n",
      "Epoch 837/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2865.9743 - val_loss: 7965.7185\n",
      "Epoch 838/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2865.7247 - val_loss: 7964.0766\n",
      "Epoch 839/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2865.4754 - val_loss: 7962.4449\n",
      "Epoch 840/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2865.2273 - val_loss: 7960.8171\n",
      "Epoch 841/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2864.9803 - val_loss: 7959.1822\n",
      "Epoch 842/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2864.7343 - val_loss: 7957.5604\n",
      "Epoch 843/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2864.4887 - val_loss: 7955.9507\n",
      "Epoch 844/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2864.2441 - val_loss: 7954.3416\n",
      "Epoch 845/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2864.0009 - val_loss: 7952.7301\n",
      "Epoch 846/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2863.7581 - val_loss: 7951.1249\n",
      "Epoch 847/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2863.5166 - val_loss: 7949.5256\n",
      "Epoch 848/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2863.2757 - val_loss: 7947.9262\n",
      "Epoch 849/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2863.0363 - val_loss: 7946.3372\n",
      "Epoch 850/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2862.7978 - val_loss: 7944.7518\n",
      "Epoch 851/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2862.5601 - val_loss: 7943.1687\n",
      "Epoch 852/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2862.3228 - val_loss: 7941.5927\n",
      "Epoch 853/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2862.0870 - val_loss: 7940.0228\n",
      "Epoch 854/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2861.8517 - val_loss: 7938.4555\n",
      "Epoch 855/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2861.6175 - val_loss: 7936.8956\n",
      "Epoch 856/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2861.3844 - val_loss: 7935.3399\n",
      "Epoch 857/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2861.1518 - val_loss: 7933.7864\n",
      "Epoch 858/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2860.9204 - val_loss: 7932.2358\n",
      "Epoch 859/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2860.6898 - val_loss: 7930.6953\n",
      "Epoch 860/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2860.4601 - val_loss: 7929.1498\n",
      "Epoch 861/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2860.2310 - val_loss: 7927.4329\n",
      "Epoch 862/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2860.0036 - val_loss: 7925.9967\n",
      "Epoch 863/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2859.7760 - val_loss: 7924.5105\n",
      "Epoch 864/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2859.5503 - val_loss: 7923.0014\n",
      "Epoch 865/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2859.3245 - val_loss: 7921.4869\n",
      "Epoch 866/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2859.1005 - val_loss: 7919.9763\n",
      "Epoch 867/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2858.8769 - val_loss: 7918.4651\n",
      "Epoch 868/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2858.6547 - val_loss: 7916.9642\n",
      "Epoch 869/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2858.4330 - val_loss: 7915.4623\n",
      "Epoch 870/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2858.2121 - val_loss: 7913.9669\n",
      "Epoch 871/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2857.9923 - val_loss: 7912.4720\n",
      "Epoch 872/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2857.7727 - val_loss: 7910.9781\n",
      "Epoch 873/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2857.5546 - val_loss: 7909.4941\n",
      "Epoch 874/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2857.3369 - val_loss: 7908.0095\n",
      "Epoch 875/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2857.1202 - val_loss: 7906.5312\n",
      "Epoch 876/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2856.9048 - val_loss: 7905.0612\n",
      "Epoch 877/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2856.6897 - val_loss: 7903.5918\n",
      "Epoch 878/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2856.4761 - val_loss: 7902.1264\n",
      "Epoch 879/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2856.2627 - val_loss: 7900.6624\n",
      "Epoch 880/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2856.0503 - val_loss: 7899.2067\n",
      "Epoch 881/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2855.8390 - val_loss: 7897.7508\n",
      "Epoch 882/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2855.6282 - val_loss: 7896.3035\n",
      "Epoch 883/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2855.4184 - val_loss: 7894.8563\n",
      "Epoch 884/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2855.2095 - val_loss: 7893.4189\n",
      "Epoch 885/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2855.0012 - val_loss: 7891.9873\n",
      "Epoch 886/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2854.7938 - val_loss: 7890.5576\n",
      "Epoch 887/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2854.5868 - val_loss: 7889.1273\n",
      "Epoch 888/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2854.3815 - val_loss: 7887.7082\n",
      "Epoch 889/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2854.1765 - val_loss: 7886.2973\n",
      "Epoch 890/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2853.9725 - val_loss: 7884.8701\n",
      "Epoch 891/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2853.7687 - val_loss: 7883.4567\n",
      "Epoch 892/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2853.5662 - val_loss: 7882.0468\n",
      "Epoch 893/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2853.3644 - val_loss: 7880.6396\n",
      "Epoch 894/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2853.1637 - val_loss: 7879.2351\n",
      "Epoch 895/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2852.9635 - val_loss: 7877.8418\n",
      "Epoch 896/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2852.7641 - val_loss: 7876.4509\n",
      "Epoch 897/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2852.5663 - val_loss: 7875.0594\n",
      "Epoch 898/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2852.3677 - val_loss: 7873.6859\n",
      "Epoch 899/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2852.1710 - val_loss: 7872.3067\n",
      "Epoch 900/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2851.9745 - val_loss: 7870.9301\n",
      "Epoch 901/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2851.7787 - val_loss: 7869.5563\n",
      "Epoch 902/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2851.5842 - val_loss: 7868.1888\n",
      "Epoch 903/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2851.3900 - val_loss: 7866.8193\n",
      "Epoch 904/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2851.1970 - val_loss: 7865.4391\n",
      "Epoch 905/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2851.0048 - val_loss: 7864.0820\n",
      "Epoch 906/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2850.8131 - val_loss: 7862.7469\n",
      "Epoch 907/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2850.6223 - val_loss: 7861.4026\n",
      "Epoch 908/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2850.4318 - val_loss: 7860.0574\n",
      "Epoch 909/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2850.2426 - val_loss: 7858.7147\n",
      "Epoch 910/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2850.0536 - val_loss: 7857.3713\n",
      "Epoch 911/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2849.8658 - val_loss: 7856.0352\n",
      "Epoch 912/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2849.6790 - val_loss: 7854.6998\n",
      "Epoch 913/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2849.4921 - val_loss: 7853.3713\n",
      "Epoch 914/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2849.3065 - val_loss: 7852.0505\n",
      "Epoch 915/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2849.1214 - val_loss: 7850.7319\n",
      "Epoch 916/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2848.9374 - val_loss: 7849.4173\n",
      "Epoch 917/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2848.7537 - val_loss: 7848.1010\n",
      "Epoch 918/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2848.5711 - val_loss: 7846.7981\n",
      "Epoch 919/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2848.3890 - val_loss: 7845.4898\n",
      "Epoch 920/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2848.2076 - val_loss: 7844.1929\n",
      "Epoch 921/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2848.0277 - val_loss: 7842.9016\n",
      "Epoch 922/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2847.8474 - val_loss: 7841.6084\n",
      "Epoch 923/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2847.6679 - val_loss: 7840.3153\n",
      "Epoch 924/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2847.4898 - val_loss: 7839.0296\n",
      "Epoch 925/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2847.3120 - val_loss: 7837.7419\n",
      "Epoch 926/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2847.1346 - val_loss: 7836.4596\n",
      "Epoch 927/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2846.9582 - val_loss: 7835.1868\n",
      "Epoch 928/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2846.7830 - val_loss: 7833.9131\n",
      "Epoch 929/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2846.6076 - val_loss: 7832.6471\n",
      "Epoch 930/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2846.4332 - val_loss: 7831.3833\n",
      "Epoch 931/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2846.2600 - val_loss: 7830.1243\n",
      "Epoch 932/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2846.0869 - val_loss: 7828.8629\n",
      "Epoch 933/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2845.9149 - val_loss: 7827.6085\n",
      "Epoch 934/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2845.7430 - val_loss: 7826.3612\n",
      "Epoch 935/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2845.5724 - val_loss: 7825.1097\n",
      "Epoch 936/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2845.4021 - val_loss: 7823.8710\n",
      "Epoch 937/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2845.2329 - val_loss: 7822.6322\n",
      "Epoch 938/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2845.0639 - val_loss: 7821.3940\n",
      "Epoch 939/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2844.8954 - val_loss: 7820.1652\n",
      "Epoch 940/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2844.7280 - val_loss: 7818.9383\n",
      "Epoch 941/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2844.5611 - val_loss: 7817.7132\n",
      "Epoch 942/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2844.3951 - val_loss: 7816.4927\n",
      "Epoch 943/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2844.2296 - val_loss: 7815.2727\n",
      "Epoch 944/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2844.0652 - val_loss: 7814.0520\n",
      "Epoch 945/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2843.9005 - val_loss: 7812.8403\n",
      "Epoch 946/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2843.7371 - val_loss: 7811.6337\n",
      "Epoch 947/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2843.5741 - val_loss: 7810.4302\n",
      "Epoch 948/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2843.4114 - val_loss: 7809.2281\n",
      "Epoch 949/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2843.2500 - val_loss: 7808.0294\n",
      "Epoch 950/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2843.0890 - val_loss: 7806.8299\n",
      "Epoch 951/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2842.9288 - val_loss: 7805.6327\n",
      "Epoch 952/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2842.7690 - val_loss: 7804.4453\n",
      "Epoch 953/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2842.6096 - val_loss: 7803.2561\n",
      "Epoch 954/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2842.4515 - val_loss: 7802.0751\n",
      "Epoch 955/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2842.2939 - val_loss: 7800.8927\n",
      "Epoch 956/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2842.1366 - val_loss: 7799.7143\n",
      "Epoch 957/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2841.9796 - val_loss: 7798.5469\n",
      "Epoch 958/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2841.8239 - val_loss: 7797.3854\n",
      "Epoch 959/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2841.6685 - val_loss: 7796.2222\n",
      "Epoch 960/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2841.5136 - val_loss: 7795.0541\n",
      "Epoch 961/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2841.3591 - val_loss: 7793.8982\n",
      "Epoch 962/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2841.2060 - val_loss: 7792.7392\n",
      "Epoch 963/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2841.0530 - val_loss: 7791.5864\n",
      "Epoch 964/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2840.9007 - val_loss: 7790.4382\n",
      "Epoch 965/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2840.7487 - val_loss: 7789.2908\n",
      "Epoch 966/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2840.5976 - val_loss: 7788.1488\n",
      "Epoch 967/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2840.4469 - val_loss: 7787.0120\n",
      "Epoch 968/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2840.2973 - val_loss: 7785.8754\n",
      "Epoch 969/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2840.1482 - val_loss: 7784.7449\n",
      "Epoch 970/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2839.9992 - val_loss: 7783.6138\n",
      "Epoch 971/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2839.8511 - val_loss: 7782.4833\n",
      "Epoch 972/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2839.7035 - val_loss: 7781.3610\n",
      "Epoch 973/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2839.5560 - val_loss: 7780.2408\n",
      "Epoch 974/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2839.4100 - val_loss: 7779.1285\n",
      "Epoch 975/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2839.2637 - val_loss: 7778.0164\n",
      "Epoch 976/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2839.1186 - val_loss: 7776.9070\n",
      "Epoch 977/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2838.9741 - val_loss: 7775.7981\n",
      "Epoch 978/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2838.8298 - val_loss: 7774.6900\n",
      "Epoch 979/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2838.6858 - val_loss: 7773.5885\n",
      "Epoch 980/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2838.5430 - val_loss: 7772.4868\n",
      "Epoch 981/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2838.4006 - val_loss: 7771.3893\n",
      "Epoch 982/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2838.2591 - val_loss: 7770.2965\n",
      "Epoch 983/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2838.1172 - val_loss: 7769.2095\n",
      "Epoch 984/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2837.9767 - val_loss: 7768.1241\n",
      "Epoch 985/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2837.8364 - val_loss: 7767.0465\n",
      "Epoch 986/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2837.6969 - val_loss: 7765.9664\n",
      "Epoch 987/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2837.5577 - val_loss: 7764.8874\n",
      "Epoch 988/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2837.4193 - val_loss: 7763.8161\n",
      "Epoch 989/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2837.2809 - val_loss: 7762.7455\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2837.1435 - val_loss: 7761.6703\n",
      "Epoch 991/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2837.0064 - val_loss: 7760.6078\n",
      "Epoch 992/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2836.8697 - val_loss: 7759.5499\n",
      "Epoch 993/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2836.7339 - val_loss: 7758.4868\n",
      "Epoch 994/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2836.5984 - val_loss: 7757.4248\n",
      "Epoch 995/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2836.4636 - val_loss: 7756.3687\n",
      "Epoch 996/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2836.3294 - val_loss: 7755.3190\n",
      "Epoch 997/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2836.1956 - val_loss: 7754.2697\n",
      "Epoch 998/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2836.0620 - val_loss: 7753.2293\n",
      "Epoch 999/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2835.9297 - val_loss: 7752.1912\n",
      "Epoch 1000/1000\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2835.7972 - val_loss: 7751.1494\n"
     ]
    }
   ],
   "source": [
    "# Sub model 4 - CNN\n",
    "\n",
    "rmse = []\n",
    "r2 = []\n",
    "for ts in range(3, 11, 1):  \n",
    "    \n",
    "    # time step & lag\n",
    "    data_X, data_Y = time_step(data , ts, 1, 1)\n",
    "    \n",
    "    # 데이터 분할\n",
    "    NUM_TRAIN = int(data_X.shape[0] * 0.6)\n",
    "    NUM_VAL = int(data_X.shape[0] * 0.8)\n",
    "\n",
    "    train_X = data_X[:NUM_TRAIN]\n",
    "    train_Y = data_Y[:NUM_TRAIN]\n",
    "\n",
    "    val_X = data_X[NUM_TRAIN:NUM_VAL]\n",
    "    val_Y = data_Y[NUM_TRAIN:NUM_VAL]\n",
    "\n",
    "    test_X = data_X[NUM_VAL:]\n",
    "    test_Y =data_Y[NUM_VAL:]\n",
    "\n",
    "    train_X, val_X, test_X = normalization(train_X, val_X, test_X)\n",
    "    \n",
    "    # 함수형 API\n",
    "    input_tensor = Input(shape=(train_X.shape[1],))\n",
    "    x = layers.Reshape((1, train_X.shape[1], 1))(input_tensor)\n",
    "    x = layers.Conv2D(16, kernel_size=(1,2), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(8, kernel_size=(1,2), padding='same', activation='relu')(x)\n",
    "    x = layers.Conv2D(4, kernel_size=(1,2), padding='valid', activation='relu')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    output_tensor = layers.Dense(1)(x)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    mc = ModelCheckpoint('./model/CNN/model_{}.h5'.format(ts), monitor='val_loss', save_best_only=True)\n",
    "    \n",
    "    model.fit(train_X, train_Y,\n",
    "              batch_size=8,\n",
    "              epochs=1000,\n",
    "              shuffle=False,\n",
    "              validation_data=(val_X, val_Y),\n",
    "              callbacks=[early_stopping, mc],\n",
    "              verbose=1)\n",
    "    \n",
    "    best_model = load_model('./model/CNN/model_{}.h5'.format(ts))\n",
    "    \n",
    "    y_pred = best_model.predict(test_X)\n",
    "    y_pred = y_pred.reshape(-1).astype('float32')\n",
    "    y_real = test_Y.reshape(-1).astype('float32')\n",
    "    \n",
    "    raw= {'Observed': list(y_real), 'Predicted': list(y_pred)}\n",
    "    rr = pd.DataFrame(raw)\n",
    "#     rr.to_csv(\"./Submodel/DNN/time_step/timse_step{}.csv\".format(ts))\n",
    "    reg = sm.OLS.from_formula(\"Observed ~ Predicted\",rr).fit()\n",
    "\n",
    "    try:\n",
    "        RMSE = round(math.sqrt(mean_squared_error(y_real, y_pred)), 3)\n",
    "        R2 = round(reg.rsquared, 3)   \n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    rmse.append(RMSE)\n",
    "    r2.append(R2)\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.plot(test_Y, label='Observed')\n",
    "#     plt.plot(y_predict, label='Predicted')\n",
    "#     plt.legend()\n",
    "#     plt.savefig('fig_{}.png'.format(ts), dpi=300)\n",
    " \n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[102.019, 102.77, 104.261, 104.613, 111.061, 138.974, 122.417, 119.803]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.837, 0.83, 0.826, 0.826, 0.812, 0.782, 0.782, 0.798]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.413, 0.424, 0.43, 0.432, 0.459, 0.574, 0.518, 0.507]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = list(np.array(rmse) / np.array(std_list))\n",
    "\n",
    "rmse_std = []\n",
    "for i in tmp:\n",
    "    rmse_std.append(round(i, 3))\n",
    "rmse_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./model/DNN/model_4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_53\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_75 (InputLayer)        (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 16)                80        \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 257\n",
      "Trainable params: 257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Staking Ensemble\n",
    "# 모델 불러오기\n",
    "import tqdm\n",
    "def load_all_models(time_step):\n",
    "    all_models = []\n",
    "    model_list = ['DNN', 'LSTM', 'GRU', 'CNN']\n",
    "    for i in tqdm.tqdm(model_list):\n",
    "        filename = './model/{}/model_{}.h5'.format(i, time_step)\n",
    "        model = load_model(filename)\n",
    "        all_models.append(model)\n",
    "        print('>loaded {}'.format(filename))\n",
    "    print('\\n>complete loading')\n",
    "    return all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [01:57<05:53, 117.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded ./model/DNN/model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [03:58<03:57, 118.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded ./model/LSTM/model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [05:58<01:59, 119.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded ./model/GRU/model_3.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [07:58<00:00, 119.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">loaded ./model/CNN/model_3.h5\n",
      "\n",
      ">complete loading\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_model = load_all_models(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x7f9702d11b50>,\n",
       " <keras.engine.training.Model at 0x7f9702f38f50>,\n",
       " <keras.engine.training.Model at 0x7f9701997ed0>,\n",
       " <keras.engine.training.Model at 0x7f9702260250>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_stacked_model(members, train, val):\n",
    "    num = 1\n",
    "    for i in range(len(members)):\n",
    "        model = members[i]\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "            layer.name = 'ensemble_' + str(num) + '_'\n",
    "            num += 1\n",
    "    \n",
    "    ensemble_inputs = [model.input for model in members]\n",
    "    ensemble_outputs = [model.output for model in members]\n",
    "\n",
    "    merge = layers.concatenate(ensemble_outputs)\n",
    "    hidden = layers.Dense(10, activation = 'relu')(merge)\n",
    "    hidden = layers.Dense(4, activation = 'relu')(hidden)\n",
    "    output_tensor = layers.Dense(1)(hidden)\n",
    "    \n",
    "    model = Model(ensemble_inputs, output_tensor)\n",
    "\n",
    "    # compile\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    \n",
    "    print('훈련 가능한 층(가중치, 편향) :',len(model.trainable_weights))\n",
    "    \n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=20)\n",
    "    mc = ModelCheckpoint('./model/ensembel.h5', monitor='val_loss', save_best_only=True)\n",
    "    \n",
    "    train_X, train_Y = train\n",
    "    val_X, val_Y = val \n",
    "    \n",
    "    model.fit([train_X, train_X, train_X, train_X], train_Y, \n",
    "              epochs=10000, \n",
    "              verbose=1,\n",
    "              validation_data=([val_X, val_X, val_X, val_X], val_Y),\n",
    "              batch_size=8,\n",
    "              shuffle=False,\n",
    "              callbacks=[early_stopping, mc])\n",
    "    \n",
    "    model = load_model('./model/ensembel.h5')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time step & lag\n",
    "data_X, data_Y = time_step(data , 3, 1, 1)\n",
    "\n",
    "# 데이터 분할\n",
    "NUM_TRAIN = int(data_X.shape[0] * 0.6)\n",
    "NUM_VAL = int(data_X.shape[0] * 0.8)\n",
    "\n",
    "train_X = data_X[:NUM_TRAIN]\n",
    "train_Y = data_Y[:NUM_TRAIN]\n",
    "\n",
    "val_X = data_X[NUM_TRAIN:NUM_VAL]\n",
    "val_Y = data_Y[NUM_TRAIN:NUM_VAL]\n",
    "\n",
    "test_X = data_X[NUM_VAL:]\n",
    "test_Y =data_Y[NUM_VAL:]\n",
    "\n",
    "train_X, val_X, test_X = normalization(train_X, val_X, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = [train_X, train_Y]\n",
    "val = [val_X, val_Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 가능한 층(가중치, 편향) : 6\n"
     ]
    }
   ],
   "source": [
    "model = define_stacked_model(all_model, train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#예측시도\n",
    "model = load_model('./model/ensembel.h5')\n",
    "y_pred = model.predict([test_X, test_X, test_X, test_X])\n",
    "y_pred = y_pred.reshape(-1).astype('float32')\n",
    "y_real = test_Y.reshape(-1).astype('float32')\n",
    "\n",
    "raw= {'Observed': list(y_real), 'Predicted': list(y_pred)}\n",
    "rr = pd.DataFrame(raw)\n",
    "reg = sm.OLS.from_formula(\"Observed ~ Predicted\",rr).fit()\n",
    "\n",
    "rmse = round(math.sqrt(mean_squared_error(y_real, y_pred)), 3)\n",
    "r2 = round(reg.rsquared, 3)   \n",
    "\n",
    "plt.plot(y_real, label = 'Observed')\n",
    "plt.plot(y_pred, label = 'Predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107.819, 0.838)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.437"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(rmse/test_Y.std(), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 15)\n",
    "mc = ModelCheckpoint('./model/ensembel_full.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "model.fit([train_X, train_X, train_X, train_X], train_Y, \n",
    "          epochs=10000, \n",
    "          verbose=0,\n",
    "          validation_data=([val_X, val_X, val_X, val_X], val_Y),\n",
    "          batch_size=8,\n",
    "          shuffle=False,\n",
    "          callbacks=[early_stopping, mc])\n",
    "\n",
    "model = load_model('./model/ensembel_full.h5')\n",
    "y_pred = model.predict([test_X, test_X, test_X, test_X])\n",
    "y_pred = y_pred.reshape(-1).astype('float32')\n",
    "y_real = test_Y.reshape(-1).astype('float32')\n",
    "\n",
    "raw= {'Observed': list(y_real), 'Predicted': list(y_pred)}\n",
    "rr = pd.DataFrame(raw)\n",
    "reg = sm.OLS.from_formula(\"Observed ~ Predicted\",rr).fit()\n",
    "\n",
    "rmse = round(math.sqrt(mean_squared_error(y_real, y_pred)), 3)\n",
    "r2 = round(reg.rsquared, 3)   \n",
    "\n",
    "plt.plot(y_real, label = 'Observed')\n",
    "plt.plot(y_pred, label = 'Predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107.716, 0.838)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.436"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(rmse/test_Y.std(), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
